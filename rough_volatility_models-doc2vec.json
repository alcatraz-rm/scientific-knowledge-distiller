[
    {
        "authors": [
            "B. Stemper"
        ],
        "title": "Rough volatility models",
        "publication_date": "None",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.14279/DEPOSITONCE-8422",
        "urls": [
            "https://www.semanticscholar.org/paper/e93f0dae9a502077bc359e9408fe418eb1172b3d"
        ],
        "id": "id8140755685045339080",
        "abstract": null,
        "versions": [],
        "rank": 0
    },
    {
        "authors": [
            "Ognjen Radovi\u0107",
            "Ma\u0161a Georgiev",
            "Milica \u0110or\u0111evi\u0107"
        ],
        "title": "Total cost of ownership of infrastructure as a service for SME",
        "publication_date": "2021-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Centre for Evaluation in Education and Science (CEON/CEES)",
        "volume": "",
        "doi": "10.5937/ekonomika2104037r",
        "urls": [
            "https://web.archive.org/web/20220113184743/https://scindeks-clanci.ceon.rs/data/pdf/0350-137X/2021/0350-137X2104037R.pdf"
        ],
        "id": "id1690652847371989726",
        "abstract": "Cloud Computing offers significant cost benefits for SMEs that often do not manage internal IT infrastructure and start-up companies that do not have their own IT infrastructure. This paper presents a total cost of ownership (TCO) approach for cloud computing services with an emphasis on the infrastructure as a service (IaaS) model. Also, the paper presents a methodology for estimating total cost of ownership (TCO) when running computer instances in the IaaS cloud using the GARCH model to predict transaction volatility. The research results show that it is possible to successfully use GARCH models when there is historical data on the number of transactions. In addition, simulation shows that, when there are large oscillations in the number of transactions, the best choice is to reserve instances according to the Partial-Upfront price model. In contrast, if the transaction number is relatively stable, the best choice is the All-Upfront model.",
        "versions": [],
        "rank": 1
    },
    {
        "authors": [
            "N. A. Zawali",
            "L. Muhamad Safiih",
            "D.A.D Anthea"
        ],
        "title": "Bootstrap percentile in GARCH models: Study case on volatility of Kuala Lumpur Shariah Index (KLSI)",
        "publication_date": "2011-12-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/CHUSER.2011.6163873",
        "urls": [
            "https://www.semanticscholar.org/paper/aa150a4e0e88731b56446a8b44fe6a0b2f6a0b75"
        ],
        "id": "id-4268210861460096563",
        "abstract": "High demand on the Islamic concept in stock market by investors and institutions has led to the establishment of the Kuala Lumpur Shariah Index (KLSI). To view the sustainability and effectiveness of those concepts, a further study specifically on the volatility of KLSI should be considered. In this study, the Generalized Autoregressive Conditional Heteroscedasticity, GARCH (1,1) model and the proposed model which is GARCH (1,1) hybrid with bootstrap percentiles was used to analyze the volatility of KLSI considered. For that proposed, two stages processed were performed. The first stage using GARCH (1,1) model. Bootstrap method with two replications had been considered in the second stages which were 100 replications and 500 replications. Daily KLSI returns data for the year 2009 was implemented and divided into three period of time horizon which is 1 month, 3 month and 6 month. The effectiveness of the proposed model is investigated by comparing the existing and the proposed models through the confidence intervals. The results showed that the proposed method is significantly better for estimating the conditional variance due to shortest intervals. Therefore, the proposed model is suitable in order to estimate the volatility of KLSI data. Hence, it gives confidence to the investors as well as an institution to invest in Islamic financial.",
        "versions": [
            {
                "year": 2011,
                "source": "SupportedSources.CROSSREF",
                "title": "Bootstrap percentile in GARCH models: Study case on volatility of Kuala Lumpur Shariah Index (KLSI)",
                "journal": "",
                "urls": [
                    "http://xplorestaging.ieee.org/ielx5/6156581/6163686/06163873.pdf?arnumber=6163873",
                    "http://dx.doi.org/10.1109/chuser.2011.6163873"
                ],
                "doi": "10.1109/chuser.2011.6163873",
                "publication_date": "2011-01-01 00:00:00"
            }
        ],
        "rank": 2
    },
    {
        "authors": [
            "R. Cumby",
            "Stephen Figlewski",
            "Joel Hasbrouck"
        ],
        "title": "Forecasting Volatilities and Correlations with EGARCH Models",
        "publication_date": "1993-11-30 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.3905/jod.1993.407877",
        "urls": [
            "https://www.semanticscholar.org/paper/29945c6d7c7cc88ba6533d4efb6350beb92cb3fb"
        ],
        "id": "id-953597041440872229",
        "abstract": "Volatility varies randomly over time, making forecasting it d@cult. Formal models for systems with timevarying volatility have been developed in recent years, and widely applied in economics and finance. Models in the Autoregressive Conditional Heteroscedasticity (ARCH) family have been particularly popular. Prior studies of ARCH-type models of securities return variances have looked at a single asset and focused on in-sample explanation of volatility movements, rather than forecasting. This article considers time variation for both volatilities and correlations among returns on broad asset classes in the US. and Japan, specijcally, equities, long-term government bonds, a n d the do l l a r lyen exchange rate. We are most concerned with out-$--sample forecasting performance. We fi t Exponen t i a l Genera l ized ARCH (EGARCH) models for the returns variances of weekly data from 1977 to 1990. In-sample parameter estimates are statistically signijcant and of the expected signs and magnitudes. In both regressions and directional tests of outof-sample forecasting ability, the EGARCH models seem to contain more information than historical volatility. But overall explanatory power is not great. Forecasting correlations is less successful. Only six of  ten pairwise correlations show any significant ARCH efects. Although the model forecasts were less biased than the historical correlation, explanatory power in all cases is very low.",
        "versions": [],
        "rank": 3
    },
    {
        "authors": [
            "T. G. M\u00fcller",
            "J. \u010eurech",
            "S. Hasegawa",
            "M. Abe",
            "K. Kawakami",
            "T. Kasuga",
            "D. Kinoshita",
            "D. Kuroda",
            "S. Urakawa",
            "S. Okumura",
            "Y. Sarugaku",
            "S. Miyasaka",
            "Y. Takagi",
            "P. R. Weissman",
            "Y.-J. Choi",
            "S. Larson",
            "K. Yanagisawa",
            "S. Nagayama"
        ],
        "title": "Thermo-physical properties of 162173 (1999 JU3), a potential flyby and rendezvous target for interplanetary missions",
        "publication_date": "2010-12-09 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "EDP Sciences",
        "volume": "",
        "doi": "10.1051/0004-6361/201015599",
        "urls": [
            "https://web.archive.org/web/20170815045257/https://www.aanda.org/articles/aa/pdf/2011/01/aa15599-10.pdf"
        ],
        "id": "id-287948176733999858",
        "abstract": "Near-Earth asteroid 162173 (1999 JU3) is a potential flyby and rendezvous target for interplanetary missions because of its easy to reach orbit. The physical and thermal properties of the asteroid are relevant for establishing the scientific mission goals and also important in the context of near-Earth object studies in general. Our goal was to derive key physical parameters such as shape, spin-vector, size, geometric albedo, and surface properties of 162173 (1999 JU3). With three sets of published thermal observations (ground-based N-band, Akari IRC, Spitzer IRS), we applied a thermophysical model to derive the radiometric properties of the asteroid. The calculations were performed for the full range of possible shape and spin-vector solutions derived from the available sample of visual lightcurve observations. The near-Earth asteroid 162173 (1999 JU3) has an effective diameter of 0.87 +/- 0.03 km and a geometric albedo of 0.070 +/- 0.006. The chi2-test reveals a strong preference for a retrograde sense of rotation with a spin-axis orientation of lambda_ecl = 73 deg, beta_ecl = -62 deg and P_sid = 7.63 +/- 0.01 h. The most likely thermal inertia ranges between 200 and 600 Jm-2s-0.5K-1, about a factor of 2 lower than the value for 25143 Itokawa. This indicates that the surface lies somewhere between a thick-dust regolith and a rock/boulder/cm-sized, gravel-dominated surface like that of 25143 Itokawa. Our analysis represents the first time that shape and spin-vector information has been derived from a combined data set of visual lightcurves (reflected light) and mid-infrared photometry and spectroscopy (thermal emission).",
        "versions": [],
        "rank": 4
    },
    {
        "authors": [
            "St\u00e9phane Colin",
            "Lucien Baldas"
        ],
        "title": "Editorial for the Special Issue on Gas Flows in Microsystems",
        "publication_date": "2019-07-25 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "MDPI AG",
        "volume": "",
        "doi": "10.3390/mi10080494",
        "urls": [
            "https://web.archive.org/web/20200311052822/https://hal.archives-ouvertes.fr/hal-02194703/file/micromachines-10-00494.pdf"
        ],
        "id": "id-4638114377592086965",
        "abstract": "The last two decades have witnessed a rapid development of microelectromechanical systems (MEMS) involving gas microflows in various technical fields [...]",
        "versions": [],
        "rank": 5
    },
    {
        "authors": [
            "Eduardo Abi Jaber"
        ],
        "title": "Stochastic Invariance and Stochastic Volterra Equations",
        "publication_date": "2018-10-18 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://www.semanticscholar.org/paper/962a31fac9901549415a2a660dc80fe3b75ddcd3"
        ],
        "id": "id-8095290200975563696",
        "abstract": "The present thesis deals with the theory of finite dimensional stochastic equations.In the first part, we derive necessary and sufficient geometric conditions on the coefficients of a stochastic differential equation for the existence of a constrained solution, under weak regularity on the coefficients. In the second part, we tackle existence and uniqueness problems of stochastic Volterra equations of convolution type. These equations are in general non-Markovian. We establish their correspondence with infinite dimensional equations which allows us to approximate them by finite dimensional stochastic differential equations of Markovian type. Finally, we illustrate our findings with an application to mathematical finance, namely rough volatility modeling. We design a stochastic volatility model with an appealing trade-off between flexibility and tractability.",
        "versions": [],
        "rank": 6
    },
    {
        "authors": [
            "Ben R Craig",
            "Valeriya Dinger"
        ],
        "title": "A microeconometric investigation into bank interest rate rigidity",
        "publication_date": "None",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "https://core.ac.uk/download/pdf/6247771.pdf"
        ],
        "id": "id-3050823780517551876",
        "abstract": "Using a unique dataset of interest rates offered by a large sample of U.S. banks on various retail deposit and loan products, we explore the rigidity of bank retail interest rates. We study periods over which retail interest rates remain fixed (\"spells\") and document a large degree of lumpiness of retail interest rate adjustments as well as substantial variation in the duration of these spells, both across and within different products. To explore the sources of this variation we apply duration analysis and calculate the probability that a bank will change a given deposit or loan rate under various conditions. Consistent with a nonconvex adjustment costs theory, we find that the probability of a bank changing its retail rate is initially increasing with time. Then as heterogeneity of the sample overwhelms this effect, the hazard rate decreases with time. The duration of the spells is significantly affected by the accumulated change in money market interest rates since the last retail rate change, the size of the bank and its geographical scope.Interest rates ; Bank deposits",
        "versions": [],
        "rank": 7
    },
    {
        "authors": [
            "Alexander Ulanov",
            "Andrey Simanovsky"
        ],
        "title": "Term Validation for Vocabulary Construction and Key Term Extraction",
        "publication_date": "2011-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20220806145340/https://aclanthology.org/R11-1114.pdf"
        ],
        "id": "id5013206826234994956",
        "abstract": "We extract new terminology from a text by term validation in a dictionary. Our approach is based on estimating probabilities for previously unseen terms, i.e. not present in a dictionary. To do this we apply several probabilistic models previously not used for term recognition and propose a new one. We apply restriction of domain similarity on terms used for probability estimation and vary the parameters of the models. Performance of our approach is demonstrated using Wikipedia titles vocabulary.",
        "versions": [],
        "rank": 8
    },
    {
        "authors": [
            "Qinghua Hu",
            "Zongxia Xie",
            "Daren Yu"
        ],
        "title": "Hybrid attribute reduction based on a novel fuzzy-rough model and information granulation",
        "publication_date": "2007-12-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Pattern Recognit.",
        "volume": "40",
        "doi": "10.1016/j.patcog.2007.03.017",
        "urls": [
            "https://www.semanticscholar.org/paper/38ab3f137f438bcaa0674f13577fa8606b0899a7"
        ],
        "id": "id-1095076562438135432",
        "abstract": null,
        "versions": [],
        "rank": 9
    },
    {
        "authors": [
            "Yunxin Sang",
            "Yang Bao"
        ],
        "title": "Predicting Corporate Risk by Jointly Modeling Company Networks and Dialogues in Earnings Conference Calls",
        "publication_date": "2022-05-25 17:43:59+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2206.06174v3",
            "http://arxiv.org/abs/2206.06174v3",
            "http://arxiv.org/pdf/2206.06174v3"
        ],
        "id": "id6070329940159659555",
        "abstract": "Earnings conference calls are significant information events for volatility\nforecasting, which is essential for financial risk management and asset\npricing. Although some recent volatility forecasting models have utilized the\ntextual content of conference calls, the dialogue structures of conference\ncalls and company relationships are almost ignored in extant literature. To\nbridge this gap, we propose a new model called Temporal Virtual Graph Neural\nNetwork (TVGNN) for volatility forecasting by jointly modeling conference call\ndialogues and company networks. Our model differs from existing models in\nseveral important ways. First, we propose to exploit more dialogue structures\nby encoding position, utterance, speaker role, and Q\\&A segments. Second, we\npropose to encode the market states for volatility forecasting by extending the\nGated Recurrent Units (GRU). Third, we propose a new method for constructing\ntemporal company networks in which the messages can only flow from temporally\npreceding to successive nodes, and extend the Graph Attention Networks (GAT)\nfor modeling company relationships. We collect conference call transcripts of\nS\\&P500 companies from 2008 to 2019, and construct a dataset of conference call\ndialogues with additional information on dialogue structures and company\nnetworks. Empirical results on our dataset demonstrate the superiority of our\nmodel over competitive baselines for volatility forecasting. We also conduct\nsupplementary analyses to examine the effectiveness of our model's key\ncomponents and interpretability.",
        "versions": [],
        "rank": 10
    },
    {
        "authors": [
            "Ben Moews",
            "Gbenga Ibikunle"
        ],
        "title": "Predictive intraday correlations in stable and volatile market environments: Evidence from deep learning",
        "publication_date": "2020-02-24 17:19:54+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "10.1016/j.physa.2020.124392",
        "urls": [
            "http://arxiv.org/pdf/2002.10385v1",
            "http://dx.doi.org/10.1016/j.physa.2020.124392",
            "http://arxiv.org/abs/2002.10385v1",
            "http://arxiv.org/pdf/2002.10385v1"
        ],
        "id": "id5135253315398342543",
        "abstract": "Standard methods and theories in finance can be ill-equipped to capture\nhighly non-linear interactions in financial prediction problems based on\nlarge-scale datasets, with deep learning offering a way to gain insights into\ncorrelations in markets as complex systems. In this paper, we apply deep\nlearning to econometrically constructed gradients to learn and exploit lagged\ncorrelations among S&P 500 stocks to compare model behaviour in stable and\nvolatile market environments, and under the exclusion of target stock\ninformation for predictions. In order to measure the effect of time horizons,\nwe predict intraday and daily stock price movements in varying interval lengths\nand gauge the complexity of the problem at hand with a modification of our\nmodel architecture. Our findings show that accuracies, while remaining\nsignificant and demonstrating the exploitability of lagged correlations in\nstock markets, decrease with shorter prediction horizons. We discuss\nimplications for modern finance theory and our work's applicability as an\ninvestigative tool for portfolio managers. Lastly, we show that our model's\nperformance is consistent in volatile markets by exposing it to the environment\nof the recent financial crisis of 2007/2008.",
        "versions": [
            {
                "year": 2020,
                "source": "SupportedSources.INTERNET_ARCHIVE",
                "title": "Predictive intraday correlations in stable and volatile market environments: Evidence from deep learning",
                "journal": "",
                "urls": [
                    "https://web.archive.org/web/20200321060256/https://arxiv.org/pdf/2002.10385v1.pdf"
                ],
                "doi": "",
                "publication_date": "2020-02-24 00:00:00"
            }
        ],
        "rank": 11
    },
    {
        "authors": [
            "Hakala, Scott",
            "Kaplan, Richard",
            "Thorsen, Madge"
        ],
        "title": "Rediscovering the Economics of Loss Causation",
        "publication_date": "2005-12-27 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "https://core.ac.uk/download/76622339.pdf"
        ],
        "id": "id2132113668871571203",
        "abstract": "Abstract  This article explores the economic principles and theories underlying loss causation in the context of securities fraud litigation. It explains the difference between \u201cinvestment loss\u201d and recoverable \u201cinflationary loss\u201d and posits that the latter consists of the difference between inflation in stock prices caused by the fraud at the time of purchase and inflation in the price at the time of sale. It reviews scenarios in which inflationary loss due to fraud may occur and would be recognized as a matter of economic theory as well as a matter of law. It urges that Dura v. Broudo Pharmaceuticals, 125 S. Ct. 1627 (2005), did not change these fundamental premises, but that pleaders may need to be far more specific in pleading loss causation and in clarifying these principles, as a result of the Supreme Court\u2019s opinion in that case",
        "versions": [],
        "rank": 12
    },
    {
        "authors": [
            "Alessio Brown",
            "Christian Merkl",
            "Dennis Snower"
        ],
        "title": "AN INCENTIVE THEORY OF MATCHING",
        "publication_date": "2013-10-23 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Cambridge University Press (CUP)",
        "volume": "",
        "doi": "10.1017/s1365100513000527",
        "urls": [
            "https://web.archive.org/web/20170811191728/http://ftp.iza.org/dp4145.pdf"
        ],
        "id": "id-1519079001021173360",
        "abstract": "An Incentive Theory of Matching This paper presents a theory explaining the labor market matching process through microeconomic incentives. There are heterogeneous variations in the characteristics of workers and jobs, and firms face adjustment costs in responding to these variations. Matches and separations are described through firms' job offer and firing decisions and workers' job acceptance and quit decisions. This approach obviates the need for a matching function. On this theoretical basis, we argue that the matching function is vulnerable to the Lucas critique. Our calibrated model for the U.S. economy can account for important empirical regularities that the conventional matching model cannot. JEL Classification: E24, E32, J63, J64",
        "versions": [],
        "rank": 13
    },
    {
        "authors": [
            "A. Rothschild",
            "A. Sloan",
            "R. Tenne"
        ],
        "title": "Growth of WS2 Nanotubes Phases",
        "publication_date": "2000-05-13 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Journal of the American Chemical Society",
        "volume": "122",
        "doi": "10.1021/JA994118V",
        "urls": [
            "https://www.semanticscholar.org/paper/b067497ec3f485a5ececa5ca38dbf0169aba5940"
        ],
        "id": "id-559700671901417950",
        "abstract": "Recently, a method to produce bulk quantities of pure multiwall WS2 nanotubes, which could reach several microns in length, has been developed. A detailed study of the growth mechanism of these WS2 nanotubes has been undertaken, which is reported hereby. A series of experiments were conducted to define the key parameters, which determine the shape of the WS2 nanotubes. An alternative approach for the synthesis of WS2 nanotubes, starting from long WO3-x nanowhiskers, which can be extended for the synthesis of other nanotubes, is described as well.",
        "versions": [
            {
                "year": 2000,
                "source": "SupportedSources.OPENALEX",
                "title": "Growth of WS<sub>2</sub> Nanotubes Phases",
                "journal": "",
                "urls": [
                    "https://openalex.org/W3201430196",
                    "https://doi.org/10.1021/ja994118v"
                ],
                "doi": "10.1021/ja994118v",
                "publication_date": "2000-05-13 00:00:00"
            }
        ],
        "rank": 14
    },
    {
        "authors": [
            "Liyan Geng",
            "Junhai Ma"
        ],
        "title": "TSK Fuzzy Inference System Based GARCH Model for Forecasting Exchange Rate Volatility",
        "publication_date": "2008-10-18 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery",
        "volume": "3",
        "doi": "10.1109/FSKD.2008.228",
        "urls": [
            "https://www.semanticscholar.org/paper/577cda567cce5010ef162fc9081cc14989b4f47b"
        ],
        "id": "id-7662655585311913429",
        "abstract": "This paper applies TSK fuzzy inference system to the GARCH model for predicting the conditional volatility of foreign exchange rates returns. Out-of-sample forecast results of using TSK-based GARCH model are compared with that of an ANN-based and a SVM-based GARCH models, respectively. The empirical study shows that for the RMSE, MAE and Mincer-Zarnowitz regression test, the TSK-based GARCH model outperforms the ANN-based and SVM-based GARCH models. Therefore, TSK-based GARCH model is expected to be important in developing the novel strategies for volatility trading and advanced risk management.",
        "versions": [
            {
                "year": 2008,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "TSK Fuzzy Inference System Based GARCH Model for Forecasting Exchange Rate Volatility",
                "journal": "2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery",
                "urls": [
                    "https://www.semanticscholar.org/paper/577cda567cce5010ef162fc9081cc14989b4f47b"
                ],
                "doi": "10.1109/FSKD.2008.228",
                "publication_date": "2008-10-18 00:00:00"
            }
        ],
        "rank": 15
    },
    {
        "authors": [
            "Hwai-Chung Ho"
        ],
        "title": "Forecasting the distribution of long-horizon returns with time-varying volatility",
        "publication_date": "2022-01-19 07:48:40+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2201.07457v1",
            "http://arxiv.org/abs/2201.07457v1",
            "http://arxiv.org/pdf/2201.07457v1"
        ],
        "id": "id-5761124589957313148",
        "abstract": "The study of long-horizon returns has received a great deal of attention in\nrecent years (see, for example, Boudoukh, Richardson, and Whitelaw (2008),\nNeuberger (2012) and Lee (2013), Fama and French (2018)). While most of the\ndiscussions are concerned with some practical issues in investment, few have\ntouched the important aspect on risk management. The approach adopted in this\narticle is to predict the future distribution of the returns of a fixed\nlong-horizon by which the risk measures of interest that come in the form of a\ndistributional functional such as the value at risk (VaR) and the conditional\ntail expectation (CTE) can be easily derived. The characteristic feature of our\napproach which requires no specification of the volatility dynamics nor\nparametric assumptions of the shock distribution extends the work by Ho et al.\n(2016) and Ho ( 2017) to a more general volatility dynamics that includes both\nthe widely-used SV model and the GARCH model (Bollerslev, 1986) as special\ncases.",
        "versions": [],
        "rank": 16
    },
    {
        "authors": [
            "A. Medvedev",
            "O. Scaillet"
        ],
        "title": "Approximation and Calibration of Short-Term Implied Volatilities Under Jump-Diffusion Stochastic Volatility",
        "publication_date": "2006-01-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.2139/ssrn.910212",
        "urls": [
            "https://www.semanticscholar.org/paper/892e63084aa57d03dc279d2a66a23b78870c7af3",
            "https://archive-ouverte.unige.ch/unige:79885/ATTACHMENT01"
        ],
        "id": "id-8965109613644525823",
        "abstract": "We derive a closed-form asymptotic expansion formula for option implied volatility under a two-factor jump-diffusion stochastic volatility model when time-to-maturity is small. Based on numerical experiments we describe the range of time-to-maturity and moneyness for which the approximation is accurate. We further propose a simple calibration procedure of an arbitrary parametric model to short-term near-the-money implied volatilities. An important advantage of our approximation is that it is free of the unobserved spot volatility. Therefore, the model can be calibrated on option data pooled across different calendar dates in order to extract information from the dynamics of the implied volatility smile. An example of calibration to a sample of S&P500 option prices is provided. We find that jumps are significant. The evidence also supports an affine specification for the jump intensity and Constant-Elasticity-of-Variance for the dynamics of the return volatility.",
        "versions": [],
        "rank": 17
    },
    {
        "authors": [
            "Mingliang Zhang",
            "Kui\u2010Qing Peng",
            "Xia Fan",
            "J. Jie",
            "R. Zhang",
            "\u2021. A. S. Lee",
            "N. Wong"
        ],
        "title": "Preparation of Large-Area Uniform Silicon Nanowires Arrays through Metal-Assisted Chemical Etching",
        "publication_date": "2008-03-04 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Journal of Physical Chemistry C",
        "volume": "112",
        "doi": "10.1021/JP077053O",
        "urls": [
            "https://www.semanticscholar.org/paper/049215c3a719f79a63e920ef5980b557da0d9aa3"
        ],
        "id": "id-7424262615512624650",
        "abstract": "A facile fabricating method has been established for large-area uniform silicon nanowires arrays. All silicon nanowires obtained were single crystals and epitaxial on the substrate. Six kinds of silicon wafers with different types, surface orientations, and doping levels were utilized as starting materials. With the catalysis of silver nanoparticles, room-temperature mild chemical etching was conducted in aqueous solution of hydrofluoric acid (HF) and hydrogen peroxide (H2O2). The corresponding silicon nanowires arrays with different morphologies were obtained. The silicon nanowires possess the same type and same doping level of the starting wafer. All nanowires on the substrate have the same orientation. For instance, both (100)- and (111)-oriented p-type wafers produced silicon nanowires in the (100) direction. For every kind of silicon wafer, the effect of etching conditions, such as components of etchant, temperature, and time, were systemically investigated. This is an appropriate method to produce a...",
        "versions": [
            {
                "year": 2008,
                "source": "SupportedSources.OPENALEX",
                "title": "Preparation of Large-Area Uniform Silicon Nanowires Arrays through Metal-Assisted Chemical Etching",
                "journal": "",
                "urls": [
                    "https://openalex.org/W2017901301",
                    "https://doi.org/10.1021/jp077053o"
                ],
                "doi": "10.1021/jp077053o",
                "publication_date": "2008-03-04 00:00:00"
            }
        ],
        "rank": 18
    },
    {
        "authors": [
            "Assar, Said",
            "Kim, Kwansoo",
            "Lee, Sang-Yong Tom"
        ],
        "title": "Coin Market Behavior using  Social Sentiment Markov Chains",
        "publication_date": "2019-06-15 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "https://core.ac.uk/download/326833576.pdf"
        ],
        "id": "id6034441758845639826",
        "abstract": "2017 was the pivotal year for the cryptocurrency made its foray into the mainstream financial markets. However, in 2018 it was a panic itself. For the market, it is imperative to ruminate reasonable analysis and expectations compiling various situations. We examine the dynamic interactions between the coin market behavior and market events and social metrics to incorporate potential coin traders\u2019 social belief and response into the market moves. We use hidden Markov model performing four different experiments in two-coin markets. We show that market events such as closing price and trading volume are important predictors for the coin market behavior, but not equally in all experiments. Interestingly, hidden Markov process demonstrates that social media metrics fairly explain the future behavior of the coin markets. Overall, this study shows the combined impact of market events and social factors through varied sequences adjusted for each market situation on the coin market behavior",
        "versions": [],
        "rank": 19
    },
    {
        "authors": [
            "Lucien Boulet"
        ],
        "title": "Forecasting High-Dimensional Covariance Matrices of Asset Returns with Hybrid GARCH-LSTMs",
        "publication_date": "2021-08-25 23:41:43+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2109.01044v1",
            "http://arxiv.org/abs/2109.01044v1",
            "http://arxiv.org/pdf/2109.01044v1"
        ],
        "id": "id-7038374791374177296",
        "abstract": "Several academics have studied the ability of hybrid models mixing univariate\nGeneralized Autoregressive Conditional Heteroskedasticity (GARCH) models and\nneural networks to deliver better volatility predictions than purely\neconometric models. Despite presenting very promising results, the\ngeneralization of such models to the multivariate case has yet to be studied.\nMoreover, very few papers have examined the ability of neural networks to\npredict the covariance matrix of asset returns, and all use a rather small\nnumber of assets, thus not addressing what is known as the curse of\ndimensionality. The goal of this paper is to investigate the ability of hybrid\nmodels, mixing GARCH processes and neural networks, to forecast covariance\nmatrices of asset returns. To do so, we propose a new model, based on\nmultivariate GARCHs that decompose volatility and correlation predictions. The\nvolatilities are here forecast using hybrid neural networks while correlations\nfollow a traditional econometric process. After implementing the models in a\nminimum variance portfolio framework, our results are as follows. First, the\naddition of GARCH parameters as inputs is beneficial to the model proposed.\nSecond, the use of one-hot-encoding to help the neural network differentiate\nbetween each stock improves the performance. Third, the new model proposed is\nvery promising as it not only outperforms the equally weighted portfolio, but\nalso by a significant margin its econometric counterpart that uses univariate\nGARCHs to predict the volatilities.",
        "versions": [],
        "rank": 20
    },
    {
        "authors": [
            "S. B. Santra",
            "B. Sapoval"
        ],
        "title": "Multifractal Collision Spectrum of Ballistic Particles with Fractal Surfaces",
        "publication_date": "2005-12-06 04:27:59+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": "Fractals 13, 9 (2005)",
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/cond-mat/0512106v1",
            "http://arxiv.org/abs/cond-mat/0512106v1",
            "http://arxiv.org/pdf/cond-mat/0512106v1"
        ],
        "id": "id-3791650858860364093",
        "abstract": "Ballistic particles interacting with irregular surfaces are representative of\nmany physical problems in the Knudsen diffusion regime. In this paper, the\ncollisions of ballistic particles interacting with an irregular surface modeled\nby a quadratic Koch curve, are studied numerically. The $q$ moments of the\nsource spatial distribution of collision numbers $\\mu(x)$ are characterized by\na sequence of ``collision exponent'' $\\tau(q)$. The measure $\\mu(x)$ is found\nto be multifractal even when a random micro-roughness (or random re-emission)\nof the surface exists. The dimensions $f(\\alpha)$, obtained by a Legendre\ntransformation from $\\tau(q)$, consist of two parabolas corresponding to a\ntrinomial multifractal. This is demonstrated for a particular case by obtaining\nan exact $f(\\alpha)$ for a multiplicative trinomial mass distribution. The\ntrinomial nature of the multifractality is related to the type of surface\nmacro-irregularity considered here and is independent of the micro-roughness of\nthe surface which however influence the values of $\\alpha_{min}$ and\n$\\alpha_{max}$. The information dimension $D_I$ increases significantly with\nthe micro-roughness of the surface. Interestingly, in contrast with this point\nof view, the surface seems to work uniformly. This correspond to an absence of\nscreening effects in Knudsen diffusion.",
        "versions": [],
        "rank": 21
    },
    {
        "authors": [
            "Vlachos",
            "Schmidt",
            "Aris"
        ],
        "title": "Kinetics of faceting of crystals in growth, etching, and equilibrium.",
        "publication_date": "1993-03-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Physical review. B, Condensed matter",
        "volume": "47 9",
        "doi": "10.1103/PHYSREVB.47.4896",
        "urls": [
            "https://www.semanticscholar.org/paper/955010af8743fabd1e2f7bb33cb512ca2e9579bf"
        ],
        "id": "id6675725329388056309",
        "abstract": "The faceting of crystals in equilibrium with the gas phase and also during crystal growth and etching conditions is studied using the Monte Carlo method. The dynamics of the transformation of unstable crystallographic orientations into hill and valley structures and the spatial patterns that develop are examined as functions of surface temperature, crystallographic orientation, and strength of interatomic potential for two transport processes: adsorption-desorption and surface diffusion. The results are compared with the continuum theory for facet formation. Thermodynamically unstable orientations break into hill and valley structures, and faceting exhibits three time regimes: disordering, facet nucleation, and coarsening of small facets to large facets. Faceting is accelerated as temperature increases, but thermal roughening can occur at high temperatures. Surface diffusion is the dominant mechanism at short times and small facets but adsorption-desorption becomes important at long times and large facets. Growth and etching promote faceting for conditions close to equilibrium but induce kinetic roughening for conditions far from equilibrium. Simultaneous irreversible growth and etching conditions with fast surface diffusion result in enhanced faceting.",
        "versions": [
            {
                "year": 1993,
                "source": "SupportedSources.OPENALEX",
                "title": "Kinetics of faceting of crystals in growth, etching, and equilibrium",
                "journal": "",
                "urls": [
                    "https://openalex.org/W2086132688",
                    "https://doi.org/10.1103/physrevb.47.4896"
                ],
                "doi": "10.1103/physrevb.47.4896",
                "publication_date": "1993-03-01 00:00:00"
            }
        ],
        "rank": 22
    },
    {
        "authors": [
            "Samuele Sommariva",
            "Tiziano Maffei",
            "G. Migliavacca",
            "Tiziano Faravelli",
            "Eliseo Ranzi"
        ],
        "title": "A predictive multi-step kinetic model of coal devolatilization",
        "publication_date": "2010-02-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "",
        "volume": "89",
        "doi": "10.1016/j.fuel.2009.07.023",
        "urls": [
            "https://openalex.org/W2040493256",
            "https://doi.org/10.1016/j.fuel.2009.07.023"
        ],
        "id": "id5489336455466658789",
        "abstract": "",
        "versions": [
            {
                "year": 2010,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "A predictive multi-step kinetic model of coal devolatilization",
                "journal": "Fuel",
                "urls": [
                    "https://www.semanticscholar.org/paper/cdfa3e7233bb1af0f0f56eae528f60b0411d22e5"
                ],
                "doi": "10.1016/J.FUEL.2009.07.023",
                "publication_date": "2010-02-01 00:00:00"
            }
        ],
        "rank": 23
    },
    {
        "authors": [
            "Lin, E.",
            "Chen, C.",
            "Gerlach, R."
        ],
        "title": "Forecasting volatility with asymmetric smooth transition dynamic range models",
        "publication_date": "2012-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1016/j.ijforecast.2011.09.002",
        "urls": [
            "https://api.elsevier.com/content/article/PII:S0169207011001373?httpAccept=text/xml",
            "https://api.elsevier.com/content/article/PII:S0169207011001373?httpAccept=text/plain",
            "http://dx.doi.org/10.1016/j.ijforecast.2011.09.002"
        ],
        "id": "id993030290128488319",
        "abstract": "",
        "versions": [
            {
                "year": 2012,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Forecasting volatility with asymmetric smooth transition dynamic range models",
                "journal": "International Journal of Forecasting",
                "urls": [
                    "https://www.semanticscholar.org/paper/c7dd8dec162a47b955bc5bfb4403f5d841dc8b73"
                ],
                "doi": "10.1016/J.IJFORECAST.2011.09.002",
                "publication_date": "2012-05-10 00:00:00"
            }
        ],
        "rank": 24
    },
    {
        "authors": [
            "Balazs Feil",
            "S. Kucherenko",
            "N. Shah"
        ],
        "title": "Volatility calibration using spline and high dimensional model representation models",
        "publication_date": "2009-08-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Wilmott Journal",
        "volume": "1",
        "doi": "10.1002/WILJ.18",
        "urls": [
            "https://www.semanticscholar.org/paper/2dbd1605679c46cc05806ed09653f31849aa713c"
        ],
        "id": "id-1530518533619466392",
        "abstract": "The local volatility function is approximated using two different models: a bicubic spline and High Dimensional Model Representation (HDMR) model. For a bicubic spline the local volatility values \u03c3i at a chosen discrete set of knots are determined by minimizing the least square error between market and model option prices. Model option prices are found using the one-factor diffusion process for the underlying asset. For the HDMR model, the parameters to be optimized are the parameters of the HDMR model. Smoothness of the approximation functions is crucial to overcome the ill-posedness of the volatility calibration problem. Two models are compared using two test cases. It is shown that the HDMR model can produce more accurate results than the cubic spline model, and it is also cheaper to run. It is demonstrated that the considered approach can accurately reproduce not only option prices but Greeks as well. Copyright \u00a9 2009 Wilmott Magazine Ltd",
        "versions": [
            {
                "year": 2009,
                "source": "SupportedSources.CROSSREF",
                "title": "Volatility calibration using spline and high dimensional model representation models",
                "journal": "",
                "urls": [
                    "https://api.wiley.com/onlinelibrary/tdm/v1/articles/10.1002%2Fwilj.18",
                    "http://onlinelibrary.wiley.com/wol1/doi/10.1002/wilj.18/fullpdf",
                    "http://dx.doi.org/10.1002/wilj.18"
                ],
                "doi": "10.1002/wilj.18",
                "publication_date": "2009-01-01 00:00:00"
            }
        ],
        "rank": 25
    },
    {
        "authors": [
            "V. Alfi",
            "F. Coccetti",
            "M. Marotta",
            "L. Pietronero",
            "M. Takayasu"
        ],
        "title": "Hidden forces and fluctuations from moving averages: A test study",
        "publication_date": "2006-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Elsevier BV",
        "volume": "",
        "doi": "10.1016/j.physa.2006.04.113",
        "urls": [
            "https://web.archive.org/web/20180725202544/http://cds.cern.ch/record/921617/files/0601089.pdf"
        ],
        "id": "id3011012400280726807",
        "abstract": "The possibility that price dynamics is affected by its distance from a moving average has been recently introduced as new statistical tool. The purpose is to identify the tendency of the price dynamics to be attractive or repulsive with respect to its own moving average. We consider a number of tests for various models which clarify the advantages and limitations of this new approach. The analysis leads to the identification of an effective potential with respect to the moving average. Its specific implementation requires a detailed consideration of various effects which can alter the statistical methods used. However, the study of various model systems shows that this approach is indeed suitable to detect hidden forces in the market which go beyond usual correlations and volatility clustering.",
        "versions": [],
        "rank": 26
    },
    {
        "authors": [
            "Yinli Shen",
            "Xiaoxing Huang",
            "Yue Zhang",
            "Jing Pan",
            "Yaxin Liu",
            "Yunlan Jiang",
            "Lianhui Li"
        ],
        "title": "Application of Three-Dimensional Image Reconstruction Technology in Neurogenic Intestinal Nursing Tasks",
        "publication_date": "2022-10-11 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Hindawi Limited",
        "volume": "",
        "doi": "10.1155/2022/4840189",
        "urls": [
            "https://web.archive.org/web/20221013125636/https://downloads.hindawi.com/journals/sp/2022/4840189.pdf"
        ],
        "id": "id-3649584441232688552",
        "abstract": "Neurogenic intestinal care is currently a major research topic in the medical field. In order to improve the accuracy of neurogenic intestinal care and simplify the process of neurogenic intestinal care, this paper adopts a three-dimensional analysis theory to extract the key indicators in neurogenic intestinal care. Through the analysis and calculation of the test data, the calculation results of neurogenic intestinal care under the effect of three-dimensional reconstruction technology were obtained. Through the analysis of the results, the calculation law under the action of the optimization model can be obtained. Based on the three-dimensional reconstruction theory, the contents of neurogenic intestinal care were analyzed by the three-dimensional reconstruction de-highlighting algorithm. The three-dimensional curve was used to screen the key indicators of neurogenic intestinal care, so as to obtain the optimized heavy weight model, and the three-dimensional reconstruction model can analyze the indicators of neurogenic intestinal care. It can be seen from relevant studies that different indicators have different trends in their range of change in the curve projection diagram of the 3D curve screening method. Among them, the curve shadow and curve point have obvious downward changes, while the curve deviation has U-shaped changes. The range of curve weights is relatively large. The variation rule between different data in the 3D curve segment can be obtained through the cost function. Among them, the cost function index and the cost model parameter have the same change trend, and the overall fluctuation range is relatively small through the space index. In the calculation results of neurogenic intestinal care, different factors will have a great influence on the calculation results. Neurons and intestinal peristalsis have the same change trend, while the linear characteristics of nerve endings are relatively obvious, and the fluctuation characteristics of gastrointestinal digestion are good. The health standard decreases linearly with the increase of the sample, and the dynamic reconstruction has a positive effect on the data. This study can provide research ideas for the analysis of neurogenic gut.",
        "versions": [],
        "rank": 27
    },
    {
        "authors": [
            "Boussard, Jean-Marc"
        ],
        "title": "Consequences of price volatility in evaluating the benefits of liberalisation",
        "publication_date": "None",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "https://core.ac.uk/download/pdf/7302720.pdf"
        ],
        "id": "id1550981314957275316",
        "abstract": "Many computable general equilibrium models have been set up recently, in order to assess the benefits of trade liberalisation, especially in agriculture. Although figures magnitudes differ from one model to another, they cannot reach any other conclusion than positive benefits. On the other hand, historical experience shows that liberalisation, far from being a new idea, has been tried at several occasions during the two last centuries, repeatedly ending in crisis, and hasty return to various forms of protection. A possible explanation could be in the comparative static approach of most liberalisation proponents, and their neglect of dynamic aspects. Especially, because risk is necessarily tied with unfulfilled expectations, it should play a decisive role in modelling. A new model is developed along this line, showing the possibility of a chaotic price regime, which would prevent full liberalisation to be feasible.globalisation; risk ; volatility ; modelling ; trade ; agriculture ; Doha ; WTO;",
        "versions": [],
        "rank": 28
    },
    {
        "authors": [
            "B. N. Murphy",
            "N. M. Donahue",
            "C. Fountoukis",
            "M. Dall'Osto",
            "C. O'Dowd",
            "A. Kiendler-Scharr",
            "S. N. Pandis"
        ],
        "title": "Functionalization and fragmentation during ambient organic aerosol aging: application of the 2-D volatility basis set to field studies",
        "publication_date": "2012-04-18 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Copernicus GmbH",
        "volume": "",
        "doi": "10.5194/acpd-12-9857-2012",
        "urls": [
            "https://web.archive.org/web/20171127125707/https://core.ac.uk/download/pdf/34903069.pdf"
        ],
        "id": "id-4426107640725563785",
        "abstract": "Multigenerational oxidation chemistry of atmospheric organic compounds and its effects on aerosol loadings and chemical composition is investigated by implementing the Two-Dimensional Volatility Basis Set (2-D-VBS) in a Lagrangian host chemical transport model. Three model formulations were chosen to explore the complex interactions 5 25 cessing have small effects on OA levels but heterogeneous oxidation, as implemented here, does enhance O:C by about 0.1. The different schemes result in very different fractional attribution for OA between anthropogenic and biogenic sources. 9859 ACPD 12, 9857-9901, 2012",
        "versions": [],
        "rank": 29
    },
    {
        "authors": [
            "Gianluca Cassese",
            "Massimo Guidolin"
        ],
        "title": "Modelling the implied volatility surface: Does market efficiency matter?",
        "publication_date": "2006-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Elsevier BV",
        "volume": "",
        "doi": "10.1016/j.irfa.2005.10.003",
        "urls": [
            "https://web.archive.org/web/20141231220534/http://research.stlouisfed.org/wp/2005/2005-008.pdf"
        ],
        "id": "id-2340911380085173824",
        "abstract": "We analyze the volatility surface vs. moneyness and time to expiration implied by MIBO options written on the MIB30, the most important Italian stock index. We specify and \u00det a number of models of the implied volatility surface and \u00dend that it has a rich and interesting structure that strongly departs from a constant volatility, Black-Scholes benchmark. This result is robust to alternative econometric approaches, including generalized least squares approaches that take into account both the panel structure of the data and the likely presence of heteroskedasticity and serial correlation in the random disturbances. Finally we show that the degree of pricing efficiency of this options market can strongly condition the results of the econometric analysis and therefore our understanding of the pricing mechanism underlying observed MIBO option prices. Applications to value-at-risk and portfolio choice calculations illustrate the importance of using arbitrage-free data only. JEL code: G12, G13.",
        "versions": [],
        "rank": 30
    },
    {
        "authors": [
            "Martin McDermott",
            "Sharmista Chatterjee",
            "Xiaoli Hu",
            "Ariel Ash-Shakoor",
            "Reginald Avery",
            "Anastasiya Belyaeva",
            "Celia Cruz",
            "Minerva Hughes",
            "Joanne Leadbetter",
            "Conrad Merkle",
            "Taylor Moot",
            "Sepideh Parvinian",
            "Dinesh Patwardhan",
            "David Saylor",
            "Nancy Tang",
            "Tina Zhang"
        ],
        "title": "Application of Quality by Design (QbD) Approach to Ultrasonic Atomization Spray Coating of Drug-Eluting Stents",
        "publication_date": "2015-01-07 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "American Association of Pharmaceutical Scientists (AAPS)",
        "volume": "",
        "doi": "10.1208/s12249-014-0266-9",
        "urls": [
            "https://web.archive.org/web/20200208031949/http://europepmc.org/backend/ptpmcrender.fcgi?accid=PMC4508304&blobtype=pdf"
        ],
        "id": "id4148439195205755202",
        "abstract": "The drug coating process for coated drug-eluting stents (DES) has been identified as a key source of inter-and intra-batch variability in drug elution rates. Quality-by-design (QbD) principles were applied to gain an understanding of the ultrasonic spray coating process of DES. Statistically based design of experiments (DOE) were used to understand the relationship between ultrasonic atomization spray coating parameters and dependent variables such as coating mass ratio, roughness, drug solid state composite microstructure, and elution kinetics. Defect-free DES coatings composed of 70% 85:15 poly(DL-lactide-co-glycolide) and 30% everolimus were fabricated with a constant coating mass. The drug elution profile was characterized by a mathematical model describing biphasic release kinetics. Model coefficients were analyzed as a DOE response. Changes in ultrasonic coating processing conditions resulted in substantial changes in roughness and elution kinetics. Based on the outcome from the DOE study, a design space was defined in terms of the critical coating process parameters resulting in optimum coating roughness and drug elution. This QbD methodology can be useful to enhance the quality of coated DES.",
        "versions": [
            {
                "year": 2015,
                "source": "SupportedSources.INTERNET_ARCHIVE",
                "title": "Application of Quality by Design (QbD) Approach to Ultrasonic Atomization Spray Coating of Drug-Eluting Stents",
                "journal": "American Association of Pharmaceutical Scientists (AAPS)",
                "urls": [
                    "https://web.archive.org/web/20200208031949/http://europepmc.org/backend/ptpmcrender.fcgi?accid=PMC4508304&blobtype=pdf"
                ],
                "doi": "10.1208/s12249-014-0266-9",
                "publication_date": "2015-01-07 00:00:00"
            },
            {
                "year": 2015,
                "source": "SupportedSources.INTERNET_ARCHIVE",
                "title": "Application of Quality by Design (QbD) Approach to Ultrasonic Atomization Spray Coating of Drug-Eluting Stents",
                "journal": "American Association of Pharmaceutical Scientists (AAPS)",
                "urls": [
                    "https://web.archive.org/web/20200208031949/http://europepmc.org/backend/ptpmcrender.fcgi?accid=PMC4508304&blobtype=pdf"
                ],
                "doi": "10.1208/s12249-014-0266-9",
                "publication_date": "2015-01-07 00:00:00"
            },
            {
                "year": 2015,
                "source": "SupportedSources.INTERNET_ARCHIVE",
                "title": "Application of Quality by Design (QbD) Approach to Ultrasonic Atomization Spray Coating of Drug-Eluting Stents",
                "journal": "American Association of Pharmaceutical Scientists (AAPS)",
                "urls": [
                    "https://web.archive.org/web/20200208031949/http://europepmc.org/backend/ptpmcrender.fcgi?accid=PMC4508304&blobtype=pdf"
                ],
                "doi": "10.1208/s12249-014-0266-9",
                "publication_date": "2015-01-07 00:00:00"
            },
            {
                "year": 2015,
                "source": "SupportedSources.INTERNET_ARCHIVE",
                "title": "Application of Quality by Design (QbD) Approach to Ultrasonic Atomization Spray Coating of Drug-Eluting Stents",
                "journal": "American Association of Pharmaceutical Scientists (AAPS)",
                "urls": [
                    "https://web.archive.org/web/20200208031949/http://europepmc.org/backend/ptpmcrender.fcgi?accid=PMC4508304&blobtype=pdf"
                ],
                "doi": "10.1208/s12249-014-0266-9",
                "publication_date": "2015-01-07 00:00:00"
            }
        ],
        "rank": 31
    },
    {
        "authors": [
            "Zhi-Lian Guo",
            "Yan-Ling Liu",
            "Hai-Long Yang"
        ],
        "title": "A Novel Rough Set Model in Generalized Single Valued Neutrosophic Approximation Spaces and Its Application",
        "publication_date": "2017-07-17 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Symmetry",
        "volume": "9",
        "doi": "10.3390/sym9070119",
        "urls": [
            "https://www.semanticscholar.org/paper/fe6bd6f05f83d086300bfe1d0b6d53ca0c1dfea7",
            "https://www.mdpi.com/2073-8994/9/7/119/pdf"
        ],
        "id": "id-5636178858347064635",
        "abstract": "In this paper, we extend the rough set model on two different universes in intuitionistic fuzzy approximation spaces to a single-valued neutrosophic environment. Firstly, based on the ( \u03b1 , \u03b2 , \u03b3 ) -cut relation R \u02dc { ( \u03b1 , \u03b2 , \u03b3 ) } , we propose a rough set model in generalized single-valued neutrosophic approximation spaces. Then, some properties of the new rough set model are discussed. Furthermore, we obtain two extended models of the new rough set model\u2014the degree rough set model and the variable precision rough set model\u2014and study some of their properties. Finally, we explore an example to illustrate the validity of the new rough set model.",
        "versions": [],
        "rank": 32
    },
    {
        "authors": [
            "J. Conlon",
            "Michael G. Sullivan"
        ],
        "title": "Convergence to Black-Scholes for ergodic volatility models",
        "publication_date": "2005-06-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "European Journal of Applied Mathematics",
        "volume": "16",
        "doi": "10.1017/S0956792505006285",
        "urls": [
            "https://www.semanticscholar.org/paper/41d3c8e99a9574c184b976a196b47ab5401cabbd"
        ],
        "id": "id819078656933769601",
        "abstract": "We study the effect of stochastic volatility on option prices. In the fast mean-reversion model for stochastic volatility of [5], we show that there is a full asymptotic expansion for the option price, centered at the Black-Scholes price. We show how to callibrate the first two terms in the expansion with the implied volatility surface. We show, however, that this price does not converge in a strong sense to Black-Scholes as the mean-reversion rate increases.",
        "versions": [
            {
                "year": 2005,
                "source": "SupportedSources.CROSSREF",
                "title": "Convergence to Black-Scholes for ergodic volatility models",
                "journal": "",
                "urls": [
                    "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/S0956792505006285",
                    "http://dx.doi.org/10.1017/s0956792505006285"
                ],
                "doi": "10.1017/s0956792505006285",
                "publication_date": "2005-09-07 00:00:00"
            }
        ],
        "rank": 33
    },
    {
        "authors": [
            "A. Abdou"
        ],
        "title": "Accounting for Volatility Decay in Time Series Models for Leveraged Exchange Traded Funds",
        "publication_date": "2017-06-15 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.2139/ssrn.2980208",
        "urls": [
            "https://www.semanticscholar.org/paper/8faf96dbdc3a15e86da154aa8e79f9f388563a80"
        ],
        "id": "id1546149778950342489",
        "abstract": "Leverage Exchange Traded Funds (LETF's) returns tend to deviate from their underlying assets' multiple returns as their holding period increase, a phenomenon known as volatility decay. Algebraically, it is shown that volatility decay is intensified for inverse leveraged funds and as the leverage multiplier increases. The paper uses a novel approach to account for volatility decay. The ARIMA model ability to forecast future returns is tested for three major indexes and is shown to provide more accurate estimates for S&P500. The returns of S&P500 and its corresponding LETFs are fitted to an Autoregressive Integrated Moving Average (ARIMA) model. Theoretically, the constant of the ARIMA model and the variance of their Gaussian errors captures the volatility decay effect. Generalized Autoregressive Conditional Heteroskedasticity (GARCH) models provide more flexibility in modeling conditional variance that is non-stationary. The theoretical results are verified empirically, and the constant of the fitted model captures the intensity of the decay and its direction.",
        "versions": [
            {
                "year": 2017,
                "source": "SupportedSources.CROSSREF",
                "title": "Accounting for Volatility Decay in Time Series Models for Leveraged Exchange Traded Funds",
                "journal": "",
                "urls": [
                    "http://dx.doi.org/10.2139/ssrn.2980208"
                ],
                "doi": "10.2139/ssrn.2980208",
                "publication_date": "2017-01-01 00:00:00"
            }
        ],
        "rank": 34
    },
    {
        "authors": [
            "Frank Heid"
        ],
        "title": "The cyclical effects of the Basel II capital requirements",
        "publication_date": "2007-12-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "",
        "volume": "31",
        "doi": "10.1016/j.jbankfin.2007.03.004",
        "urls": [
            "https://openalex.org/W1994478130",
            "https://doi.org/10.1016/j.jbankfin.2007.03.004"
        ],
        "id": "id5106042745399096867",
        "abstract": "",
        "versions": [
            {
                "year": 2007,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "The Cyclical Effects of the Basel II Capital Requirements",
                "journal": "Journal of Banking and Finance",
                "urls": [
                    "https://www.semanticscholar.org/paper/3d1b1caf43715d8698abdb8ef008b55125f8a235"
                ],
                "doi": "10.1016/J.JBANKFIN.2007.03.004",
                "publication_date": "2007-12-01 00:00:00"
            }
        ],
        "rank": 35
    },
    {
        "authors": [
            "Malcolm P. Baker",
            "Brendan O. Bradley",
            "Jeffrey Wurgler"
        ],
        "title": "Benchmarks as Limits to Arbitrage: Understanding the Low-Volatility Anomaly",
        "publication_date": "2010-03-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Financial Analysts Journal",
        "volume": "67",
        "doi": "10.2469/faj.v67.n1.4",
        "urls": [
            "https://www.semanticscholar.org/paper/08b2e4ffcfefe5420243c832274633e69288b893",
            "http://archive.nyu.edu/bitstream/2451/29593/2/Benchmarks15.pdf"
        ],
        "id": "id-6124065164473198260",
        "abstract": "Contrary to basic finance principles, high-beta and high-volatility stocks have long underperformed low-beta and low-volatility stocks. This anomaly may be partly explained by the fact that the typical institutional investor\u2019s mandate to beat a fixed benchmark discourages arbitrage activity in both high-alpha, low-beta stocks and low-alpha, high-beta stocks. Although there are many candidates for the greatest anomaly in finance, a particularly compelling one is the long-term success of low-volatility and low-beta stock portfolios. Over 1968\u20132008, low-volatility and low-beta portfolios have offered an enviable combination of high average returns and small drawdowns. This runs counter to the fundamental principle that risk is compensated with higher expected return. We applied principles of behavioral finance to shed light on the drivers of this anomalous performance and to assess the likelihood that it will persist. To recap the anomaly, whether risk is defined as volatility or beta and whether we consider all stocks or only large caps, low risk consistently outperformed high risk over this period. A dollar invested in the lowest-volatility portfolio in January 1968 would have increased to $59.55 by the end of 2008. Over this period, inflation eroded the real value of a dollar to about $0.17, meaning that the low-risk portfolio produced a $10.12 gain in real terms. In contrast, a dollar invested in the highest-volatility portfolio would have been worth 58 cents at the end of December 2008, assuming no transaction costs. Given the declining value of the dollar, the real value of the high-volatility portfolio declined to less than 10 cents\u2014a 90 percent decline in real terms! The anomaly with respect to beta risk is similar. A dollar invested in the lowest-beta portfolio in January 1968 would have grown to $60.46 ($10.28 in real terms), and a dollar invested in the highest-beta portfolio would have grown to $3.77 (64 cents in real terms). Like the high-volatility investor, the high-beta investor also failed to recover his dollar in real terms and underperformed his \u201cconservative\u201d beta neighbor by 964 percent. Behavioral models of security prices, such as ours, combine two ingredients. The first is that some market participants are irrational in some particular way. In the context of the low-risk anomaly, we believe that an important subset of investors have a preference for risky stocks. This preference derives from the biases that afflict the individual investor. We believe individuals\u2019 preferences for lotteries and well-established biases of representativeness and overconfidence lead to demand for risk that is not warranted by fundamentals. This irrational demand causes such high-risk stocks to be overpriced, which, all else equal, leads to lower future returns. The second ingredient is limits to arbitrage\u2014an explanation for why the \u201csmart money\u201d does not step in and offset the price impact of any irrational demand. With respect to the low-risk anomaly, we believe that the underappreciated limit on arbitrage is benchmarking. Many institutional investors who are in a position to offset the irrational demand for risk have fixed-benchmark mandates, typically capitalization weighted, which, by their nature, discourage investments in low-beta and low-volatility stocks. We showed that traditional fixed-benchmark mandates (with a leverage constraint, an assumption that we discuss) cause institutional investors to pass up the superior risk\u2013return trade-off of low-beta and low-volatility portfolios. Rather than being a stabilizing force on prices, the typical institutional contract for delegated portfolio management can induce the manager to hold higher-beta stocks, even those with negative alpha. In this article, we review in more detail the long-term performance of low-risk portfolios, present our behavioral explanation and some associated evidence, and discuss the practical implications for investors and investment managers. Perhaps the most important practical implication is that unless individual investors\u2019 preference for volatile stocks and the use of benchmarks are somehow reversed, the low-risk anomaly is likely to persist.",
        "versions": [],
        "rank": 36
    },
    {
        "authors": [
            "Matthieu Garcin",
            "M. Grasselli"
        ],
        "title": "Long versus short time scales: the rough dilemma and beyond",
        "publication_date": "2021-11-08 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Decisions in Economics and Finance",
        "volume": "45",
        "doi": "10.1007/s10203-021-00358-3",
        "urls": [
            "https://www.semanticscholar.org/paper/31c2757d2967c4af3cbb75d07fb572b7b0e6787b"
        ],
        "id": "id7978676108446195766",
        "abstract": null,
        "versions": [
            {
                "year": 2021,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Long versus short time scales: the rough dilemma and beyond",
                "journal": "Decisions in Economics and Finance",
                "urls": [
                    "https://www.semanticscholar.org/paper/9ae839ac54ce4afc9a46f61d12cb6d903d12da6b"
                ],
                "doi": "10.1007/s10203-021-00358-3",
                "publication_date": "2021-11-08 00:00:00"
            }
        ],
        "rank": 37
    },
    {
        "authors": [
            "Ruosen Yang",
            "Sam Du",
            "Jianpeng Huang",
            "Yuteng Zhang"
        ],
        "title": "A stock volatility prediction using hybrid machine learning models",
        "publication_date": "2022-08-23 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1117/12.2647212",
        "urls": [
            "https://www.semanticscholar.org/paper/d8e06dbfd0d60bb3f8a6af3d1abec81b1550f56f"
        ],
        "id": "id-5276287008858208359",
        "abstract": "With the development of social economy, people's concept of investment and financial management has gradually strengthened. Machine learning can be applied in the volatility. In our paper, we use hybrid model based on XGBoost, LightGBM and TabNet for predicting realized volatility. We conclude some related works and represent our hybrid model in the detail. In the experiment process, we compare our hybrid model with other models, and the result shows that our hybrid model owns the lowest RMSPE score 0.198 among all compared models.",
        "versions": [
            {
                "year": 2022,
                "source": "SupportedSources.CROSSREF",
                "title": "A stock volatility prediction using hybrid machine learning models",
                "journal": "",
                "urls": [
                    "http://dx.doi.org/10.1117/12.2647212"
                ],
                "doi": "10.1117/12.2647212",
                "publication_date": "2022-08-23 00:00:00"
            }
        ],
        "rank": 38
    },
    {
        "authors": [
            "G. Bekaert",
            "Eric C. Engstrom",
            "Andrey Ermolov"
        ],
        "title": "Bad Environments, Good Environments: A Non-Gaussian Asymmetric Volatility Model",
        "publication_date": "2014-04-10 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.2139/ssrn.2296898",
        "urls": [
            "https://www.semanticscholar.org/paper/4e7a5fd651d9eba4c7e0231afc99b0fbdd15809f"
        ],
        "id": "id2265926307746750781",
        "abstract": "We propose an extension of standard asymmetric volatility models in the generalized autoregressive conditional heteroskedasticity (GARCH) class that admits conditional non-Gaussianities in a tractable fashion. Our \u201cbad environment\u2013good environment\u201d (BEGE) model utilizes two gamma-distributed shocks and generates a conditional shock distribution with time-varying heteroskedasticity, skewness, and kurtosis. The BEGE model features nontrivial news impact curves and closed-form solutions for higher-order moments. In an empirical application to stock returns, the BEGE model outperforms asymmetric GARCH and regime-switching models along several dimensions.",
        "versions": [],
        "rank": 39
    },
    {
        "authors": [
            "Hongquan Li",
            "Yongmiao Hong"
        ],
        "title": "Financial Volatility Forecasting with Range-based Autoregressive Volatility Model",
        "publication_date": "2011-06-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Finance Research Letters",
        "volume": "8",
        "doi": "10.1016/J.FRL.2010.12.002",
        "urls": [
            "https://www.semanticscholar.org/paper/ad0ebdd4c8e923c7a416c847c20ecc2e3362931b"
        ],
        "id": "id-7919554441000582652",
        "abstract": null,
        "versions": [],
        "rank": 40
    },
    {
        "authors": [
            "M. Gradzewicz"
        ],
        "title": "Endogenous Growth Mechanism as a Source of Medium Term Fluctuations in the Labor Market: Application to the US Economy",
        "publication_date": "2009-04-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.2139/SSRN.1752228",
        "urls": [
            "https://www.semanticscholar.org/paper/c2a90d2472816c9ff9828319134c9fe49e1358a4",
            "http://www.nbp.pl/publikacje/materialy_i_studia/57_en.pdf"
        ],
        "id": "id6590684106659315950",
        "abstract": "A considerable part of the economic literature focuses on the sources and mechanisms of economic cycles. The bulk of this literature, including Real Business Cycle theory (see e.g. papers of Kydland and Prescott 1982, Prescott 1986, King, Plosser, and Rebelo 1988) or New-Keynesian theory (see e.g. Woodford 2003, Smets and Wouters 2003, Christiano, Eichenbaum, and Evans 2005), aim at explaining business cycles. Business cycles are usually defined, following a seminal contribution of Burns and Mitchell (1946), as fluctuations with periodicity between 1 and 8 years. But in the recent years, there has been a growing recognition of the importance of economic cycles that last more than 8 years - the so called medium term cycles. Blanchard (1997) and Solow (2000) were among the first, who stressed the importance of research on this issue and the need to develop models accounting for medium term fluctuations.The most apparent empirical evidence on the importance of medium term cycle is the behavior of unemployment rate in the US economy. Unemployment was relatively low in the 1950s and 1960s of the last century, then increased on average for roughly next 20 years and later, in the 1990s, went back to a lower level. These fluctuations occur with periodicity far greater than a decade. Also the divergence of unemployment experience in US and large continental European countries in the 1970s and 1980s (for a discussion, see e.g. Blanchard 2006) is an indirect evidence of the importance of medium term fluctuations. The literature on changes in productivity growth trend in US (see e.g. Basu, Fernald, and Shapiro 2001) documents another important aspect of this issue.An important paper of Comin and Gertler (2006) documents, in a rigorous way (using band-pass filters of Christiano and Fitzgerald 1999), various facts on medium term fluctuations in goods and capital markets. The paper also defines medium term cycles as fluctuations of periodicity up to 50 years. Comin and Gertler proposed a theoretical framework well suited for analyzing medium term cycles \u2013 they introduced concepts from the endogenous growth theory into the RBC model. Their approach follows a seminal paper by Romer (1990), with modifications accounting for the Jones\u2019 critique of Romer\u2019s model(see Jones 1995). Within their framework, short term shocks affect the profitability of production activity and influence the incentives to innovate and develop new products. Ultimately, it induces fluctuations in the number of available products, resulting in medium term fluctuations of the whole economy. One of the main findings of Comin and Gertler is that medium term fluctuations can be explained by the same factors as business cycle fluctuations1. What is important from our perspective, Comin & Gertler focused on capital and goods markets, leaving the analysis of labor market for further research. This study aims at filling this gap. The empirical evidence on medium term fluctuations in the labor market is presented e.g. in the papers of Hall (2005d) and Hall (2005c). He stressed the importance of fluctuations in medium term frequencies in many macro variables. Additionally, he hypothesized that medium term cycles can result from adjustments that take place in an asymmetric information environment. Alternative explanations of the lower frequency variation in the labor market variables focus more closely on factors specific to the labor market itself. One of them is the hysteresis effect (see e.g. Blanchard and Summers 1986, Blanchard and Summers 1987), as predicted by the insider-outsider theory. Another branch of the literature highlights the role of demography in generating low-frequency labor market volatility, e.g. the prolonged effects of baby-boom generations (see e.g. Flaim 1990) or the changes in participation rates (see e.g. Juhn and Potter 2006) . In this study we focus on the question if medium term fluctuations in the labor market may be explained by the prolonged effects of short lived shocks coming from the goods market. We focus simultaneously on the short term component and the medium term component of medium term cycle in a unified way. As the data suggest that the medium term volatility is present in various markets of the economy, we do not explain lower frequency variation in the labor market with factors specific only to labor market, but instead we look for a common source of volatility in various markets of the economy.So, in other words, this study aims at answering the question, whether the shocks, believed to be the source of traditional business cycles, are able to generate substantial medium term fluctuations in the labor market. The main theses of this study can be stated as follows: 1. Variation of economic activity in medium term frequencies is substantial and comparable to the variation in business cycle frequencies. 2. A large part of medium term fluctuations in both labor and goods markets may be explained by the same sources. 3. Endogenous growth mechanism is able to explain a large part of variation in medium term fluctuations. We construct a theoretical model (with explicitly specified micro foundations), that belongs to a class of Dynamic Stochastic General Equilibrium models, and then we calibrate (and partially estimate) it and verify its predictions against the data. As our analysis requires longer time series, we decided to focus on the US economy. Additionally, there have been many empirical papers analyzing US economy, which simplifies the calibration of the model. Following Romer (1990), we use the endogenous growth framework augmented with the search-matching description of the labor market. It follows closely the Diamond-Mortensen-Pissarides framework (the notion of this framework originates form a seminal contributions by Diamond 1982, Mortensen 1982, Pissarides 1985). The search theory introduces an inherent friction into the functioning of the decentralized labor market and allows to model unemployment as an equilibrium phenomenon. As a source of volatility we use the technology shock, as it is commonly used in the Real Business Cycle literature and, as Hall (2005c) noticed, could also be the main driving force of the medium term labor market fluctuations. The literature acknowledges the fact that the standard search-matching models underestimate the volatility of unemployment, as observed in the data (see e.g Costain and Reiter 2003, Shimer 2005, Hall 2005b). Thus, we will analyze two extensions of the model that address this issue: shocks to matching technology and real wage rigidity.Our framework focuses on the consequences of the changes in the developments of the goods market for the labor market. Thus, we do not model explicitly the labor supply decisions and treat them as exogenously given. We admit, that labor supply shifts could be an important source of economic fluctuations, also in the medium term, but to simplify the analysis we are leaving it outside the model. It allows us to see how important the main mechanisms of our model are in explaining the patterns in the data. Introduction of the endogenous labor supply could only improve the model performance. This theory has at least two implications. First, in order to account for economic variation in medium term frequencies, it seems that there is no need for a new generation of models, but it is enough to augment the current generation of DSGE models with elements of the endogenous growth theory. Second, if our theory is true, the effects of economic policies are more persistent than it is usually implied by the standard DSGE framework. The last issue may be especially important for the monetary policy, but we will leave this for further research.The study is organized as follows. First, we briefly discuss the existing literature in the context of the issues that are important from the perspective of the study. Then, we describe the US data features, concentrating on the medium term characteristics and derive a set of \u201dstylized facts\u201d that will be useful from the modeling perspective. Next, we present the details and derivations of the theoretical model, which includes both the endogenous growth component and the search-matching mechanism on the labor market. This section also discusses the steady state properties and restrictions imposed on the model structure by the balanced growth path assumption. Next, we discuss our calibration strategy, along with the data and information sources used for this purpose. As the stochastic parameters of the model, together with stochastic shocks, are estimated from the US data, this section also addresses the estimation issues. The last section presents the predictions of the estimated model and verifies them against the US data. As the basic version of the model understates the extent of labor market volatility, we also extend our analysis in two distinct dimensions. Firstly, we introduce shocks to matching technology and secondly - real wage rigidities, both extensions aimed at resolving the volatility issue. In each case, we check the model predictions and verify its properties. The last part of this section compares the predictions of the model extended for wage rigidities with the predictions of the benchmark model - basic RBC model with search-matching and wage rigidities - and presents some evidence on the importance of the endogenous growth component. The last section concludes and discuss some implications for our results for policy and the economic modeling.",
        "versions": [
            {
                "year": 2009,
                "source": "SupportedSources.INTERNET_ARCHIVE",
                "title": "Endogenous Growth Mechanism as a Source of Medium Term Fluctuations in the Labor Market: Application to the US Economy",
                "journal": "Elsevier BV",
                "urls": [
                    "https://web.archive.org/web/20170808031739/http://www.nbp.pl/publikacje/materialy_i_studia/57_en.pdf"
                ],
                "doi": "10.2139/ssrn.1752228",
                "publication_date": "2009-01-01 00:00:00"
            }
        ],
        "rank": 41
    },
    {
        "authors": [
            "Axel Dreher",
            "Eric Werker",
            "James Raymond Vreeland",
            "Stephan Klasen"
        ],
        "title": "The Costs of Favoritism: Is Politically-driven Aid less Effective?",
        "publication_date": "None",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "https://core.ac.uk/download/pdf/6662051.pdf"
        ],
        "id": "id7335527272310741753",
        "abstract": "As is now well documented, aid is given for both political as well as economic reasons. The conventional wisdom is that politically-motivated aid is less effective in promoting developmental objectives. We examine the ex-post performance ratings of World Bank projects and generally find that projects that are potentially politically motivated \u2013 such as those granted to governments holding a non-permanent seat on the United Nations Security Council or an Executive Directorship at the World Bank \u2013 are no more likely, on average, to get a negative quality rating than other projects. When aid is given to Security Council members with higher short-term debt, however, a negative quality rating is more likely. So we find evidence that World Bank project quality suffers as a consequence of political influence only when the recipient country is economically vulnerable in the first place.World Bank, aid effectiveness, political influence, United Nations Security Council",
        "versions": [],
        "rank": 42
    },
    {
        "authors": [
            "Lei Tan",
            "Bo Zheng",
            "Jun-Jie Chen",
            "Xiong-Fei Jiang"
        ],
        "title": "How volatilities nonlocal in time affect the price dynamics in complex financial systems",
        "publication_date": "2015-02-03 12:03:41+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "10.1371/journal.pone.0118399",
        "urls": [
            "http://arxiv.org/pdf/1502.00824v1",
            "http://dx.doi.org/10.1371/journal.pone.0118399",
            "http://arxiv.org/abs/1502.00824v1",
            "http://arxiv.org/pdf/1502.00824v1"
        ],
        "id": "id-2971834257899512333",
        "abstract": "What is the dominating mechanism of the price dynamics in financial systems\nis of great interest to scientists. The problem whether and how volatilities\naffect the price movement draws much attention. Although many efforts have been\nmade, it remains challenging. Physicists usually apply the concepts and methods\nin statistical physics, such as temporal correlation functions, to study\nfinancial dynamics. However, the usual volatility-return correlation function,\nwhich is local in time, typically fluctuates around zero. Here we construct\ndynamic observables nonlocal in time to explore the volatility-return\ncorrelation, based on the empirical data of hundreds of individual stocks and\n25 stock market indices in different countries. Strikingly, the correlation is\ndiscovered to be non-zero, with an amplitude of a few percent and a duration of\nover two weeks. This result provides compelling evidence that past volatilities\nnonlocal in time affect future returns. Further, we introduce an agent-based\nmodel with a novel mechanism, that is, the asymmetric trading preference in\nvolatile and stable markets, to understand the microscopic origin of the\nvolatility-return correlation nonlocal in time.",
        "versions": [],
        "rank": 43
    },
    {
        "authors": [
            "F. Slemr",
            "W. Seiler",
            "G. Schuster"
        ],
        "title": "Latitudinal distribution of Mercury over the Atlantic Ocean",
        "publication_date": "1981-02-20 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Journal of Geophysical Research",
        "volume": "86",
        "doi": "10.1029/JC086IC02P01159",
        "urls": [
            "https://www.semanticscholar.org/paper/eeffc48f585540bdfc19e593720ecc65a8502245"
        ],
        "id": "id3198540396826500204",
        "abstract": "Mercury in air and in surface water has been measured during a ship expedition across the Atlantic Ocean between Hamburg (50\u00b0N) and Buenos Aires (35\u00b0S). The data show an interhemispherical difference of total gaseous mercury, with average concentrations of 1.56 \u00b1 0.32 ng/m3 in the northern hemisphere and 1.05 \u00b1 0.22 ng/m3 in the southern hemisphere. Dimethyl mercury concentrations in clean marine air are \u22640.1 ng Hg/m3 or \u226410% of the total gaseous mercury. The interhemispheric concentration difference and the variability of gaseous mercury of \u00b116% imply a mean tropospheric residence time of atmospheric mercury of approximately 0.9 years. With a total tropospheric burden of 5.0 \u00d7 109 g, source and sink strengths are estimated to be 6 \u00d7 109 g mercury per year. Most of the mercury produced must originate from continental sources, by both anthropogenic and natural processes. The oceans seem to be only of minor importance in the global atmospheric mercury budget. The mercury content in water was 2\u20138 ng/1. The mercury concentrations in air and in water did not correlate.",
        "versions": [
            {
                "year": 1981,
                "source": "SupportedSources.OPENALEX",
                "title": "Latitudinal distribution of Mercury over the Atlantic Ocean",
                "journal": "",
                "urls": [
                    "https://openalex.org/W1993300301",
                    "https://doi.org/10.1029/jc086ic02p01159"
                ],
                "doi": "10.1029/jc086ic02p01159",
                "publication_date": "1981-02-20 00:00:00"
            }
        ],
        "rank": 44
    },
    {
        "authors": [
            "G. Bao",
            "Peijun Li"
        ],
        "title": "Near-Field Imaging of Infinite Rough Surfaces in Dielectric Media",
        "publication_date": "2014-05-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "SIAM J. Imaging Sci.",
        "volume": "7",
        "doi": "10.1137/130944485",
        "urls": [
            "https://www.semanticscholar.org/paper/2ec7075bab6eda58f905ae3e219434ec30cea9fe"
        ],
        "id": "id-1570987932562489351",
        "abstract": "This paper is concerned with an inverse surface scattering problem in near-field optical imaging, which is to reconstruct the scattering surface of a dielectric medium with a resolution beyond the diffraction limit. It is a nontrivial extension of the authors' work on near-field imaging of infinite rough surfaces from impenetrable to penetrable media [G. Bao and P. Li, SIAM J. Appl. Math., 73 (2013), pp. 2162--2187], where a more sophisticated transmission problem needs to be considered. The scattering surface is modeled as a small and smooth deformation of a plan surface. Based on a transformed field expansion, an analytic solution, which is given as a power series, is derived for the direct scattering problem. By neglecting high order terms in the power series, the original nonlinear inverse problem is linearized; explicit and unified reconstruction formulas are deduced for both reflection and transmission configurations. A spectral cut-off regularization is adopted to suppress the exponential growth of...",
        "versions": [],
        "rank": 45
    },
    {
        "authors": [
            "G Keoleian",
            "M Lepech",
            "H Zhang"
        ],
        "title": "An integrated life cycle assessment and life cycle analysis model for pavement overlay systems",
        "publication_date": "2008-06-20 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "CRC Press",
        "volume": "",
        "doi": "10.1201/9780203885307.ch141",
        "urls": [
            "https://web.archive.org/web/20150726150520/http://web.stanford.edu:80/~mlepech/pubs/ialcce.lcamodel.08.pdf"
        ],
        "id": "id89463956357174747",
        "abstract": "Pavement systems have significant impacts on the environment and economy due to large material consumption, energy input, and capital investment. To evaluate the sustainability of rigid pavement overlay designs, an integrated life cycle assessment and life cycle cost analysis model was developed to calculate the environmental impacts and costs of overlay systems resulting from material production and distribution, overlay construction and maintenance, construction-related traffic congestion, overlay usage, and end of life management. An unbonded concrete overlay system, a hot mix asphalt overlay system, and an alternative engineered cementitious composite (ECC) overlay system are examined. Model results indicate that the ECC overlay system reduces total life cycle energy by 15% and 72%, greenhouse gas (GHG) emissions by 32% and 37%, and costs by 40% and 58% compared to the concrete overlay system and the HMA overlay system, respectively, over the entire 40 year life cycle. These advantages are derived from the enhanced material properties of ECC which prevent reflective cracking failures (discussed in a complementary paper). Material consumption, traffic congestion caused by construction activities, and roughness effects caused by overlay deterioration are identified as three dominant factors that influence the environmental impacts and costs of overlay systems.",
        "versions": [],
        "rank": 46
    },
    {
        "authors": [
            "Marusak, P."
        ],
        "title": "Application of Fuzzy Wiener Models in Efficient MPC Algorithms",
        "publication_date": "2010-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-3-642-13529-3_71",
        "urls": [
            "http://link.springer.com/content/pdf/10.1007/978-3-642-13529-3_71.pdf",
            "http://dx.doi.org/10.1007/978-3-642-13529-3_71"
        ],
        "id": "id7338699657356149201",
        "abstract": "",
        "versions": [
            {
                "year": 2010,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Application of Fuzzy Wiener Models in Efficient MPC Algorithms",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/c517ce9da6eae2f23b28784d1de6b7c013a6f51b"
                ],
                "doi": "10.1007/978-3-642-13529-3_71",
                "publication_date": "2010-06-28 00:00:00"
            }
        ],
        "rank": 47
    },
    {
        "authors": [
            "Antoine Sanner",
            "Lars Pastewka"
        ],
        "title": "Crack-front model for adhesion of soft elastic spheres with chemical heterogeneity",
        "publication_date": "2021-08-15 07:56:30+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "10.1016/j.jmps.2022.104781",
        "urls": [
            "http://arxiv.org/pdf/2108.06683v1",
            "http://dx.doi.org/10.1016/j.jmps.2022.104781",
            "http://arxiv.org/abs/2108.06683v1",
            "http://arxiv.org/pdf/2108.06683v1"
        ],
        "id": "id1037633775619350546",
        "abstract": "Adhesion hysteresis can be caused by elastic instabilities that are triggered\nby surface roughness or chemical heterogeneity. However, the role of these\ninstabilities in adhesion hysteresis remains poorly understood because we lack\ntheoretical and numerical models accounting for realistic roughness. Our work\nfocuses on the adhesion of soft elastic spheres with low roughness or weak\nheterogeneity, where the indentation process can be described as a\nGriffith-like propagation of a nearly circular external crack. We discuss how\nto describe the contact of spheres with chemical heterogeneity that leads to\nfluctuations in the local work of adhesion. We introduce a variational\nfirst-order crack-perturbation model and validate our approach using\nboundary-element simulations. The crack-perturbation model faithfully predicts\ncontact shapes and hysteretic force-penetration curves, provided that the\ncontact perimeter remains close to a circle and the contact area is simply\nconnected. Computationally, the crack-perturbation model is orders of magnitude\nmore efficient than the corresponding boundary element formulation, allowing\nfor realistic heterogeneity fields. Furthermore, our crack-front formulation\nclarifies the connection of adhesion hysteresis to classic theories on pinning\nof elastic lines.",
        "versions": [],
        "rank": 48
    },
    {
        "authors": [
            "Oron",
            "Bankoff"
        ],
        "title": "Dewetting of a Heated Surface by an Evaporating Liquid Film under Conjoining/Disjoining Pressures.",
        "publication_date": "1999-10-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Journal of colloid and interface science",
        "volume": "218 1",
        "doi": "10.1006/JCIS.1999.6390",
        "urls": [
            "https://www.semanticscholar.org/paper/ad14a981c7ec64d5efb9d84badb5ae0be7d3c343"
        ],
        "id": "id-3124246447258334840",
        "abstract": "In the present work we consider a model for the evolution of a thin nonpolar liquid film on a coated solid surface under the action of attractive and repulsive molecular forces governed by a 3-4 power-law potential, rather than the Lennard-Jones 3-9 potential employed for an ideal plane interface (molecularly clean and smooth). The model is used for both volatile and nonvolatile isothermal liquid films. It is shown that in the nonvolatile case the evolution results in the emergence of static steady states consisting of liquid ridges separated by very thin films. A supercritical bifurcation from the trivial state is shown to be possible in the presence of repulsive forces, while in the presence of only attractive forces the bifurcation is subcritical. In the evaporative case the long-time evolution of the film is shown to lead to its flattening and then to its apparent vanishing. Several scenarios for the film disappearance are found. A relationship between the rate of expansion of the dry spot and the apparent contact angle is examined. The effect of thermocapillarity on the film evolution is also considered. Copyright 1999 Academic Press.",
        "versions": [
            {
                "year": 1999,
                "source": "SupportedSources.OPENALEX",
                "title": "Dewetting of a Heated Surface by an Evaporating Liquid Film under Conjoining/Disjoining Pressures",
                "journal": "",
                "urls": [
                    "https://openalex.org/W1964900692",
                    "https://doi.org/10.1006/jcis.1999.6390"
                ],
                "doi": "10.1006/jcis.1999.6390",
                "publication_date": "1999-10-01 00:00:00"
            }
        ],
        "rank": 49
    },
    {
        "authors": [
            "Chorng-Shyong Ong",
            "Jih-Jeng Huang",
            "G. Tzeng"
        ],
        "title": "Using Rough Set Theory for Detecting the Interaction Terms in a Generalized Logit Model",
        "publication_date": "2004-06-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-3-540-25929-9_77",
        "urls": [
            "https://www.semanticscholar.org/paper/8e8a0200661faff234f9ad60a9c0a0047daa33dc"
        ],
        "id": "id-727149374483060681",
        "abstract": null,
        "versions": [],
        "rank": 50
    },
    {
        "authors": [
            "P. Hansen",
            "A. Lunde"
        ],
        "title": "A Forecast Comparison of Volatility Models: Does Anything Beat a Garch(1,1)?",
        "publication_date": "2004-03-22 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.2139/ssrn.264571",
        "urls": [
            "https://www.semanticscholar.org/paper/91d17214abfd0cdc1d508c62711becc6677e995e",
            "https://cdr.lib.unc.edu/downloads/9880vt352"
        ],
        "id": "id3052961038426890890",
        "abstract": "We compare 330 ARCH-type models in terms of their ability to describe the conditional variance. The models are compared out-of-sample using DM-$ exchange rate data and IBM return data, where the latter is based on a new data set of realized variance. We find no evidence that a GARCH(1,1) is outperformed by more sophisticated models in our analysis of exchange rates, whereas the GARCH(1,1) is clearly inferior to models that can accommodate a leverage effect in our analysis of IBM returns. The models are compared with the test for superior predictive ability (SPA) and the reality check for data snooping (RC). Our empirical results show that the RC lacks power to an extent that makes it unable to distinguish 'good' and 'bad' models in our analysis.",
        "versions": [],
        "rank": 51
    },
    {
        "authors": [
            "A. Gulisashvili"
        ],
        "title": "Large Deviation Principle for Volterra Type Fractional Stochastic Volatility Models",
        "publication_date": "2017-10-29 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "SIAM J. Financial Math.",
        "volume": "9",
        "doi": "10.1137/17M116344X",
        "urls": [
            "https://www.semanticscholar.org/paper/08fb79200492577b7e558298a8dd28e063d021d3",
            "http://arxiv.org/pdf/1710.10711"
        ],
        "id": "id3685662165466404117",
        "abstract": "We study fractional stochastic volatility models for the asset price, in which the volatility process is a positive continuous function $\\sigma$ of a continuous fractional stochastic process $\\widehat{B}$. The main result obtained in the present paper is a generalization of the large deviation principle for the log-price process due to M. Forde and H. Zhang. In their work, Forde and Zhang assume that the function $\\sigma$ satisfies a global H\\\"{o}lder condition and $\\widehat{B}$ is fractional Brownian motion, whereas in the present paper, the function $\\sigma$ satisfies a very mild condition expressed in terms of a local modulus of continuity, while the process $\\widehat{B}$ is a general Volterra type Gaussian process. We establish a small-noise large deviation principle for the log-price in a fractional stochastic volatility model, and under an additional condition of self-similarity of the process $\\widehat{B}$, derive a similar large deviation principle in the small-time regime. Using the latter result, we obtain asymptotic formulas for binary options, call and put options, and the implied volatility in the small-maturity small-log-moneyness regime.",
        "versions": [],
        "rank": 52
    },
    {
        "authors": [
            "J. Fuggle",
            "F. Hillebrecht",
            "Z. Zo\u0142nierek",
            "R. L\u00e4sser",
            "C. Freiburg",
            "O. Gunnarsson",
            "K. Sch\u00f6nhammer"
        ],
        "title": "Electronic structure of Ce and its intermetallic compounds",
        "publication_date": "1983-06-15 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Physical Review B",
        "volume": "27",
        "doi": "10.1103/PHYSREVB.27.7330",
        "urls": [
            "https://www.semanticscholar.org/paper/df10fd78cc0b209174452b5125c361baacfef16a"
        ],
        "id": "id-2855522321857600341",
        "abstract": "We report the core-level x-ray photoelectron spectroscopy spectra of 30 intermetallic compounds of La and Ce. The results are discussed in the light of calculations using the Anderson impurity model of the $4f$ levels and including the degeneracy of the $4f$ levels. The comparison allows us to derive values for the coupling between the $f$ levels and the conduction states $\\ensuremath{\\Delta}$ and the number of $4f$ electrons ${n}_{f}$. We find $\\ensuremath{\\Delta}$ to be up to \\ensuremath{\\sim} 150 meV in some Ce intermetallic compounds, and find ${n}_{f}$ to range from \\ensuremath{\\sim}0.8-1.1. We cannot reconcile the core-level results with the traditional promotional model in which $\\ensuremath{\\Delta}$ was assumed to be 10 meV or less and the $f$-electron count could range from 1 down to zero in Ce intermetallic compounds.",
        "versions": [
            {
                "year": 1983,
                "source": "SupportedSources.OPENALEX",
                "title": "Electronic structure of Ce and its intermetallic compounds",
                "journal": "",
                "urls": [
                    "https://openalex.org/W2085047049",
                    "https://doi.org/10.1103/physrevb.27.7330"
                ],
                "doi": "10.1103/physrevb.27.7330",
                "publication_date": "1983-06-15 00:00:00"
            }
        ],
        "rank": 53
    },
    {
        "authors": [
            "Yacine A\u00eft-Sahalia",
            "D. Xiu"
        ],
        "title": "Likelihood\u2010Based Volatility Estimators in the Presence of Market Microstructure Noise",
        "publication_date": "2012-03-27 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1002/9781118272039.CH14",
        "urls": [
            "https://www.semanticscholar.org/paper/df2002890ace6c509e6b3430dd0ca7553e270e22"
        ],
        "id": "id1768769918287345168",
        "abstract": "Driven by the need for accurate measurement of financial risk using intraday data, high frequency econometric methods have been evolving rapidly, bringing into focus a range of issues that were otherwise unobservable or, in many cases, irrelevant from the perspective of daily and weekly data or lower frequency data. The huge amount of intraday tick-by-tick data provides rich and timely information regarding fluctuations of traded assets and their comovements, which may yield more accurate measurements of volatility and covariance over relatively short horizons than estimates based on years of historical data at low frequency. However, statistical inference with high frequency data presents many challenges. Closer scrutiny of the data reveals the pervasive presence of market microstructure noise, including frictions such as the existence of bid-ask spreads and bounces, the discreteness of price changes, the price impact of some transactions, and informational effects, all of which add volatility to the observed price process. When measuring correlation, the fact that the two assets may not trade or otherwise be observed at exactly the same times, known as observation",
        "versions": [
            {
                "year": 2012,
                "source": "SupportedSources.CROSSREF",
                "title": "Likelihood-Based Volatility Estimators in the Presence of Market Microstructure Noise",
                "journal": "",
                "urls": [
                    "https://onlinelibrary.wiley.com/doi/full/10.1002/9781118272039.ch14",
                    "http://dx.doi.org/10.1002/9781118272039.ch14"
                ],
                "doi": "10.1002/9781118272039.ch14",
                "publication_date": "2012-03-27 00:00:00"
            }
        ],
        "rank": 54
    },
    {
        "authors": [
            "Christian Kahl",
            "P. J\u00e4ckel"
        ],
        "title": "Fast strong approximation Monte Carlo schemes for stochastic volatility models",
        "publication_date": "2006-12-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Quantitative Finance",
        "volume": "6",
        "doi": "10.1080/14697680600841108",
        "urls": [
            "https://www.semanticscholar.org/paper/19904d8cdcf4ddb01deec2a65f6f2f67152c8a49"
        ],
        "id": "id5446954774525922229",
        "abstract": "Numerical integration methods for stochastic volatility models in financial markets are discussed. We concentrate on two classes of stochastic volatility models where the volatility is either directly given by a mean-reverting CEV process or as a transformed Ornstein\u2013Uhlenbeck process. For the latter, we introduce a new model based on a simple hyperbolic transformation. Various numerical methods for integrating mean-reverting CEV processes are analysed and compared with respect to positivity preservation and efficiency. Moreover, we develop a simple and robust integration scheme for the two-dimensional system using the strong convergence behaviour as an indicator for the approximation quality. This method, which we refer to as the IJK (137) scheme, is applicable to all types of stochastic volatility models and can be employed as a drop-in replacement for the standard log-Euler procedure.",
        "versions": [
            {
                "year": 2006,
                "source": "SupportedSources.CROSSREF",
                "title": "Fast strong approximation Monte Carlo schemes for stochastic volatility models",
                "journal": "",
                "urls": [
                    "http://www.tandfonline.com/doi/pdf/10.1080/14697680600841108",
                    "http://dx.doi.org/10.1080/14697680600841108"
                ],
                "doi": "10.1080/14697680600841108",
                "publication_date": "2006-01-01 00:00:00"
            }
        ],
        "rank": 55
    },
    {
        "authors": [
            "Achterberg A.",
            "Asaoka I.",
            "Askarov A. I.",
            "Berezhko E. G.",
            "Berezhko E. G.",
            "Biermann P. L.",
            "Braun R.",
            "Byung\u2010Il Jun",
            "Dale\u00a0A. Frail",
            "Dorfi E. A.",
            "Drury L.",
            "Epstein R. I.",
            "Favata F.",
            "Furst E.",
            "Gloria Dubner",
            "Green D. A.",
            "Gull S. F.",
            "Holt S. S.",
            "Hyesung Kang",
            "Kang H.",
            "Kazimierz\u00a0J. Borkowski",
            "Kesteven M. J.",
            "Lagage P. O.",
            "Lawrence Rudnick",
            "Malkov M. A.",
            "Markiewicz W. J.",
            "Mathewson D. S.",
            "Muxlow T. W. B.",
            "Nakai N.",
            "Namir\u00a0E. Kassim",
            "Peimbert M.",
            "Pineault S.",
            "Predehl P.",
            "Reach W. T.",
            "Richard McCray",
            "Shklovsky I. S.",
            "T.\u00a0W. Jones",
            "Vink J.",
            "Wallace B. J.",
            "Zhang X."
        ],
        "title": "$10^{51}$ Ergs: The Evolution of Shell Supernova Remnants",
        "publication_date": "1997-10-21 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": null,
        "volume": "",
        "doi": "10.1086/316122",
        "urls": [
            "http://arxiv.org/abs/astro-ph/9710227"
        ],
        "id": "id8281757513635315917",
        "abstract": "This paper reports on a workshop hosted by the University of Minnesota, March\n23-26, 1997. It addressed fundamental dynamical issues associated with the\nevolution of shell supernova remnants and the relationships between supernova\nremnants and their environments. The workshop considered, in addition to\nclassical shell SNRs, dynamical issues involving X-ray filled composite\nremnants and pulsar driven shells, such as that in the Crab Nebula.\nApproximately 75 participants with wide ranging interests attended the\nworkshop. An even larger community helped through extensive on-line debates\nprior to the meeting. Each of the several sessions, organized mostly around\nchronological labels, also addressed some underlying, general physical themes:\nHow are SNR dynamics and structures modified by the character of the CSM and\nthe ISM and vice versa? How are magnetic fields generated in SNRs and how do\nmagnetic fields influence SNRs? Where and how are cosmic-rays (electrons and\nions) produced in SNRs and how does their presence influence or reveal SNR\ndynamics? How does SNR blast energy partition into various components over time\nand what controls conversion between components? In lieu of a proceedings\nvolume, we present here a synopsis of the workshop in the form of brief\nsummaries of the workshop sessions. The sharpest impressions from the workshop\nwere the crucial and under-appreciated roles that environments have on SNR\nappearance and dynamics and the critical need for broad-based studies to\nunderstand these beautiful, but enigmatic objects. \\\\Comment: 54 pages text, no figures, Latex (aasms4.sty). submitted to the PAS",
        "versions": [],
        "rank": 56
    },
    {
        "authors": [
            "S. A. Gromilov",
            "A. V. Ivanchenko",
            "S. A. Prokhorova",
            "S. M. Zemskova"
        ],
        "title": "Organization of oriented layers of ZnII, CdII, HgIIdiethyldithiocarbamatoiodine complexes",
        "publication_date": "1996-08-08 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "International Union of Crystallography (IUCr)",
        "volume": "",
        "doi": "10.1107/s0108767396080592",
        "urls": [
            "https://web.archive.org/web/20180725020749/http://journals.iucr.org/a/issues/1996/a1/00/a42141/a42141.pdf"
        ],
        "id": "id2309907701505648749",
        "abstract": "The measurements of diffuse scattering (DS) in grazing incidence x-ray diffraction (GID) can provide infonnation on atomic ordering in smface and interface roughness of crystals which is not accessible l:iy usual specular and non-specular x-ray scatteting. In contrast to the usual non-specular x-ray scattering which is proportional to the mean fluctuations of matetial density 8:;co. the DS in GID is mainly detem1ined by fluctuations of crystal pola.rizability 8:;ch. where his the reciprocal lattice vector con\u00b7esponding to GID. A theory of DS on correlated and uncorrelated interface roughness under GID based on the matrix solution to GID in multilayers and the distorted wave Bom approximation is applied to two GID experiments with an etched Ge smface and a GaAs/AlAs superlattice car1ied out at CHESS and ESRF, respectively. In both cases a good accordance between the theory and the expetiment is observed. In the case of the etched Ge smface, an anti-Yoneda dip in the DS pattern at the Bragg peak and two symmetric shoulders on the Bragg curve wings have been found and explained. In the case of the GaAs/ AlAs super lattice, the DS sepmated from the coherent GID by means of high-resolution measurements was compa.r\u00b7ed to x-ray reflectivity data and it has been shown that the atomic ordeting was preserved in the intetface roughness, while it was pmtially destroyed in the surface roughness. MS12.03.08 CORRELATED ROUGHNESS INFORJ.vLI\\TION FROM DIFFUSE X-RAY SCATTERING OF STEPPED SUR-FACES. P.M. Reimer, Y. Ylli11aguchi, J.H. Li, H. Hashizume, Tokyo Institute of Technology We discuss the problem of extracting useful infom1ation on intetfacial roughness con\u00b7eJations from glancing angle diffuse scattering data. In recent yems, the distorted wave Bom approximation (DWBA) has been successfully applied to model diffuse scattering from fractally rough surfaces. However, many smfaces/interfaces of interest a.r\u00b7e often stepped due to small substt\u00b7ate miscut angles, ar1d the fractal approach does not take into account such stt\u00b7ong, periodic, correlated intetface structures. We discuss how to extt\u00b7act infotmation on roughness para.I11eters and roughness conelations from the diffuse intensity under such circumstances, using Si/SiGe heterostt\u00b7uctures and calcite surfaces as examples. (Applications will be found in related presentations by J.H. Li andY. Yamaguchi). PS12.03.09 IN-SITU X-RW REFLECTIVITY MEASURE-MENT OF THIN FILM GROWTH. Chih-Hao Lee and Sung-Yuh Tseng, Department of Nuclear Engineering and Engineeting Physics, National Tsing Hua University, Hsinchu, Taiwan, 30043 X-ray reflectivity method was used to measure in-situ the thickness and smface roughness of a thin film during deposition growth. Intensity oscillation as function of time car1 be observed as the film thickness grows. The oscillation a.rnplitude is damped as the surface roughness increase. The experiment procedure is similiar to ellipsometry or RHLEED. Wnile only kinematic theory is needed to interpret the experiment data, the X-ray reflectivity method is much easier to fit the model. In this method, the measurement sensitivity of the film thickness can be selected by changing the specular angle. A higher incidence angle is more sensitive to thinner layer. As the speculm angle approaches anti-Bragg angle, the measurement is sensitive to the monolayer growth of the thin film. PS12.03. A literature review on volatile Zn(II), Cd(II), Hg(II) dialkyldithiocmbamates has been made; their crystal structures, IR and UV spectra, thermal properties have been analyzed. A number of new dialkyldithiocarbamates with different alkyl substituents was synthesized. The layers of up to 1 nllan from both homo-and heterometallic diethyeldithiocarbamato-iodine complexes ([MM'(Et2NCS2hi2], M,M' = Zn, Cd, Hg) were obtained by means of evaporation in vacuum and further vapor deposition on silicon, qua.r\u00b7tz and glass substrates. An analysis of the X-ray powder patterns leads to the next conclusions: the layers a.r\u00b7e the ideal oriented polycrystal films in all cases; in the case of M=M'=Cd complexes, the crystal structure of the films obtained differs from the initial one; for M=Cd, M'=Hg, the films obtained have both an1orphous and crystal structures. The latters have the [001] texture axis. The sh'Lictural organization of the layers in the following direction was analyzed: the scale of the location of these complexes and their orientation relative to the smface. It was shown that the film smface is formed by C2Hs terminal groups. The films were subjected to thermolysis until the corresponding sulphides arose. The surface diffracted waves a.r\u00b7e theoretically investigated versus on the azimuth and pole angles of incidence of X-rays with the wave front amplitude periodically vmying along the single crystal (SC) surface. The smface waves a.r\u00b7e attenuating on both sides across the vacuum-structure boundmy. The following scheme of X-ray grazing incidence diffraction (GID) is investigated: The Xray plane wave is reflected by the diffraction grating (DG). The reflected radiation's wave front amplitude is va.r\u00b7ying periodically along the same direction, at which the reflecting elements of DG are petiodically deposited. Then the reflected wave falls at grazing angles onto a SC. The diffracting lattice planes of SC a.r\u00b7e normal to the entrance surface (symmet1ical Laue case). Due to modern technologies the device performing elements' thicknesses are in nanometer ranges e.g. in the integrated circuits, solid state lasers etc., and if in particular\u00b7 the performing elements a.r\u00b7e deposited pe1iodically on the substrate, one may consider the device surface layer as the reflecting DG for the X -rays. The reflection function of such DG may be used for the control ar1d monitoring of device surface elements quality. The conditions at which the reflected from DG X-ray wave field has the nmrow angular spectrum are investigated in detail. The method of investigation of such modulated incident waves by the GID technique is suggested.",
        "versions": [],
        "rank": 57
    },
    {
        "authors": [
            "Wing Chan",
            "Bryce Shelton",
            "Yan Wu"
        ],
        "title": "Volatility Spillovers Arising from the Financialization of Commodities",
        "publication_date": "2018-10-27 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "MDPI AG",
        "volume": "",
        "doi": "10.3390/jrfm11040072",
        "urls": [
            "https://web.archive.org/web/20190430130400/https://res.mdpi.com/jrfm/jrfm-11-00072/article_deploy/jrfm-11-00072.pdf?filename=&attachment=1"
        ],
        "id": "id4936053605060737419",
        "abstract": "This paper examines whether the proliferation of new index products, such as commodity-tracking exchange-traded funds (ETFs), amplified the volatility transmission channel introduced by financialization. This paper focuses on the volatility spillover effects among crude oil, metals, agriculture, and non-energy commodity markets. The results show financialization has an impact on the volatility of commodity prices, predominantly for non-energy commodities. However, the impact on volatility is not symmetric across all commodities. The analysis of index investment and investors' positions in futures markets shows that, when a relationship exists, it is generally negatively correlated with the realized volatility of non-energy commodities. Using realized volatility in the difference-in-difference model provides estimates that are inconsistent with other findings that non-energy commodities, traded as a part of indices, have experienced higher volatility. The results are similar to the index investment and futures market analysis, where increased participation by investors through new investment products has put download pressure on realized volatility.",
        "versions": [],
        "rank": 58
    },
    {
        "authors": [
            "N. Atoi"
        ],
        "title": "Testing Volatility in Nigeria Stock Market using GARCH Models",
        "publication_date": "None",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "5",
        "doi": "",
        "urls": [
            "https://www.semanticscholar.org/paper/af09ee37b4ea876937f2de91122b3bbdbed0a4cb"
        ],
        "id": "id-751319597865535289",
        "abstract": "The contributions of error distributions have been ignored while modeling stock market volatility in Nigeria and studies have shown that the application of appropriate error distribution in volatility model enhances efficiency of the model. Using Nigeria All Share Index from January 2, 2008 to February 11, 2013, this study estimates first order symmetric and asymmetric volatility models each in Normal, Student\u2019s-t and generalized error distributions with the view to selecting the best forecasting volatility model with the most appropriate error distribution. The results suggest the presence of leverage effect meaning that volatility responds more to bad news than it does to equal magnitude of good news. The news impact curves validate this result. The last twenty eight days out-of-sample forecast adjudged Power-GARCH (1, 1, 1) in student\u2019s t error distribution as the best predictive model based on Root Mean Square Error and Theil Inequality Coefficient. The study therefore recommends that empirical works should consider alternative error distributions with a view to achieving a robust volatility forecasting model that could guarantee a sound policy decisions.",
        "versions": [],
        "rank": 59
    },
    {
        "authors": [
            "Miguel A. Savastano",
            "Sebastian Edwards"
        ],
        "title": "Exchange Rates in Emerging Economies: What Do We Know? What Do We Need to Know?",
        "publication_date": "None",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "https://core.ac.uk/download/pdf/6822565.pdf"
        ],
        "id": "id-7229122553539343212",
        "abstract": "Exchange rates have been at the center of economic debates in emerging economies. Issues related to the feasibility of flexible exchange rates, the relationship between exchange rate volatility and growth, and the role of exchange rate overvaluation in recent crises, among other, have been extensively discussed during the last few years. In this paper we address some of the most important exchange rate-related issues in emerging economies. In particular, we deal with: (a) the merits of alternative exchange rate regimes: (b) the extent to which purchasing power parity holds in the long run in these countries; and (c) models to assess real exchange rate overvaluation. We also discuss future areas for research on exchange rates in the emerging nations.",
        "versions": [],
        "rank": 60
    },
    {
        "authors": [
            "Qing X. Li",
            "Tiejun Wang",
            "Ping Li",
            "Ling Liu",
            "Qixu Gong",
            "Yuanzhu Chen"
        ],
        "title": "The effect of news and public mood on stock movements",
        "publication_date": "2014-09-10 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "",
        "volume": "278",
        "doi": "10.1016/j.ins.2014.03.096",
        "urls": [
            "https://openalex.org/W1984430235",
            "https://doi.org/10.1016/j.ins.2014.03.096"
        ],
        "id": "id-5786400645164597246",
        "abstract": "",
        "versions": [
            {
                "year": 2014,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "The effect of news and public mood on stock movements",
                "journal": "Inf. Sci.",
                "urls": [
                    "https://www.semanticscholar.org/paper/6202cd603dfb0cc0fad45fa537c200074e10bba3"
                ],
                "doi": "10.1016/j.ins.2014.03.096",
                "publication_date": "2014-09-10 00:00:00"
            }
        ],
        "rank": 61
    },
    {
        "authors": [
            "Alexey Cheskidov",
            "Diana Ma"
        ],
        "title": "Leray-alpha model and transition to turbulence in rough-wall boundary layers",
        "publication_date": "2006-11-01 19:35:57+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/physics/0611001v2",
            "http://arxiv.org/abs/physics/0611001v2",
            "http://arxiv.org/pdf/physics/0611001v2"
        ],
        "id": "id-1900635965523069512",
        "abstract": "In the present study, we use a fifth-order ordinary differential equation, a\ngeneralization of the Blasius equation derived from the Leray-alpha model, to\nexamine the transition to turbulence in rough-wall boundary-layer flows. This\nequation, combined with a weaker formulation of the von Karman log law modified\nto include the effects of surface roughness, provides a family of turbulent\nvelocity profiles with two free parameters: the momentum thickness based\nReynolds number and the roughness function. As a result, a skin-friction\ncorrelation is obtained and predictions of the transitional Reynolds numbers\nand maximal skin-friction values are made based on the roughness function.",
        "versions": [],
        "rank": 62
    },
    {
        "authors": [
            "K\u00fchn, Roland",
            "Meyer, Thomas",
            "Ricart, Cristina",
            "Zegenhagen, Mark T.",
            "Ziegler, Felix"
        ],
        "title": "Experimental investigation of a liquid desiccant system for air dehumidification working with ionic liquids",
        "publication_date": "2015-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "Energy Procedia",
        "volume": "",
        "doi": "10.14279/depositonce-6932",
        "urls": [
            "https://core.ac.uk/download/157752217.pdf"
        ],
        "id": "id5078354204106478817",
        "abstract": "Electrically-driven compression chillers are the commonly used technology for cooling and dehumidifying air. Open sorption systems driven by solar heat are an alternative to conventional air dehumidification technology and may reduce primary energy consumption. For air dehumidification, liquid desiccant systems may exhibit some process engineering and thermodynamic advantages in comparison to solid desiccant systems. The liquid desiccant must exhibit low equilibrium water vapour pressures at the available heat rejection temperature level to achieve low air dew point temperatures and thus a strong air dehumidification with comparably low driving temperatures. Desiccant mass fractions should be as low as possible, but in order to achieve low vapour pressures required desiccant mass fractions may surpass the solubility limit. In the paper at hand, first experimental results of an internally cooled and heated, open liquid desiccant system working with an ionic liquid designed for air dehumidification are presented. It is demonstrated that ionic liquids designed according to the boundary conditions of the respective application may be a promising alternative to commonly used desiccants such as lithium chloride for solar air dehumidification with comparably high heat rejection and low driving temperatures",
        "versions": [],
        "rank": 63
    },
    {
        "authors": [
            "F. Angerosa",
            "Roberta Mostallino",
            "C. Basti",
            "Raffaella Vito"
        ],
        "title": "Influence of malaxation temperature and time on the quality of virgin olive oils",
        "publication_date": "2001-01-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "",
        "volume": "72",
        "doi": "10.1016/s0308-8146(00)00194-1",
        "urls": [
            "https://openalex.org/W2093679671",
            "https://doi.org/10.1016/s0308-8146(00)00194-1"
        ],
        "id": "id-9182051830685349542",
        "abstract": "",
        "versions": [
            {
                "year": 0,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Influence of malaxation temperature and time on the quality of virgin olive oils",
                "journal": "Food Chemistry",
                "urls": [
                    "https://www.semanticscholar.org/paper/4d3128d9057afcb83ab1809595f63fa5c5873a40"
                ],
                "doi": "10.1016/S0308-8146(00)00194-1",
                "publication_date": "None"
            }
        ],
        "rank": 64
    },
    {
        "authors": [
            "Wei Bao",
            "Jun Yue",
            "Yulei Rao"
        ],
        "title": "A deep learning framework for financial time series using stacked autoencoders and long-short term memory",
        "publication_date": "2017-07-14 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "PLoS ONE",
        "volume": "12",
        "doi": "10.1371/journal.pone.0180944",
        "urls": [
            "https://www.semanticscholar.org/paper/8718f7463b65147431872def16ddd2f08059fa23",
            "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0180944&type=printable"
        ],
        "id": "id6983190324910332156",
        "abstract": "The application of deep learning approaches to finance has received a great deal of attention from both investors and researchers. This study presents a novel deep learning framework where wavelet transforms (WT), stacked autoencoders (SAEs) and long-short term memory (LSTM) are combined for stock price forecasting. The SAEs for hierarchically extracted deep features is introduced into stock price forecasting for the first time. The deep learning framework comprises three stages. First, the stock price time series is decomposed by WT to eliminate noise. Second, SAEs is applied to generate deep high-level features for predicting the stock price. Third, high-level denoising features are fed into LSTM to forecast the next day\u2019s closing price. Six market indices and their corresponding index futures are chosen to examine the performance of the proposed model. Results show that the proposed model outperforms other similar models in both predictive accuracy and profitability performance.",
        "versions": [
            {
                "year": 2017,
                "source": "SupportedSources.OPENALEX",
                "title": "A deep learning framework for financial time series using stacked autoencoders and long-short term memory",
                "journal": "",
                "urls": [
                    "https://openalex.org/W2734777338",
                    "https://doi.org/10.1371/journal.pone.0180944",
                    "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0180944&type=printable"
                ],
                "doi": "10.1371/journal.pone.0180944",
                "publication_date": "2017-07-14 00:00:00"
            }
        ],
        "rank": 65
    },
    {
        "authors": [
            "Cohen-Cole, Ethan",
            "Morse, Jonathan"
        ],
        "title": "Monetary policy and capital regulation in the US and Europe",
        "publication_date": "None",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "https://core.ac.uk/download/pdf/6497626.pdf"
        ],
        "id": "id-7257279811946330703",
        "abstract": "From the onset of the 2007-2009 crisis, the Federal Reserve and the European Central Bank have aggressively lowered interest rates. Both sets of changes are at odds with an anti-inflationary stance of monetary policy; indeed, as the crisis began in August 2007 inflation expectations were high and rising, particularly in the United States. We have two additions to the literature. One, we present a model economy with a leveraged and regulated financial sector. Two, we find optimal Taylor rules for our economy that are consistent with a strong pro-inflationary reaction during financial crisis while maintaining a standard output-inflation mandate. We have three interpretations of our results. One, because the Federal Reserve has partial control over bank regulation it can exercise regulatory lenience. Two, the Fed\u2019s stronger output orientation means that it will potentially respond more quickly when faced with constrained banks. Three, our results support procyclical capital regulation. JEL Classification: E52, E58, G18, G28capital regulation, crisis, monetary policy",
        "versions": [],
        "rank": 66
    },
    {
        "authors": [
            "M. Hertzberg",
            "I. Zlochower",
            "K. Cashdollar"
        ],
        "title": "Volatility model for coal dust flame propagation and extinguishment",
        "publication_date": "None",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "21",
        "doi": "10.1016/S0082-0784(88)80260-1",
        "urls": [
            "https://www.semanticscholar.org/paper/7d2ba92d8aece9fa79e4ac48c5661eba312fbab3"
        ],
        "id": "id4784956059787011629",
        "abstract": null,
        "versions": [],
        "rank": 67
    },
    {
        "authors": [
            "Ingo Krossing",
            "Andreas Reisinger"
        ],
        "title": "Chemistry with weakly-coordinating fluorinated alkoxyaluminate anions: Gas phase cations in condensed phases?",
        "publication_date": "2006-11-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "",
        "volume": "250",
        "doi": "10.1016/j.ccr.2005.10.023",
        "urls": [
            "https://openalex.org/W1994212274",
            "https://doi.org/10.1016/j.ccr.2005.10.023"
        ],
        "id": "id552283905206516024",
        "abstract": "",
        "versions": [
            {
                "year": 2006,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Chemistry with weakly-coordinating fluorinated alkoxyaluminate anions: Gas phase cations in condensed phases?",
                "journal": "Coordination Chemistry Reviews",
                "urls": [
                    "https://www.semanticscholar.org/paper/b02ef6e81d29e8a7505a78927d54fa459a5bcfe7"
                ],
                "doi": "10.1016/J.CCR.2005.10.023",
                "publication_date": "2006-11-01 00:00:00"
            }
        ],
        "rank": 68
    },
    {
        "authors": [
            "Barrett, Christopher B.",
            "Bellemare, Marc F.",
            "Just, David R."
        ],
        "title": "The Welfare Impacts of Commodity Price Fluctuations: Evidence from Rural Ethiopia",
        "publication_date": "None",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "https://core.ac.uk/download/pdf/6465925.pdf"
        ],
        "id": "id-1634639898909008893",
        "abstract": "Many governments try to stabilize commodity prices based on the widespread belief that households value price stability and that the poor especially benefit from food price stabilization. We derive an exact measure of multivariate price risk aversion and of associated household willingness to pay for price stabilization across multiple commodities. Using data from a panel of Ethiopian households, we estimate that the average household would be willing to pay 6-32 percent of its income to eliminate fluctuations in the prices of the seven primary food commodities. But not everyone benefits from price stabilization. Contrary to conventional wisdom, the welfare gains from eliminating price fluctuations would be concentrated in the upper 40 percent of the income distribution, making food price stabilization a distributionally regressive policy in this context.Price Fluctuations; Price Stabilization; Price Risk; Risk and Uncertainty",
        "versions": [],
        "rank": 69
    },
    {
        "authors": [
            "Truc Le"
        ],
        "title": "Stochastic market volatility models",
        "publication_date": "2005-05-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Applied Financial Economics Letters",
        "volume": "1",
        "doi": "10.1080/17446540500101986",
        "urls": [
            "https://www.semanticscholar.org/paper/e8c07d8f64429fe2c352a013ceae68f0382b6484"
        ],
        "id": "id7507226762122067673",
        "abstract": "A new market-based approach to evaluating options on an asset is offered. The model corresponds to the real situations encountered in the market: option prices are not uniquely determined by their underlying asset but mainly by another factor, namely stochastic market volatility (or simply SMV). To begin constructing SMV, it is assumed that there exists a hedging portfolio which replicates perfectly the value of the underlying option. By \u2018perfectly\u2019, it is meant that the value of the hedging portfolio will always equal exactly to the option. The hedging portfolio takes asset price and SMV as its input, therefore, for a given asset price the correct value of SMV gives the correct value for the option. SMV presents the dynamics of options market. We provide the proof of existence and uniqueness of solutions for SMV.",
        "versions": [
            {
                "year": 2005,
                "source": "SupportedSources.CROSSREF",
                "title": "Stochastic market volatility models",
                "journal": "",
                "urls": [
                    "http://www.tandfonline.com/doi/pdf/10.1080/17446540500101986",
                    "http://dx.doi.org/10.1080/17446540500101986"
                ],
                "doi": "10.1080/17446540500101986",
                "publication_date": "2005-01-01 00:00:00"
            }
        ],
        "rank": 70
    },
    {
        "authors": [
            "Stephan Haug",
            "Claudia Kl\u00fcppelberg",
            "German Straub"
        ],
        "title": "Fractionally integrated COGARCH processes",
        "publication_date": "2015-01-15 14:35:11+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1501.03694v3",
            "http://arxiv.org/abs/1501.03694v3",
            "http://arxiv.org/pdf/1501.03694v3"
        ],
        "id": "id4120786805123572186",
        "abstract": "We construct fractionally integrated continuous-time GARCH models, which\ncapture the observed long range dependence of squared volatility in\nhigh-frequency data. Since the usual Molchan-Golosov and Mandelbrot-van-Ness\nfractional kernels lead to problems in the definition of the model, we resort\nto moderately long memory processes by choosing a fractional parameter\n$d\\in(-0.5,0)$ and remove the singularities of the kernel to obtain\nnon-pathological sample paths. The volatility of the new fractional COGARCH\nprocess has positive features like stationarity, and its covariance function\nshows an algebraic decay, which make it applicable to econometric\nhigh-frequency data. In an empirical application the model is fitted to\nexchange rate data using a simulation-based version of the generalised method\nof moments.",
        "versions": [],
        "rank": 71
    },
    {
        "authors": [
            "A. Gulisashvili"
        ],
        "title": "Large Deviation Principle for Volterra Type Fractional Stochastic Volatility Models",
        "publication_date": "2017-10-29 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "SIAM J. Financial Math.",
        "volume": "9",
        "doi": "10.1137/17M116344X",
        "urls": [
            "https://www.semanticscholar.org/paper/08fb79200492577b7e558298a8dd28e063d021d3",
            "http://arxiv.org/pdf/1710.10711"
        ],
        "id": "id150933251597474561",
        "abstract": "We study fractional stochastic volatility models for the asset price, in which the volatility process is a positive continuous function $\\sigma$ of a continuous fractional stochastic process $\\widehat{B}$. The main result obtained in the present paper is a generalization of the large deviation principle for the log-price process due to M. Forde and H. Zhang. In their work, Forde and Zhang assume that the function $\\sigma$ satisfies a global H\\\"{o}lder condition and $\\widehat{B}$ is fractional Brownian motion, whereas in the present paper, the function $\\sigma$ satisfies a very mild condition expressed in terms of a local modulus of continuity, while the process $\\widehat{B}$ is a general Volterra type Gaussian process. We establish a small-noise large deviation principle for the log-price in a fractional stochastic volatility model, and under an additional condition of self-similarity of the process $\\widehat{B}$, derive a similar large deviation principle in the small-time regime. Using the latter result, we obtain asymptotic formulas for binary options, call and put options, and the implied volatility in the small-maturity small-log-moneyness regime.",
        "versions": [
            {
                "year": 2018,
                "source": "SupportedSources.CROSSREF",
                "title": "Large Deviation Principle for Volterra Type Fractional Stochastic Volatility Models",
                "journal": "",
                "urls": [
                    "https://epubs.siam.org/doi/pdf/10.1137/17M116344X",
                    "http://dx.doi.org/10.1137/17m116344x"
                ],
                "doi": "10.1137/17m116344x",
                "publication_date": "2018-01-01 00:00:00"
            }
        ],
        "rank": 72
    },
    {
        "authors": [
            "Hans J. Czap",
            "Kanybek Nur-tegin"
        ],
        "title": "Corruption: Democracy, Autocracy, and Political Stability",
        "publication_date": "None",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "https://core.ac.uk/download/pdf/6552586.pdf"
        ],
        "id": "id2430560876329990978",
        "abstract": "The recent empirical literature on corruption has identified a long list of variables that correlate significantly with corruption but only five were distinguished by Leamer\u2019s Extreme Bounds Analysis as robust to various samples, measures of corruption, and regression specifications. Among these five factors that were found to reduce corruption are decades-long tradition of democracy and political stability. In today\u2019s world, however, there are many countries that combine one of these two robust determinants of corruption with the opposite of the other: politically stable autocracies or newly formed and unstable democracies. The central question raised in this paper is: Is it worth, in terms of corruption, for a country to trade stability with autocratic rule for political freedoms but with transitional instability? We find that the answer to this question is in the affirmative - the level of corruption is indeed lower in unstable democracies than in stable dictatorships. Our results are robust to various measures of corruption, alternative regressor indices, and regression specifications.corruption, democracy, autocracy, dictatorship, political stability",
        "versions": [],
        "rank": 73
    },
    {
        "authors": [
            "Th\u00e9ophile Griveau-Billion",
            "Ben Calderhead"
        ],
        "title": "A Dynamic Bayesian Model for Interpretable Decompositions of Market Behaviour",
        "publication_date": "2019-04-17 09:30:42+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1904.08153v3",
            "http://arxiv.org/abs/1904.08153v3",
            "http://arxiv.org/pdf/1904.08153v3"
        ],
        "id": "id1945279420945185446",
        "abstract": "We propose a heterogeneous simultaneous graphical dynamic linear model\n(H-SGDLM), which extends the standard SGDLM framework to incorporate a\nheterogeneous autoregressive realised volatility (HAR-RV) model. This novel\napproach creates a GPU-scalable multivariate volatility estimator, which\ndecomposes multiple time series into economically-meaningful variables to\nexplain the endogenous and exogenous factors driving the underlying\nvariability. This unique decomposition goes beyond the classic one step ahead\nprediction; indeed, we investigate inferences up to one month into the future\nusing stocks, FX futures and ETF futures, demonstrating its superior\nperformance according to accuracy of large moves, longer-term prediction and\nconsistency over time.",
        "versions": [],
        "rank": 74
    },
    {
        "authors": [
            "S.P. Nandi",
            "Philip M Walker"
        ],
        "title": "Activated diffusion of methane in coal",
        "publication_date": "1970-07-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "",
        "volume": "49",
        "doi": "10.1016/0016-2361(70)90023-2",
        "urls": [
            "https://openalex.org/W2011047501",
            "https://doi.org/10.1016/0016-2361(70)90023-2"
        ],
        "id": "id8534248777520255022",
        "abstract": "",
        "versions": [
            {
                "year": 1970,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Activated diffusion of methane in coal",
                "journal": "Fuel",
                "urls": [
                    "https://www.semanticscholar.org/paper/f3259b5bc7973b2878ee49962c6db8576518c324"
                ],
                "doi": "10.1016/0016-2361(70)90023-2",
                "publication_date": "1970-07-01 00:00:00"
            }
        ],
        "rank": 75
    },
    {
        "authors": [
            "Yu Zheng",
            "Yongxin Yang",
            "Bowei Chen"
        ],
        "title": "Incorporating prior financial domain knowledge into neural networks for implied volatility surface prediction",
        "publication_date": "2019-04-29 17:35:41+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "10.1145/3447548.3467115",
        "urls": [
            "http://arxiv.org/pdf/1904.12834v5",
            "http://dx.doi.org/10.1145/3447548.3467115",
            "http://arxiv.org/abs/1904.12834v5",
            "http://arxiv.org/pdf/1904.12834v5"
        ],
        "id": "id-1423861270468693751",
        "abstract": "In this paper we develop a novel neural network model for predicting implied\nvolatility surface. Prior financial domain knowledge is taken into account. A\nnew activation function that incorporates volatility smile is proposed, which\nis used for the hidden nodes that process the underlying asset price. In\naddition, financial conditions, such as the absence of arbitrage, the\nboundaries and the asymptotic slope, are embedded into the loss function. This\nis one of the very first studies which discuss a methodological framework that\nincorporates prior financial domain knowledge into neural network architecture\ndesign and model training. The proposed model outperforms the benchmarked\nmodels with the option data on the S&P 500 index over 20 years. More\nimportantly, the domain knowledge is satisfied empirically, showing the model\nis consistent with the existing financial theories and conditions related to\nimplied volatility surface.",
        "versions": [],
        "rank": 76
    },
    {
        "authors": [
            "Amir Ahmad Dar",
            "N. Anuradha"
        ],
        "title": "Use of orthogonal arrays and design of experiment via Taguchi L9 method in probability of default",
        "publication_date": "2018-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Growing Science",
        "volume": "",
        "doi": "10.5267/j.ac.2017.11.001",
        "urls": [
            "https://web.archive.org/web/20190308190222/http://pdfs.semanticscholar.org/ed21/2d6cadd3f86b4d7e9b340c075257dc927b97.pdf"
        ],
        "id": "id5735485343755513922",
        "abstract": "The Taguchi's orthogonal array is based on a mathematical model of factorial designs. This paper investigates the effects of four parameters in Probability of Default (PD) using Black-Scholes model (BSM) for call option at one period by considering asset value , firm's debt , expected growth and the volatility . The main aim is to determine which parameters affect mostly on PD of a firm. The experiment is based on the orthogonal array L9 in which the four parameters are varied at three levels. Finally, the ANOM is used to describe the best combination and ANOVA is implemented to measure the contribution of the given independent variables.",
        "versions": [],
        "rank": 77
    },
    {
        "authors": [
            "P. M. Reimer",
            "Y. Yamaguchi",
            "J. H. Li",
            "H. Hashizume"
        ],
        "title": "Correlated roughness information from diffuse X-ray scattering of stepped surfaces",
        "publication_date": "1996-08-08 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "International Union of Crystallography (IUCr)",
        "volume": "",
        "doi": "10.1107/s0108767396080610",
        "urls": [
            "https://web.archive.org/web/20180719090934/http://journals.iucr.org/a/issues/1996/a1/00/a42139/a42139.pdf"
        ],
        "id": "id-4122645668182727650",
        "abstract": "The measurements of diffuse scattering (DS) in grazing incidence x-ray diffraction (GID) can provide infonnation on atomic ordering in smface and interface roughness of crystals which is not accessible l:iy usual specular and non-specular x-ray scatteting. In contrast to the usual non-specular x-ray scattering which is proportional to the mean fluctuations of matetial density 8:;co. the DS in GID is mainly detem1ined by fluctuations of crystal pola.rizability 8:;ch. where his the reciprocal lattice vector con\u00b7esponding to GID. A theory of DS on correlated and uncorrelated interface roughness under GID based on the matrix solution to GID in multilayers and the distorted wave Bom approximation is applied to two GID experiments with an etched Ge smface and a GaAs/AlAs superlattice car1ied out at CHESS and ESRF, respectively. In both cases a good accordance between the theory and the expetiment is observed. In the case of the etched Ge smface, an anti-Yoneda dip in the DS pattern at the Bragg peak and two symmetric shoulders on the Bragg curve wings have been found and explained. In the case of the GaAs/ AlAs super lattice, the DS sepmated from the coherent GID by means of high-resolution measurements was compa.r\u00b7ed to x-ray reflectivity data and it has been shown that the atomic ordeting was preserved in the intetface roughness, while it was pmtially destroyed in the surface roughness. MS12.03.08 CORRELATED ROUGHNESS INFORJ.vLI\\TION FROM DIFFUSE X-RAY SCATTERING OF STEPPED SUR-FACES. P.M. Reimer, Y. Ylli11aguchi, J.H. Li, H. Hashizume, Tokyo Institute of Technology We discuss the problem of extracting useful infom1ation on intetfacial roughness con\u00b7eJations from glancing angle diffuse scattering data. In recent yems, the distorted wave Bom approximation (DWBA) has been successfully applied to model diffuse scattering from fractally rough surfaces. However, many smfaces/interfaces of interest a.r\u00b7e often stepped due to small substt\u00b7ate miscut angles, ar1d the fractal approach does not take into account such stt\u00b7ong, periodic, correlated intetface structures. We discuss how to extt\u00b7act infotmation on roughness para.I11eters and roughness conelations from the diffuse intensity under such circumstances, using Si/SiGe heterostt\u00b7uctures and calcite surfaces as examples. (Applications will be found in related presentations by J.H. Li andY. Yamaguchi). PS12.03.09 IN-SITU X-RW REFLECTIVITY MEASURE-MENT OF THIN FILM GROWTH. Chih-Hao Lee and Sung-Yuh Tseng, Department of Nuclear Engineering and Engineeting Physics, National Tsing Hua University, Hsinchu, Taiwan, 30043 X-ray reflectivity method was used to measure in-situ the thickness and smface roughness of a thin film during deposition growth. Intensity oscillation as function of time car1 be observed as the film thickness grows. The oscillation a.rnplitude is damped as the surface roughness increase. The experiment procedure is similiar to ellipsometry or RHLEED. Wnile only kinematic theory is needed to interpret the experiment data, the X-ray reflectivity method is much easier to fit the model. In this method, the measurement sensitivity of the film thickness can be selected by changing the specular angle. A higher incidence angle is more sensitive to thinner layer. As the speculm angle approaches anti-Bragg angle, the measurement is sensitive to the monolayer growth of the thin film. PS12.03. A literature review on volatile Zn(II), Cd(II), Hg(II) dialkyldithiocmbamates has been made; their crystal structures, IR and UV spectra, thermal properties have been analyzed. A number of new dialkyldithiocarbamates with different alkyl substituents was synthesized. The layers of up to 1 nllan from both homo-and heterometallic diethyeldithiocarbamato-iodine complexes ([MM'(Et2NCS2hi2], M,M' = Zn, Cd, Hg) were obtained by means of evaporation in vacuum and further vapor deposition on silicon, qua.r\u00b7tz and glass substrates. An analysis of the X-ray powder patterns leads to the next conclusions: the layers a.r\u00b7e the ideal oriented polycrystal films in all cases; in the case of M=M'=Cd complexes, the crystal structure of the films obtained differs from the initial one; for M=Cd, M'=Hg, the films obtained have both an1orphous and crystal structures. The latters have the [001] texture axis. The sh'Lictural organization of the layers in the following direction was analyzed: the scale of the location of these complexes and their orientation relative to the smface. It was shown that the film smface is formed by C2Hs terminal groups. The films were subjected to thermolysis until the corresponding sulphides arose. The surface diffracted waves a.r\u00b7e theoretically investigated versus on the azimuth and pole angles of incidence of X-rays with the wave front amplitude periodically vmying along the single crystal (SC) surface. The smface waves a.r\u00b7e attenuating on both sides across the vacuum-structure boundmy. The following scheme of X-ray grazing incidence diffraction (GID) is investigated: The Xray plane wave is reflected by the diffraction grating (DG). The reflected radiation's wave front amplitude is va.r\u00b7ying periodically along the same direction, at which the reflecting elements of DG are petiodically deposited. Then the reflected wave falls at grazing angles onto a SC. The diffracting lattice planes of SC a.r\u00b7e normal to the entrance surface (symmet1ical Laue case). Due to modern technologies the device performing elements' thicknesses are in nanometer ranges e.g. in the integrated circuits, solid state lasers etc., and if in particular\u00b7 the performing elements a.r\u00b7e deposited pe1iodically on the substrate, one may consider the device surface layer as the reflecting DG for the X -rays. The reflection function of such DG may be used for the control ar1d monitoring of device surface elements quality. The conditions at which the reflected from DG X-ray wave field has the nmrow angular spectrum are investigated in detail. The method of investigation of such modulated incident waves by the GID technique is suggested.",
        "versions": [],
        "rank": 78
    },
    {
        "authors": [
            "Horst Uwe Keller",
            "Ekkehard K\u00fchrt"
        ],
        "title": "Cometary Nuclei\u2014From Giotto to Rosetta",
        "publication_date": "2020-01-29 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Springer Science and Business Media LLC",
        "volume": "",
        "doi": "10.1007/s11214-020-0634-6",
        "urls": [
            "https://web.archive.org/web/20200507215706/https://link.springer.com/content/pdf/10.1007/s11214-020-0634-6.pdf"
        ],
        "id": "id-5214964267043333276",
        "abstract": "We will briefly recapitulate the beginning of modern cometary physic. Then we will assess the results of the cometary flyby missions previous to ESA's Rosetta rendezvous with comet 67P/Churyumov-Gerasimenko. Emphasis is given to the physical properties of cometary nuclei. We will relate the results of the Rosetta mission to those of the flybys. A major conclusion is that the visited cometary nuclei seem to be alike but represent different stages of evolution. Coma composition and appearance are not only controlled by the composition of the nucleus but also strongly influenced by the shape and rotation axis orientation of the nucleus and resulting seasons that generate varying surface coverage by back fall material. Rosetta showed that the coma composition is not only varying spatially but also strongly with time during the perihelion passage. Hence past interpretations of cometary coma observations have to be re-considered. Finally, we will try to assess the impact of the cornerstone mission leading to a critical evaluation of the mission results. Lessons learned from Rosetta are discussed; major progress and open points in cometary research are reviewed.",
        "versions": [],
        "rank": 79
    },
    {
        "authors": [
            "Xue-cheng Wu",
            "L. Yao",
            "Yingchun Wu",
            "Xiaodan Lin",
            "Ling-hong Chen",
            "Jun Chen",
            "Xiang Gao",
            "K. Cen"
        ],
        "title": "In-Situ Characterization of Coal Particle Combustion via Long Working Distance Digital In-Line Holography",
        "publication_date": "2018-07-19 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1021/ACS.ENERGYFUELS.8B01685",
        "urls": [
            "https://www.semanticscholar.org/paper/e13fcce6be789931016e11d9402bd9ccf591f48e"
        ],
        "id": "id-8420561623881420279",
        "abstract": "A long working distance digital holographic system is developed to study burning coal particles, which are less than 200 \u03bcm in diameter, in a methane-air flame. A general model for the lensed digit...",
        "versions": [
            {
                "year": 2018,
                "source": "SupportedSources.OPENALEX",
                "title": "In-Situ Characterization of Coal Particle Combustion via Long Working Distance Digital In-Line Holography",
                "journal": "",
                "urls": [
                    "https://openalex.org/W2883690153",
                    "https://doi.org/10.1021/acs.energyfuels.8b01685"
                ],
                "doi": "10.1021/acs.energyfuels.8b01685",
                "publication_date": "2018-07-19 00:00:00"
            }
        ],
        "rank": 80
    },
    {
        "authors": [
            "F. Loreto",
            "P. Nascetti",
            "A. Graverini",
            "M. Mannozzi"
        ],
        "title": "Emission and content of monoterpenes in intact and wounded needles of the Mediterranean pine, Pinus pinea",
        "publication_date": "2000-10-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Functional Ecology",
        "volume": "14",
        "doi": "10.1046/J.1365-2435.2000.T01-1-00457.X",
        "urls": [
            "https://www.semanticscholar.org/paper/4e97c3bc5a160adfb8bb1c60182d98e18b3b6d90"
        ],
        "id": "id7762890662416036718",
        "abstract": "1.\u2002Biogenic emission of isoprenoids may be involved in protecting plants against pathogens and may interfere with the chemistry of atmosphere. Pinus pinea (L.) is one of the most widespread conifers in the Mediterranean area and is a potentially strong emitter of monoterpenes. \n \n2.\u2002We demonstrated by gas-exchange studies that monoterpenes other than trans-\u03b2-ocimene are not emitted significantly by intact primary and secondary needles of 3-year-old P. pinea plants. \n \n3.\u2002Trans-\u03b2-ocimene emission is light- and CO2-dependent. Therefore this compound is probably formed from photosynthetic carbon in the chloroplasts and does not originate from the same biochemical route as other monoterpenes stored in resin ducts. \n \n4.\u2002Trans-\u03b2-ocimene emission starts in spring, peaks in summer and ceases at the end of summer. This strong seasonality may mark a phase-shift in needle ontogeny, but is not related strictly to changes in photosynthesis. \n \n5.\u2002Wounded needles, either illuminated or darkened, massively release monoterpenes contained in the ducts, primarily limonene and \u03b1-pinene. Monoterpene release from wounded needles rapidly decreases but does not cease altogether, even after 24\u00a0h. The amount of monoterpenes emitted from wounded needles in 24\u00a0h can be estimated at about 1200 and 120\u00a0\u00b5mol\u00a0g\u00a0\u22121\u00a0day\u22121 (dry mass) of limonene and \u03b1-pinene, respectively. Wounded needles are a main contributor to monoterpene emission by vegetation. \n \n6.\u2002Monoterpene content is two to three times greater in primary than in secondary needles. In primary needles, typical only of young plants, the elevated content of monoterpenes may allow plant survival against pathogenic attacks.",
        "versions": [
            {
                "year": 2000,
                "source": "SupportedSources.OPENALEX",
                "title": "Emission and content of monoterpenes in intact and wounded needles of the Mediterranean Pine, <i>Pinus pinea</i>",
                "journal": "",
                "urls": [
                    "https://openalex.org/W2068097374",
                    "https://doi.org/10.1046/j.1365-2435.2000.t01-1-00457.x"
                ],
                "doi": "10.1046/j.1365-2435.2000.t01-1-00457.x",
                "publication_date": "2000-10-01 00:00:00"
            }
        ],
        "rank": 81
    },
    {
        "authors": [
            "Michael Funke",
            "Yu-Fu Chen"
        ],
        "title": "Global Warming and Extreme Events: Rethinking the Timing and Intensity of Environmental Policy",
        "publication_date": "None",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "https://core.ac.uk/download/pdf/6634486.pdf"
        ],
        "id": "id-7299472791043896599",
        "abstract": "The possibility of low-probability extreme events has reignited the debate over the optimal intensity and timing of climate policy. In this paper we therefore contribute to the literature by assessing the implications of low-probability extreme events on environmental policy in a continuous-time real options model with \u201ctail risk\u201d. In a nutshell, our results indicate the importance of tail risk and call for foresighted pre-emptive climate policies.climate policy, extreme events, real options, Levy process",
        "versions": [],
        "rank": 82
    },
    {
        "authors": [
            "W. Fei",
            "Yuanping Cheng",
            "Shouqing Lu",
            "K. Jin",
            "Wei Zhao"
        ],
        "title": "Influence of Coalification on the Pore Characteristics of Middle\u2013High Rank Coal",
        "publication_date": "2014-08-28 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Energy & Fuels",
        "volume": "28",
        "doi": "10.1021/EF5014055",
        "urls": [
            "https://www.semanticscholar.org/paper/94a4e1aa18d794c2b54da834d456076f3e65a2f4"
        ],
        "id": "id-6742518230625673751",
        "abstract": "The pore size distribution, pore shape and connectivity, and fractal characteristics are investigated to determine the pore characteristics of three different samples of middle\u2013high rank coal. Pores of more than and less than 10 nm were measured using mercury intrusion porosimetry (MIP) and gas adsorption, respectively. The pore size distribution was verified with the initial methane diffusion rate and CH4 desorption. Fractal dimensions of seepage pores and adsorption pores were counted using the results from MIP and gas adsorption, respectively. First, the results show that micropores and transition pores occupy the most volume and specific surface area. Micropores and transition pores, as well as porosity, gradually increase as coal rank increases. Second, the fractal dimensions of seepage pores and adsorption pores gradually increase with increasing coal rank, which shows that coalification makes pore structure more complex and pore surface rougher. Additionally, the fractal dimensions of bigger pores ...",
        "versions": [
            {
                "year": 2014,
                "source": "SupportedSources.OPENALEX",
                "title": "Influence of Coalification on the Pore Characteristics of Middle\u2013High Rank Coal",
                "journal": "",
                "urls": [
                    "https://openalex.org/W2322066449",
                    "https://doi.org/10.1021/ef5014055"
                ],
                "doi": "10.1021/ef5014055",
                "publication_date": "2014-08-28 00:00:00"
            }
        ],
        "rank": 83
    },
    {
        "authors": [
            "Y. Yao"
        ],
        "title": "Generalization of Rough Sets Using Relationships Between Attribute Values",
        "publication_date": "None",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://www.semanticscholar.org/paper/ae5431d1ed6dff0b3757876097d8d6ddef23a3a8"
        ],
        "id": "id-1685528247277641794",
        "abstract": "The notion of rough sets is generalized by using an arbitrary binary relation on attribute values in information systems, instead of the trivial equality relation. The relation, not necessarily equivalence, between objects are defined in terms of relationships between attribute values. The adoption of other types of relations enables us to define various classes of rough set models. This study provides a basis for nonstandard rough sets. The results are complementary to that of investigations based on modal logic.",
        "versions": [],
        "rank": 84
    },
    {
        "authors": [
            "Wei-dong Shi",
            "Hong-liang Wang",
            "Ling Zhou",
            "Ping-ping Zou",
            "Chuan Wang"
        ],
        "title": "The Estimation and Experiment of Axial Force in Deep Well Pump Basing on Numerical Simulation",
        "publication_date": "2010-12-16 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "MECS Publisher",
        "volume": "",
        "doi": "10.5815/ijmecs.2010.02.08",
        "urls": [
            "https://web.archive.org/web/20190428170915/http://www.mecs-press.org/ijmecs/ijmecs-v2-n2/IJMECS-V2-N2-8.pdf"
        ],
        "id": "id2418131542394755013",
        "abstract": "an axial force estimation is a crucial problem in the design of a deep well pump. According to the cost of time and financial resources by experimental measurement and low precision and applicability of using experiential formulas, the effects of solid modeling, mesh generation, residual convergence precision, turbulence model and numerical solutions on the accuracy of numerical simulation were investigated. And the best scheme was applied in the numerical simulation to predict the axial thrust of the deep well pump. The simulation values of axial force are in agreement with the testing values, and the maximum error is less than 10%.",
        "versions": [],
        "rank": 85
    },
    {
        "authors": [
            "Dimos S. Kambouroudis",
            "D. McMillan",
            "Katerina Tsakou"
        ],
        "title": "Forecasting realized volatility: The role of implied volatility, leverage effect, overnight returns, and volatility of realized volatility",
        "publication_date": "2021-07-15 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1002/FUT.22241",
        "urls": [
            "https://www.semanticscholar.org/paper/7b0890c3dade16a293b42ee2f3857e9ac34f8cc2",
            "https://cronfa.swan.ac.uk/Record/cronfa57115/Download/57115__20620__517e5fbd074641039bd407ab7828e055.pdf"
        ],
        "id": "id-2957462775622800377",
        "abstract": "We examine the role of implied volatility, leverage effect, overnight returns and volatility of realized volatility in forecasting realized volatility by extending the heterogeneous autoregressive (HAR) model to include these additional variables. We find that implied volatility is important in forecasting future realized volatility. In most cases a model that accounts for implied volatility provides a significantly better forecast than more sophisticated models that account for other features of volatility, but exclude the information backed out from option prices. This result is consistent over time. We also assess whether leverage effect, overnight returns and volatility of realized volatility carry any incremental information beyond that captured by implied volatility and past realized volatility. We find that while overnight returns and leverage e\u02d9ect are important for some markets, the volatility of realized volatility is of limited value for most stock markets.",
        "versions": [
            {
                "year": 2021,
                "source": "SupportedSources.CROSSREF",
                "title": "Forecasting realized volatility: The role of implied volatility, leverage effect, overnight returns, and volatility of realized volatility",
                "journal": "",
                "urls": [
                    "https://onlinelibrary.wiley.com/doi/pdf/10.1002/fut.22241",
                    "https://onlinelibrary.wiley.com/doi/full-xml/10.1002/fut.22241",
                    "https://onlinelibrary.wiley.com/doi/pdf/10.1002/fut.22241",
                    "http://dx.doi.org/10.1002/fut.22241"
                ],
                "doi": "10.1002/fut.22241",
                "publication_date": "2021-07-15 00:00:00"
            }
        ],
        "rank": 86
    },
    {
        "authors": [
            "Piotr Szczepocki"
        ],
        "title": "Application of iterated filtering to stochastic volatility models based on non-Gaussian Ornstein-Uhlenbeck process",
        "publication_date": "2020-06-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Statistics in Transition New Series",
        "volume": "21",
        "doi": "10.21307/stattrans-2020-019",
        "urls": [
            "https://www.semanticscholar.org/paper/29074ec477013c2e4da4371d65b93dfb7e454f45",
            "https://sciendo.com/pdf/10.21307/stattrans-2020-019"
        ],
        "id": "id-4074192652366165352",
        "abstract": "Abstract Barndorff-Nielsen and Shephard (2001) proposed a class of stochastic volatility models in which the volatility follows the Ornstein\u2013Uhlenbeck process driven by a positive Levy process without the Gaussian component. The parameter estimation of these models is challenging because the likelihood function is not available in a closed-form expression. A large number of estimation techniques have been proposed, mainly based on Bayesian inference. The main aim of the paper is to present an application of iterated filtering for parameter estimation of such models. Iterated filtering is a method for maximum likelihood inference based on a series of filtering operations, which provide a sequence of parameter estimates that converges to the maximum likelihood estimate. An application to S&P500 index data shows the model perform well and diagnostic plots for iterated filtering ensure convergence iterated filtering to maximum likelihood estimates. Empirical application is accompanied by a simulation study that confirms the validity of the approach in the case of Barndorff-Nielsen and Shephard\u2019s stochastic volatility models.",
        "versions": [
            {
                "year": 2020,
                "source": "SupportedSources.CROSSREF",
                "title": "Application of iterated filtering to stochastic volatility models based on non-Gaussian Ornstein-Uhlenbeck process",
                "journal": "",
                "urls": [
                    "https://www.sciendo.com/pdf/10.21307/stattrans-2020-019",
                    "http://dx.doi.org/10.21307/stattrans-2020-019"
                ],
                "doi": "10.21307/stattrans-2020-019",
                "publication_date": "2020-06-01 00:00:00"
            }
        ],
        "rank": 87
    },
    {
        "authors": [
            "Qingqing Liu",
            "Di Gao",
            "Wei Xu"
        ],
        "title": "Effect of Sanding Processes on the Surface Properties of Modified Poplar Coated by Primer Compared with Mahogany",
        "publication_date": "2020-09-02 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "MDPI AG",
        "volume": "",
        "doi": "10.3390/coatings10090856",
        "urls": [
            "https://web.archive.org/web/20200908182352/https://res.mdpi.com/d_attachment/coatings/coatings-10-00856/article_deploy/coatings-10-00856-v2.pdf"
        ],
        "id": "id-5490463931934001423",
        "abstract": "The surface roughness, static and dynamic liquid wettability of modified poplar wood were measured by different surface treatment of brushing primer and sanding. With the increase of the number of grinding paper, the depth parameters Ra, Ry, Rz and Rp of surface roughness of modified poplar decreased, and the density parameter Sm (the average spacing of micro unevenness of contour) decreased at first and then increased. With the increase of number of the grinding paper, the contact angle of water and glycerol for modified poplar wood decreased at first and then increased. After the modified poplar wood was brushed with the primer and sanded with 240# sandpaper, the density parameter Sm was 0.307, the equilibrium contact angle of distilled water was 34.88, and the equilibrium contact angle of glycerin was 36.46, all of which were the lowest number. At this time, the surface roughness was improved, and the modified poplar has the good wettability that is greater than the mahogany wood wettability. Compared with mahogany, the rough depth parameters of the modified poplar are smaller to those of mahogany, but the Sm of modified poplar wood is greater than that of the mahogany. After the same surface pretreatment, the wetting speed of glycerol on the surface of mahogany is higher than that of the modified poplar.",
        "versions": [],
        "rank": 88
    },
    {
        "authors": [
            "R\u00faben Sousa",
            "Ana Bela Cruzeiro",
            "Manuel Guerra"
        ],
        "title": "Barrier Option Pricing under the 2-Hypergeometric Stochastic Volatility Model",
        "publication_date": "2016-10-11 08:10:45+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "10.1016/j.cam.2017.06.034",
        "urls": [
            "http://arxiv.org/pdf/1610.03230v2",
            "http://dx.doi.org/10.1016/j.cam.2017.06.034",
            "http://arxiv.org/abs/1610.03230v2",
            "http://arxiv.org/pdf/1610.03230v2"
        ],
        "id": "id-5815885867876351893",
        "abstract": "We investigate the pricing of financial options under the 2-hypergeometric\nstochastic volatility model. This is an analytically tractable model that\nreproduces the volatility smile and skew effects observed in empirical market\ndata.\n  Using a regular perturbation method from asymptotic analysis of partial\ndifferential equations, we derive an explicit and easily computable approximate\nformula for the pricing of barrier options under the 2-hypergeometric\nstochastic volatility model. The asymptotic convergence of the method is proved\nunder appropriate regularity conditions, and a multi-stage method for improving\nthe quality of the approximation is discussed. Numerical examples are also\nprovided.",
        "versions": [],
        "rank": 89
    },
    {
        "authors": [
            "J. Pesl"
        ],
        "title": "The Influence of the Empirical Parameters to the Emission Model",
        "publication_date": "None",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://www.semanticscholar.org/paper/3ff25d587bbbd215b8308e4830afe1faacd9e19a"
        ],
        "id": "id7369568044085034300",
        "abstract": "The important characteristic feature of algorithms for environmental modelling is the complexity of their mathematical representation. If we do not want very rough results, it is not so easy to omit influences like weather, human factor, etc. Many parameters in algorithms and their mathematical formulations are in praxis substituted by empirical constants, although it is well known that their values are very volatile. The reason is not that the scientists do not see this variance, but they simply don't know how to introduce data uncertainty into the algorithm formulation of model or are afraid of the resulting formula complexity. In the second case, nowadays it's a good time to change it. As the information and communication technology capabilities are growing rapidly, also the software for scientists becomes strong mathematical power to overcome problems with formula complexity, specifically the computer algebra systems. As they introduced connectivity features, which were the domain of the general programming languages earlier, they can be used as full implementation tool including the practical data manipulation. This paper shows the current research of Masaryk University in Brno in the field of introducing uncertainty formulas into the algorithms solving biological and environmental mathematical models. Case study of air pollution caused by the transport will be presented.",
        "versions": [],
        "rank": 90
    },
    {
        "authors": [
            "C. Kl\u00fcppelberg",
            "A. Lindner",
            "R. Maller"
        ],
        "title": "A continuous-time GARCH process driven by a L\u00e9vy process: stationarity and second-order behaviour",
        "publication_date": "2004-09-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Journal of Applied Probability",
        "volume": "41",
        "doi": "10.1239/jap/1091543413",
        "urls": [
            "https://www.semanticscholar.org/paper/71670c3c9514c545ddbafe04b7c0ca043d53e917",
            "https://epub.ub.uni-muenchen.de/1794/1/paper_425.pdf"
        ],
        "id": "id-8544823965171411986",
        "abstract": "We use a discrete-time analysis, giving necessary and sufficient conditions for the almost-sure convergence of ARCH(1) and GARCH(1,1) discrete-time models, to suggest an extension of the ARCH and GARCH concepts to continuous-time processes. Our \u2018COGARCH\u2019 (continuous-time GARCH) model, based on a single background driving L\u00e9vy process, is different from, though related to, other continuous-time stochastic volatility models that have been proposed. The model generalises the essential features of discrete-time GARCH processes, and is amenable to further analysis, possessing useful Markovian and stationarity properties.",
        "versions": [
            {
                "year": 2004,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "A continuous-time GARCH process driven by a L\u00e9vy process: stationarity and second-order behaviour",
                "journal": "Journal of Applied Probability",
                "urls": [
                    "https://www.semanticscholar.org/paper/71670c3c9514c545ddbafe04b7c0ca043d53e917",
                    "https://epub.ub.uni-muenchen.de/1794/1/paper_425.pdf"
                ],
                "doi": "10.1239/jap/1091543413",
                "publication_date": "2004-09-01 00:00:00"
            }
        ],
        "rank": 91
    },
    {
        "authors": [
            "S. Pal"
        ],
        "title": "Computational Theory Perception (CTP), Rough-Fuzzy Uncertainty Analysis and Mining in Bioinformatics and Web Intelligence: A Unified Framework",
        "publication_date": "None",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Trans. Rough Sets",
        "volume": "11",
        "doi": "10.1007/978-3-642-11479-3_7",
        "urls": [
            "https://www.semanticscholar.org/paper/cad0419f55df3037c9af7526a30e2db759fc97f1"
        ],
        "id": "id-2631430806027500925",
        "abstract": null,
        "versions": [],
        "rank": 92
    },
    {
        "authors": [
            "D. Spero",
            "R. Jarvis"
        ],
        "title": "Path planning for a mobile robot in a rough terrain environment",
        "publication_date": "2002-11-09 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ROMOCO.2002.1177142",
        "urls": [
            "https://www.semanticscholar.org/paper/cb2d9c7e56b122225daf4470be9b05deaf3d3448"
        ],
        "id": "id-5755213028759367024",
        "abstract": "The robust control of a mobile robot in a rough terrain environment is a challenging endeavour, since any reliance on favourable surface or environmental conditions will inevitably lead to task failure. This paper presents the preliminary development of a unified navigation system used to control a nonholonomic mobile robot in an a priori unknown outdoor domain. Accurate, high-resolution environmental data was gathered from a scanning laser rangefinder (ladar), which constitutes the robot's exteroceptive perception system. Using this data, a 3D tessellated environmental model was created that generically captures terrain traversability. By adapting the rapidly-exploring random tree approach to the tessellated model, an efficient kinodynamic path planning algorithm was devised that enables point-to-point trajectory traversal. This path planning strategy was found to be a computationally efficient method of producing robust and versatile path plans.",
        "versions": [],
        "rank": 93
    },
    {
        "authors": [
            "R. Braun",
            "P. Blenkinsopp",
            "S. Mullock",
            "C. Corlett",
            "K. F. Willey",
            "J. Vickerman",
            "N. Winograd"
        ],
        "title": "Performance characteristics of a chemical imaging time-of-flight mass spectrometer.",
        "publication_date": "1998-09-30 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Rapid communications in mass spectrometry : RCM",
        "volume": "12 18",
        "doi": "10.1002/(SICI)1097-0231(19980930)12:18<1246::AID-RCM316>3.0.CO;2-C",
        "urls": [
            "https://www.semanticscholar.org/paper/7c220775a2f9874cc8441c00843b3f28ab5dbb70"
        ],
        "id": "id1975825824904790419",
        "abstract": "A chemical imaging time-of-flight secondary ion mass spectrometer is described. It consists of a liquid metal ion gun, medium energy resolution reflectron mass analyzer, liquid nitrogen cooled sample stage, preparation chamber and dual stage entry port. Unique features include compatibility with laser postionization experiments, large field of view, cryogenic sample handling capability and high incident ion beam current. Instrument performance is illustrated by the characterization of scanning electron microscopy grids, silver and functionalized polystyrene beads and the postionization of an organic overlayer on a gold substrate.",
        "versions": [
            {
                "year": 1998,
                "source": "SupportedSources.OPENALEX",
                "title": "Performance characteristics of a chemical imaging time-of-flight mass spectrometer",
                "journal": "",
                "urls": [
                    "https://openalex.org/W2007919850",
                    "https://doi.org/10.1002/(sici)1097-0231(19980930)12:18<1246::aid-rcm316>3.0.co;2-c"
                ],
                "doi": "10.1002/(sici)1097-0231(19980930)12:18<1246::aid-rcm316>3.0.co;2-c",
                "publication_date": "1998-09-30 00:00:00"
            }
        ],
        "rank": 94
    },
    {
        "authors": [
            "Isao Yagi",
            "Shunya Maruyama",
            "Takanobu Mizuta"
        ],
        "title": "Trading Strategies of a Leveraged ETF in a Continuous Double Auction Market Using an Agent-Based Simulation",
        "publication_date": "2020-10-25 05:04:20+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": "Complexity, 3497689, Vol. 2020",
        "volume": "",
        "doi": "10.1155/2020/3497689",
        "urls": [
            "http://arxiv.org/pdf/2010.13036v1",
            "http://dx.doi.org/10.1155/2020/3497689",
            "http://arxiv.org/abs/2010.13036v1",
            "http://arxiv.org/pdf/2010.13036v1"
        ],
        "id": "id2345061774868591185",
        "abstract": "A leveraged ETF is a fund aimed at achieving a rate of return several times\ngreater than that of the underlying asset such as Nikkei 225 futures. Recently,\nit has been suggested that rebalancing trades of a leveraged ETF may\ndestabilize the financial markets. An empirical study using an agent-based\nsimulation indicated that a rebalancing trade strategy could affect the price\nformation of an underlying asset market. However, no leveraged ETF trading\nmethod for suppressing the increase in volatility as much as possible has yet\nbeen proposed. In this paper, we compare different strategies of trading for a\nproposed trading model and report the results of our investigation regarding\nhow best to suppress an increase in market volatility. As a result, it was\nfound that as the minimum number of orders in a rebalancing trade increases,\nthe impact on the market price formation decreases.",
        "versions": [],
        "rank": 95
    },
    {
        "authors": [
            "Mine Caglar",
            "Ceren Vardar"
        ],
        "title": "Distribution of Maximum Loss for Fractional Brownian Motion",
        "publication_date": "2012-08-13 09:05:24+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1208.2527v1",
            "http://arxiv.org/abs/1208.2527v1",
            "http://arxiv.org/pdf/1208.2527v1"
        ],
        "id": "id-1363153889403649244",
        "abstract": "In finance, the price of a volatile asset can be modeled using fractional\nBrownian motion (fBm) with Hurst parameter $H>1/2.$ The Black-Scholes model for\nthe values of returns of an asset using fBm is given as, [Y_t=Y_0\n\\exp{((r+\\mu)t+\\sigma B_t^H)}, t\\geq 0], where $Y_0$ is the initial value, $r$\nis constant interest rate, $\\mu$ is constant drift and $\\sigma$ is constant\ndiffusion coefficient of fBm, which is denoted by $(B_t^H)$ where $t \\geq 0.$\nBlack-Scholes model can be constructed with some Markov processes such as\nBrownian motion. The advantage of modeling with fBm to Markov proccesses is its\ncapability of exposing the dependence between returns. The real life data for a\nvolatile asset display long-range dependence property. For this reason, using\nfBm is a more realistic model compared to Markov processes. Investors would be\ninterested in any kind of information on the risk in order to manage it or\nhedge it. The maximum possible loss is one way to measure highest possible\nrisk. Therefore, it is an important variable for investors. In our study, we\ngive some theoretical bounds on the distribution of maximum possible loss of\nfBm. We provide both asymptotical and strong estimates for the tail probability\nof maximum loss of standard fBm and fBm with drift and diffusion coefficients.\nIn the investment point of view, these results explain, how large values of\npossible loss behave and its bounds.",
        "versions": [],
        "rank": 96
    },
    {
        "authors": [
            "Dean M. Hanink"
        ],
        "title": "Clark's \"Dimensions of Spatial Price Dispersion\": Comments and Extensions",
        "publication_date": "2010-09-03 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Wiley",
        "volume": "",
        "doi": "10.1111/j.1538-4632.1987.tb00115.x",
        "urls": [
            "https://archive.org/details/sim_geographical-analysis_1987-01_19_1/page/83"
        ],
        "id": "id-7076162708572072026",
        "abstract": "",
        "versions": [
            {
                "year": 2010,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Clark's \u201cDimensions of Spatial Price Dispersion\u201d: Comments and Extensions",
                "journal": "Geographical Analysis",
                "urls": [
                    "https://www.semanticscholar.org/paper/bef327985b65e8e4c65784c74bbdcfb9ce28986a",
                    "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/j.1538-4632.1987.tb00115.x"
                ],
                "doi": "10.1111/J.1538-4632.1987.TB00115.X",
                "publication_date": "2010-09-03 00:00:00"
            }
        ],
        "rank": 97
    },
    {
        "authors": [
            "Mar\u00eda T. Morales",
            "Franca Angerosa",
            "Ram\u00f3n Aparicio"
        ],
        "title": "Effect of the extraction conditions of virgin olive oil on the lipoxygenase cascade:Chemical and sensory implications",
        "publication_date": "1999-04-30 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Departmento de Publicaciones del CSIC",
        "volume": "",
        "doi": "10.3989/gya.1999.v50.i2.645",
        "urls": [
            "https://web.archive.org/web/20171129100716/https://core.ac.uk/download/pdf/36032945.pdf"
        ],
        "id": "id981806766190070238",
        "abstract": "RESUMEN Efecto de las condiciones de extracci\u00f3n del aceite de oliva virgen en la ruta de la iipoxigenasa: implicaciones qu\u00edmicas y sensoriales. SUMMARY Effect of the extraction conditions of virgin olive oil on the lipoxygenase cascade: Chemical and sensory implications. The volatile compounds produced through the lipoxygenase cascade are responsible for the most remarkable sensory attributes of virgin olive oil. The paper analyses the evolution of these compounds according to different conditions of temperature and time of the malaxing process. The influence of these parameters on the production of Ce and Cs volatile compounds is stated together with the effect that the amount of these compounds has on the most remarkable virgin olive oil sensory descriptors (green, bitter-pungent, sweet and undesirable). Optima values of temperature and time are given for producing high sensory quality virgin olive oils. Three cultivars, Spanish Picual and Italian Frantoio and Coratina, were characterised by sensory attributes and volatile compounds quantified by two different methodologies in order to avoid that results could be circumscribed to a specific cultivar or a quantification method. KEY-WORDS: Extraction systems -Lipoxygenase (cascade) - Virgin olive oil -Volatile compounds.",
        "versions": [],
        "rank": 98
    },
    {
        "authors": [
            "A. Dikshit-Ratnaparkhi",
            "D. Bormane",
            "R. Ghongade"
        ],
        "title": "Evaluation of Rough set and Fuzzy rough set models with application to multi-attribute decision making",
        "publication_date": "2019-07-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/WorldS4.2019.8903970",
        "urls": [
            "https://www.semanticscholar.org/paper/ce699cf7c02bee11cc0e1ff09d75a115ee472d60"
        ],
        "id": "id3207738018817422694",
        "abstract": "Uncertainty and randomness is inherent to real valued datasets. With the advent of fuzzy concepts, noise tolerant models are being studied by researchers nearly for a decade. Fuzzy sets and extended fuzzy sets are now widely used to represent the vague and ambiguous nature of datasets. The proposed work investigates the relationship between the output class and the optimal attribute subset on the basis of rules induced using rough sets, vaguely quantified rough sets, ordered weighted average fuzzy rough sets and fuzzy rough k-nearest neighbor model. Fuzzy rough sets and its extended models have been applied on bench mark databases. The novelty of the work lies in the application of these models on optimally generated subsets. The optimal generation of attributes is carried out using discernibility matrix based approach. This approach is also compared with the standard correlation and mutual information based approaches. The results indicate that fuzzy rough k-nearest neighbour approach combined with discernibility matrix based attribute generation outperforms other methods in terms of classification accuracy. Sensitivity analysis indicates the efficacy of the proposed model over traditional approaches.",
        "versions": [
            {
                "year": 2019,
                "source": "SupportedSources.CROSSREF",
                "title": "Evaluation of Rough set and Fuzzy rough set models with application to multi-attribute decision making",
                "journal": "",
                "urls": [
                    "http://xplorestaging.ieee.org/ielx7/8892594/8903920/08903970.pdf?arnumber=8903970",
                    "http://dx.doi.org/10.1109/worlds4.2019.8903970"
                ],
                "doi": "10.1109/worlds4.2019.8903970",
                "publication_date": "2019-01-01 00:00:00"
            }
        ],
        "rank": 99
    }
]