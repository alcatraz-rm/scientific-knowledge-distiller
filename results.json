[
    {
        "authors": [
            "Wang, H.",
            "Zhao, C.",
            "Zhao, X.",
            "Chen, F."
        ],
        "title": "Layer Adaptive Deep Neural Networks for\u00a0Out-of-Distribution Detection",
        "publication_date": "2022-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-3-031-05936-0_41",
        "urls": [
            "https://link.springer.com/content/pdf/10.1007/978-3-031-05936-0_41",
            "http://dx.doi.org/10.1007/978-3-031-05936-0_41"
        ],
        "id": "id748370673721710388",
        "abstract": "",
        "versions": [
            {
                "year": 0,
                "source": "SupportedSources.UNPAYWALL",
                "title": "Layer Adaptive Deep Neural Networks for Out-of-Distribution Detection",
                "journal": "Lecture Notes in Computer Science",
                "urls": [
                    "https://doi.org/10.1007/978-3-031-05936-0_41"
                ],
                "doi": "10.1007/978-3-031-05936-0_41",
                "publication_date": "None"
            }
        ],
        "rank": 0
    },
    {
        "authors": [
            "Such, O.",
            "Fabricius, R.",
            "Tarabek, P."
        ],
        "title": "Introducing students to out-of-distribution detection with deep neural networks",
        "publication_date": "2022-10-20 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/iceta57911.2022.9974603",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/9973812/9974602/09974603.pdf?arnumber=9974603",
            "http://dx.doi.org/10.1109/iceta57911.2022.9974603"
        ],
        "id": "id7260275202785044543",
        "abstract": "",
        "versions": [
            {
                "year": 0,
                "source": "SupportedSources.UNPAYWALL",
                "title": "Introducing students to out-of-distribution detection with deep neural networks",
                "journal": "2022 20th International Conference on Emerging eLearning Technologies and Applications (ICETA)",
                "urls": [
                    "https://doi.org/10.1109/iceta57911.2022.9974603"
                ],
                "doi": "10.1109/iceta57911.2022.9974603",
                "publication_date": "None"
            }
        ],
        "rank": 1
    },
    {
        "authors": [
            "Cao, S.",
            "Zhang, Z."
        ],
        "title": "Deep Hybrid Models for Out-of-Distribution Detection",
        "publication_date": "2022-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/cvpr52688.2022.00469",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/9878378/9878366/09879060.pdf?arnumber=9879060",
            "http://dx.doi.org/10.1109/cvpr52688.2022.00469"
        ],
        "id": "id-660296009747219921",
        "abstract": "",
        "versions": [],
        "rank": 2
    },
    {
        "authors": [
            "Jha, S.",
            "Roy, A."
        ],
        "title": "On Detection of Out of Distribution Inputs in Deep Neural Networks",
        "publication_date": "2021-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/cogmi52975.2021.00044",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/9750278/9750279/09750292.pdf?arnumber=9750292",
            "http://dx.doi.org/10.1109/cogmi52975.2021.00044"
        ],
        "id": "id-4885740089035536669",
        "abstract": "",
        "versions": [],
        "rank": 3
    },
    {
        "authors": [
            "Cui, P.",
            "Wang, J."
        ],
        "title": "Out-of-Distribution (OOD) Detection Based on Deep Learning: A Review",
        "publication_date": "2022-10-28 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.3390/electronics11213500",
        "urls": [
            "https://www.mdpi.com/2079-9292/11/21/3500/pdf",
            "http://dx.doi.org/10.3390/electronics11213500"
        ],
        "id": "id-1076435813921075654",
        "abstract": "",
        "versions": [],
        "rank": 4
    },
    {
        "authors": [
            "Henriksson, J.",
            "Berger, C.",
            "Borg, M.",
            "Tornberg, L.",
            "Sathyamoorthy, S.",
            "Englund, C."
        ],
        "title": "Performance Analysis of Out-of-Distribution Detection on Various Trained Neural Networks",
        "publication_date": "2019-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/seaa.2019.00026",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/8893991/8906511/08906748.pdf?arnumber=8906748",
            "http://dx.doi.org/10.1109/seaa.2019.00026"
        ],
        "id": "id8082356453078970340",
        "abstract": "",
        "versions": [],
        "rank": 5
    },
    {
        "authors": [
            "Henriksson, J.",
            "Berger, C.",
            "Borg, M.",
            "Tornberg, L.",
            "Sathyamoorthy, S.",
            "Englund, C."
        ],
        "title": "Performance analysis of out-of-distribution detection on trained neural networks",
        "publication_date": "2021-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1016/j.infsof.2020.106409",
        "urls": [
            "https://api.elsevier.com/content/article/PII:S0950584919302204?httpAccept=text/xml",
            "https://api.elsevier.com/content/article/PII:S0950584919302204?httpAccept=text/plain",
            "http://dx.doi.org/10.1016/j.infsof.2020.106409"
        ],
        "id": "id-6411229004708489033",
        "abstract": "",
        "versions": [],
        "rank": 6
    },
    {
        "authors": [
            "Dong Woo Lee",
            "Yeongjae Cheon"
        ],
        "title": "Soft Labeling Affects Out-of-Distribution Detection of Deep Neural   Networks",
        "publication_date": "2020-07-07 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "arXiv (Cornell University)",
        "volume": "",
        "doi": "10.48550/arxiv.2007.03212",
        "urls": [
            "https://openalex.org/W3039726358",
            "https://doi.org/10.48550/arxiv.2007.03212",
            "http://arxiv.org/pdf/2007.03212"
        ],
        "id": "id-7420156043514785944",
        "abstract": "",
        "versions": [],
        "rank": 7
    },
    {
        "authors": [
            "Matan Haroush",
            "Tzivel Frostig",
            "Ruth Heller",
            "Daniel Soudry"
        ],
        "title": "Statistical Testing for Efficient Out of Distribution Detection in Deep Neural Networks.",
        "publication_date": "2021-02-25 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "arXiv (Cornell University)",
        "volume": "",
        "doi": null,
        "urls": [
            "https://openalex.org/W3130430360"
        ],
        "id": "id6844538341394497332",
        "abstract": "",
        "versions": [],
        "rank": 8
    },
    {
        "authors": [
            "Siegismund, D.",
            "Heyse, S.",
            "Steigele, S."
        ],
        "title": "Uncertainty with deep learning: a practical view on out of distribution detection",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/sds49233.2020.00025",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/9142329/9144743/09145013.pdf?arnumber=9145013",
            "http://dx.doi.org/10.1109/sds49233.2020.00025"
        ],
        "id": "id3866961618703460430",
        "abstract": "",
        "versions": [],
        "rank": 9
    },
    {
        "authors": [
            "Yu, S.",
            "Lee, D.",
            "Yu, H."
        ],
        "title": "Convolutional Neural Networks with Compression Complexity Pooling for Out-of-Distribution Image Detection",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.24963/ijcai.2020/337",
        "urls": [
            "http://dx.doi.org/10.24963/ijcai.2020/337"
        ],
        "id": "id-7957344552026791226",
        "abstract": "",
        "versions": [],
        "rank": 10
    },
    {
        "authors": [
            "Aman Jantan",
            "Abiodun Esther Omolara",
            "Kemi Victoria Dada",
            "Nachaat AbdElatif Mohamed",
            "Humaira Arshad"
        ],
        "title": "State-of-the-art in artificial neural network applications: A survey",
        "publication_date": "2018-11-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Heliyon",
        "volume": "4",
        "doi": "10.1016/j.heliyon.2018.e00938",
        "urls": [
            "https://openalex.org/W2901312569",
            "https://doi.org/10.1016/j.heliyon.2018.e00938",
            "http://www.cell.com/article/S2405844018332067/pdf"
        ],
        "id": "id-4690734944097716852",
        "abstract": "",
        "versions": [],
        "rank": 11
    },
    {
        "authors": [
            "Taylor Denounden",
            "Krzysztof Czarnecki",
            "Rick Salay",
            "Sachin Vernekar",
            "Vahdat Abdelzad",
            "Buu Phan"
        ],
        "title": "Detecting Out-of-Distribution Inputs in Deep Neural Networks Using an Early-Layer Output",
        "publication_date": "2019-10-23 00:00:00",
        "source": "SupportedSources.PAPERS_WITH_CODE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://arxiv.org/pdf/1910.10307v1.pdf",
            "https://github.com/gietema/ood-early-layer-detection"
        ],
        "id": "id-5709322874532134089",
        "abstract": "Deep neural networks achieve superior performance in challenging tasks such as image classification. However, deep classifiers tend to incorrectly classify out-of-distribution (OOD) inputs, which are inputs that do not belong to the classifier training distribution. Several approaches have been proposed to detect OOD inputs, but the detection task is still an ongoing challenge. In this paper, we propose a new OOD detection approach that can be easily applied to an existing classifier and does not need to have access to OOD samples. The detector is a one-class classifier trained on the output of an early layer of the original classifier fed with its original training set. We apply our approach to several low- and high-dimensional datasets and compare it to the state-of-the-art detection approaches. Our approach achieves substantially better results over multiple metrics.",
        "versions": [
            {
                "year": 2019,
                "source": "SupportedSources.INTERNET_ARCHIVE",
                "title": "Detecting Out-of-Distribution Inputs in Deep Neural Networks Using an Early-Layer Output",
                "journal": "",
                "urls": [
                    "https://web.archive.org/web/20200828092606/https://arxiv.org/pdf/1910.10307v1.pdf"
                ],
                "doi": "",
                "publication_date": "2019-10-23 00:00:00"
            }
        ],
        "rank": 12
    },
    {
        "authors": [
            "Mohammad Sabokrou",
            "Mahmood Fathy",
            "Guoying Zhao",
            "Ehsan Adeli"
        ],
        "title": "Deep End-to-End One-Class Classifier",
        "publication_date": "2021-02-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "IEEE transactions on neural networks and learning systems",
        "volume": "32",
        "doi": "10.1109/tnnls.2020.2979049",
        "urls": [
            "https://openalex.org/W3016045843",
            "https://doi.org/10.1109/tnnls.2020.2979049",
            "http://jultika.oulu.fi/files/nbnfi-fe2021042311461.pdf"
        ],
        "id": "id4597537396858597557",
        "abstract": "",
        "versions": [],
        "rank": 13
    },
    {
        "authors": [
            "Nguyen, A.",
            "Lu, F.",
            "Munoz, G.",
            "Raff, E.",
            "Nicholas, C.",
            "Holt, J."
        ],
        "title": "Out of Distribution Data Detection Using Dropout Bayesian Neural Networks",
        "publication_date": "2022-06-28 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1609/aaai.v36i7.20757",
        "urls": [
            "https://ojs.aaai.org/index.php/AAAI/article/download/20757/20516",
            "https://ojs.aaai.org/index.php/AAAI/article/download/20757/20516",
            "http://dx.doi.org/10.1609/aaai.v36i7.20757"
        ],
        "id": "id-8507314144236571780",
        "abstract": "",
        "versions": [],
        "rank": 14
    },
    {
        "authors": [
            "Lee, W.",
            "Millman, S.",
            "Desai, N.",
            "Srivatsa, M.",
            "Liu, C."
        ],
        "title": "NeuralFP: Out-of-distribution Detection using Fingerprints of Neural Networks",
        "publication_date": "2021-01-10 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/icpr48806.2021.9412489",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/9411940/9411911/09412489.pdf?arnumber=9412489",
            "http://dx.doi.org/10.1109/icpr48806.2021.9412489"
        ],
        "id": "id-5531664046556516012",
        "abstract": "",
        "versions": [],
        "rank": 15
    },
    {
        "authors": [
            "Felix Altenberger",
            "Claus Lenz"
        ],
        "title": "A Non-Technical Survey on Deep Convolutional Neural Network Architectures",
        "publication_date": "2018-03-06 11:40:46+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1803.02129v1",
            "http://arxiv.org/abs/1803.02129v1",
            "http://arxiv.org/pdf/1803.02129v1"
        ],
        "id": "id-5426090120453394452",
        "abstract": "Artificial neural networks have recently shown great results in many\ndisciplines and a variety of applications, including natural language\nunderstanding, speech processing, games and image data generation. One\nparticular application in which the strong performance of artificial neural\nnetworks was demonstrated is the recognition of objects in images, where deep\nconvolutional neural networks are commonly applied. In this survey, we give a\ncomprehensive introduction to this topic (object recognition with deep\nconvolutional neural networks), with a strong focus on the evolution of network\narchitectures. Therefore, we aim to compress the most important concepts in\nthis field in a simple and non-technical manner to allow for future researchers\nto have a quick general understanding.\n  This work is structured as follows:\n  1. We will explain the basic ideas of (convolutional) neural networks and\ndeep learning and examine their usage for three object recognition tasks: image\nclassification, object localization and object detection.\n  2. We give a review on the evolution of deep convolutional neural networks by\nproviding an extensive overview of the most important network architectures\npresented in chronological order of their appearances.",
        "versions": [],
        "rank": 16
    },
    {
        "authors": [
            "Sina Mohseni",
            "Mandar Pitale",
            "Jay Yadawa",
            "Zhangyang Wang"
        ],
        "title": "Self-Supervised Learning for Generalizable Out-of-Distribution Detection",
        "publication_date": "2020-04-03 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Proceedings of the ... AAAI Conference on Artificial Intelligence",
        "volume": "34",
        "doi": "10.1609/aaai.v34i04.5966",
        "urls": [
            "https://openalex.org/W2997212544",
            "https://doi.org/10.1609/aaai.v34i04.5966",
            "https://ojs.aaai.org/index.php/AAAI/article/download/5966/5822"
        ],
        "id": "id6580597376350310931",
        "abstract": "",
        "versions": [],
        "rank": 17
    },
    {
        "authors": [
            "Timothy J. O'Shea",
            "Jakob Hoydis"
        ],
        "title": "An Introduction to Deep Learning for the Physical Layer",
        "publication_date": "2017-10-02 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "IEEE Transactions on Cognitive Communications and Networking",
        "volume": "3",
        "doi": "10.1109/tccn.2017.2758370",
        "urls": [
            "https://openalex.org/W2734408173",
            "https://doi.org/10.1109/tccn.2017.2758370",
            "http://arxiv.org/pdf/1702.00832"
        ],
        "id": "id-6802136127290694824",
        "abstract": "",
        "versions": [],
        "rank": 18
    },
    {
        "authors": [
            "Christopher, B."
        ],
        "title": "Evaluating &amp; enhancing deep learning systems via out-of-distribution detection",
        "publication_date": "None",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.32657/10356/162032",
        "urls": [
            "http://dx.doi.org/10.32657/10356/162032"
        ],
        "id": "id-2596601960978316954",
        "abstract": "",
        "versions": [],
        "rank": 19
    },
    {
        "authors": [
            "Yousif, H."
        ],
        "title": "Deep neural networks for animal object detection and recognition in the wild",
        "publication_date": "None",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.32469/10355/76154",
        "urls": [
            "http://dx.doi.org/10.32469/10355/76154"
        ],
        "id": "id2218907126924413350",
        "abstract": "",
        "versions": [],
        "rank": 20
    },
    {
        "authors": [
            "Ye, G."
        ],
        "title": "Large-Scale Video Event Detection Using Deep Neural Networks",
        "publication_date": "2018-04-09 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1201/9781351119023-1",
        "urls": [
            "http://dx.doi.org/10.1201/9781351119023-1"
        ],
        "id": "id818874581355116820",
        "abstract": "",
        "versions": [],
        "rank": 21
    },
    {
        "authors": [
            "Nilesh A. Ahuja",
            "Ibrahima J. Ndiour",
            "Trushant Kalyanpur",
            "Omesh Tickoo"
        ],
        "title": "Probabilistic Modeling of Deep Features for Out-of-Distribution and Adversarial Detection",
        "publication_date": "2019-09-25 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "arXiv (Cornell University)",
        "volume": "",
        "doi": null,
        "urls": [
            "https://openalex.org/W2975050087"
        ],
        "id": "id5470321393645418825",
        "abstract": "",
        "versions": [],
        "rank": 22
    },
    {
        "authors": [
            "Nicholas Carlini",
            "David Wagner"
        ],
        "title": "Towards Evaluating the Robustness of Neural Networks",
        "publication_date": "2017-05-22 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "IEEE Symposium on Security and Privacy",
        "volume": "",
        "doi": "10.1109/sp.2017.49",
        "urls": [
            "https://openalex.org/W2963857521",
            "https://doi.org/10.1109/sp.2017.49",
            "http://arxiv.org/pdf/1608.04644"
        ],
        "id": "id5710730028166769245",
        "abstract": "",
        "versions": [],
        "rank": 23
    },
    {
        "authors": [
            "Megyeri, I.",
            "Hegedus, I.",
            "Jelasity, M."
        ],
        "title": "Robust Classification Combined with Robust out-of-Distribution Detection: An Empirical Analysis",
        "publication_date": "2021-07-18 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ijcnn52387.2021.9533635",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/9533266/9533267/09533635.pdf?arnumber=9533635",
            "http://dx.doi.org/10.1109/ijcnn52387.2021.9533635"
        ],
        "id": "id8917537613970733431",
        "abstract": "",
        "versions": [],
        "rank": 24
    },
    {
        "authors": [
            "Anguelov, Dragomir",
            "Erhan, Dumitru",
            "Jia, Yangqing",
            "Liu, Wei",
            "Rabinovich, Andrew",
            "Reed, Scott",
            "Sermanet, Pierre",
            "Szegedy, Christian",
            "Vanhoucke, Vincent"
        ],
        "title": "Going Deeper with Convolutions",
        "publication_date": "2014-09-16 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/cvpr.2015.7298594",
        "urls": [
            "http://arxiv.org/abs/1409.4842"
        ],
        "id": "id4581371278049467900",
        "abstract": "We propose a deep convolutional neural network architecture codenamed\n\"Inception\", which was responsible for setting the new state of the art for\nclassification and detection in the ImageNet Large-Scale Visual Recognition\nChallenge 2014 (ILSVRC 2014). The main hallmark of this architecture is the\nimproved utilization of the computing resources inside the network. This was\nachieved by a carefully crafted design that allows for increasing the depth and\nwidth of the network while keeping the computational budget constant. To\noptimize quality, the architectural decisions were based on the Hebbian\nprinciple and the intuition of multi-scale processing. One particular\nincarnation used in our submission for ILSVRC 2014 is called GoogLeNet, a 22\nlayers deep network, the quality of which is assessed in the context of\nclassification and detection",
        "versions": [
            {
                "year": 2015,
                "source": "SupportedSources.OPENALEX",
                "title": "Going deeper with convolutions",
                "journal": "Computer Vision and Pattern Recognition",
                "urls": [
                    "https://openalex.org/W2097117768",
                    "https://doi.org/10.1109/cvpr.2015.7298594",
                    "http://arxiv.org/pdf/1409.4842"
                ],
                "doi": "10.1109/cvpr.2015.7298594",
                "publication_date": "2015-06-07 00:00:00"
            }
        ],
        "rank": 25
    },
    {
        "authors": [
            "Peter Meer"
        ],
        "title": "Are Deep Neural Networks \"Robust\"?",
        "publication_date": "2020-08-25 16:57:19+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2008.12650v1",
            "http://arxiv.org/abs/2008.12650v1",
            "http://arxiv.org/pdf/2008.12650v1"
        ],
        "id": "id-1826736877163970679",
        "abstract": "Separating outliers from inliers is the definition of robustness in computer\nvision. This essay delineates how deep neural networks are different than\ntypical robust estimators. Deep neural networks not robust by this traditional\ndefinition.",
        "versions": [],
        "rank": 26
    },
    {
        "authors": [
            "Martin Mundt",
            "Iuliia Pliushch",
            "Sagnik Majumder",
            "Visvanathan Ramesh"
        ],
        "title": "Open Set Recognition Through Deep Neural Network Uncertainty: Does Out-of-Distribution Detection Require Generative Classifiers?",
        "publication_date": "2019-10-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "International Conference on Computer Vision",
        "volume": "",
        "doi": "10.1109/iccvw.2019.00098",
        "urls": [
            "https://openalex.org/W2992671401",
            "https://doi.org/10.1109/iccvw.2019.00098",
            "http://arxiv.org/pdf/1908.09625"
        ],
        "id": "id-372207978326793666",
        "abstract": "",
        "versions": [
            {
                "year": 2019,
                "source": "SupportedSources.INTERNET_ARCHIVE",
                "title": "Open Set Recognition Through Deep Neural Network Uncertainty: Does Out-of-Distribution Detection Require Generative Classifiers?",
                "journal": "",
                "urls": [
                    "https://web.archive.org/web/20200907032452/https://arxiv.org/pdf/1908.09625v1.pdf"
                ],
                "doi": "",
                "publication_date": "2019-08-26 00:00:00"
            },
            {
                "year": 0,
                "source": "SupportedSources.UNPAYWALL",
                "title": "Open Set Recognition Through Deep Neural Network Uncertainty: Does Out-of-Distribution Detection Require Generative Classifiers?",
                "journal": "2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)",
                "urls": [
                    "https://doi.org/10.1109/iccvw.2019.00098"
                ],
                "doi": "10.1109/iccvw.2019.00098",
                "publication_date": "None"
            },
            {
                "year": 2019,
                "source": "SupportedSources.CROSSREF",
                "title": "Open Set Recognition Through Deep Neural Network Uncertainty: Does Out-of-Distribution Detection Require Generative Classifiers?",
                "journal": "",
                "urls": [
                    "http://xplorestaging.ieee.org/ielx7/8982559/9021948/09022417.pdf?arnumber=9022417",
                    "http://dx.doi.org/10.1109/iccvw.2019.00098"
                ],
                "doi": "10.1109/iccvw.2019.00098",
                "publication_date": "2019-01-01 00:00:00"
            }
        ],
        "rank": 27
    },
    {
        "authors": [
            "Maxime Oquab",
            "L\u00e9on Bottou",
            "Ivan Laptev",
            "Josef Sivic"
        ],
        "title": "Learning and Transferring Mid-level Image Representations Using Convolutional Neural Networks",
        "publication_date": "2014-06-23 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "HAL (Le Centre pour la Communication Scientifique Directe)",
        "volume": "",
        "doi": "10.1109/cvpr.2014.222",
        "urls": [
            "https://openalex.org/W2161381512",
            "https://doi.org/10.1109/cvpr.2014.222",
            "http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Oquab_Learning_and_Transferring_2014_CVPR_paper.pdf"
        ],
        "id": "id7225777606558937874",
        "abstract": "",
        "versions": [],
        "rank": 28
    },
    {
        "authors": [
            "Hashemi, V.",
            "K\u0159et\u00ednsk\u1ef3, J.",
            "Rieder, S.",
            "Schmidt, J."
        ],
        "title": "Runtime Monitoring for\u00a0Out-of-Distribution Detection in\u00a0Object Detection Neural Networks",
        "publication_date": "2023-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-3-031-27481-7_36",
        "urls": [
            "https://link.springer.com/content/pdf/10.1007/978-3-031-27481-7_36",
            "http://dx.doi.org/10.1007/978-3-031-27481-7_36"
        ],
        "id": "id-2773314709756459795",
        "abstract": "",
        "versions": [],
        "rank": 29
    },
    {
        "authors": [
            "Gianni Franchi",
            "Andrei Bursuc",
            "Emanuel Aldea",
            "S\u00e9verine Dubuisson",
            "Isabelle Bloch"
        ],
        "title": "TRADI: Tracking Deep Neural Network Weight Distributions",
        "publication_date": "2020-08-23 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Lecture Notes in Computer Science",
        "volume": "",
        "doi": "10.1007/978-3-030-58520-4_7",
        "urls": [
            "https://openalex.org/W3055795587",
            "https://doi.org/10.1007/978-3-030-58520-4_7",
            "https://hal.archives-ouvertes.fr/hal-02922336/document"
        ],
        "id": "id6368346107195001080",
        "abstract": "",
        "versions": [],
        "rank": 30
    },
    {
        "authors": [
            "Macedo, D.",
            "Ren, T.",
            "Zanchettin, C.",
            "Oliveira, A.",
            "Ludermir, T."
        ],
        "title": "Entropic Out-of-Distribution Detection: Seamless Detection of Unknown Examples",
        "publication_date": "2022-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/tnnls.2021.3112897",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/5962385/9786556/09556483.pdf?arnumber=9556483",
            "http://dx.doi.org/10.1109/tnnls.2021.3112897"
        ],
        "id": "id-6727929981235847400",
        "abstract": "",
        "versions": [],
        "rank": 31
    },
    {
        "authors": [
            "Siyu Luan",
            "Zonghua Gu",
            "Leonid B. Freidovich",
            "Lili Jiang",
            "Qingling Zhao"
        ],
        "title": "Out-of-Distribution Detection for Deep Neural Networks With Isolation Forest and Local Outlier Factor",
        "publication_date": "2021-08-27 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "IEEE Access",
        "volume": "9",
        "doi": "10.1109/access.2021.3108451",
        "urls": [
            "https://openalex.org/W3197264024",
            "https://doi.org/10.1109/access.2021.3108451",
            "https://ieeexplore.ieee.org/ielx7/6287639/6514899/09524615.pdf"
        ],
        "id": "id-5687097074457265462",
        "abstract": "",
        "versions": [
            {
                "year": 0,
                "source": "SupportedSources.UNPAYWALL",
                "title": "Out-of-Distribution Detection for Deep Neural Networks With Isolation Forest and Local Outlier Factor",
                "journal": "IEEE Access",
                "urls": [
                    "https://doi.org/10.1109/access.2021.3108451"
                ],
                "doi": "10.1109/access.2021.3108451",
                "publication_date": "None"
            },
            {
                "year": 2021,
                "source": "SupportedSources.CROSSREF",
                "title": "Out-of-Distribution Detection for Deep Neural Networks With Isolation Forest and Local Outlier Factor",
                "journal": "",
                "urls": [
                    "http://xplorestaging.ieee.org/ielx7/6287639/9312710/09524615.pdf?arnumber=9524615",
                    "http://dx.doi.org/10.1109/access.2021.3108451"
                ],
                "doi": "10.1109/access.2021.3108451",
                "publication_date": "2021-01-01 00:00:00"
            }
        ],
        "rank": 32
    },
    {
        "authors": [
            "Angelov, P.",
            "Soares, E."
        ],
        "title": "Towards explainable deep neural networks (xDNN)",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1016/j.neunet.2020.07.010",
        "urls": [
            "https://api.elsevier.com/content/article/PII:S0893608020302513?httpAccept=text/xml",
            "https://api.elsevier.com/content/article/PII:S0893608020302513?httpAccept=text/plain",
            "http://dx.doi.org/10.1016/j.neunet.2020.07.010"
        ],
        "id": "id-2936929247250267468",
        "abstract": "",
        "versions": [],
        "rank": 33
    },
    {
        "authors": [
            "Nguyen-Son, H.",
            "Thao, T.",
            "Hidano, S.",
            "Bracamonte, V.",
            "Kiyomoto, S.",
            "Yamaguchi, R."
        ],
        "title": "OPA2D: One-Pixel Attack, Detection, and Defense in Deep Neural Networks",
        "publication_date": "2021-07-18 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ijcnn52387.2021.9534332",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/9533266/9533267/09534332.pdf?arnumber=9534332",
            "http://dx.doi.org/10.1109/ijcnn52387.2021.9534332"
        ],
        "id": "id-2974298624494053935",
        "abstract": "",
        "versions": [],
        "rank": 34
    },
    {
        "authors": [
            "Macedo, D.",
            "Ren, T.",
            "Zanchettin, C.",
            "Oliveira, A.",
            "Ludermir, T."
        ],
        "title": "Entropic Out-of-Distribution Detection",
        "publication_date": "2021-07-18 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ijcnn52387.2021.9533899",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/9533266/9533267/09533899.pdf?arnumber=9533899",
            "http://dx.doi.org/10.1109/ijcnn52387.2021.9533899"
        ],
        "id": "id8005991118375493476",
        "abstract": "",
        "versions": [],
        "rank": 35
    },
    {
        "authors": [
            "Jinhong Lin"
        ],
        "title": "WeShort: Out-of-distribution Detection With Weak Shortcut structure",
        "publication_date": "2022-06-27 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "figshare",
        "volume": "",
        "doi": "10.6084/m9.figshare.20164346.v1",
        "urls": [
            "https://web.archive.org/web/20220628031536/https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/36057101/rzqjkwzwnpcjwsrtffvsgjbhwhzsxpbb.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIYCQYOYV5JSSROOA/20220628/eu-west-1/s3/aws4_request&X-Amz-Date=20220628T031536Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=90a60e5833713f93633558e9637b54a574df9918a0dba1f042c717f75f105d2c"
        ],
        "id": "id-96041656174533570",
        "abstract": "Neural networks have achieved impressive performance for data in the distribution which is the same as the training set but can produce an overconfident incorrect result for the data these networks have never seen. Therefore, it is essential to detect whether inputs come from out-of-distribution(OOD) in order to guarantee the safety of neural networks deployed in the real world. In this paper, we propose a simple and effective post-hoc technique, WeShort, to reduce the overconfidence of neural networks on OOD data. Our method is inspired by the observation of the internal residual structure, which shows the separation of the OOD and in-distribution (ID) data in the shortcut layer. Our method is compatible with different OOD detection scores and can generalize well to different architectures of networks. We demonstrate our method on various OOD datasets to show its competitive performances and provide reasonable hypotheses to explain why our method works. On the ImageNet benchmark, Weshort achieves state-of-the-art performance on the false positive rate (FPR95) and the area under the receiver operating characteristic (AUROC) on the family of post-hoc methods.",
        "versions": [
            {
                "year": 2022,
                "source": "SupportedSources.INTERNET_ARCHIVE",
                "title": "WeShort: Out-of-distribution Detection With Weak Shortcut structure",
                "journal": "",
                "urls": [
                    "https://web.archive.org/web/20220715054329/https://arxiv.org/pdf/2207.05055v2.pdf"
                ],
                "doi": "",
                "publication_date": "2022-08-19 00:00:00"
            },
            {
                "year": 2022,
                "source": "SupportedSources.INTERNET_ARCHIVE",
                "title": "WeShort: Out-of-distribution Detection With Weak Shortcut structure",
                "journal": "figshare",
                "urls": [
                    "https://web.archive.org/web/20220703132143/https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/36070547/jwkhwhtvzkxshqqqhzftzfwdyhpnvmdg.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIYCQYOYV5JSSROOA/20220703/eu-west-1/s3/aws4_request&X-Amz-Date=20220703T132143Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=7db075e960dd9fa6c7542e23d1470e1d319ffe3592b0ab483e13c1cb4dcf86dc"
                ],
                "doi": "10.6084/m9.figshare.20164346.v3",
                "publication_date": "2022-06-28 00:00:00"
            },
            {
                "year": 2022,
                "source": "SupportedSources.INTERNET_ARCHIVE",
                "title": "WeShort: Out-of-distribution Detection With Weak Shortcut structure",
                "journal": "figshare",
                "urls": [
                    "https://web.archive.org/web/20220629063750/https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/36057308/WeShort8.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIYCQYOYV5JSSROOA/20220629/eu-west-1/s3/aws4_request&X-Amz-Date=20220629T063750Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=9261810c63e06710f22934c85ad734432fabe7185dc96daa6dee341bfe9eb20b"
                ],
                "doi": "10.6084/m9.figshare.20164346.v2",
                "publication_date": "2022-06-27 00:00:00"
            }
        ],
        "rank": 36
    },
    {
        "authors": [
            "Jinsol Lee",
            "Ghassan AlRegib"
        ],
        "title": "Gradients as a Measure of Uncertainty in Neural Networks",
        "publication_date": "2020-10-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "International Conference on Image Processing",
        "volume": "",
        "doi": "10.1109/icip40778.2020.9190679",
        "urls": [
            "https://openalex.org/W3090434739",
            "https://doi.org/10.1109/icip40778.2020.9190679",
            "http://arxiv.org/pdf/2008.08030"
        ],
        "id": "id-5777447154438777725",
        "abstract": "",
        "versions": [
            {
                "year": 2020,
                "source": "SupportedSources.INTERNET_ARCHIVE",
                "title": "Gradients as a Measure of Uncertainty in Neural Networks",
                "journal": "",
                "urls": [
                    "https://web.archive.org/web/20200916132120/https://arxiv.org/pdf/2008.08030v2.pdf"
                ],
                "doi": "",
                "publication_date": "2020-09-03 00:00:00"
            }
        ],
        "rank": 37
    },
    {
        "authors": [
            "Schulz, H.",
            "Behnke, S."
        ],
        "title": "Structured Prediction for Object Detection in Deep Neural Networks",
        "publication_date": "2014-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-3-319-11179-7_50",
        "urls": [
            "http://link.springer.com/content/pdf/10.1007/978-3-319-11179-7_50",
            "http://dx.doi.org/10.1007/978-3-319-11179-7_50"
        ],
        "id": "id-1567271916936727191",
        "abstract": "",
        "versions": [],
        "rank": 38
    },
    {
        "authors": [
            "Xu, J.",
            "Diao, B.",
            "Cui, B.",
            "Yang, K.",
            "Li, C.",
            "Hong, H."
        ],
        "title": "Pruning Filter via Gaussian Distribution Feature for Deep Neural Networks Acceleration",
        "publication_date": "2022-07-18 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ijcnn55064.2022.9892389",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/9891857/9889787/09892389.pdf?arnumber=9892389",
            "http://dx.doi.org/10.1109/ijcnn55064.2022.9892389"
        ],
        "id": "id6738995943688113207",
        "abstract": "",
        "versions": [],
        "rank": 39
    },
    {
        "authors": [
            "Pan, J."
        ],
        "title": "Recent Deep Neural Networks for Object Detection",
        "publication_date": "2023-02-10 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.54097/hset.v31i.5153",
        "urls": [
            "https://drpress.org/ojs/index.php/HSET/article/download/5153/4991",
            "https://drpress.org/ojs/index.php/HSET/article/download/5153/4991",
            "http://dx.doi.org/10.54097/hset.v31i.5153"
        ],
        "id": "id559462474185755392",
        "abstract": "",
        "versions": [],
        "rank": 40
    },
    {
        "authors": [
            "Jie Ren",
            "Peter Liu",
            "Emily Fertig",
            "Jasper Snoek",
            "Ryan Poplin",
            "Mark A. DePristo",
            "J. S. Dillon",
            "Balaji Lakshminarayanan"
        ],
        "title": "Likelihood Ratios for Out-of-Distribution Detection",
        "publication_date": "2019-06-07 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Neural Information Processing Systems",
        "volume": "32",
        "doi": null,
        "urls": [
            "https://openalex.org/W2970946347"
        ],
        "id": "id-5933350845585230887",
        "abstract": "",
        "versions": [],
        "rank": 41
    },
    {
        "authors": [
            "Gao, Y.",
            "Su, Q."
        ],
        "title": "Out-of-Distribution Detection with Uncertainty Enhanced Attention Maps",
        "publication_date": "2021-07-18 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ijcnn52387.2021.9533779",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/9533266/9533267/09533779.pdf?arnumber=9533779",
            "http://dx.doi.org/10.1109/ijcnn52387.2021.9533779"
        ],
        "id": "id-445532433019810194",
        "abstract": "",
        "versions": [],
        "rank": 42
    },
    {
        "authors": [
            "Honglak Lee",
            "Roger Grosse",
            "Rajesh Ranganath",
            "Andrew Y. Ng"
        ],
        "title": "Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations",
        "publication_date": "2009-06-14 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "International Conference on Machine Learning",
        "volume": "",
        "doi": "10.1145/1553374.1553453",
        "urls": [
            "https://openalex.org/W2130325614",
            "https://doi.org/10.1145/1553374.1553453"
        ],
        "id": "id-3353518239451518529",
        "abstract": "",
        "versions": [],
        "rank": 43
    },
    {
        "authors": [
            "You, J."
        ],
        "title": "Deep Neural Networks for Object Detection",
        "publication_date": "2022-11-10 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.54097/hset.v17i.2576",
        "urls": [
            "https://drpress.org/ojs/index.php/HSET/article/download/2576/2479",
            "https://drpress.org/ojs/index.php/HSET/article/download/2576/2479",
            "http://dx.doi.org/10.54097/hset.v17i.2576"
        ],
        "id": "id-5622194725006090832",
        "abstract": "",
        "versions": [],
        "rank": 44
    },
    {
        "authors": [
            "Xiongjie Chen",
            "Yunpeng Li",
            "Yongxin Yang"
        ],
        "title": "Batch-Ensemble Stochastic Neural Networks for Out-of-Distribution Detection",
        "publication_date": "2022-06-26 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20220628091850/https://arxiv.org/pdf/2206.12911v1.pdf"
        ],
        "id": "id-4358470517894143978",
        "abstract": "Out-of-distribution (OOD) detection has recently received much attention from the machine learning community due to its importance in deploying machine learning models in real-world applications. In this paper we propose an uncertainty quantification approach by modelling the distribution of features. We further incorporate an efficient ensemble mechanism, namely batch-ensemble, to construct the batch-ensemble stochastic neural networks (BE-SNNs) and overcome the feature collapse problem. We compare the performance of the proposed BE-SNNs with the other state-of-the-art approaches and show that BE-SNNs yield superior performance on several OOD benchmarks, such as the Two-Moons dataset, the FashionMNIST vs MNIST dataset, FashionMNIST vs NotMNIST dataset, and the CIFAR10 vs SVHN dataset.",
        "versions": [],
        "rank": 45
    },
    {
        "authors": [
            "Sobhani, P.",
            "Inkpen, D.",
            "Zhu, X."
        ],
        "title": "Exploring deep neural networks for multitarget stance detection",
        "publication_date": "2018-08-06 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1111/coin.12189",
        "urls": [
            "https://api.wiley.com/onlinelibrary/tdm/v1/articles/10.1111%2Fcoin.12189",
            "http://onlinelibrary.wiley.com/wol1/doi/10.1111/coin.12189/fullpdf",
            "http://dx.doi.org/10.1111/coin.12189"
        ],
        "id": "id7700032020512125909",
        "abstract": "",
        "versions": [],
        "rank": 46
    },
    {
        "authors": [
            "Jarrod Haas",
            "William Yolland",
            "Bernhard Rabus"
        ],
        "title": "Linking Neural Collapse and L2 Normalization with Improved Out-of-Distribution Detection in Deep Neural Networks",
        "publication_date": "2023-01-11 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20230115170908/https://arxiv.org/pdf/2209.08378v3.pdf"
        ],
        "id": "id-4282662753912837569",
        "abstract": "We propose a simple modification to standard ResNet architectures--L2 normalization over feature space--that substantially improves out-of-distribution (OoD) performance on the previously proposed Deep Deterministic Uncertainty (DDU) benchmark. We show that this change also induces early Neural Collapse (NC), an effect linked to better OoD performance. Our method achieves comparable or superior OoD detection scores and classification accuracy in a small fraction of the training time of the benchmark. Additionally, it substantially improves worst case OoD performance over multiple, randomly initialized models. Though we do not suggest that NC is the sole mechanism or a comprehensive explanation for OoD behaviour in deep neural networks (DNN), we believe NC's simple mathematical and geometric structure can provide a framework for analysis of this complex phenomenon in future work.",
        "versions": [
            {
                "year": 2022,
                "source": "SupportedSources.PAPERS_WITH_CODE",
                "title": "Linking Neural Collapse and L2 Normalization with Improved Out-of-Distribution Detection in Deep Neural Networks",
                "journal": "",
                "urls": [
                    "https://arxiv.org/pdf/2209.08378v3.pdf"
                ],
                "doi": "",
                "publication_date": "2022-09-17 00:00:00"
            }
        ],
        "rank": 47
    },
    {
        "authors": [
            "Zarai, R.",
            "Kachout, M.",
            "Hazber, M.",
            "Mahdi, M."
        ],
        "title": "Recurrent Neural Networks and Deep Neural Networks Based on Intrusion Detection System",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.4236/oalib.1106151",
        "urls": [
            "http://dx.doi.org/10.4236/oalib.1106151"
        ],
        "id": "id-9084979315042241972",
        "abstract": "",
        "versions": [],
        "rank": 48
    },
    {
        "authors": [
            "Chao Dong",
            "Chen Change Loy",
            "Kaiming He",
            "Xiaoou Tang"
        ],
        "title": "Image Super-Resolution Using Deep Convolutional Networks",
        "publication_date": "2016-02-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
        "volume": "38",
        "doi": "10.1109/tpami.2015.2439281",
        "urls": [
            "https://openalex.org/W1885185971",
            "https://doi.org/10.1109/tpami.2015.2439281",
            "http://arxiv.org/pdf/1501.00092"
        ],
        "id": "id5207100501149176561",
        "abstract": "",
        "versions": [],
        "rank": 49
    },
    {
        "authors": [
            "David Mac\u00eado",
            "Tsang Ing Ren",
            "Cleber Zanchettin",
            "Adriano L. I. Oliveira",
            "Teresa Ludermir"
        ],
        "title": "Entropic Out-of-Distribution Detection",
        "publication_date": "2021-05-24 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20201205011648/https://arxiv.org/pdf/1908.05569v11.pdf"
        ],
        "id": "id3257534080850448627",
        "abstract": "Out-of-distribution (OOD) detection approaches usually present special requirements (e.g., hyperparameter validation, collection of outlier data) and produce side effects (e.g., classification accuracy drop, slower energy-inefficient inferences). We argue that these issues are a consequence of the SoftMax loss anisotropy and disagreement with the maximum entropy principle. Thus, we propose the IsoMax loss and the entropic score. The seamless drop-in replacement of the SoftMax loss by IsoMax loss requires neither additional data collection nor hyperparameter validation. The trained models do not exhibit classification accuracy drop and produce fast energy-efficient inferences. Moreover, our experiments show that training neural networks with IsoMax loss significantly improves their OOD detection performance. The IsoMax loss exhibits state-of-the-art performance under the mentioned conditions (fast energy-efficient inference, no classification accuracy drop, no collection of outlier data, and no hyperparameter validation), which we call the seamless OOD detection task. In future work, current OOD detection methods may replace the SoftMax loss with the IsoMax loss to improve their performance on the commonly studied non-seamless OOD detection problem.",
        "versions": [],
        "rank": 50
    },
    {
        "authors": [
            "Das, S.",
            "Dutta, A.",
            "Sharma, S.",
            "Godboley, S."
        ],
        "title": "A Comparative Analysis of a Novel Anomaly Detection Algorithm with Neural Networks",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.4018/978-1-7998-0414-7.ch004",
        "urls": [
            "https://www.igi-global.com/viewtitle.aspx?TitleId=237863",
            "http://dx.doi.org/10.4018/978-1-7998-0414-7.ch004"
        ],
        "id": "id3985395366851449104",
        "abstract": "",
        "versions": [],
        "rank": 51
    },
    {
        "authors": [
            "Sageev Oore",
            "Chandramouli S Sastry"
        ],
        "title": "Zero-Shot Out-of-Distribution Detection with Feature Correlations",
        "publication_date": "2019-09-25 00:00:00",
        "source": "SupportedSources.PAPERS_WITH_CODE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://openreview.net/pdf?id=r1g6MCEtwr",
            "https://github.com/zeroshot-ood/ood-detection"
        ],
        "id": "id-9180439983081105174",
        "abstract": "When presented with Out-of-Distribution (OOD) examples, deep neural networks yield confident, incorrect predictions. Detecting OOD examples is challenging, and the potential risks are high. In this paper, we propose to detect OOD examples by identifying inconsistencies between activity patterns and class predicted. We find that characterizing activity patterns by feature correlations and identifying anomalies in pairwise feature correlation values can yield high OOD detection rates. We identify anomalies in the pairwise feature correlations by simply comparing each pairwise correlation value with its respective range observed over the training data. Unlike many approaches, this can be used with any pre-trained softmax classifier and does not require access to OOD data for fine-tuning hyperparameters, nor does it require OOD access for inferring parameters. The method is applicable across a variety of architectures and vision datasets and generally performs better than or equal to state-of-the-art OOD detection methods, including those that do assume access to OOD examples.",
        "versions": [],
        "rank": 52
    },
    {
        "authors": [
            "Gaikwad, D.",
            "Mukeri, A."
        ],
        "title": "Fine Tuned Deep Neural Networks for Intrusion Detection System",
        "publication_date": "2020-06-06 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.46610/jonscn.2020.v06i02.002",
        "urls": [
            "http://matjournals.in/index.php/JONSCN/article/view/5143",
            "http://dx.doi.org/10.46610/jonscn.2020.v06i02.002"
        ],
        "id": "id285050795570126712",
        "abstract": "",
        "versions": [],
        "rank": 53
    },
    {
        "authors": [
            "Sanghoon Hong",
            "Byungseok Roh",
            "Kye-Hyeon Kim",
            "Yeongjae Cheon",
            "Minje Park"
        ],
        "title": "PVANet: Lightweight Deep Neural Networks for Real-time Object Detection",
        "publication_date": "2016-11-23 17:43:28+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1611.08588v2",
            "http://arxiv.org/abs/1611.08588v2",
            "http://arxiv.org/pdf/1611.08588v2"
        ],
        "id": "id5493834068815128365",
        "abstract": "In object detection, reducing computational cost is as important as improving\naccuracy for most practical usages. This paper proposes a novel network\nstructure, which is an order of magnitude lighter than other state-of-the-art\nnetworks while maintaining the accuracy. Based on the basic principle of more\nlayers with less channels, this new deep neural network minimizes its\nredundancy by adopting recent innovations including C.ReLU and Inception\nstructure. We also show that this network can be trained efficiently to achieve\nsolid results on well-known object detection benchmarks: 84.9% and 84.2% mAP on\nVOC2007 and VOC2012 while the required compute is less than 10% of the recent\nResNet-101.",
        "versions": [],
        "rank": 54
    },
    {
        "authors": [
            "Sheraz Naseer",
            "Y. Saleem",
            "S. Khalid",
            "Muhammad Khawar Bashir",
            "Jihun Han",
            "M. Iqbal",
            "Kijun Han"
        ],
        "title": "Enhanced Network Anomaly Detection Based on Deep Neural Networks",
        "publication_date": "2018-08-17 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "IEEE Access",
        "volume": "6",
        "doi": "10.1109/ACCESS.2018.2863036",
        "urls": [
            "https://www.semanticscholar.org/paper/83996f9214d998ffb5ea8c2ea6104e96584f587b"
        ],
        "id": "id1589547788677638954",
        "abstract": "Due to the monumental growth of Internet applications in the last decade, the need for security of information network has increased manifolds. As a primary defense of network infrastructure, an intrusion detection system is expected to adapt to dynamically changing threat landscape. Many supervised and unsupervised techniques have been devised by researchers from the discipline of machine learning and data mining to achieve reliable detection of anomalies. Deep learning is an area of machine learning which applies neuron-like structure for learning tasks. Deep learning has profoundly changed the way we approach learning tasks by delivering monumental progress in different disciplines like speech processing, computer vision, and natural language processing to name a few. It is only relevant that this new technology must be investigated for information security applications. The aim of this paper is to investigate the suitability of deep learning approaches for anomaly-based intrusion detection system. For this research, we developed anomaly detection models based on different deep neural network structures, including convolutional neural networks, autoencoders, and recurrent neural networks. These deep models were trained on NSLKDD training data set and evaluated on both test data sets provided by NSLKDD, namely NSLKDDTest+ and NSLKDDTest21. All experiments in this paper are performed by authors on a GPU-based test bed. Conventional machine learning-based intrusion detection models were implemented using well-known classification techniques, including extreme learning machine, nearest neighbor, decision-tree, random-forest, support vector machine, naive-bays, and quadratic discriminant analysis. Both deep and conventional machine learning models were evaluated using well-known classification metrics, including receiver operating characteristics, area under curve, precision-recall curve, mean average precision and accuracy of classification. Experimental results of deep IDS models showed promising results for real-world application in anomaly detection systems.",
        "versions": [],
        "rank": 55
    },
    {
        "authors": [
            "Gabriel C. Fernandez",
            "Shouhuai Xu"
        ],
        "title": "A Case Study on Using Deep Learning for Network Intrusion Detection",
        "publication_date": "2019-10-05 03:44:23+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1910.02203v1",
            "http://arxiv.org/abs/1910.02203v1",
            "http://arxiv.org/pdf/1910.02203v1"
        ],
        "id": "id-5390119398654274304",
        "abstract": "Deep Learning has been very successful in many application domains. However,\nits usefulness in the context of network intrusion detection has not been\nsystematically investigated. In this paper, we report a case study on using\ndeep learning for both supervised network intrusion detection and unsupervised\nnetwork anomaly detection. We show that Deep Neural Networks (DNNs) can\noutperform other machine learning based intrusion detection systems, while\nbeing robust in the presence of dynamic IP addresses. We also show that\nAutoencoders can be effective for network anomaly detection.",
        "versions": [],
        "rank": 56
    },
    {
        "authors": [
            "Anugya Srivastava",
            "Shriya Jain",
            "Mugdha Thigle"
        ],
        "title": "Out of Distribution Detection on ImageNet-O",
        "publication_date": "2022-01-23 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20220129092442/https://arxiv.org/pdf/2201.09352v1.pdf"
        ],
        "id": "id-4377851376285881825",
        "abstract": "Out of distribution (OOD) detection is a crucial part of making machine learning systems robust. The ImageNet-O dataset is an important tool in testing the robustness of ImageNet trained deep neural networks that are widely used across a variety of systems and applications. We aim to perform a comparative analysis of OOD detection methods on ImageNet-O, a first of its kind dataset with a label distribution different than that of ImageNet, that has been created to aid research in OOD detection for ImageNet models. As this dataset is fairly new, we aim to provide a comprehensive benchmarking of some of the current state of the art OOD detection methods on this novel dataset. This benchmarking covers a variety of model architectures, settings where we haves prior access to the OOD data versus when we don't, predictive score based approaches, deep generative approaches to OOD detection, and more.",
        "versions": [],
        "rank": 57
    },
    {
        "authors": [
            "Frank Rosenblatt"
        ],
        "title": "The perceptron: A probabilistic model for information storage and organization in the brain.",
        "publication_date": "1958-11-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Psychological Review",
        "volume": "65",
        "doi": "10.1037/h0042519",
        "urls": [
            "https://openalex.org/W2040870580",
            "https://doi.org/10.1037/h0042519"
        ],
        "id": "id-4304706149370155838",
        "abstract": "",
        "versions": [],
        "rank": 58
    },
    {
        "authors": [
            "Shah, M.",
            "Kapdi, R."
        ],
        "title": "Object detection using deep neural networks",
        "publication_date": "2017-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/iccons.2017.8250570",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/8241057/8250514/08250570.pdf?arnumber=8250570",
            "http://dx.doi.org/10.1109/iccons.2017.8250570"
        ],
        "id": "id1998751215427865679",
        "abstract": "",
        "versions": [],
        "rank": 59
    },
    {
        "authors": [
            "Johri, E.",
            "Ahuja, M.",
            "Chothani, D.",
            "Dayani, U."
        ],
        "title": "Covid-19 Detection Using Convolution Neural Networks",
        "publication_date": "2021-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.2139/ssrn.3867914",
        "urls": [
            "http://dx.doi.org/10.2139/ssrn.3867914"
        ],
        "id": "id-5289256302104219553",
        "abstract": "",
        "versions": [],
        "rank": 60
    },
    {
        "authors": [
            "Kyongsik Yun",
            "Alexander Huyen",
            "Thomas Lu"
        ],
        "title": "Deep Neural Networks for Pattern Recognition",
        "publication_date": "2018-09-25 18:23:49+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1809.09645v1",
            "http://arxiv.org/abs/1809.09645v1",
            "http://arxiv.org/pdf/1809.09645v1"
        ],
        "id": "id4990531589048192800",
        "abstract": "In the field of pattern recognition research, the method of using deep neural\nnetworks based on improved computing hardware recently attracted attention\nbecause of their superior accuracy compared to conventional methods. Deep\nneural networks simulate the human visual system and achieve human equivalent\naccuracy in image classification, object detection, and segmentation. This\nchapter introduces the basic structure of deep neural networks that simulate\nhuman neural networks. Then we identify the operational processes and\napplications of conditional generative adversarial networks, which are being\nactively researched based on the bottom-up and top-down mechanisms, the most\nimportant functions of the human visual perception process. Finally, recent\ndevelopments in training strategies for effective learning of complex deep\nneural networks are addressed.",
        "versions": [],
        "rank": 61
    },
    {
        "authors": [
            "Kumar Sricharan",
            "Ashok Srivastava"
        ],
        "title": "Building robust classifiers through generation of confident out of distribution examples",
        "publication_date": "2018-12-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "arXiv (Cornell University)",
        "volume": "",
        "doi": null,
        "urls": [
            "https://openalex.org/W2902277560"
        ],
        "id": "id8494708792322033527",
        "abstract": "",
        "versions": [],
        "rank": 62
    },
    {
        "authors": [
            "Gabi Shalev",
            "Yossi Adi",
            "Joseph Keshet"
        ],
        "title": "Out-of-distribution detection using multiple semantic label representations",
        "publication_date": "2018-12-03 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Neural Information Processing Systems",
        "volume": "31",
        "doi": null,
        "urls": [
            "https://openalex.org/W2888635935"
        ],
        "id": "id626260905085050421",
        "abstract": "",
        "versions": [
            {
                "year": 2018,
                "source": "SupportedSources.OPENALEX",
                "title": "Out-of-Distribution Detection using Multiple Semantic Label Representations",
                "journal": "arXiv (Cornell University)",
                "urls": [
                    "https://openalex.org/W2953272802"
                ],
                "doi": null,
                "publication_date": "2018-08-20 00:00:00"
            }
        ],
        "rank": 63
    },
    {
        "authors": [
            "Feng Chen",
            "Xujiang Zhao",
            "Chen Zhao",
            "Haoliang Wang"
        ],
        "title": "Layer Adaptive Deep Neural Networks for Out-of-distribution Detection",
        "publication_date": "2022-03-01 00:00:00",
        "source": "SupportedSources.PAPERS_WITH_CODE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://arxiv.org/pdf/2203.00192v1.pdf",
            "https://github.com/haoliangwang86/la-ood"
        ],
        "id": "id906155455933654048",
        "abstract": "During the forward pass of Deep Neural Networks (DNNs), inputs gradually transformed from low-level features to high-level conceptual labels. While features at different layers could summarize the important factors of the inputs at varying levels, modern out-of-distribution (OOD) detection methods mostly focus on utilizing their ending layer features. In this paper, we proposed a novel layer-adaptive OOD detection framework (LA-OOD) for DNNs that can fully utilize the intermediate layers' outputs. Specifically, instead of training a unified OOD detector at a fixed ending layer, we train multiple One-Class SVM OOD detectors simultaneously at the intermediate layers to exploit the full spectrum characteristics encoded at varying depths of DNNs. We develop a simple yet effective layer-adaptive policy to identify the best layer for detecting each potential OOD example. LA-OOD can be applied to any existing DNNs and does not require access to OOD samples during the training. Using three DNNs of varying depth and architectures, our experiments demonstrate that LA-OOD is robust against OODs of varying complexity and can outperform state-of-the-art competitors by a large margin on some real-world datasets.",
        "versions": [],
        "rank": 64
    },
    {
        "authors": [
            "Aggarwal, C."
        ],
        "title": "Training Deep Neural Networks",
        "publication_date": "2018-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-3-319-94463-0_3",
        "urls": [
            "http://link.springer.com/content/pdf/10.1007/978-3-319-94463-0_3",
            "http://dx.doi.org/10.1007/978-3-319-94463-0_3"
        ],
        "id": "id4266090107825560423",
        "abstract": "",
        "versions": [],
        "rank": 65
    },
    {
        "authors": [
            "Bejnordi, Babak Ehteshami",
            "Ciompi, Francesco",
            "Ghafoorian, Mohsen",
            "Kooi, Thijs",
            "Litjens, Geert",
            "Setio, Arnaud Arindra Adiyoso",
            "S\u00e1nchez, Clara I.",
            "van der Laak, Jeroen A. W. M.",
            "van Ginneken, Bram"
        ],
        "title": "A Survey on Deep Learning in Medical Image Analysis",
        "publication_date": "2017-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1016/j.media.2017.07.005",
        "urls": [
            "http://arxiv.org/abs/1702.05747"
        ],
        "id": "id4896699016694997767",
        "abstract": "Deep learning algorithms, in particular convolutional networks, have rapidly\nbecome a methodology of choice for analyzing medical images. This paper reviews\nthe major deep learning concepts pertinent to medical image analysis and\nsummarizes over 300 contributions to the field, most of which appeared in the\nlast year. We survey the use of deep learning for image classification, object\ndetection, segmentation, registration, and other tasks and provide concise\noverviews of studies per application area. Open challenges and directions for\nfuture research are discussed.Comment: Revised survey includes expanded discussion section and reworked\n  introductory section on common deep architectures. Added missed papers from\n  before Feb 1st 201",
        "versions": [],
        "rank": 66
    },
    {
        "authors": [
            "Thabang Mathonsi",
            "Terence L. van Zyl"
        ],
        "title": "Multivariate Anomaly Detection based on Prediction Intervals Constructed using Deep Learning",
        "publication_date": "2021-10-07 12:34:31+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2110.03393v1",
            "http://arxiv.org/abs/2110.03393v1",
            "http://arxiv.org/pdf/2110.03393v1"
        ],
        "id": "id-5991056681153685040",
        "abstract": "It has been shown that deep learning models can under certain circumstances\noutperform traditional statistical methods at forecasting. Furthermore, various\ntechniques have been developed for quantifying the forecast uncertainty\n(prediction intervals). In this paper, we utilize prediction intervals\nconstructed with the aid of artificial neural networks to detect anomalies in\nthe multivariate setting. Challenges with existing deep learning-based anomaly\ndetection approaches include $(i)$ large sets of parameters that may be\ncomputationally intensive to tune, $(ii)$ returning too many false positives\nrendering the techniques impractical for use, $(iii)$ requiring labeled\ndatasets for training which are often not prevalent in real life. Our approach\novercomes these challenges. We benchmark our approach against the oft-preferred\nwell-established statistical models. We focus on three deep learning\narchitectures, namely, cascaded neural networks, reservoir computing and long\nshort-term memory recurrent neural networks. Our finding is deep learning\noutperforms (or at the very least is competitive to) the latter.",
        "versions": [],
        "rank": 67
    },
    {
        "authors": [
            "Guy Bar-Shalom",
            "Yonatan Geifman",
            "Ran El-Yaniv"
        ],
        "title": "Distribution Shift Detection for Deep Neural Networks",
        "publication_date": "2022-10-19 21:27:25+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2210.10897v2",
            "http://arxiv.org/abs/2210.10897v2",
            "http://arxiv.org/pdf/2210.10897v2"
        ],
        "id": "id-8988011272217594126",
        "abstract": "To deploy and operate deep neural models in production, the quality of their\npredictions, which might be contaminated benignly or manipulated maliciously by\ninput distributional deviations, must be monitored and assessed. Specifically,\nwe study the case of monitoring the healthy operation of a deep neural network\n(DNN) receiving a stream of data, with the aim of detecting input\ndistributional deviations over which the quality of the network's predictions\nis potentially damaged. Using selective prediction principles, we propose a\ndistribution deviation detection method for DNNs. The proposed method is\nderived from a tight coverage generalization bound computed over a sample of\ninstances drawn from the true underlying distribution. Based on this bound, our\ndetector continuously monitors the operation of the network over a test window\nand fires off an alarm whenever a deviation is detected. This novel detection\nmethod consistently and significantly outperforms the state of the art with\nrespect to the CIFAR-10 and ImageNet datasets, thus establishing a new\nperformance bar for this task, while being substantially more efficient in time\nand space complexities.",
        "versions": [],
        "rank": 68
    },
    {
        "authors": [
            "Zhang, G."
        ],
        "title": "Object detection with deep neural networks under constrained scenarios",
        "publication_date": "None",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.32657/10356/164687",
        "urls": [
            "http://dx.doi.org/10.32657/10356/164687"
        ],
        "id": "id-1220206474402869241",
        "abstract": "",
        "versions": [],
        "rank": 69
    },
    {
        "authors": [
            "Serghei, T.",
            "Ichim, L.",
            "Popescu, D."
        ],
        "title": "Human Detection in Restricted Areas Using Deep Convolutional Neural Networks",
        "publication_date": "2022-11-15 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/telfor56187.2022.9983720",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/9983661/9983662/09983720.pdf?arnumber=9983720",
            "http://dx.doi.org/10.1109/telfor56187.2022.9983720"
        ],
        "id": "id2146776058729641644",
        "abstract": "",
        "versions": [],
        "rank": 70
    },
    {
        "authors": [
            "Michelucci, U."
        ],
        "title": "Feedforward Neural Networks",
        "publication_date": "2018-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-1-4842-3790-8_3",
        "urls": [
            "http://link.springer.com/content/pdf/10.1007/978-1-4842-3790-8_3",
            "http://dx.doi.org/10.1007/978-1-4842-3790-8_3"
        ],
        "id": "id5700641638536407178",
        "abstract": "",
        "versions": [],
        "rank": 71
    },
    {
        "authors": [
            "Zhu, Q.",
            "Zheng, G.",
            "Yan, Y."
        ],
        "title": "Effective Out-of-Distribution Detection in Classifier Based on PEDCC-Loss",
        "publication_date": "2022-08-02 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/s11063-022-10970-y",
        "urls": [
            "https://link.springer.com/content/pdf/10.1007/s11063-022-10970-y.pdf",
            "https://link.springer.com/article/10.1007/s11063-022-10970-y/fulltext.html",
            "https://link.springer.com/content/pdf/10.1007/s11063-022-10970-y.pdf",
            "http://dx.doi.org/10.1007/s11063-022-10970-y"
        ],
        "id": "id-2191362105157355986",
        "abstract": "",
        "versions": [],
        "rank": 72
    },
    {
        "authors": [
            "Pedro Domingos"
        ],
        "title": "A few useful things to know about machine learning",
        "publication_date": "2012-10-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Communications of The ACM",
        "volume": "55",
        "doi": "10.1145/2347736.2347755",
        "urls": [
            "https://openalex.org/W2161336914",
            "https://doi.org/10.1145/2347736.2347755",
            "http://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf"
        ],
        "id": "id5953359344910011290",
        "abstract": "",
        "versions": [],
        "rank": 73
    },
    {
        "authors": [
            "Bouganis, Christos-Savvas",
            "Xia, Guoxuan"
        ],
        "title": "On the Usefulness of Deep Ensemble Diversity for Out-of-Distribution  Detection",
        "publication_date": "2022-09-20 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "http://arxiv.org/abs/2207.07517"
        ],
        "id": "id-8656672570149183743",
        "abstract": "The ability to detect Out-of-Distribution (OOD) data is important in\nsafety-critical applications of deep learning. The aim is to separate\nIn-Distribution (ID) data drawn from the training distribution from OOD data\nusing a measure of uncertainty extracted from a deep neural network. Deep\nEnsembles are a well-established method of improving the quality of uncertainty\nestimates produced by deep neural networks, and have been shown to have\nsuperior OOD detection performance compared to single models. An existing\nintuition in the literature is that the diversity of Deep Ensemble predictions\nindicates distributional shift, and so measures of diversity such as Mutual\nInformation (MI) should be used for OOD detection. We show experimentally that\nthis intuition is not valid on ImageNet-scale OOD detection -- using MI leads\nto 30-40% worse %FPR@95 compared to single-model entropy on some OOD datasets.\nWe suggest an alternative explanation for Deep Ensembles' better OOD detection\nperformance -- OOD detection is binary classification and we are ensembling\ndiverse classifiers. As such we show that practically, even better OOD\ndetection performance can be achieved for Deep Ensembles by averaging\ntask-specific detection scores such as Energy over the ensemble.Comment: Workshop on Uncertainty Quantification for Computer Vision, ECCV 202",
        "versions": [],
        "rank": 74
    },
    {
        "authors": [
            "Charles Blundell",
            "Balaji Lakshminarayanan",
            "Alexander Pritzel"
        ],
        "title": "Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles",
        "publication_date": "2016-12-05 00:00:00",
        "source": "SupportedSources.PAPERS_WITH_CODE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1612.01474v3.pdf",
            "https://github.com/StanfordASL/SCOD",
            "http://papers.nips.cc/paper/7219-simple-and-scalable-predictive-uncertainty-estimation-using-deep-ensembles.pdf"
        ],
        "id": "id-297143997890414661",
        "abstract": "Deep neural networks (NNs) are powerful black box predictors that have\nrecently achieved impressive performance on a wide spectrum of tasks.\nQuantifying predictive uncertainty in NNs is a challenging and yet unsolved\nproblem. Bayesian NNs, which learn a distribution over weights, are currently\nthe state-of-the-art for estimating predictive uncertainty; however these\nrequire significant modifications to the training procedure and are\ncomputationally expensive compared to standard (non-Bayesian) NNs. We propose\nan alternative to Bayesian NNs that is simple to implement, readily\nparallelizable, requires very little hyperparameter tuning, and yields high\nquality predictive uncertainty estimates. Through a series of experiments on\nclassification and regression benchmarks, we demonstrate that our method\nproduces well-calibrated uncertainty estimates which are as good or better than\napproximate Bayesian NNs. To assess robustness to dataset shift, we evaluate\nthe predictive uncertainty on test examples from known and unknown\ndistributions, and show that our method is able to express higher uncertainty\non out-of-distribution examples. We demonstrate the scalability of our method\nby evaluating predictive uncertainty estimates on ImageNet.",
        "versions": [],
        "rank": 75
    },
    {
        "authors": [
            "Christophe Cerisara",
            "Paul Caillon",
            "Guillaume Le Berre"
        ],
        "title": "Unsupervised Post-Tuning of Deep Neural Networks",
        "publication_date": "2021-07-18 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/IJCNN52387.2021.9534198",
        "urls": [
            "https://www.semanticscholar.org/paper/c3ccdae9b40b699c18684511895cf8b1c4aaa0c7"
        ],
        "id": "id-1299101935707979236",
        "abstract": "We propose in this work a new unsupervised training procedure that is most effective when it is applied after supervised training and fine-tuning of deep neural network classifiers. While standard regularization techniques combat overfitting by means that are unrelated to the target classification loss, such as by minimizing the L2 norm or by adding noise either in the data, model or process, the proposed unsupervised training loss reduces overfitting by optimizing the true classifier risk. The proposed approach is evaluated on several tasks of increasing difficulty and varying conditions: unsupervised training, post-tuning and anomaly detection. It is also tested both on simple neural networks, such as small multi-layer perceptron, and complex Natural Language Processing models, e.g., pretrained BERT embeddings. Experimental results confirm the theory and show that the proposed approach gives the best results in post-tuning conditions, i.e., when applied after supervised training and fine-tuning.",
        "versions": [],
        "rank": 76
    },
    {
        "authors": [
            "Gao Huang",
            "Guang-Bin Huang",
            "Shiji Song",
            "Keyou You"
        ],
        "title": "Trends in extreme learning machines: A review",
        "publication_date": "2015-01-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Neural Networks",
        "volume": "61",
        "doi": "10.1016/j.neunet.2014.10.001",
        "urls": [
            "https://openalex.org/W2121971770",
            "https://doi.org/10.1016/j.neunet.2014.10.001"
        ],
        "id": "id5012718754359438785",
        "abstract": "",
        "versions": [],
        "rank": 77
    },
    {
        "authors": [
            "Benenson, Rodrigo",
            "Hosang, Jan",
            "Omran, Mohamed",
            "Schiele, Bernt"
        ],
        "title": "Taking a Deeper Look at Pedestrians",
        "publication_date": "2015-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/cvpr.2015.7299034",
        "urls": [
            "http://arxiv.org/abs/1501.05790"
        ],
        "id": "id6283756850817005508",
        "abstract": "In this paper we study the use of convolutional neural networks (convnets)\nfor the task of pedestrian detection. Despite their recent diverse successes,\nconvnets historically underperform compared to other pedestrian detectors. We\ndeliberately omit explicitly modelling the problem into the network (e.g. parts\nor occlusion modelling) and show that we can reach competitive performance\nwithout bells and whistles. In a wide range of experiments we analyse small and\nbig convnets, their architectural choices, parameters, and the influence of\ndifferent training data, including pre-training on surrogate tasks.\n  We present the best convnet detectors on the Caltech and KITTI dataset. On\nCaltech our convnets reach top performance both for the Caltech1x and\nCaltech10x training setup. Using additional data at training time our strongest\nconvnet model is competitive even to detectors that use additional data\n(optical flow) at test time",
        "versions": [],
        "rank": 78
    },
    {
        "authors": [
            "Anisha Roy",
            "Rikhi Bose",
            "Jayabrata Bhaduri"
        ],
        "title": "A fast accurate fine-grain object detection model based on YOLOv4 deep neural network",
        "publication_date": "2021-10-30 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Neural Computing and Applications",
        "volume": "34",
        "doi": "10.1007/s00521-021-06651-x",
        "urls": [
            "https://www.semanticscholar.org/paper/a4900016b1a6baffd5b52d340da791e863b04243"
        ],
        "id": "id2880556803730527772",
        "abstract": null,
        "versions": [],
        "rank": 79
    },
    {
        "authors": [
            "Chao Dong",
            "Chen Change Loy",
            "Kaiming He",
            "Xiaoou Tang"
        ],
        "title": "Learning a Deep Convolutional Network for Image Super-Resolution",
        "publication_date": "2014-09-06 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Lecture Notes in Computer Science",
        "volume": "",
        "doi": "10.1007/978-3-319-10593-2_13",
        "urls": [
            "https://openalex.org/W54257720",
            "https://doi.org/10.1007/978-3-319-10593-2_13",
            "https://link.springer.com/content/pdf/10.1007%2F978-3-319-10593-2_13.pdf"
        ],
        "id": "id1733914905510148044",
        "abstract": "",
        "versions": [],
        "rank": 80
    },
    {
        "authors": [
            "Zhang, Z."
        ],
        "title": "Towards real-time object detection on edge with deep neural networks",
        "publication_date": "None",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.32469/10355/67715",
        "urls": [
            "http://dx.doi.org/10.32469/10355/67715"
        ],
        "id": "id-4982804305820042323",
        "abstract": "",
        "versions": [],
        "rank": 81
    },
    {
        "authors": [
            "Michelucci, U."
        ],
        "title": "Fundamentals of Convolutional Neural Networks",
        "publication_date": "2019-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-1-4842-4976-5_3",
        "urls": [
            "http://link.springer.com/content/pdf/10.1007/978-1-4842-4976-5_3",
            "http://dx.doi.org/10.1007/978-1-4842-4976-5_3"
        ],
        "id": "id-2653394863882997379",
        "abstract": "",
        "versions": [],
        "rank": 82
    },
    {
        "authors": [
            "Zhu, G.",
            "Zhao, T."
        ],
        "title": "Deep-gKnock: Nonlinear group-feature selection with deep neural networks",
        "publication_date": "2021-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1016/j.neunet.2020.12.004",
        "urls": [
            "https://api.elsevier.com/content/article/PII:S0893608020304214?httpAccept=text/xml",
            "https://api.elsevier.com/content/article/PII:S0893608020304214?httpAccept=text/plain",
            "http://dx.doi.org/10.1016/j.neunet.2020.12.004"
        ],
        "id": "id-1854002374127429417",
        "abstract": "",
        "versions": [],
        "rank": 83
    },
    {
        "authors": [
            "Qian, H.",
            "Xu, J.",
            "Zhou, J."
        ],
        "title": "Object Detection Using Deep Convolutional Neural Networks",
        "publication_date": "2018-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/cac.2018.8623808",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/8603844/8623021/08623808.pdf?arnumber=8623808",
            "http://dx.doi.org/10.1109/cac.2018.8623808"
        ],
        "id": "id-2015485188593279710",
        "abstract": "",
        "versions": [],
        "rank": 84
    },
    {
        "authors": [
            "Yaser, A.",
            "Mousa, H.",
            "Hussein, M."
        ],
        "title": "Improved DDoS Detection Utilizing Deep Neural Networks and Feedforward Neural Networks as Autoencoder",
        "publication_date": "2022-08-12 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.3390/fi14080240",
        "urls": [
            "https://www.mdpi.com/1999-5903/14/8/240/pdf",
            "http://dx.doi.org/10.3390/fi14080240"
        ],
        "id": "id-7680285779027942488",
        "abstract": "",
        "versions": [],
        "rank": 85
    },
    {
        "authors": [
            "Yaniv Taigman",
            "Ming Yang",
            "Marc'Aurelio Ranzato",
            "Lior Wolf"
        ],
        "title": "DeepFace: Closing the Gap to Human-Level Performance in Face Verification",
        "publication_date": "2014-06-23 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Computer Vision and Pattern Recognition",
        "volume": "",
        "doi": "10.1109/cvpr.2014.220",
        "urls": [
            "https://openalex.org/W2145287260",
            "https://doi.org/10.1109/cvpr.2014.220"
        ],
        "id": "id1229244851228293192",
        "abstract": "",
        "versions": [],
        "rank": 86
    },
    {
        "authors": [
            "Andre G. C. Pacheco",
            "Chandramouli Shama Sastry",
            "Thomas Trappenberg",
            "Sageev Oore",
            "Renato A. Krohling"
        ],
        "title": "On Out-of-Distribution Detection Algorithms with Deep Neural Skin Cancer Classifiers",
        "publication_date": "2020-06-14 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Computer Vision and Pattern Recognition",
        "volume": "",
        "doi": "10.1109/cvprw50498.2020.00374",
        "urls": [
            "https://openalex.org/W3034217686",
            "https://doi.org/10.1109/cvprw50498.2020.00374"
        ],
        "id": "id-7444039598689950228",
        "abstract": "",
        "versions": [
            {
                "year": 2020,
                "source": "SupportedSources.CROSSREF",
                "title": "On Out-of-Distribution Detection Algorithms with Deep Neural Skin Cancer Classifiers",
                "journal": "",
                "urls": [
                    "http://xplorestaging.ieee.org/ielx7/9142289/9150305/09150878.pdf?arnumber=9150878",
                    "http://dx.doi.org/10.1109/cvprw50498.2020.00374"
                ],
                "doi": "10.1109/cvprw50498.2020.00374",
                "publication_date": "2020-01-01 00:00:00"
            }
        ],
        "rank": 87
    },
    {
        "authors": [
            "Davidian, M.",
            "Vanetik, N.",
            "Kiperberg, M."
        ],
        "title": "Ransomware Detection with Deep Neural Networks",
        "publication_date": "2022-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.5220/0011008000003120",
        "urls": [
            "http://dx.doi.org/10.5220/0011008000003120"
        ],
        "id": "id7264470828303254090",
        "abstract": "",
        "versions": [],
        "rank": 88
    },
    {
        "authors": [
            "Ramon Oliveira",
            "Pedro Tabacof",
            "Eduardo Valle"
        ],
        "title": "Known Unknowns: Uncertainty Quality in Bayesian Neural Networks",
        "publication_date": "2016-12-23 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20200912114227/https://arxiv.org/pdf/1612.01251v2.pdf"
        ],
        "id": "id6666607331920015172",
        "abstract": "We evaluate the uncertainty quality in neural networks using anomaly detection. We extract uncertainty measures (e.g. entropy) from the predictions of candidate models, use those measures as features for an anomaly detector, and gauge how well the detector differentiates known from unknown classes. We assign higher uncertainty quality to candidate models that lead to better detectors. We also propose a novel method for sampling a variational approximation of a Bayesian neural network, called One-Sample Bayesian Approximation (OSBA). We experiment on two datasets, MNIST and CIFAR10. We compare the following candidate neural network models: Maximum Likelihood, Bayesian Dropout, OSBA, and --- for MNIST --- the standard variational approximation. We show that Bayesian Dropout and OSBA provide better uncertainty information than Maximum Likelihood, and are essentially equivalent to the standard variational approximation, but much faster.",
        "versions": [],
        "rank": 89
    },
    {
        "authors": [
            "Riccardo Miotto",
            "Fei Wang",
            "Shuang Wang",
            "Xiaoqian Jiang",
            "Joel T. Dudley"
        ],
        "title": "Deep learning for healthcare: review, opportunities and challenges",
        "publication_date": "2018-11-27 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Briefings in Bioinformatics",
        "volume": "19",
        "doi": "10.1093/bib/bbx044",
        "urls": [
            "https://openalex.org/W2610332124",
            "https://doi.org/10.1093/bib/bbx044",
            "https://europepmc.org/articles/pmc6455466?pdf=render"
        ],
        "id": "id-6253755815258701293",
        "abstract": "",
        "versions": [],
        "rank": 90
    },
    {
        "authors": [
            "Guoxuan Xia",
            "Christos-Savvas Bouganis"
        ],
        "title": "On the Usefulness of Deep Ensemble Diversity for Out-of-Distribution Detection",
        "publication_date": "2022-07-15 15:02:38+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2207.07517v2",
            "http://arxiv.org/abs/2207.07517v2",
            "http://arxiv.org/pdf/2207.07517v2"
        ],
        "id": "id5513825849323284736",
        "abstract": "The ability to detect Out-of-Distribution (OOD) data is important in\nsafety-critical applications of deep learning. The aim is to separate\nIn-Distribution (ID) data drawn from the training distribution from OOD data\nusing a measure of uncertainty extracted from a deep neural network. Deep\nEnsembles are a well-established method of improving the quality of uncertainty\nestimates produced by deep neural networks, and have been shown to have\nsuperior OOD detection performance compared to single models. An existing\nintuition in the literature is that the diversity of Deep Ensemble predictions\nindicates distributional shift, and so measures of diversity such as Mutual\nInformation (MI) should be used for OOD detection. We show experimentally that\nthis intuition is not valid on ImageNet-scale OOD detection -- using MI leads\nto 30-40% worse %FPR@95 compared to single-model entropy on some OOD datasets.\nWe suggest an alternative explanation for Deep Ensembles' better OOD detection\nperformance -- OOD detection is binary classification and we are ensembling\ndiverse classifiers. As such we show that practically, even better OOD\ndetection performance can be achieved for Deep Ensembles by averaging\ntask-specific detection scores such as Energy over the ensemble.",
        "versions": [],
        "rank": 91
    },
    {
        "authors": [
            "Kibok Lee",
            "Kimin Lee",
            "Honglak Lee",
            "Jinwoo Shin"
        ],
        "title": "A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks",
        "publication_date": "2018-07-10 00:00:00",
        "source": "SupportedSources.PAPERS_WITH_CODE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1807.03888v2.pdf",
            "https://github.com/pokaxpoka/deep_Mahalanobis_detector",
            "http://papers.nips.cc/paper/7947-a-simple-unified-framework-for-detecting-out-of-distribution-samples-and-adversarial-attacks.pdf"
        ],
        "id": "id-8132678142440498600",
        "abstract": "Detecting test samples drawn sufficiently far away from the training\ndistribution statistically or adversarially is a fundamental requirement for\ndeploying a good classifier in many real-world machine learning applications.\nHowever, deep neural networks with the softmax classifier are known to produce\nhighly overconfident posterior distributions even for such abnormal samples. In\nthis paper, we propose a simple yet effective method for detecting any abnormal\nsamples, which is applicable to any pre-trained softmax neural classifier. We\nobtain the class conditional Gaussian distributions with respect to (low- and\nupper-level) features of the deep models under Gaussian discriminant analysis,\nwhich result in a confidence score based on the Mahalanobis distance. While\nmost prior methods have been evaluated for detecting either out-of-distribution\nor adversarial samples, but not both, the proposed method achieves the\nstate-of-the-art performances for both cases in our experiments. Moreover, we\nfound that our proposed method is more robust in harsh cases, e.g., when the\ntraining dataset has noisy labels or small number of samples. Finally, we show\nthat the proposed method enjoys broader usage by applying it to\nclass-incremental learning: whenever out-of-distribution samples are detected,\nour classification rule can incorporate new classes well without further\ntraining deep models.",
        "versions": [],
        "rank": 92
    },
    {
        "authors": [
            "Michelucci, U."
        ],
        "title": "Training Neural Networks",
        "publication_date": "2018-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-1-4842-3790-8_4",
        "urls": [
            "http://link.springer.com/content/pdf/10.1007/978-1-4842-3790-8_4",
            "http://dx.doi.org/10.1007/978-1-4842-3790-8_4"
        ],
        "id": "id1362189685420298493",
        "abstract": "",
        "versions": [],
        "rank": 93
    },
    {
        "authors": [
            "Weilin Xu",
            "David Evans",
            "Yanjun Qi"
        ],
        "title": "Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks",
        "publication_date": "2017-04-04 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "ArXiv",
        "volume": "abs/1704.01155",
        "doi": "10.14722/ndss.2018.23198",
        "urls": [
            "https://www.semanticscholar.org/paper/9fec45e1ff97ffb0e0cf9f039e39b46043430301"
        ],
        "id": "id108736932709901063",
        "abstract": "Although deep neural networks (DNNs) have achieved great success in many tasks, they can often be fooled by \\emph{adversarial examples} that are generated by adding small but purposeful distortions to natural examples. Previous studies to defend against adversarial examples mostly focused on refining the DNN models, but have either shown limited success or required expensive computation. We propose a new strategy, \\emph{feature squeezing}, that can be used to harden DNN models by detecting adversarial examples. Feature squeezing reduces the search space available to an adversary by coalescing samples that correspond to many different feature vectors in the original space into a single sample. By comparing a DNN model's prediction on the original input with that on squeezed inputs, feature squeezing detects adversarial examples with high accuracy and few false positives. This paper explores two feature squeezing methods: reducing the color bit depth of each pixel and spatial smoothing. These simple strategies are inexpensive and complementary to other defenses, and can be combined in a joint detection framework to achieve high detection rates against state-of-the-art attacks.",
        "versions": [],
        "rank": 94
    },
    {
        "authors": [
            "David Mac\u00eado"
        ],
        "title": "Towards Robust Deep Learning using Entropic Losses",
        "publication_date": "2022-08-06 00:00:00",
        "source": "SupportedSources.PAPERS_WITH_CODE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://arxiv.org/pdf/2208.03566v1.pdf",
            "https://github.com/dlmacedo/entropic-out-of-distribution-detection"
        ],
        "id": "id900043369114686431",
        "abstract": "Current deep learning solutions are well known for not informing whether they can reliably classify an example during inference. One of the most effective ways to build more reliable deep learning solutions is to improve their performance in the so-called out-of-distribution detection task, which essentially consists of \"know that you do not know\" or \"know the unknown\". In other words, out-of-distribution detection capable systems may reject performing a nonsense classification when submitted to instances of classes on which the neural network was not trained. This thesis tackles the defiant out-of-distribution detection task by proposing novel loss functions and detection scores. Uncertainty estimation is also a crucial auxiliary task in building more robust deep learning systems. Therefore, we also deal with this robustness-related task, which evaluates how realistic the probabilities presented by the deep neural network are. To demonstrate the effectiveness of our approach, in addition to a substantial set of experiments, which includes state-of-the-art results, we use arguments based on the principle of maximum entropy to establish the theoretical foundation of the proposed approaches. Unlike most current methods, our losses and scores are seamless and principled solutions that produce accurate predictions in addition to fast and efficient inference. Moreover, our approaches can be incorporated into current and future projects simply by replacing the loss used to train the deep neural network and computing a rapid score for detection.",
        "versions": [
            {
                "year": 2022,
                "source": "SupportedSources.INTERNET_ARCHIVE",
                "title": "Towards Robust Deep Learning using Entropic Losses",
                "journal": "",
                "urls": [
                    "https://web.archive.org/web/20220810071046/https://arxiv.org/pdf/2208.03566v1.pdf"
                ],
                "doi": "",
                "publication_date": "2022-08-06 00:00:00"
            }
        ],
        "rank": 95
    },
    {
        "authors": [
            "Xiongwei Wu",
            "Doyen Sahoo",
            "Steven C. H. Hoi"
        ],
        "title": "Recent Advances in Deep Learning for Object Detection",
        "publication_date": "2019-08-10 02:54:17+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1908.03673v1",
            "http://arxiv.org/abs/1908.03673v1",
            "http://arxiv.org/pdf/1908.03673v1"
        ],
        "id": "id1633445246912637098",
        "abstract": "Object detection is a fundamental visual recognition problem in computer\nvision and has been widely studied in the past decades. Visual object detection\naims to find objects of certain target classes with precise localization in a\ngiven image and assign each object instance a corresponding class label. Due to\nthe tremendous successes of deep learning based image classification, object\ndetection techniques using deep learning have been actively studied in recent\nyears. In this paper, we give a comprehensive survey of recent advances in\nvisual object detection with deep learning. By reviewing a large body of recent\nrelated work in literature, we systematically analyze the existing object\ndetection frameworks and organize the survey into three major parts: (i)\ndetection components, (ii) learning strategies, and (iii) applications &\nbenchmarks. In the survey, we cover a variety of factors affecting the\ndetection performance in detail, such as detector architectures, feature\nlearning, proposal generation, sampling strategies, etc. Finally, we discuss\nseveral future directions to facilitate and spur future research for visual\nobject detection with deep learning. Keywords: Object Detection, Deep Learning,\nDeep Convolutional Neural Networks",
        "versions": [],
        "rank": 96
    },
    {
        "authors": [
            "Nidhi Sindhwani",
            "Rohit Anand",
            "S. Meivel",
            "Rati Shukla",
            "M. P. Yadav",
            "Vikash Yadav"
        ],
        "title": "Performance Analysis of Deep Neural Networks Using Computer Vision",
        "publication_date": "2021-10-13 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "EAI Endorsed Trans. Ind. Networks Intell. Syst.",
        "volume": "8",
        "doi": "10.4108/eai.13-10-2021.171318",
        "urls": [
            "https://www.semanticscholar.org/paper/d57d3674085f17288e1b44d1399ebd35d0b3ada3"
        ],
        "id": "id-8409837025135632819",
        "abstract": "INTRODUCTION: In recent years, deep learning techniques have been made to outperform the earlier state-of-the-art machine learning techniques in many areas, with one of the most notable cases being computer vision. Deep learning is also employed to train the neural networks with the images and to perform the various tasks such as classification and segmentation using several different models. The size and depth of current deep learning models have increased to solve certain tasks as these models provide better accuracy. As pre-trained weights may be used for further training and prevent costly computing, transfer learning is therefore of vital importance. A brief account is given of their history, structure, benefits, and drawbacks, followed by a description of their applications in the different tasks of computer vision, such as object detection, face recognition etc. OBJECTIVE:. The purpose of this paper is to train a deep neural network to properly classify the images that it has never seen before, define techniques to enhance the efficiency of deep learning and deploy deep neural networks in various applications. METHOD: The proposed approach represents that after the reading of images, 256x256 pixel image\u2019s random parts are extracted and noise, distortion, flip, or rotation transforms are applied. Multiple convolution and pooling steps are applied by controlling the stride lengths. RESULT: Data analysis and research findings showed that DNN models have been implemented in three main configurations of deep learning: CNTK, MXNet and TensorFlow. The proposed work outperforms the previous techniques in predicting the dependent variables, learning rate, image count, image mean, performance analysis of loss rate and learning rate during training, performance Analysis of Loss with respect to Epoch for Training, Validation and Accuracy. CONCLUSION: This research encompasses a large variety of computer applications, from image recognition and machine translation to enhanced learning. DNN models have been implemented in three main configurations of deep learning: CNTK, MXNet and TensorFlow. Extensive research has been conducted using the various deep architectures such as AlexNet, InceptionNet, etc. To the best of authors\u2019 knowledge, this is the first work that presents a quantitative analysis of the deep architectures mentioned above.",
        "versions": [],
        "rank": 97
    },
    {
        "authors": [
            "Xin Li",
            "Fuxin Li"
        ],
        "title": "Adversarial Examples Detection in Deep Networks with Convolutional Filter Statistics",
        "publication_date": "2016-12-22 19:45:31+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1612.07767v2",
            "http://arxiv.org/abs/1612.07767v2",
            "http://arxiv.org/pdf/1612.07767v2"
        ],
        "id": "id2157017052251732918",
        "abstract": "Deep learning has greatly improved visual recognition in recent years.\nHowever, recent research has shown that there exist many adversarial examples\nthat can negatively impact the performance of such an architecture. This paper\nfocuses on detecting those adversarial examples by analyzing whether they come\nfrom the same distribution as the normal examples. Instead of directly training\na deep neural network to detect adversarials, a much simpler approach was\nproposed based on statistics on outputs from convolutional layers. A cascade\nclassifier was designed to efficiently detect adversarials. Furthermore,\ntrained from one particular adversarial generating mechanism, the resulting\nclassifier can successfully detect adversarials from a completely different\nmechanism as well. The resulting classifier is non-subdifferentiable, hence\ncreates a difficulty for adversaries to attack by using the gradient of the\nclassifier. After detecting adversarial examples, we show that many of them can\nbe recovered by simply performing a small average filter on the image. Those\nfindings should lead to more insights about the classification mechanisms in\ndeep convolutional neural networks.",
        "versions": [],
        "rank": 98
    },
    {
        "authors": [
            "Apoorv Vyas",
            "Nataraj Jammalamadaka",
            "Xia Zhu",
            "Dipankar Das",
            "Bharat Kaul",
            "Theodore L. Willke"
        ],
        "title": "Out-of-Distribution Detection Using an Ensemble of Self Supervised Leave-Out Classifiers",
        "publication_date": "2018-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Springer International Publishing",
        "volume": "",
        "doi": "10.1007/978-3-030-01237-3_34",
        "urls": [
            "https://web.archive.org/web/20180922013323/http://openaccess.thecvf.com:80/content_ECCV_2018/papers/Apoorv_Vyas_Out-of-Distribution_Detection_Using_ECCV_2018_paper.pdf"
        ],
        "id": "id-4997167178821709604",
        "abstract": "As deep learning methods form a critical part in commercially important applications such as autonomous driving and medical diagnostics, it is important to reliably detect out-of-distribution (OOD) inputs while employing these algorithms. In this work, we propose an OOD detection algorithm which comprises of an ensemble of classifiers. We train each classifier in a self-supervised manner by leaving out a random subset of training data as OOD data and the rest as in-distribution (ID) data. We propose a novel margin-based loss over the softmax output which seeks to maintain at least a margin m between the average entropy of the OOD and in-distribution samples. In conjunction with the standard cross-entropy loss, we minimize the novel loss to train an ensemble of classifiers. We also propose a novel method to combine the outputs of the ensemble of classifiers to obtain OOD detection score and class prediction. Overall, our method convincingly outperforms Hendrycks et al. [7] and the current state-of-the-art ODIN [13] on several OOD detection benchmarks.",
        "versions": [
            {
                "year": 2018,
                "source": "SupportedSources.INTERNET_ARCHIVE",
                "title": "Out-of-Distribution Detection Using an Ensemble of Self Supervised Leave-out Classifiers",
                "journal": "",
                "urls": [
                    "https://web.archive.org/web/20200830051539/https://arxiv.org/pdf/1809.03576v1.pdf"
                ],
                "doi": "",
                "publication_date": "2018-09-04 00:00:00"
            }
        ],
        "rank": 99
    },
    {
        "authors": [
            "Yen-Chang Hsu",
            "Yilin Shen",
            "Hongxia Jin",
            "Zsolt Kira"
        ],
        "title": "Generalized ODIN: Detecting Out-of-Distribution Image Without Learning From Out-of-Distribution Data",
        "publication_date": "2020-06-14 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "arXiv (Cornell University)",
        "volume": "",
        "doi": "10.1109/cvpr42600.2020.01096",
        "urls": [
            "https://openalex.org/W3034230713",
            "https://doi.org/10.1109/cvpr42600.2020.01096",
            "http://arxiv.org/pdf/2002.11297"
        ],
        "id": "id-1495115935779558812",
        "abstract": "",
        "versions": [
            {
                "year": 2020,
                "source": "SupportedSources.PAPERS_WITH_CODE",
                "title": "Generalized ODIN: Detecting Out-of-distribution Image without Learning from Out-of-distribution Data",
                "journal": "",
                "urls": [
                    "https://arxiv.org/pdf/2002.11297v2.pdf",
                    "https://github.com/sayakpaul/Generalized-ODIN-TF",
                    "http://openaccess.thecvf.com/content_CVPR_2020/papers/Hsu_Generalized_ODIN_Detecting_Out-of-Distribution_Image_Without_Learning_From_Out-of-Distribution_Data_CVPR_2020_paper.pdf"
                ],
                "doi": "",
                "publication_date": "2020-02-26 00:00:00"
            }
        ],
        "rank": 100
    },
    {
        "authors": [
            "Yen-Chang Hsu",
            "Yilin Shen",
            "Hongxia Jin",
            "Zsolt Kira"
        ],
        "title": "Generalized ODIN: Detecting Out-of-distribution Image without Learning   from Out-of-distribution Data",
        "publication_date": "2020-02-26 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "arXiv (Cornell University)",
        "volume": "",
        "doi": "10.48550/arxiv.2002.11297",
        "urls": [
            "https://openalex.org/W3008768558",
            "https://doi.org/10.48550/arxiv.2002.11297",
            "http://arxiv.org/pdf/2002.11297"
        ],
        "id": "id-2442146814567687140",
        "abstract": "",
        "versions": [],
        "rank": 101
    },
    {
        "authors": [
            "Andrew P. Bradley"
        ],
        "title": "The use of the area under the ROC curve in the evaluation of machine learning algorithms",
        "publication_date": "1997-07-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Pattern Recognition",
        "volume": "30",
        "doi": "10.1016/s0031-3203(96)00142-2",
        "urls": [
            "https://openalex.org/W2155653793",
            "https://doi.org/10.1016/s0031-3203(96)00142-2",
            "https://eprints.qut.edu.au/180272/1/114256.pdf"
        ],
        "id": "id3227195606748406496",
        "abstract": "",
        "versions": [],
        "rank": 102
    },
    {
        "authors": [
            "Andrew G. Howard",
            "Menglong Zhu",
            "Bo Chen",
            "Dmitry Kalenichenko",
            "Weijun Wang",
            "Tobias Weyand",
            "M. Andreetto",
            "Hartwig Adam"
        ],
        "title": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications",
        "publication_date": "2017-04-17 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "ArXiv",
        "volume": "abs/1704.04861",
        "doi": "",
        "urls": [
            "https://www.semanticscholar.org/paper/3647d6d0f151dc05626449ee09cc7bce55be497e"
        ],
        "id": "id-1973762859883291850",
        "abstract": "We present a class of efficient models called MobileNets for mobile and embedded vision applications. MobileNets are based on a streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. We introduce two simple global hyper-parameters that efficiently trade off between latency and accuracy. These hyper-parameters allow the model builder to choose the right sized model for their application based on the constraints of the problem. We present extensive experiments on resource and accuracy tradeoffs and show strong performance compared to other popular models on ImageNet classification. We then demonstrate the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization.",
        "versions": [],
        "rank": 103
    },
    {
        "authors": [
            "Yvan Saeys",
            "I\u00f1aki Inza",
            "Pedro Larra\u00f1aga"
        ],
        "title": "A review of feature selection techniques in bioinformatics",
        "publication_date": "2007-09-10 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Bioinformatics",
        "volume": "23",
        "doi": "10.1093/bioinformatics/btm344",
        "urls": [
            "https://openalex.org/W2119387367",
            "https://doi.org/10.1093/bioinformatics/btm344",
            "http://bioinformatics.oxfordjournals.org/content/23/19/2507.full.pdf"
        ],
        "id": "id-2417698452710967191",
        "abstract": "",
        "versions": [],
        "rank": 104
    },
    {
        "authors": [
            "Ali Sharif Razavian",
            "Hossein Azizpour",
            "Josephine Sullivan",
            "Stefan Carlsson"
        ],
        "title": "CNN Features Off-the-Shelf: An Astounding Baseline for Recognition",
        "publication_date": "2014-06-23 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Computer Vision and Pattern Recognition",
        "volume": "",
        "doi": "10.1109/cvprw.2014.131",
        "urls": [
            "https://openalex.org/W2062118960",
            "https://doi.org/10.1109/cvprw.2014.131",
            "http://arxiv.org/pdf/1403.6382.pdf"
        ],
        "id": "id-8712227502156118287",
        "abstract": "",
        "versions": [],
        "rank": 105
    },
    {
        "authors": [
            "Baoguang Shi",
            "Xiang Bai",
            "Cong Yao"
        ],
        "title": "An End-to-End Trainable Neural Network for Image-Based Sequence Recognition and Its Application to Scene Text Recognition",
        "publication_date": "2017-11-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
        "volume": "39",
        "doi": "10.1109/tpami.2016.2646371",
        "urls": [
            "https://openalex.org/W2194187530",
            "https://doi.org/10.1109/tpami.2016.2646371",
            "http://arxiv.org/pdf/1507.05717"
        ],
        "id": "id-3707500725941738953",
        "abstract": "",
        "versions": [],
        "rank": 106
    },
    {
        "authors": [
            "Leibig, C.",
            "Allken, V.",
            "Ayhan, M.",
            "Berens, P.",
            "Wahl, S."
        ],
        "title": "Leveraging uncertainty information from deep neural networks for disease detection",
        "publication_date": "2016-10-28 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1101/084210",
        "urls": [
            "https://syndication.highwire.org/content/doi/10.1101/084210",
            "http://dx.doi.org/10.1101/084210"
        ],
        "id": "id7012752941631920715",
        "abstract": "",
        "versions": [],
        "rank": 107
    },
    {
        "authors": [
            "David Mac\u00eado",
            "Cleber Zanchettin",
            "Teresa Ludermir"
        ],
        "title": "Distinction Maximization Loss: Efficiently Improving Out-of-Distribution Detection and Uncertainty Estimation by Replacing the Loss and Calibrating",
        "publication_date": "2022-08-05 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20220812002320/https://arxiv.org/pdf/2205.05874v5.pdf"
        ],
        "id": "id-4999730545574267575",
        "abstract": "Building robust deterministic neural networks remains a challenge. On the one hand, some approaches improve out-of-distribution detection at the cost of reducing classification accuracy in some situations. On the other hand, some methods simultaneously increase classification accuracy, uncertainty estimation, and out-of-distribution detection at the expense of reducing the inference efficiency. In this paper, we propose training deterministic neural networks using our DisMax loss, which works as a drop-in replacement for the usual SoftMax loss (i.e., the combination of the linear output layer, the SoftMax activation, and the cross-entropy loss). Starting from the IsoMax+ loss, we create each logit based on the distances to all prototypes, rather than just the one associated with the correct class. We also introduce a mechanism to combine images to construct what we call fractional probability regularization. Moreover, we present a fast way to calibrate the network after training. Finally, we propose a composite score to perform out-of-distribution detection. Our experiments show that DisMax usually outperforms current approaches simultaneously in classification accuracy, uncertainty estimation, and out-of-distribution detection while maintaining deterministic neural network inference efficiency. The code to reproduce the results is available at https://github.com/dlmacedo/distinction-maximization-loss.",
        "versions": [],
        "rank": 108
    },
    {
        "authors": [
            "Cheon, J.",
            "Baek, S.",
            "Paik, S."
        ],
        "title": "Invariance of object detection in untrained deep neural networks",
        "publication_date": "2022-09-10 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1101/2022.09.08.507096",
        "urls": [
            "https://syndication.highwire.org/content/doi/10.1101/2022.09.08.507096",
            "http://dx.doi.org/10.1101/2022.09.08.507096"
        ],
        "id": "id-5707628900323319487",
        "abstract": "",
        "versions": [],
        "rank": 109
    },
    {
        "authors": [
            "Bendale Abhijit",
            "Carlini Nicholas",
            "Glorot Xavier",
            "Krueger David",
            "Srivastava Nitish",
            "Xu Weilin"
        ],
        "title": "Efficient Defenses Against Adversarial Attacks",
        "publication_date": "2017-08-30 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1145/3128572.3140449",
        "urls": [
            "http://arxiv.org/abs/1707.06728"
        ],
        "id": "id-3113965169269836913",
        "abstract": "Following the recent adoption of deep neural networks (DNN) accross a wide\nrange of applications, adversarial attacks against these models have proven to\nbe an indisputable threat. Adversarial samples are crafted with a deliberate\nintention of undermining a system. In the case of DNNs, the lack of better\nunderstanding of their working has prevented the development of efficient\ndefenses. In this paper, we propose a new defense method based on practical\nobservations which is easy to integrate into models and performs better than\nstate-of-the-art defenses. Our proposed solution is meant to reinforce the\nstructure of a DNN, making its prediction more stable and less likely to be\nfooled by adversarial samples. We conduct an extensive experimental study\nproving the efficiency of our method against multiple attacks, comparing it to\nnumerous defenses, both in white-box and black-box setups. Additionally, the\nimplementation of our method brings almost no overhead to the training\nprocedure, while maintaining the prediction performance of the original model\non clean samples.Comment: 16 page",
        "versions": [],
        "rank": 110
    },
    {
        "authors": [
            "Ran, X.",
            "Xu, M.",
            "Mei, L.",
            "Xu, Q.",
            "Liu, Q."
        ],
        "title": "Detecting out-of-distribution samples via variational auto-encoder with reliable uncertainty estimation",
        "publication_date": "2022-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1016/j.neunet.2021.10.020",
        "urls": [
            "https://api.elsevier.com/content/article/PII:S0893608021004111?httpAccept=text/xml",
            "https://api.elsevier.com/content/article/PII:S0893608021004111?httpAccept=text/plain",
            "http://dx.doi.org/10.1016/j.neunet.2021.10.020"
        ],
        "id": "id-9009383008939580731",
        "abstract": "",
        "versions": [],
        "rank": 111
    },
    {
        "authors": [
            "Ev Zisselman",
            "Aviv Tamar"
        ],
        "title": "Deep Residual Flow for Out of Distribution Detection",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "IEEE",
        "volume": "",
        "doi": "10.1109/cvpr42600.2020.01401",
        "urls": [
            "https://web.archive.org/web/20220220181940/https://openaccess.thecvf.com/content_CVPR_2020/papers/Zisselman_Deep_Residual_Flow_for_Out_of_Distribution_Detection_CVPR_2020_paper.pdf"
        ],
        "id": "id-6317852894220816225",
        "abstract": "The effective application of neural networks in the realworld relies on proficiently detecting out-of-distribution examples. Contemporary methods seek to model the distribution of feature activations in the training data for adequately distinguishing abnormalities, and the state-of-theart method uses Gaussian distribution models. In this work, we present a novel approach that improves upon the stateof-the-art by leveraging an expressive density model based on normalizing flows. We introduce the residual flow, a novel flow architecture that learns the residual distribution from a base Gaussian distribution. Our model is general, and can be applied to any data that is approximately Gaussian. For out of distribution detection in image datasets, our approach provides a principled improvement over the state-of-the-art. Specifically, we demonstrate the effectiveness of our method in ResNet and DenseNet architectures trained on various image datasets. For example, on a ResNet trained on CIFAR-100 and evaluated on detection of out-of-distribution samples from the ImageNet dataset, holding the true positive rate (TPR) at 95%, we improve the true negative rate (TNR) from 56.7% (current state-of-theart) to 77.5% (ours).",
        "versions": [
            {
                "year": 2020,
                "source": "SupportedSources.CROSSREF",
                "title": "Deep Residual Flow for Out of Distribution Detection",
                "journal": "",
                "urls": [
                    "http://xplorestaging.ieee.org/ielx7/9142308/9156271/09157674.pdf?arnumber=9157674",
                    "http://dx.doi.org/10.1109/cvpr42600.2020.01401"
                ],
                "doi": "10.1109/cvpr42600.2020.01401",
                "publication_date": "2020-01-01 00:00:00"
            },
            {
                "year": 2020,
                "source": "SupportedSources.INTERNET_ARCHIVE",
                "title": "Deep Residual Flow for Out of Distribution Detection",
                "journal": "",
                "urls": [
                    "https://web.archive.org/web/20200723114229/https://arxiv.org/pdf/2001.05419v3.pdf"
                ],
                "doi": "",
                "publication_date": "2020-07-19 00:00:00"
            }
        ],
        "rank": 112
    },
    {
        "authors": [
            "Josh Tobin",
            "Rachel H. Fong",
            "Alex K. Ray",
            "Jonas Schneider",
            "Wojciech Zaremba",
            "Pieter Abbeel"
        ],
        "title": "Domain randomization for transferring deep neural networks from simulation to the real world",
        "publication_date": "2017-03-20 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Intelligent Robots and Systems",
        "volume": "",
        "doi": "10.1109/iros.2017.8202133",
        "urls": [
            "https://openalex.org/W2605102758",
            "https://doi.org/10.1109/iros.2017.8202133",
            "http://arxiv.org/pdf/1703.06907"
        ],
        "id": "id1724871261150917310",
        "abstract": "",
        "versions": [],
        "rank": 113
    },
    {
        "authors": [
            "Matan Haroush",
            "Tzviel Frostig",
            "Ruth Heller",
            "Daniel Soudry"
        ],
        "title": "A statistical framework for efficient out of distribution detection in deep neural networks",
        "publication_date": "2022-03-31 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20220515094901/https://arxiv.org/pdf/2102.12967v3.pdf"
        ],
        "id": "id-1575608860016130004",
        "abstract": "Background. Commonly, Deep Neural Networks (DNNs) generalize well on samples drawn from a distribution similar to that of the training set. However, DNNs' predictions are brittle and unreliable when the test samples are drawn from a dissimilar distribution. This is a major concern for deployment in real-world applications, where such behavior may come at a considerable cost, such as industrial production lines, autonomous vehicles, or healthcare applications. Contributions. We frame Out Of Distribution (OOD) detection in DNNs as a statistical hypothesis testing problem. Tests generated within our proposed framework combine evidence from the entire network. Unlike previous OOD detection heuristics, this framework returns a p-value for each test sample. It is guaranteed to maintain the Type I Error (T1E - incorrectly predicting OOD for an actual in-distribution sample) for test data. Moreover, this allows to combine several detectors while maintaining the T1E. Building on this framework, we suggest a novel OOD procedure based on low-order statistics. Our method achieves comparable or better results than state-of-the-art methods on well-accepted OOD benchmarks, without retraining the network parameters or assuming prior knowledge on the test distribution \u2013 and at a fraction of the computational cost.",
        "versions": [
            {
                "year": 2021,
                "source": "SupportedSources.PAPERS_WITH_CODE",
                "title": "A statistical framework for efficient out of distribution detection in deep neural networks",
                "journal": "",
                "urls": [
                    "https://arxiv.org/pdf/2102.12967v3.pdf",
                    "https://openreview.net/pdf?id=Oy9WeuZD51"
                ],
                "doi": "",
                "publication_date": "2021-02-25 00:00:00"
            }
        ],
        "rank": 114
    },
    {
        "authors": [
            "Joseph Redmon",
            "Santosh K. Divvala",
            "Ross Girshick",
            "Ali Farhadi"
        ],
        "title": "You Only Look Once: Unified, Real-Time Object Detection",
        "publication_date": "2016-06-27 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Computer Vision and Pattern Recognition",
        "volume": "",
        "doi": "10.1109/cvpr.2016.91",
        "urls": [
            "https://openalex.org/W2963037989",
            "https://doi.org/10.1109/cvpr.2016.91",
            "http://arxiv.org/pdf/1506.02640"
        ],
        "id": "id8363846405337700018",
        "abstract": "",
        "versions": [],
        "rank": 115
    },
    {
        "authors": [
            "Jihyo Kim",
            "Jiin Koo",
            "Sangheum Hwang"
        ],
        "title": "A Unified Benchmark for the Unknown Detection Capability of Deep Neural Networks",
        "publication_date": "2021-12-01 08:07:01+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2112.00337v1",
            "http://arxiv.org/abs/2112.00337v1",
            "http://arxiv.org/pdf/2112.00337v1"
        ],
        "id": "id-1885911810543354626",
        "abstract": "Deep neural networks have achieved outstanding performance over various\ntasks, but they have a critical issue: over-confident predictions even for\ncompletely unknown samples. Many studies have been proposed to successfully\nfilter out these unknown samples, but they only considered narrow and specific\ntasks, referred to as misclassification detection, open-set recognition, or\nout-of-distribution detection. In this work, we argue that these tasks should\nbe treated as fundamentally an identical problem because an ideal model should\npossess detection capability for all those tasks. Therefore, we introduce the\nunknown detection task, an integration of previous individual tasks, for a\nrigorous examination of the detection capability of deep neural networks on a\nwide spectrum of unknown samples. To this end, unified benchmark datasets on\ndifferent scales were constructed and the unknown detection capabilities of\nexisting popular methods were subject to comparison. We found that Deep\nEnsemble consistently outperforms the other approaches in detecting unknowns;\nhowever, all methods are only successful for a specific type of unknown. The\nreproducible code and benchmark datasets are available at\nhttps://github.com/daintlab/unknown-detection-benchmarks .",
        "versions": [],
        "rank": 116
    },
    {
        "authors": [
            "Shipeng Xie",
            "Da Chen",
            "Rong Zhang",
            "Hui Xue"
        ],
        "title": "Deep Features Analysis with Attention Networks",
        "publication_date": "2019-01-20 18:44:43+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1901.10042v1",
            "http://arxiv.org/abs/1901.10042v1",
            "http://arxiv.org/pdf/1901.10042v1"
        ],
        "id": "id2156249789645980414",
        "abstract": "Deep neural network models have recently draw lots of attention, as it\nconsistently produce impressive results in many computer vision tasks such as\nimage classification, object detection, etc. However, interpreting such model\nand show the reason why it performs quite well becomes a challenging question.\nIn this paper, we propose a novel method to interpret the neural network models\nwith attention mechanism. Inspired by the heatmap visualization, we analyze the\nrelation between classification accuracy with the attention based heatmap. An\nimproved attention based method is also included and illustrate that a better\nclassifier can be interpreted by the attention based heatmap.",
        "versions": [],
        "rank": 117
    },
    {
        "authors": [
            "Simeone, Osvaldo"
        ],
        "title": "A Very Brief Introduction to Machine Learning With Applications to  Communication Systems",
        "publication_date": "2018-11-05 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/tccn.2018.2881442",
        "urls": [
            "https://core.ac.uk/download/195274082.pdf"
        ],
        "id": "id2116492720790575925",
        "abstract": "Given the unprecedented availability of data and computing resources, there\nis widespread renewed interest in applying data-driven machine learning methods\nto problems for which the development of conventional engineering solutions is\nchallenged by modelling or algorithmic deficiencies. This tutorial-style paper\nstarts by addressing the questions of why and when such techniques can be\nuseful. It then provides a high-level introduction to the basics of supervised\nand unsupervised learning. For both supervised and unsupervised learning,\nexemplifying applications to communication networks are discussed by\ndistinguishing tasks carried out at the edge and at the cloud segments of the\nnetwork at different layers of the protocol stack",
        "versions": [],
        "rank": 118
    },
    {
        "authors": [
            "Kimin Lee",
            "Honglak Lee",
            "Kibok Lee",
            "Jinwoo Shin"
        ],
        "title": "Training Confidence-calibrated Classifiers for Detecting Out-of-Distribution Samples",
        "publication_date": "2017-11-26 00:00:00",
        "source": "SupportedSources.PAPERS_WITH_CODE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1711.09325v3.pdf",
            "https://github.com/alinlab/Confident_classifier",
            "https://openreview.net/pdf?id=ryiAv2xAZ"
        ],
        "id": "id-1695338111954519073",
        "abstract": "The problem of detecting whether a test sample is from in-distribution (i.e.,\ntraining distribution by a classifier) or out-of-distribution sufficiently\ndifferent from it arises in many real-world machine learning applications.\nHowever, the state-of-art deep neural networks are known to be highly\noverconfident in their predictions, i.e., do not distinguish in- and\nout-of-distributions. Recently, to handle this issue, several threshold-based\ndetectors have been proposed given pre-trained neural classifiers. However, the\nperformance of prior works highly depends on how to train the classifiers since\nthey only focus on improving inference procedures. In this paper, we develop a\nnovel training method for classifiers so that such inference algorithms can\nwork better. In particular, we suggest two additional terms added to the\noriginal loss (e.g., cross entropy). The first one forces samples from\nout-of-distribution less confident by the classifier and the second one is for\n(implicitly) generating most effective training samples for the first one. In\nessence, our method jointly trains both classification and generative neural\nnetworks for out-of-distribution. We demonstrate its effectiveness using deep\nconvolutional neural networks on various popular image datasets.",
        "versions": [],
        "rank": 119
    },
    {
        "authors": [
            "Mikko Honkala",
            "Dani Korpi",
            "Janne M. J. Huttunen"
        ],
        "title": "DeepRx: Fully Convolutional Deep Learning Receiver",
        "publication_date": "2021-02-02 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "IEEE Transactions on Wireless Communications",
        "volume": "20",
        "doi": "10.1109/twc.2021.3054520",
        "urls": [
            "https://openalex.org/W3128783847",
            "https://doi.org/10.1109/twc.2021.3054520",
            "http://arxiv.org/pdf/2005.01494"
        ],
        "id": "id402623359218781611",
        "abstract": "",
        "versions": [],
        "rank": 120
    },
    {
        "authors": [
            "Saining Xie",
            "Ross B. Girshick",
            "Piotr Doll\u00e1r",
            "Z. Tu",
            "Kaiming He"
        ],
        "title": "Aggregated Residual Transformations for Deep Neural Networks",
        "publication_date": "2016-11-16 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/CVPR.2017.634",
        "urls": [
            "https://www.semanticscholar.org/paper/f6e0856b4a9199fa968ac00da612a9407b5cb85c"
        ],
        "id": "id-3114067859754579500",
        "abstract": "We present a simple, highly modularized network architecture for image classification. Our network is constructed by repeating a building block that aggregates a set of transformations with the same topology. Our simple design results in a homogeneous, multi-branch architecture that has only a few hyper-parameters to set. This strategy exposes a new dimension, which we call cardinality (the size of the set of transformations), as an essential factor in addition to the dimensions of depth and width. On the ImageNet-1K dataset, we empirically show that even under the restricted condition of maintaining complexity, increasing cardinality is able to improve classification accuracy. Moreover, increasing cardinality is more effective than going deeper or wider when we increase the capacity. Our models, named ResNeXt, are the foundations of our entry to the ILSVRC 2016 classification task in which we secured 2nd place. We further investigate ResNeXt on an ImageNet-5K set and the COCO detection set, also showing better results than its ResNet counterpart. The code and models are publicly available online.",
        "versions": [],
        "rank": 121
    },
    {
        "authors": [
            "Olalekan Ogunmolu",
            "Xuejun Gu",
            "Steve Jiang",
            "Nicholas Gans"
        ],
        "title": "Nonlinear Systems Identification Using Deep Dynamic Neural Networks",
        "publication_date": "2016-10-05 14:26:27+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1610.01439v1",
            "http://arxiv.org/abs/1610.01439v1",
            "http://arxiv.org/pdf/1610.01439v1"
        ],
        "id": "id-2861703961202705803",
        "abstract": "Neural networks are known to be effective function approximators. Recently,\ndeep neural networks have proven to be very effective in pattern recognition,\nclassification tasks and human-level control to model highly nonlinear\nrealworld systems. This paper investigates the effectiveness of deep neural\nnetworks in the modeling of dynamical systems with complex behavior. Three deep\nneural network structures are trained on sequential data, and we investigate\nthe effectiveness of these networks in modeling associated characteristics of\nthe underlying dynamical systems. We carry out similar evaluations on select\npublicly available system identification datasets. We demonstrate that deep\nneural networks are effective model estimators from input-output data",
        "versions": [],
        "rank": 122
    },
    {
        "authors": [
            "Warey, A.",
            "Gao, J.",
            "Grover, R."
        ],
        "title": "Prediction of Engine-Out Emissions Using Deep Convolutional Neural Networks",
        "publication_date": "2021-04-06 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.4271/2021-01-0414",
        "urls": [
            "https://www.sae.org/gsdownload/?prodCd=2021-01-0414",
            "http://dx.doi.org/10.4271/2021-01-0414"
        ],
        "id": "id-1125626124173294669",
        "abstract": "",
        "versions": [],
        "rank": 123
    },
    {
        "authors": [
            "Gr\u00e9goire Montavon",
            "Sebastian Lapuschkin",
            "Alexander Binder",
            "Wojciech Samek",
            "Klaus-Robert M\u00fcller"
        ],
        "title": "Explaining nonlinear classification decisions with deep Taylor decomposition",
        "publication_date": "2017-05-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Pattern Recognition",
        "volume": "65",
        "doi": "10.1016/j.patcog.2016.11.008",
        "urls": [
            "https://openalex.org/W2195388612",
            "https://doi.org/10.1016/j.patcog.2016.11.008",
            "https://doi.org/10.1016/j.patcog.2016.11.008"
        ],
        "id": "id4357114201374320312",
        "abstract": "",
        "versions": [],
        "rank": 124
    },
    {
        "authors": [
            "Amara Dinesh Kumar",
            "Harish Thodupunoori",
            "R. Vinayakumar",
            "K. Soman",
            "P. Poornachandran",
            "M. Alazab",
            "S. Venkatraman"
        ],
        "title": "Enhanced Domain Generating Algorithm Detection Based on Deep Neural Networks",
        "publication_date": "None",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-3-030-13057-2_7",
        "urls": [
            "https://www.semanticscholar.org/paper/dcaf303d32013d533f5ebebbf8c3a56f47f8d61a"
        ],
        "id": "id-6536068513280935553",
        "abstract": null,
        "versions": [],
        "rank": 125
    },
    {
        "authors": [
            "Liang Liang",
            "Linhai Ma",
            "Linchen Qian",
            "Jiasong Chen"
        ],
        "title": "An Algorithm for Out-Of-Distribution Attack to Neural Network Encoder",
        "publication_date": "2021-01-27 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20210202041050/https://arxiv.org/pdf/2009.08016v4.pdf"
        ],
        "id": "id-1809149657230857080",
        "abstract": "Deep neural networks (DNNs), especially convolutional neural networks, have achieved superior performance on image classification tasks. However, such performance is only guaranteed if the input to a trained model is similar to the training samples, i.e., the input follows the probability distribution of the training set. Out-Of-Distribution (OOD) samples do not follow the distribution of training set, and therefore the predicted class labels on OOD samples become meaningless. Classification-based methods have been proposed for OOD detection; however, in this study we show that this type of method has no theoretical guarantee and is practically breakable by our OOD Attack algorithm because of dimensionality reduction in the DNN models. We also show that Glow likelihood-based OOD detection is breakable as well.",
        "versions": [],
        "rank": 126
    },
    {
        "authors": [
            "Dumitrescu, C."
        ],
        "title": "Automatic Detection of K-Complexes using Deep Neural Networks with EEG Signals",
        "publication_date": "2022-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.37247/pasen.2.2022.20",
        "urls": [
            "http://dx.doi.org/10.37247/pasen.2.2022.20"
        ],
        "id": "id596985676825039517",
        "abstract": "",
        "versions": [],
        "rank": 127
    },
    {
        "authors": [
            "Gagandeep Singh",
            "Deepak Mishra"
        ],
        "title": "Probabilistic Trust Intervals for Out of Distribution Detection",
        "publication_date": "2021-07-24 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20210801220912/https://arxiv.org/pdf/2102.01336v2.pdf"
        ],
        "id": "id-965451669205722565",
        "abstract": "Building neural network classifiers with an ability to distinguish between in and out-of distribution inputs is an important step towards faithful deep learning systems. Some of the successful approaches for this, resort to architectural novelties, such as ensembles, with increased complexities in terms of the number of parameters and training procedures. Whereas some other approaches make use of surrogate samples, which are easy to create and work as proxies for actual out-of-distribution (OOD) samples, to train the networks for OOD detection. In this paper, we propose a very simple approach for enhancing the ability of a pretrained network to detect OOD inputs without even altering the original parameter values. We define a probabilistic trust interval for each weight parameter of the network and optimize its size according to the in-distribution (ID) inputs. It allows the network to sample additional weight values along with the original values at the time of inference and use the observed disagreement among the corresponding outputs for OOD detection. In order to capture the disagreement effectively, we also propose a measure and establish its suitability using empirical evidence. Our approach outperforms the existing state-of-the-art methods on various OOD datasets by considerable margins without using any real or surrogate OOD samples. We also analyze the performance of our approach on adversarial and corrupted inputs such as CIFAR-10-C and demonstrate its ability to clearly distinguish such inputs as well. By using fundamental theorem of calculus on neural networks, we explain why our technique doesn't need to observe OOD samples during training to achieve results better than the previous works.",
        "versions": [],
        "rank": 128
    },
    {
        "authors": [
            "Christian Szegedy",
            "Alexander Toshev",
            "D. Erhan"
        ],
        "title": "Deep Neural Networks for Object Detection",
        "publication_date": "2013-12-05 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://www.semanticscholar.org/paper/713f73ce5c3013d9fb796c21b981dc6629af0bd5"
        ],
        "id": "id5345222772827343723",
        "abstract": "Deep Neural Networks (DNNs) have recently shown outstanding performance on image classification tasks [14]. In this paper we go one step further and address the problem of object detection using DNNs, that is not only classifying but also precisely localizing objects of various classes. We present a simple and yet powerful formulation of object detection as a regression problem to object bounding box masks. We define a multi-scale inference procedure which is able to produce high-resolution object detections at a low cost by a few network applications. State-of-the-art performance of the approach is shown on Pascal VOC.",
        "versions": [],
        "rank": 129
    },
    {
        "authors": [
            "Wei Wang",
            "Yiqiang Sheng",
            "Jinlin Wang",
            "Xuewen Zeng",
            "Xiaozhou Ye",
            "Yongzhong Huang",
            "Ming Zhu"
        ],
        "title": "HAST-IDS: Learning Hierarchical Spatial-Temporal Features Using Deep Neural Networks to Improve Intrusion Detection",
        "publication_date": "None",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "IEEE Access",
        "volume": "6",
        "doi": "10.1109/ACCESS.2017.2780250",
        "urls": [
            "https://www.semanticscholar.org/paper/c37480fd588ef464b741338738b7dbfddb045659"
        ],
        "id": "id-614169998173497486",
        "abstract": "The development of an anomaly-based intrusion detection system (IDS) is a primary research direction in the field of intrusion detection. An IDS learns normal and anomalous behavior by analyzing network traffic and can detect unknown and new attacks. However, the performance of an IDS is highly dependent on feature design, and designing a feature set that can accurately characterize network traffic is still an ongoing research issue. Anomaly-based IDSs also have the problem of a high false alarm rate (FAR), which seriously restricts their practical applications. In this paper, we propose a novel IDS called the hierarchical spatial-temporal features-based intrusion detection system (HAST-IDS), which first learns the low-level spatial features of network traffic using deep convolutional neural networks (CNNs) and then learns high-level temporal features using long short-term memory networks. The entire process of feature learning is completed by the deep neural networks automatically; no feature engineering techniques are required. The automatically learned traffic features effectively reduce the FAR. The standard DARPA1998 and ISCX2012 data sets are used to evaluate the performance of the proposed system. The experimental results show that the HAST-IDS outperforms other published approaches in terms of accuracy, detection rate, and FAR, which successfully demonstrates its effectiveness in both feature learning and FAR reduction.",
        "versions": [],
        "rank": 130
    },
    {
        "authors": [
            "Doyup Lee",
            "Yeongjae Cheon"
        ],
        "title": "Soft Labeling Affects Out-of-Distribution Detection of Deep Neural Networks",
        "publication_date": "2020-07-07 05:50:52+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2007.03212v1",
            "http://arxiv.org/abs/2007.03212v1",
            "http://arxiv.org/pdf/2007.03212v1"
        ],
        "id": "id-1820090683643843562",
        "abstract": "Soft labeling becomes a common output regularization for generalization and\nmodel compression of deep neural networks. However, the effect of soft labeling\non out-of-distribution (OOD) detection, which is an important topic of machine\nlearning safety, is not explored. In this study, we show that soft labeling can\ndetermine OOD detection performance. Specifically, how to regularize outputs of\nincorrect classes by soft labeling can deteriorate or improve OOD detection.\nBased on the empirical results, we postulate a future work for OOD-robust DNNs:\na proper output regularization by soft labeling can construct OOD-robust DNNs\nwithout additional training of OOD samples or modifying the models, while\nimproving classification accuracy.",
        "versions": [],
        "rank": 131
    },
    {
        "authors": [
            "Vidyaratne, L.",
            "Glandon, A.",
            "Alam, M.",
            "Iftekharuddin, K."
        ],
        "title": "Deep recurrent neural network for seizure detection",
        "publication_date": "2016-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ijcnn.2016.7727334",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/7593175/7726591/07727334.pdf?arnumber=7727334",
            "http://dx.doi.org/10.1109/ijcnn.2016.7727334"
        ],
        "id": "id-2105332992022098",
        "abstract": "",
        "versions": [],
        "rank": 132
    },
    {
        "authors": [
            "Hussein Abdel-Jaber",
            "Disha Devassy",
            "Azhar Al Salam",
            "Lamya Hidaytallah",
            "Malak EL-Amir"
        ],
        "title": "A Review of Deep Learning Algorithms and Their Applications in Healthcare",
        "publication_date": "2022-02-21 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "MDPI AG",
        "volume": "",
        "doi": "10.3390/a15020071",
        "urls": [
            "https://web.archive.org/web/20220504011748/https://mdpi-res.com/d_attachment/algorithms/algorithms-15-00071/article_deploy/algorithms-15-00071-v2.pdf?version=1645517457"
        ],
        "id": "id-1780706693380357018",
        "abstract": "Deep learning uses artificial neural networks to recognize patterns and learn from them to make decisions. Deep learning is a type of machine learning that uses artificial neural networks to mimic the human brain. It uses machine learning methods such as supervised, semi-supervised, or unsupervised learning strategies to learn automatically in deep architectures and has gained much popularity due to its superior ability to learn from huge amounts of data. It was found that deep learning approaches can be used for big data analysis successfully. Applications include virtual assistants such as Alexa and Siri, facial recognition, personalization, natural language processing, autonomous cars, automatic handwriting generation, news aggregation, the colorization of black and white images, the addition of sound to silent films, pixel restoration, and deep dreaming. As a review, this paper aims to categorically cover several widely used deep learning algorithms along with their architectures and their practical applications: backpropagation, autoencoders, variational autoencoders, restricted Boltzmann machines, deep belief networks, convolutional neural networks, recurrent neural networks, generative adversarial networks, capsnets, transformer, embeddings from language models, bidirectional encoder representations from transformers, and attention in natural language processing. In addition, challenges of deep learning are also presented in this paper, such as AutoML-Zero, neural architecture search, evolutionary deep learning, and others. The pros and cons of these algorithms and their applications in healthcare are explored, alongside the future direction of this domain. This paper presents a review and a checkpoint to systemize the popular algorithms and to encourage further innovation regarding their applications. For new researchers in the field of deep learning, this review can help them to obtain many details about the advantages, disadvantages, applications, and working mechanisms of a number of deep learning algorithms. In addition, we introduce detailed information on how to apply several deep learning algorithms in healthcare, such as in relation to the COVID-19 pandemic. By presenting many challenges of deep learning in one section, we hope to increase awareness of these challenges, and how they can be dealt with. This could also motivate researchers to find solutions for these challenges.",
        "versions": [],
        "rank": 133
    },
    {
        "authors": [
            "Changgeng Yu",
            "Liu, K.",
            "Zou, W."
        ],
        "title": "A Method of Small Object Detection Based on Improved Deep Learning",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.3103/s1060992x2002006x",
        "urls": [
            "http://link.springer.com/content/pdf/10.3103/S1060992X2002006X.pdf",
            "http://link.springer.com/article/10.3103/S1060992X2002006X/fulltext.html",
            "http://link.springer.com/content/pdf/10.3103/S1060992X2002006X.pdf",
            "http://dx.doi.org/10.3103/s1060992x2002006x"
        ],
        "id": "id-8464204943438070876",
        "abstract": "",
        "versions": [],
        "rank": 134
    },
    {
        "authors": [
            "Byungtae Ahn",
            "Dong-geol Choi",
            "I. Kweon"
        ],
        "title": "Multi-Scale, Multi-Object and Real-Time Face Detection and Head Pose Estimation Using Deep Neural Networks",
        "publication_date": "2017-09-30 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "12",
        "doi": "10.7746/JKROS.2017.12.3.313",
        "urls": [
            "https://www.semanticscholar.org/paper/ac8c33cdb3a9f41fac1b7af595d3066264910c8f"
        ],
        "id": "id7797653598372563415",
        "abstract": null,
        "versions": [],
        "rank": 135
    },
    {
        "authors": [
            "Manas Sushil",
            "G. Suguna",
            "R. Lavanya",
            "M. N. Devi"
        ],
        "title": "Performance Comparison of Pre-trained Deep Neural Networks for Automated Glaucoma Detection",
        "publication_date": "2018-05-16 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-3-030-00665-5_62",
        "urls": [
            "https://www.semanticscholar.org/paper/18e98be1079ee64a325a931d00104ea81ae8b592"
        ],
        "id": "id-5066403683626405156",
        "abstract": null,
        "versions": [],
        "rank": 136
    },
    {
        "authors": [
            "M. A. Abdou"
        ],
        "title": "Literature review: efficient deep neural networks techniques for medical image analysis",
        "publication_date": "2022-02-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Neural Computing and Applications",
        "volume": "34",
        "doi": "10.1007/s00521-022-06960-9",
        "urls": [
            "https://www.semanticscholar.org/paper/40b9577c3a1f6751158c27d22557c73cd3dfcb07"
        ],
        "id": "id-1698434840658444948",
        "abstract": null,
        "versions": [],
        "rank": 137
    },
    {
        "authors": [
            "Julien Audibert",
            "Pietro Michiardi",
            "Fr\u00e9d\u00e9ric Guyard",
            "S\u00e9bastien Marti",
            "Maria A. Zuluaga"
        ],
        "title": "Do Deep Neural Networks Contribute to Multivariate Time Series Anomaly Detection?",
        "publication_date": "2022-04-04 16:32:49+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": "Pattern Recognition Volume 132, December 2022,108945",
        "volume": "",
        "doi": "10.1016/j.patcog.2022.108945",
        "urls": [
            "http://arxiv.org/pdf/2204.01637v1",
            "http://dx.doi.org/10.1016/j.patcog.2022.108945",
            "http://arxiv.org/abs/2204.01637v1",
            "http://arxiv.org/pdf/2204.01637v1"
        ],
        "id": "id8618352792181224027",
        "abstract": "Anomaly detection in time series is a complex task that has been widely\nstudied. In recent years, the ability of unsupervised anomaly detection\nalgorithms has received much attention. This trend has led researchers to\ncompare only learning-based methods in their articles, abandoning some more\nconventional approaches. As a result, the community in this field has been\nencouraged to propose increasingly complex learning-based models mainly based\non deep neural networks. To our knowledge, there are no comparative studies\nbetween conventional, machine learning-based and, deep neural network methods\nfor the detection of anomalies in multivariate time series. In this work, we\nstudy the anomaly detection performance of sixteen conventional, machine\nlearning-based and, deep neural network approaches on five real-world open\ndatasets. By analyzing and comparing the performance of each of the sixteen\nmethods, we show that no family of methods outperforms the others. Therefore,\nwe encourage the community to reincorporate the three categories of methods in\nthe anomaly detection in multivariate time series benchmarks.",
        "versions": [],
        "rank": 138
    },
    {
        "authors": [
            "Zhuang Liu",
            "Jianguo Li",
            "Zhi-Qiang Shen",
            "Gao Huang",
            "Shoumeng Yan",
            "Changshui Zhang"
        ],
        "title": "Learning Efficient Convolutional Networks through Network Slimming",
        "publication_date": "2017-10-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "2017 IEEE International Conference on Computer Vision (ICCV)",
        "volume": "",
        "doi": "10.1109/iccv.2017.298",
        "urls": [
            "https://openalex.org/W2962851801",
            "https://doi.org/10.1109/iccv.2017.298",
            "http://arxiv.org/pdf/1708.06519"
        ],
        "id": "id-4959069413821557622",
        "abstract": "",
        "versions": [],
        "rank": 139
    },
    {
        "authors": [
            "Sanmeet Kaur",
            "M. Singh"
        ],
        "title": "Hybrid intrusion detection and signature generation using Deep Recurrent Neural Networks",
        "publication_date": "2019-04-11 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Neural Computing and Applications",
        "volume": "32",
        "doi": "10.1007/s00521-019-04187-9",
        "urls": [
            "https://www.semanticscholar.org/paper/b84835298e9145893f2c2b67653921c239a489a0"
        ],
        "id": "id5635193277899335941",
        "abstract": null,
        "versions": [],
        "rank": 140
    },
    {
        "authors": [
            "Gorur, Dilan",
            "Lakshminarayanan, Balaji",
            "Matsukawa, Akihiro",
            "Nalisnick, Eric",
            "Teh, Yee Whye"
        ],
        "title": "Hybrid Models with Deep and Invertible Features",
        "publication_date": "2019-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "http://arxiv.org/abs/1902.02767"
        ],
        "id": "id574079642885727700",
        "abstract": "We propose a neural hybrid model consisting of a linear model defined on a\nset of features computed by a deep, invertible transformation (i.e. a\nnormalizing flow). An attractive property of our model is that both\np(features), the density of the features, and p(targets | features), the\npredictive distribution, can be computed exactly in a single feed-forward pass.\nWe show that our hybrid model, despite the invertibility constraints, achieves\nsimilar accuracy to purely predictive models. Moreover the generative component\nremains a good model of the input features despite the hybrid optimization\nobjective. This offers additional capabilities such as detection of\nout-of-distribution inputs and enabling semi-supervised learning. The\navailability of the exact joint density p(targets, features) also allows us to\ncompute many quantities readily, making our hybrid model a useful building\nblock for downstream applications of probabilistic deep learning.Comment: ICML 201",
        "versions": [],
        "rank": 141
    },
    {
        "authors": [
            "Peng Wu",
            "Jing Liu",
            "Fang Shen"
        ],
        "title": "A Deep One-Class Neural Network for Anomalous Event Detection in Complex Scenes",
        "publication_date": "2020-07-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "IEEE Transactions on Neural Networks and Learning Systems",
        "volume": "31",
        "doi": "10.1109/TNNLS.2019.2933554",
        "urls": [
            "https://www.semanticscholar.org/paper/355b4e74774798c177c82943eef925d66a2bb2ce"
        ],
        "id": "id6060246811268808874",
        "abstract": "How to build a generic deep one-class (DeepOC) model to solve one-class classification problems for anomaly detection, such as anomalous event detection in complex scenes? The characteristics of existing one-class labels lead to a dilemma: it is hard to directly use a multiple classifier based on deep neural networks to solve one-class classification problems. Therefore, in this article, we propose a novel DeepOC neural network, termed as DeepOC, which can simultaneously learn compact feature representations and train a DeepOC classifier. Only with the given normal samples, we use the stacked convolutional encoder to generate their low-dimensional high-level features and train a one-class classifier to make these features as compact as possible. Meanwhile, for the sake of the correct mapping relation and the feature representations\u2019 diversity, we utilize a decoder in order to reconstruct raw samples from these low-dimensional feature representations. This structure is gradually established using an adversarial mechanism during the training stage. This mechanism is the key to our model. It organically combines two seemingly contradictory components and allows them to take advantage of each other, thus making the model robust and effective. Unlike methods that use handcrafted features or those that are separated into two stages (extracting features and training classifiers), DeepOC is a one-stage model using reliable features that are automatically extracted by neural networks. Experiments on various benchmark data sets show that DeepOC is feasible and achieves the state-of-the-art anomaly detection results compared with a dozen existing methods.",
        "versions": [],
        "rank": 142
    },
    {
        "authors": [
            "Michelucci, U."
        ],
        "title": "Advanced Applied Deep Learning",
        "publication_date": "2019-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-1-4842-4976-5",
        "urls": [
            "http://link.springer.com/content/pdf/10.1007/978-1-4842-4976-5.pdf",
            "http://link.springer.com/content/pdf/10.1007/978-1-4842-4976-5",
            "http://dx.doi.org/10.1007/978-1-4842-4976-5"
        ],
        "id": "id5603177840246443116",
        "abstract": "",
        "versions": [],
        "rank": 143
    },
    {
        "authors": [
            "Bellet, M.",
            "Bellet, J.",
            "Nienborg, H.",
            "Hafed, Z.",
            "Berens, P."
        ],
        "title": "Human-level saccade detection performance using deep neural networks",
        "publication_date": "2018-06-29 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1101/359018",
        "urls": [
            "https://syndication.highwire.org/content/doi/10.1101/359018",
            "http://dx.doi.org/10.1101/359018"
        ],
        "id": "id-8259577448951811946",
        "abstract": "",
        "versions": [],
        "rank": 144
    },
    {
        "authors": [
            "Qing Yu",
            "Kiyoharu Aizawa"
        ],
        "title": "Unsupervised Out-of-Distribution Detection by Maximum Classifier Discrepancy",
        "publication_date": "2019-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "IEEE",
        "volume": "",
        "doi": "10.1109/iccv.2019.00961",
        "urls": [
            "https://web.archive.org/web/20200709213219/https://openaccess.thecvf.com/content_ICCV_2019/papers/Yu_Unsupervised_Out-of-Distribution_Detection_by_Maximum_Classifier_Discrepancy_ICCV_2019_paper.pdf"
        ],
        "id": "id-2106286572322761815",
        "abstract": "Since deep learning models have been implemented in many commercial applications, it is important to detect out-of-distribution (OOD) inputs correctly to maintain the performance of the models, ensure the quality of the collected data, and prevent the applications from being used for other-than-intended purposes. In this work, we propose a two-head deep convolutional neural network (CNN) and maximize the discrepancy between the two classifiers to detect OOD inputs. We train a two-head CNN consisting of one common feature extractor and two classifiers which have different decision boundaries but can classify in-distribution (ID) samples correctly. Unlike previous methods, we also utilize unlabeled data for unsupervised training and we use these unlabeled data to maximize the discrepancy between the decision boundaries of two classifiers to push OOD samples outside the manifold of the in-distribution (ID) samples, which enables us to detect OOD samples that are far from the support of the ID samples. Overall, our approach significantly outperforms other state-of-the-art methods on several OOD detection benchmarks and two cases of real-world simulation.",
        "versions": [
            {
                "year": 2019,
                "source": "SupportedSources.PAPERS_WITH_CODE",
                "title": "Unsupervised Out-of-Distribution Detection by Maximum Classifier Discrepancy",
                "journal": "",
                "urls": [
                    "https://arxiv.org/pdf/1908.04951v1.pdf",
                    "https://github.com/Mephisto405/Unsupervised-Out-of-Distribution-Detection-by-Maximum-Classifier-Discrepancy",
                    "http://openaccess.thecvf.com/content_ICCV_2019/papers/Yu_Unsupervised_Out-of-Distribution_Detection_by_Maximum_Classifier_Discrepancy_ICCV_2019_paper.pdf"
                ],
                "doi": "",
                "publication_date": "2019-08-14 00:00:00"
            },
            {
                "year": 2019,
                "source": "SupportedSources.INTERNET_ARCHIVE",
                "title": "Unsupervised Out-of-Distribution Detection by Maximum Classifier Discrepancy",
                "journal": "",
                "urls": [
                    "https://web.archive.org/web/20200913151550/https://arxiv.org/pdf/1908.04951v1.pdf"
                ],
                "doi": "",
                "publication_date": "2019-08-14 00:00:00"
            },
            {
                "year": 2019,
                "source": "SupportedSources.OPENALEX",
                "title": "Unsupervised Out-of-Distribution Detection by Maximum Classifier Discrepancy",
                "journal": "International Conference on Computer Vision",
                "urls": [
                    "https://openalex.org/W3006853338",
                    "https://doi.org/10.1109/iccv.2019.00961",
                    "http://arxiv.org/pdf/1908.04951"
                ],
                "doi": "10.1109/iccv.2019.00961",
                "publication_date": "2019-10-01 00:00:00"
            }
        ],
        "rank": 145
    },
    {
        "authors": [
            "Guo, Yuhong",
            "Shi, Zhenwei",
            "Ye, Jieping",
            "Zou, Zhengxia"
        ],
        "title": "Object Detection in 20 Years: A Survey",
        "publication_date": "2019-05-15 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "http://arxiv.org/abs/1905.05055"
        ],
        "id": "id2840708984664066559",
        "abstract": "Object detection, as of one the most fundamental and challenging problems in\ncomputer vision, has received great attention in recent years. Its development\nin the past two decades can be regarded as an epitome of computer vision\nhistory. If we think of today's object detection as a technical aesthetics\nunder the power of deep learning, then turning back the clock 20 years we would\nwitness the wisdom of cold weapon era. This paper extensively reviews 400+\npapers of object detection in the light of its technical evolution, spanning\nover a quarter-century's time (from the 1990s to 2019). A number of topics have\nbeen covered in this paper, including the milestone detectors in history,\ndetection datasets, metrics, fundamental building blocks of the detection\nsystem, speed up techniques, and the recent state of the art detection methods.\nThis paper also reviews some important detection applications, such as\npedestrian detection, face detection, text detection, etc, and makes an in-deep\nanalysis of their challenges as well as technical improvements in recent years.Comment: This work has been submitted to the IEEE TPAMI for possible\n  publicatio",
        "versions": [],
        "rank": 146
    },
    {
        "authors": [
            "Mahdieh Abbasi",
            "Christian Gagn\u00e9"
        ],
        "title": "Out-distribution training confers robustness to deep neural networks",
        "publication_date": "2018-03-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20200913123148/https://arxiv.org/pdf/1802.07124v3.pdf"
        ],
        "id": "id-3625758371233261727",
        "abstract": "The easiness at which adversarial instances can be generated in deep neural networks raises some fundamental questions on their functioning and concerns on their use in critical systems. In this paper, we draw a connection between over-generalization and adversaries: a possible cause of adversaries lies in models designed to make decisions all over the input space, leading to inappropriate high-confidence decisions in parts of the input space not represented in the training set. We empirically show an augmented neural network, which is not trained on any types of adversaries, can increase the robustness by detecting black-box one-step adversaries, i.e. assimilated to out-distribution samples, and making generation of white-box one-step adversaries harder.",
        "versions": [],
        "rank": 147
    },
    {
        "authors": [
            "Georgios Tzelepis",
            "Ahraz Asif",
            "Saimir Baci",
            "Selcuk Cavdar",
            "Eren Erdal Aksoy"
        ],
        "title": "Deep Neural Network Compression for Image Classification and Object Detection",
        "publication_date": "2019-10-07 12:19:37+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1910.02747v1",
            "http://arxiv.org/abs/1910.02747v1",
            "http://arxiv.org/pdf/1910.02747v1"
        ],
        "id": "id-757742206602436806",
        "abstract": "Neural networks have been notorious for being computationally expensive. This\nis mainly because neural networks are often over-parametrized and most likely\nhave redundant nodes or layers as they are getting deeper and wider. Their\ndemand for hardware resources prohibits their extensive use in embedded devices\nand puts restrictions on tasks like real-time image classification or object\ndetection. In this work, we propose a network-agnostic model compression method\ninfused with a novel dynamical clustering approach to reduce the computational\ncost and memory footprint of deep neural networks. We evaluated our new\ncompression method on five different state-of-the-art image classification and\nobject detection networks. In classification networks, we pruned about 95% of\nnetwork parameters. In advanced detection networks such as YOLOv3, our proposed\ncompression method managed to reduce the model parameters up to 59.70% which\nyielded 110X less memory without sacrificing much in accuracy.",
        "versions": [],
        "rank": 148
    },
    {
        "authors": [
            "Tiago Ramalho",
            "Miguel Miranda"
        ],
        "title": "Density estimation in representation space to predict model uncertainty",
        "publication_date": "2019-10-03 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20200912224259/https://arxiv.org/pdf/1908.07235v2.pdf"
        ],
        "id": "id-2217861140579893302",
        "abstract": "Deep learning models frequently make incorrect predictions with high confidence when presented with test examples that are not well represented in their training dataset. We propose a novel and straightforward approach to estimate prediction uncertainty in a pre-trained neural network model. Our method estimates the training data density in representation space for a novel input. A neural network model then uses this information to determine whether we expect the pre-trained model to make a correct prediction. This uncertainty model is trained by predicting in-distribution errors, but can detect out-of-distribution data without having seen any such example. We test our method for a state-of-the art image classification model in the settings of both in-distribution uncertainty estimation as well as out-of-distribution detection.",
        "versions": [],
        "rank": 149
    },
    {
        "authors": [
            "Brody Huval",
            "Adam Coates",
            "Andrew Ng"
        ],
        "title": "Deep learning for class-generic object detection",
        "publication_date": "2013-12-24 20:38:18+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1312.6885v1",
            "http://arxiv.org/abs/1312.6885v1",
            "http://arxiv.org/pdf/1312.6885v1"
        ],
        "id": "id7152341376351708453",
        "abstract": "We investigate the use of deep neural networks for the novel task of class\ngeneric object detection. We show that neural networks originally designed for\nimage recognition can be trained to detect objects within images, regardless of\ntheir class, including objects for which no bounding box labels have been\nprovided. In addition, we show that bounding box labels yield a 1% performance\nincrease on the ImageNet recognition challenge.",
        "versions": [
            {
                "year": 2013,
                "source": "SupportedSources.INTERNET_ARCHIVE",
                "title": "Deep learning for class-generic object detection",
                "journal": "",
                "urls": [
                    "https://web.archive.org/web/20200829012650/https://arxiv.org/pdf/1312.6885v1.pdf"
                ],
                "doi": "",
                "publication_date": "2013-12-24 00:00:00"
            }
        ],
        "rank": 150
    },
    {
        "authors": [
            "Dang Duy Thang",
            "Toshihiro Matsui"
        ],
        "title": "Automated Detection System for Adversarial Examples with High-Frequency Noises Sieve",
        "publication_date": "2019-08-05 05:05:29+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1908.01469v1",
            "http://arxiv.org/abs/1908.01469v1",
            "http://arxiv.org/pdf/1908.01469v1"
        ],
        "id": "id-7836948620563334514",
        "abstract": "Deep neural networks are being applied in many tasks with encouraging\nresults, and have often reached human-level performance. However, deep neural\nnetworks are vulnerable to well-designed input samples called adversarial\nexamples. In particular, neural networks tend to misclassify adversarial\nexamples that are imperceptible to humans. This paper introduces a new\ndetection system that automatically detects adversarial examples on deep neural\nnetworks. Our proposed system can mostly distinguish adversarial samples and\nbenign images in an end-to-end manner without human intervention. We exploit\nthe important role of the frequency domain in adversarial samples and propose a\nmethod that detects malicious samples in observations. When evaluated on two\nstandard benchmark datasets (MNIST and ImageNet), our method achieved an\nout-detection rate of 99.7 - 100% in many settings.",
        "versions": [],
        "rank": 151
    },
    {
        "authors": [
            "Han, Seungyeop",
            "Krishnamurthy, Arvind",
            "Philipose, Matthai",
            "Shen, Haichen"
        ],
        "title": "Fast Video Classification via Adaptive Cascading of Deep Models",
        "publication_date": "2017-07-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/cvpr.2017.236",
        "urls": [
            "http://arxiv.org/abs/1611.06453"
        ],
        "id": "id-71618247943992904",
        "abstract": "Recent advances have enabled \"oracle\" classifiers that can classify across\nmany classes and input distributions with high accuracy without retraining.\nHowever, these classifiers are relatively heavyweight, so that applying them to\nclassify video is costly. We show that day-to-day video exhibits highly skewed\nclass distributions over the short term, and that these distributions can be\nclassified by much simpler models. We formulate the problem of detecting the\nshort-term skews online and exploiting models based on it as a new sequential\ndecision making problem dubbed the Online Bandit Problem, and present a new\nalgorithm to solve it. When applied to recognizing faces in TV shows and\nmovies, we realize end-to-end classification speedups of 2.4-7.8x/2.6-11.2x (on\nGPU/CPU) relative to a state-of-the-art convolutional neural network, at\ncompetitive accuracy.Comment: Accepted at IEEE Conference on Computer Vision and Pattern\n  Recognition (CVPR), 201",
        "versions": [],
        "rank": 152
    },
    {
        "authors": [
            "Chandramouli Shama Sastry",
            "Sageev Oore"
        ],
        "title": "Detecting Out-of-Distribution Examples with In-distribution Examples and Gram Matrices.",
        "publication_date": "2019-12-28 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "arXiv (Cornell University)",
        "volume": "",
        "doi": null,
        "urls": [
            "https://openalex.org/W2997013419"
        ],
        "id": "id-3457870094225055834",
        "abstract": "",
        "versions": [
            {
                "year": 2020,
                "source": "SupportedSources.INTERNET_ARCHIVE",
                "title": "Detecting Out-of-Distribution Examples with In-distribution Examples and Gram Matrices",
                "journal": "",
                "urls": [
                    "https://web.archive.org/web/20200913040804/https://arxiv.org/pdf/1912.12510v2.pdf"
                ],
                "doi": "",
                "publication_date": "2020-01-09 00:00:00"
            },
            {
                "year": 2019,
                "source": "SupportedSources.PAPERS_WITH_CODE",
                "title": "Detecting Out-of-Distribution Examples with In-distribution Examples and Gram Matrices",
                "journal": "",
                "urls": [
                    "https://arxiv.org/pdf/1912.12510v2.pdf",
                    "https://github.com/nazim1021/OOD-detection-using-OECC"
                ],
                "doi": "",
                "publication_date": "2019-12-28 00:00:00"
            }
        ],
        "rank": 153
    },
    {
        "authors": [
            "John Mitros and Arjun Pakrashi and Brian Mac Namee"
        ],
        "title": "Ramifications of Approximate Posterior Inference for Bayesian Deep Learning in Adversarial and Out-of-Distribution Settings",
        "publication_date": "2020-10-03 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20201007134009/https://arxiv.org/pdf/2009.01798v2.pdf"
        ],
        "id": "id2842326707097217112",
        "abstract": "Deep neural networks have been successful in diverse discriminative classification tasks, although, they are poorly calibrated often assigning high probability to misclassified predictions. Potential consequences could lead to trustworthiness and accountability of the models when deployed in real applications, where predictions are evaluated based on their confidence scores. Existing solutions suggest the benefits attained by combining deep neural networks and Bayesian inference to quantify uncertainty over the models' predictions for ambiguous datapoints. In this work we propose to validate and test the efficacy of likelihood based models in the task of out of distribution detection (OoD). Across different datasets and metrics we show that Bayesian deep learning models on certain occasions marginally outperform conventional neural networks and in the event of minimal overlap between in/out distribution classes, even the best models exhibit a reduction in AUC scores in detecting OoD data. Preliminary investigations indicate the potential inherent role of bias due to choices of initialisation, architecture or activation functions. We hypothesise that the sensitivity of neural networks to unseen inputs could be a multi-factor phenomenon arising from the different architectural design choices often amplified by the curse of dimensionality. Furthermore, we perform a study to find the effect of the adversarial noise resistance methods on in and out-of-distribution performance, as well as, also investigate adversarial noise robustness of Bayesian deep learners.",
        "versions": [],
        "rank": 154
    },
    {
        "authors": [
            "Engkarat Techapanurak",
            "Takayuki Okatani",
            "Masanori Suganuma"
        ],
        "title": "Hyperparameter-Free Out-of-Distribution Detection Using Softmax of Scaled Cosine Similarity",
        "publication_date": "2019-05-25 00:00:00",
        "source": "SupportedSources.PAPERS_WITH_CODE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://arxiv.org/pdf/1905.10628v3.pdf",
            "https://github.com/engkarat/cosine-ood-detector"
        ],
        "id": "id8509752197355743353",
        "abstract": "The ability to detect out-of-distribution (OOD) samples is vital to secure the reliability of deep neural networks in real-world applications. Considering the nature of OOD samples, detection methods should not have hyperparameters that need to be tuned depending on incoming OOD samples. However, most of the recently proposed methods do not meet this requirement, leading to compromised performance in real-world applications. In this paper, we propose a simple, hyperparameter-free method based on softmax of scaled cosine similarity. It resembles the approach employed by modern metric learning methods, but it differs in details; the differences are essential to achieve high detection performance. We show through experiments that our method outperforms the existing methods on the evaluation test recently proposed by Shafaei et al., which takes the above issue of hyperparameter dependency into account. We also show that it achieves at least comparable performance to other methods on the conventional test, where their hyperparameters are chosen using explicit OOD samples. Furthermore, it is computationally more efficient than most of the previous methods, since it needs only a single forward pass.",
        "versions": [],
        "rank": 155
    },
    {
        "authors": [
            "Erez Yahalomi"
        ],
        "title": "Modular network for high accuracy object detection",
        "publication_date": "2020-01-24 21:38:22+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2001.09203v3",
            "http://arxiv.org/abs/2001.09203v3",
            "http://arxiv.org/pdf/2001.09203v3"
        ],
        "id": "id-5805291008872427737",
        "abstract": "We present a novel modular object detection convolutional neural network that\nsignificantly improves the accuracy of object detection. The network consists\nof two stages in a hierarchical structure. The first stage is a network that\ndetects general classes. The second stage consists of separate networks to\nrefine the classification and localization of each of the general classes\nobjects. Compared to a state of the art object detection networks the\nclassification error in the modular network is improved by approximately 3-5\ntimes, from 12% to 2.5 %-4.5%. This network is easy to implement and has a 0.94\nmAP. The network architecture can be a platform to improve the accuracy of\nwidespread state of the art object detection networks and other kinds of deep\nlearning networks. We show that a deep learning network initialized by transfer\nlearning becomes more accurate as the number of classes it later trained to\ndetect becomes smaller.",
        "versions": [],
        "rank": 156
    },
    {
        "authors": [
            "Sarah Haggenm\u00fcller",
            "Roman C. Maron",
            "Achim Hekler",
            "Jochen Utikal",
            "Catarina Barata",
            "Raymond L. Barnhill",
            "Helmut Beltraminelli",
            "Carola Berking",
            "Brigid Betz-Stablein",
            "Andreas Blum",
            "Svende Braun",
            "Richard D. Carr",
            "Marc Combalia",
            "Mar\u00eda Teresa Fern\u00e1ndez-Figueras",
            "Gerardo Ferrara",
            "Sylvie Fraitag",
            "Lars E. French",
            "Frank Friedrich Gellrich",
            "Kamran Ghoreschi",
            "Matthias Goebeler",
            "Richard A. Scolyer",
            "Holger A. Haenssle",
            "Sebastian Haferkamp",
            "Lucie Heinzerling",
            "Markus V. Heppt",
            "Franz J. Hilke",
            "Sarah Hobelsberger",
            "Dieter Krahl",
            "Heinz Kutzner",
            "Aimilios Lallas",
            "Konstantinos Liopyris",
            "Mar Llamas-Velasco",
            "Josep Malvehy",
            "Friedegund Meier",
            "Cornelia S. L. M\u00fcller",
            "Alexander A. Navarini",
            "Cristian Navarrete-Dechent",
            "Antonio Perasole",
            "Gabriela Poch",
            "Sebastian Podlipnik",
            "Luis Requena",
            "Veronica Rotemberg",
            "Andrea Saggini",
            "Omar P. Sangueza",
            "Carlos Santonja",
            "Dirk Schadendorf",
            "Bastian Schilling",
            "Max Schlaak",
            "Justin Gabriel Schlager",
            "M. Sergon",
            "Wiebke Sondermann",
            "H. Peter Soyer",
            "Hans Starz",
            "Wilhelm Stolz",
            "Esmeralda Vale",
            "Wolfgang Weyers",
            "Alexander Zink",
            "Eva Krieghoff-Henning",
            "Jakob Nikolas Kather",
            "Christof von Kalle",
            "Daniel B. Lipka",
            "Stefan Fr\u00f6hling",
            "Axel Hauschild",
            "Harald Kittler",
            "Titus J. Brinker"
        ],
        "title": "Skin cancer classification via convolutional neural networks: systematic review of studies involving human experts",
        "publication_date": "2021-09-08 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "European Journal of Cancer",
        "volume": "156",
        "doi": "10.1016/j.ejca.2021.06.049",
        "urls": [
            "https://openalex.org/W3196396697",
            "https://doi.org/10.1016/j.ejca.2021.06.049",
            "http://www.ejcancer.com/article/S0959804921004445/pdf"
        ],
        "id": "id8300200676399456430",
        "abstract": "",
        "versions": [],
        "rank": 157
    },
    {
        "authors": [],
        "title": "Detailed Analysis of Top 10 AI- Deep Learning Neural Networks in Intrusion Detection for Internet of Things",
        "publication_date": "2022-06-22 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.21203/rs.3.rs-459229/v2",
        "urls": [
            "https://www.researchsquare.com/article/rs-459229/v2",
            "https://www.researchsquare.com/article/rs-459229/v2.html",
            "http://dx.doi.org/10.21203/rs.3.rs-459229/v2"
        ],
        "id": "id-5374034346897525263",
        "abstract": "",
        "versions": [],
        "rank": 158
    },
    {
        "authors": [
            "Vladimir A. Golovko",
            "Aliaksandr Kroshchanka",
            "Egor Mikhno",
            "Myroslav Komar",
            "Anatoliy Sachenko",
            "Sergei V. Bezobrazov",
            "Inna Shylinska"
        ],
        "title": "Deep Convolutional Neural Network for Recognizing the Images of Text Documents",
        "publication_date": "2019-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20220124003909/http://ceur-ws.org/Vol-2386/paper22.pdf"
        ],
        "id": "id-7414558315683401653",
        "abstract": "A comparative analysis of various methods and architectures used to solve the problem of object detection is carried out. This allows so-called oneway neural networks architectures to provide high quality solutions to the problem. A neural network algorithm for labeling images in text documents is developed on the basis of image preprocessing that simplifies the localization of individual parts of a document and the subsequent recognition of localized blocks using a deep convolutional neural network. The resulting algorithm provides a high quality of localization and an acceptable level of subsequent classification.",
        "versions": [],
        "rank": 159
    },
    {
        "authors": [
            "Yingying Zhang",
            "Desen Zhou",
            "Siqin Chen",
            "Shenghua Gao",
            "Yi Ma"
        ],
        "title": "Single-Image Crowd Counting via Multi-Column Convolutional Neural Network",
        "publication_date": "2016-06-27 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Computer Vision and Pattern Recognition",
        "volume": "",
        "doi": "10.1109/cvpr.2016.70",
        "urls": [
            "https://openalex.org/W2463631526",
            "https://doi.org/10.1109/cvpr.2016.70"
        ],
        "id": "id-8257355368127023857",
        "abstract": "",
        "versions": [],
        "rank": 160
    },
    {
        "authors": [
            "Qiuyu Zhu",
            "Guohui Zheng",
            "Jiakang Shen",
            "Rui Wang"
        ],
        "title": "Out-of-Distribution Detection Based on Feature Fusion in Neural Network Classifier Pre-Trained by PEDCC-Loss",
        "publication_date": "2022-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Institute of Electrical and Electronics Engineers (IEEE)",
        "volume": "",
        "doi": "10.1109/access.2022.3184694",
        "urls": [
            "https://web.archive.org/web/20220629072001/https://ieeexplore.ieee.org/ielx7/6287639/9668973/09801848.pdf?tp=&arnumber=9801848&isnumber=9668973&ref="
        ],
        "id": "id-8769787835944250703",
        "abstract": "Out-of-distribution (OOD) detection is related to the security and stability of deep learning models deployed in the real world. The existing OOD detection algorithms based on the neural network normally use a single scoring function to detect out-of-distribution examples, which start from the posterior probability and do not fully utilize the information of the pre-trained model. In this paper, based on our previous PEDCC-based work, feature fusion is explored in OOD detection to take maximum advantage of the pre-trained classifier features. Our improved method adopts a two-stage training approach, in which multiple OOD detection features of the first-stage neural network classifier are extracted as the input of the second-stage training. In addition, we propose the stop-near-saturation method, which can help the OOD detection algorithm find optimal network parameters without accessing OOD data. Extensive experiments on several public datasets and classification networks show that compared with other existing methods, this method has better OOD detection performance, and maintains the low computational complexity of the original PEDCC-based method. INDEX TERMS Feature fusion, in-distribution, neural network, out-of-distribution detection.",
        "versions": [],
        "rank": 161
    },
    {
        "authors": [
            "Liu, J.",
            "Gao, X.",
            "Bao, N.",
            "Tang, J.",
            "Wu, G."
        ],
        "title": "Deep convolutional neural networks for pedestrian detection with skip pooling",
        "publication_date": "2017-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ijcnn.2017.7966103",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/7958416/7965814/07966103.pdf?arnumber=7966103",
            "http://dx.doi.org/10.1109/ijcnn.2017.7966103"
        ],
        "id": "id430365856944741086",
        "abstract": "",
        "versions": [],
        "rank": 162
    },
    {
        "authors": [
            "Shahsavari, S.",
            "Sameti, H.",
            "Hadian, H."
        ],
        "title": "Speech activity detection using deep neural networks",
        "publication_date": "2017-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/iraniancee.2017.7985293",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/7973334/7985087/07985293.pdf?arnumber=7985293",
            "http://dx.doi.org/10.1109/iraniancee.2017.7985293"
        ],
        "id": "id2878873134529729457",
        "abstract": "",
        "versions": [],
        "rank": 163
    },
    {
        "authors": [
            "Aristotelis-Angelos Papadopoulos",
            "Mohammad Reza Rajati",
            "Nazim Shaikh",
            "Jiamian Wang"
        ],
        "title": "Outlier exposure with confidence control for out-of-distribution detection",
        "publication_date": "2021-06-21 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Neurocomputing",
        "volume": "441",
        "doi": "10.1016/j.neucom.2021.02.007",
        "urls": [
            "https://openalex.org/W2990064013",
            "https://doi.org/10.1016/j.neucom.2021.02.007",
            "http://arxiv.org/pdf/1906.03509"
        ],
        "id": "id8003796714981206672",
        "abstract": "",
        "versions": [
            {
                "year": 2019,
                "source": "SupportedSources.PAPERS_WITH_CODE",
                "title": "Outlier Exposure with Confidence Control for Out-of-Distribution Detection",
                "journal": "",
                "urls": [
                    "https://arxiv.org/pdf/1906.03509v4.pdf",
                    "https://github.com/nazim1021/OOD-detection-using-OECC"
                ],
                "doi": "",
                "publication_date": "2019-06-08 00:00:00"
            },
            {
                "year": 2021,
                "source": "SupportedSources.INTERNET_ARCHIVE",
                "title": "Outlier Exposure with Confidence Control for Out-of-Distribution Detection",
                "journal": "",
                "urls": [
                    "https://web.archive.org/web/20200609001650/https://arxiv.org/pdf/1906.03509v3.pdf"
                ],
                "doi": "",
                "publication_date": "2021-02-02 00:00:00"
            }
        ],
        "rank": 164
    },
    {
        "authors": [
            "Davis, Larry S.",
            "Feris, Rogerio",
            "Grauman, Kristen",
            "Kumar, Abhishek",
            "Nagarajan, Tushar",
            "Rennie, Steven",
            "Wu, Zuxuan"
        ],
        "title": "BlockDrop: Dynamic Inference Paths in Residual Networks",
        "publication_date": "2019-01-28 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/cvpr.2018.00919",
        "urls": [
            "http://arxiv.org/abs/1711.08393"
        ],
        "id": "id-6851433997288757322",
        "abstract": "Very deep convolutional neural networks offer excellent recognition results,\nyet their computational expense limits their impact for many real-world\napplications. We introduce BlockDrop, an approach that learns to dynamically\nchoose which layers of a deep network to execute during inference so as to best\nreduce total computation without degrading prediction accuracy. Exploiting the\nrobustness of Residual Networks (ResNets) to layer dropping, our framework\nselects on-the-fly which residual blocks to evaluate for a given novel image.\nIn particular, given a pretrained ResNet, we train a policy network in an\nassociative reinforcement learning setting for the dual reward of utilizing a\nminimal number of blocks while preserving recognition accuracy. We conduct\nextensive experiments on CIFAR and ImageNet. The results provide strong\nquantitative and qualitative evidence that these learned policies not only\naccelerate inference but also encode meaningful visual information. Built upon\na ResNet-101 model, our method achieves a speedup of 20\\% on average, going as\nhigh as 36\\% for some images, while maintaining the same 76.4\\% top-1 accuracy\non ImageNet.Comment: CVPR 201",
        "versions": [],
        "rank": 165
    },
    {
        "authors": [
            "Limin Wang",
            "Yuanjun Xiong",
            "Zhe Wang",
            "Yu Qiao",
            "Dahua Lin",
            "Xiaoou Tang",
            "Luc Van Gool"
        ],
        "title": "Temporal Segment Networks: Towards Good Practices for Deep Action Recognition",
        "publication_date": "2016-10-08 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Lecture Notes in Computer Science",
        "volume": "",
        "doi": "10.1007/978-3-319-46484-8_2",
        "urls": [
            "https://openalex.org/W2507009361",
            "https://doi.org/10.1007/978-3-319-46484-8_2",
            "http://arxiv.org/pdf/1608.00859"
        ],
        "id": "id-105442802274604617",
        "abstract": "",
        "versions": [],
        "rank": 166
    },
    {
        "authors": [
            "Christian Szegedy",
            "Vincent Vanhoucke",
            "Sergey Ioffe",
            "Jonathon Shlens",
            "Zbigniew Wojna"
        ],
        "title": "Rethinking the Inception Architecture for Computer Vision",
        "publication_date": "2016-06-27 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Computer Vision and Pattern Recognition",
        "volume": "",
        "doi": "10.1109/cvpr.2016.308",
        "urls": [
            "https://openalex.org/W2183341477",
            "https://doi.org/10.1109/cvpr.2016.308",
            "http://arxiv.org/pdf/1512.00567"
        ],
        "id": "id-1688057875749335436",
        "abstract": "",
        "versions": [],
        "rank": 167
    },
    {
        "authors": [
            "Marco Pavone",
            "Navid Azizan",
            "Apoorva Sharma"
        ],
        "title": "Sketching Curvature for Efficient Out-of-Distribution Detection for Deep Neural Networks",
        "publication_date": "2021-02-24 00:00:00",
        "source": "SupportedSources.PAPERS_WITH_CODE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://arxiv.org/pdf/2102.12567v1.pdf",
            "https://github.com/StanfordASL/SCOD"
        ],
        "id": "id7911803175809789891",
        "abstract": "In order to safely deploy Deep Neural Networks (DNNs) within the perception pipelines of real-time decision making systems, there is a need for safeguards that can detect out-of-training-distribution (OoD) inputs both efficiently and accurately. Building on recent work leveraging the local curvature of DNNs to reason about epistemic uncertainty, we propose Sketching Curvature of OoD Detection (SCOD), an architecture-agnostic framework for equipping any trained DNN with a task-relevant epistemic uncertainty estimate. Offline, given a trained model and its training data, SCOD employs tools from matrix sketching to tractably compute a low-rank approximation of the Fisher information matrix, which characterizes which directions in the weight space are most influential on the predictions over the training data. Online, we estimate uncertainty by measuring how much perturbations orthogonal to these directions can alter predictions at a new test input. We apply SCOD to pre-trained networks of varying architectures on several tasks, ranging from regression to classification. We demonstrate that SCOD achieves comparable or better OoD detection performance with lower computational burden relative to existing baselines.",
        "versions": [
            {
                "year": 2021,
                "source": "SupportedSources.OPENALEX",
                "title": "Sketching Curvature for Efficient Out-of-Distribution Detection for Deep Neural Networks",
                "journal": "Uncertainty in Artificial Intelligence",
                "urls": [
                    "https://openalex.org/W3186504155"
                ],
                "doi": null,
                "publication_date": "2021-07-27 00:00:00"
            },
            {
                "year": 2021,
                "source": "SupportedSources.OPENALEX",
                "title": "Sketching Curvature for Efficient Out-of-Distribution Detection for Deep Neural Networks",
                "journal": "arXiv (Cornell University)",
                "urls": [
                    "https://openalex.org/W3133483634"
                ],
                "doi": null,
                "publication_date": "2021-02-24 00:00:00"
            }
        ],
        "rank": 168
    },
    {
        "authors": [
            "Zhang, X.",
            "Wang, D."
        ],
        "title": "Boosted deep neural networks and multi-resolution cochleagram features for voice activity detection",
        "publication_date": "2014-09-14 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.21437/interspeech.2014-367",
        "urls": [
            "http://dx.doi.org/10.21437/interspeech.2014-367"
        ],
        "id": "id2370638556745818621",
        "abstract": "",
        "versions": [],
        "rank": 169
    },
    {
        "authors": [
            "Zaharah Bukhsh",
            "Aaqib Saeed"
        ],
        "title": "On Out-of-Distribution Detection for Audio with Deep Nearest Neighbors",
        "publication_date": "2023-02-25 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20221028133547/https://arxiv.org/pdf/2210.15283v1.pdf"
        ],
        "id": "id-899522878757438203",
        "abstract": "Out-of-distribution (OOD) detection is concerned with identifying data points that do not belong to the same distribution as the model's training data. For the safe deployment of predictive models in a real-world environment, it is critical to avoid making confident predictions on OOD inputs as it can lead to potentially dangerous consequences. However, OOD detection largely remains an under-explored area in the audio (and speech) domain. This is despite the fact that audio is a central modality for many tasks, such as speaker diarization, automatic speech recognition, and sound event detection. To address this, we propose to leverage feature-space of the model with deep k-nearest neighbors to detect OOD samples. We show that this simple and flexible method effectively detects OOD inputs across a broad category of audio (and speech) datasets. Specifically, it improves the false positive rate (FPR@TPR95) by 17% and the AUROC score by 7% than other prior techniques.",
        "versions": [],
        "rank": 170
    },
    {
        "authors": [
            "Xulei Yang",
            "Zeng Zeng",
            "Sin G. Teo",
            "Li Wang",
            "Vijay Chandrasekhar",
            "Steven C. H. Hoi"
        ],
        "title": "Deep Learning for Practical Image Recognition",
        "publication_date": "2018-07-19 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Knowledge Discovery and Data Mining",
        "volume": "",
        "doi": "10.1145/3219819.3219907",
        "urls": [
            "https://openalex.org/W2809371442",
            "https://doi.org/10.1145/3219819.3219907",
            "https://ink.library.smu.edu.sg/sis_research/4184"
        ],
        "id": "id-684699107526738851",
        "abstract": "",
        "versions": [],
        "rank": 171
    },
    {
        "authors": [
            "Haidar Khan",
            "Lara Marcuse",
            "B\u00fclent Yener"
        ],
        "title": "Deep density ratio estimation for change point detection",
        "publication_date": "2019-05-23 19:04:56+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1905.09876v1",
            "http://arxiv.org/abs/1905.09876v1",
            "http://arxiv.org/pdf/1905.09876v1"
        ],
        "id": "id-741407663681964885",
        "abstract": "In this work, we propose new objective functions to train deep neural network\nbased density ratio estimators and apply it to a change point detection\nproblem. Existing methods use linear combinations of kernels to approximate the\ndensity ratio function by solving a convex constrained minimization problem.\nApproximating the density ratio function using a deep neural network requires\ndefining a suitable objective function to optimize. We formulate and compare\nobjective functions that can be minimized using gradient descent and show that\nthe network can effectively learn to approximate the density ratio function.\nUsing our deep density ratio estimation objective function results in better\nperformance on a seizure detection task than other (kernel and neural network\nbased) density ratio estimation methods and other window-based change point\ndetection algorithms. We also show that the method can still support other\nneural network architectures, such as convolutional networks.",
        "versions": [],
        "rank": 172
    },
    {
        "authors": [
            "Janis Postels",
            "Hermann Blum",
            "Yannick Str\u00fcmpler",
            "Cesar Cadena",
            "Roland Siegwart",
            "Luc Van Gool",
            "Federico Tombari"
        ],
        "title": "The Hidden Uncertainty in a Neural Networks Activations",
        "publication_date": "2021-02-23 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20210302123242/https://arxiv.org/pdf/2012.03082v2.pdf"
        ],
        "id": "id3828146561712943221",
        "abstract": "The distribution of a neural network's latent representations has been successfully used to detect out-of-distribution (OOD) data. This work investigates whether this distribution moreover correlates with a model's epistemic uncertainty, thus indicates its ability to generalise to novel inputs. We first empirically verify that epistemic uncertainty can be identified with the surprise, thus the negative log-likelihood, of observing a particular latent representation. Moreover, we demonstrate that the output-conditional distribution of hidden representations also allows quantifying aleatoric uncertainty via the entropy of the predictive distribution. We analyse epistemic and aleatoric uncertainty inferred from the representations of different layers and conclude that deeper layers lead to uncertainty with similar behaviour as established - but computationally more expensive - methods (e.g. deep ensembles). While our approach does not require modifying the training process, we follow prior work and experiment with an additional regularising loss that increases the information in the latent representations. We find that this leads to improved OOD detection of epistemic uncertainty at the cost of ambiguous calibration close to the data distribution. We verify our findings on both classification and regression models.",
        "versions": [],
        "rank": 173
    },
    {
        "authors": [
            "Wesley J. Maddox",
            "Pavel Izmailov",
            "Timur Garipov",
            "Dmitry Vetrov",
            "Andrew Wilson"
        ],
        "title": "A Simple Baseline for Bayesian Uncertainty in Deep Learning",
        "publication_date": "2019-02-07 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Neural Information Processing Systems",
        "volume": "32",
        "doi": null,
        "urls": [
            "https://openalex.org/W2971130081"
        ],
        "id": "id-3046041096458596479",
        "abstract": "",
        "versions": [
            {
                "year": 2019,
                "source": "SupportedSources.PAPERS_WITH_CODE",
                "title": "A Simple Baseline for Bayesian Uncertainty in Deep Learning",
                "journal": "",
                "urls": [
                    "https://arxiv.org/pdf/1902.02476v2.pdf",
                    "https://github.com/wjmaddox/swa_gaussian",
                    "http://papers.nips.cc/paper/9472-a-simple-baseline-for-bayesian-uncertainty-in-deep-learning.pdf"
                ],
                "doi": "",
                "publication_date": "2019-02-07 00:00:00"
            },
            {
                "year": 2019,
                "source": "SupportedSources.OPENALEX",
                "title": "A Simple Baseline for Bayesian Uncertainty in Deep Learning",
                "journal": "arXiv (Cornell University)",
                "urls": [
                    "https://openalex.org/W2912168444"
                ],
                "doi": null,
                "publication_date": "2019-02-07 00:00:00"
            }
        ],
        "rank": 174
    },
    {
        "authors": [
            "Li, X.",
            "Tang, Y.",
            "Gao, T."
        ],
        "title": "Deep but lightweight neural networks for fish detection",
        "publication_date": "2017-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/oceanse.2017.8084961",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/8067435/8084562/08084961.pdf?arnumber=8084961",
            "http://dx.doi.org/10.1109/oceanse.2017.8084961"
        ],
        "id": "id6502393013907207348",
        "abstract": "",
        "versions": [],
        "rank": 175
    },
    {
        "authors": [
            "Aversano, L.",
            "Bernardi, M.",
            "Cimitile, M.",
            "Pecori, R."
        ],
        "title": "Early Detection of Parkinson Disease using Deep Neural Networks on Gait Dynamics",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ijcnn48605.2020.9207380",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/9200848/9206590/09207380.pdf?arnumber=9207380",
            "http://dx.doi.org/10.1109/ijcnn48605.2020.9207380"
        ],
        "id": "id4274076659434923394",
        "abstract": "",
        "versions": [],
        "rank": 176
    },
    {
        "authors": [
            "Alexander Immer",
            "Maciej Jan Korzepa",
            "Matthias Bauer"
        ],
        "title": "Improving predictions of Bayesian neural nets via local linearization",
        "publication_date": "2021-03-18 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "International Conference on Artificial Intelligence and Statistics",
        "volume": "",
        "doi": null,
        "urls": [
            "https://openalex.org/W3157086450"
        ],
        "id": "id-1272854486530404807",
        "abstract": "",
        "versions": [],
        "rank": 177
    },
    {
        "authors": [
            "Laurens Sluijterman",
            "Eric Cator",
            "Tom Heskes"
        ],
        "title": "Confident Neural Network Regression with Bootstrapped Deep Ensembles",
        "publication_date": "2022-02-22 14:08:24+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2202.10903v1",
            "http://arxiv.org/abs/2202.10903v1",
            "http://arxiv.org/pdf/2202.10903v1"
        ],
        "id": "id-7612039782954696296",
        "abstract": "With the rise of the popularity and usage of neural networks, trustworthy\nuncertainty estimation is becoming increasingly essential. In this paper we\npresent a computationally cheap extension of Deep Ensembles for a regression\nsetting called Bootstrapped Deep Ensembles that explicitly takes the effect of\nfinite data into account using a modified version of the parametric bootstrap.\nWe demonstrate through a simulation study that our method has comparable or\nbetter prediction intervals and superior confidence intervals compared to Deep\nEnsembles and other state-of-the-art methods. As an added bonus, our method is\nbetter capable of detecting overfitting than standard Deep Ensembles.",
        "versions": [],
        "rank": 178
    },
    {
        "authors": [
            "Boudreaux, Thomas M."
        ],
        "title": "The applications of deep neural networks to sdBV classification",
        "publication_date": "2017-12-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": null,
        "volume": "",
        "doi": "10.1515/astro-d-17-0450",
        "urls": [
            "http://arxiv.org/abs/1711.11421"
        ],
        "id": "id-8751917517680395851",
        "abstract": "With several new large-scale surveys on the horizon, including LSST, TESS,\nZTF, and Evryscope, faster and more accurate analysis methods will be required\nto adequately process the enormous amount of data produced. Deep learning, used\nin industry for years now, allows for advanced feature detection in minimally\nprepared datasets at very high speeds; however, despite the advantages of this\nmethod, its application to astrophysics has not yet been extensively explored.\nThis dearth may be due to a lack of training data available to researchers.\nHere we generate synthetic data loosely mimicking the properties of acoustic\nmode pulsating stars and we show that two separate paradigms of deep learning -\nthe Artificial Neural Network And the Convolutional Neural Network - can both\nbe used to classify this synthetic data effectively. And that additionally this\nclassification can be performed at relatively high levels of accuracy with\nminimal time spent adjusting network hyperparameters.Comment: 12 pages, 10 figures, originally presented at sdOB",
        "versions": [],
        "rank": 179
    },
    {
        "authors": [
            "Wei-Sheng Lai",
            "Jia Huang",
            "Narendra Ahuja",
            "Ming-Hsuan Yang"
        ],
        "title": "Deep Laplacian Pyramid Networks for Fast and Accurate Super-Resolution",
        "publication_date": "2017-04-12 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "arXiv (Cornell University)",
        "volume": "",
        "doi": "10.1109/cvpr.2017.618",
        "urls": [
            "https://openalex.org/W2607041014",
            "https://doi.org/10.1109/cvpr.2017.618",
            "http://arxiv.org/pdf/1704.03915"
        ],
        "id": "id3425422373362188131",
        "abstract": "",
        "versions": [],
        "rank": 180
    },
    {
        "authors": [
            "Seokyoung Hong",
            "Nahyeon An",
            "Hyungtae Cho",
            "J. Lim",
            "In-su Han",
            "Il-Sik Moon",
            "Junghwan Kim"
        ],
        "title": "A Dynamic Doft Sensor Based on Hybrid Neural Networks to Improve Early Off-spec Detection",
        "publication_date": "2022-07-23 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1007/s00366-022-01694-7",
        "urls": [
            "https://www.semanticscholar.org/paper/4729140db803ae0da666d77da476a5f550ddbb10"
        ],
        "id": "id-8523058097621542800",
        "abstract": null,
        "versions": [],
        "rank": 181
    },
    {
        "authors": [
            "Francesco Tonin",
            "Arun Pandey",
            "Panagiotis Patrinos",
            "Johan A. K. Suykens"
        ],
        "title": "Unsupervised Energy-based Out-of-distribution Detection using Stiefel-Restricted Kernel Machine",
        "publication_date": "2021-02-16 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20210220082400/https://arxiv.org/pdf/2102.08443v1.pdf"
        ],
        "id": "id8438214663007336056",
        "abstract": "Detecting out-of-distribution (OOD) samples is an essential requirement for the deployment of machine learning systems in the real world. Until now, research on energy-based OOD detectors has focused on the softmax confidence score from a pre-trained neural network classifier with access to class labels. In contrast, we propose an unsupervised energy-based OOD detector leveraging the Stiefel-Restricted Kernel Machine (St-RKM). Training requires minimizing an objective function with an autoencoder loss term and the RKM energy where the interconnection matrix lies on the Stiefel manifold. Further, we outline multiple energy function definitions based on the RKM framework and discuss their utility. In the experiments on standard datasets, the proposed method improves over the existing energy-based OOD detectors and deep generative models. Through several ablation studies, we further illustrate the merit of each proposed energy function on the OOD detection performance.",
        "versions": [],
        "rank": 182
    },
    {
        "authors": [
            "Nikita Patil",
            "Krishna Kadam",
            "Rahul Patil"
        ],
        "title": "Deep Learning",
        "publication_date": "2018-08-30 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Tejass Publisheers",
        "volume": "",
        "doi": "10.17148/ijarcce.2018.7820",
        "urls": [
            "https://web.archive.org/web/20220223042921/https://ijarcce.com/wp-content/uploads/2018/09/IJARCCE.2018.7820.pdf"
        ],
        "id": "id-2788191896805645685",
        "abstract": "Deep learning is used to identify the objects with the help of neural network. It is used to identify various objects in the world. In this, we have explained the process of identifying the objects with the help of various layers. Machine uses different layers to identify the object with the help of hidden layers which is used to train the machine depending upon the database provided to it. The more the database provided to it the more the accurate result the machine will provide.",
        "versions": [],
        "rank": 183
    },
    {
        "authors": [
            "Chen, Chao",
            "Lin, Xiao",
            "Terejanu, Gabriel"
        ],
        "title": "An Approximate Bayesian Long Short-Term Memory Algorithm for Outlier  Detection",
        "publication_date": "2019-06-03 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/icpr.2018.8545695",
        "urls": [
            "http://arxiv.org/abs/1712.08773"
        ],
        "id": "id-2492132072531500976",
        "abstract": "Long Short-Term Memory networks trained with gradient descent and\nback-propagation have received great success in various applications. However,\npoint estimation of the weights of the networks is prone to over-fitting\nproblems and lacks important uncertainty information associated with the\nestimation. However, exact Bayesian neural network methods are intractable and\nnon-applicable for real-world applications. In this study, we propose an\napproximate estimation of the weights uncertainty using Ensemble Kalman Filter,\nwhich is easily scalable to a large number of weights. Furthermore, we optimize\nthe covariance of the noise distribution in the ensemble update step using\nmaximum likelihood estimation. To assess the proposed algorithm, we apply it to\noutlier detection in five real-world events retrieved from the Twitter\nplatform",
        "versions": [],
        "rank": 184
    },
    {
        "authors": [
            "Jin, R."
        ],
        "title": "Deep neural networks based visual object detection in videos",
        "publication_date": "None",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.32657/10356/144136",
        "urls": [
            "http://dx.doi.org/10.32657/10356/144136"
        ],
        "id": "id6452541553174739526",
        "abstract": "",
        "versions": [],
        "rank": 185
    },
    {
        "authors": [
            "Talathi, S."
        ],
        "title": "Deep Recurrent Neural Networks for seizure detection and early seizure detection systems",
        "publication_date": "2017-06-05 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.2172/1366924",
        "urls": [
            "http://dx.doi.org/10.2172/1366924"
        ],
        "id": "id4501733027889946085",
        "abstract": "",
        "versions": [],
        "rank": 186
    },
    {
        "authors": [
            "Mehran H. Z. Bazargani",
            "Arjun Pakrashi",
            "Brian Mac Namee"
        ],
        "title": "The Deep Radial Basis Function Data Descriptor (D-RBFDD) Network: A One-Class Neural Network for Anomaly Detection",
        "publication_date": "2021-01-29 15:15:17+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2101.12632v1",
            "http://arxiv.org/abs/2101.12632v1",
            "http://arxiv.org/pdf/2101.12632v1"
        ],
        "id": "id1229690837607765482",
        "abstract": "Anomaly detection is a challenging problem in machine learning, and is even\nmore so when dealing with instances that are captured in low-level, raw data\nrepresentations without a well-behaved set of engineered features. The Radial\nBasis Function Data Descriptor (RBFDD) network is an effective solution for\nanomaly detection, however, it is a shallow model that does not deal\neffectively with raw data representations. This paper investigates approaches\nto modifying the RBFDD network to transform it into a deep one-class classifier\nsuitable for anomaly detection problems with low-level raw data\nrepresentations. We show that approaches based on transfer learning are not\neffective and our results suggest that this is because the latent\nrepresentations learned by generic classification models are not suitable for\nanomaly detection. Instead we show that an approach that adds multiple\nconvolutional layers before the RBF layer, to form a Deep Radial Basis Function\nData Descriptor (D-RBFDD) network, is very effective. This is shown in a set of\nevaluation experiments using multiple anomaly detection scenarios created from\npublicly available image classification datasets, and a real-world anomaly\ndetection dataset in which different types of arrhythmia are detected in\nelectrocardiogram (ECG) data. Our experiments show that the D-RBFDD network\nout-performs state-of-the-art anomaly detection methods including the Deep\nSupport Vector Data Descriptor (Deep SVDD), One-Class SVM, and Isolation Forest\non the image datasets, and produces competitive results for the ECG dataset.",
        "versions": [],
        "rank": 187
    },
    {
        "authors": [
            "Peilun Wu",
            "Hui Guo"
        ],
        "title": "LuNet: A Deep Neural Network for Network Intrusion Detection",
        "publication_date": "2019-09-22 15:34:27+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1909.10031v2",
            "http://arxiv.org/abs/1909.10031v2",
            "http://arxiv.org/pdf/1909.10031v2"
        ],
        "id": "id-842456461193137172",
        "abstract": "Network attack is a significant security issue for modern society. From small\nmobile devices to large cloud platforms, almost all computing products, used in\nour daily life, are networked and potentially under the threat of network\nintrusion. With the fast-growing network users, network intrusions become more\nand more frequent, volatile and advanced. Being able to capture intrusions in\ntime for such a large scale network is critical and very challenging. To this\nend, the machine learning (or AI) based network intrusion detection (NID), due\nto its intelligent capability, has drawn increasing attention in recent years.\nCompared to the traditional signature-based approaches, the AI-based solutions\nare more capable of detecting variants of advanced network attacks. However,\nthe high detection rate achieved by the existing designs is usually accompanied\nby a high rate of false alarms, which may significantly discount the overall\neffectiveness of the intrusion detection system. In this paper, we consider the\nexistence of spatial and temporal features in the network traffic data and\npropose a hierarchical CNN+RNN neural network, LuNet. In LuNet, the\nconvolutional neural network (CNN) and the recurrent neural network (RNN) learn\ninput traffic data in sync with a gradually increasing granularity such that\nboth spatial and temporal features of the data can be effectively extracted.\nOur experiments on two network traffic datasets show that compared to the\nstate-of-the-art network intrusion detection techniques, LuNet not only offers\na high level of detection capability but also has a much low rate of false\npositive-alarm.",
        "versions": [],
        "rank": 188
    },
    {
        "authors": [
            "Lee, Honglak",
            "Pan, Gang",
            "Sohn, Kihyuk",
            "Villegas, Ruben",
            "Zhang, Yuting"
        ],
        "title": "Improving Object Detection with Deep Convolutional Networks via Bayesian  Optimization and Structured Prediction",
        "publication_date": "2016-01-13 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/cvpr.2015.7298621",
        "urls": [
            "http://arxiv.org/abs/1504.03293"
        ],
        "id": "id-1519372747716420948",
        "abstract": "Object detection systems based on the deep convolutional neural network (CNN)\nhave recently made ground- breaking advances on several object detection\nbenchmarks. While the features learned by these high-capacity neural networks\nare discriminative for categorization, inaccurate localization is still a major\nsource of error for detection. Building upon high-capacity CNN architectures,\nwe address the localization problem by 1) using a search algorithm based on\nBayesian optimization that sequentially proposes candidate regions for an\nobject bounding box, and 2) training the CNN with a structured loss that\nexplicitly penalizes the localization inaccuracy. In experiments, we\ndemonstrated that each of the proposed methods improves the detection\nperformance over the baseline method on PASCAL VOC 2007 and 2012 datasets.\nFurthermore, two methods are complementary and significantly outperform the\nprevious state-of-the-art when combined.Comment: CVPR 201",
        "versions": [],
        "rank": 189
    },
    {
        "authors": [
            "Ma, Jiabin",
            "Wang, Liang",
            "Wang, Wei"
        ],
        "title": "Irregular Convolutional Neural Networks",
        "publication_date": "2017-06-24 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/acpr.2017.108",
        "urls": [
            "http://arxiv.org/abs/1706.07966"
        ],
        "id": "id7806783103050378491",
        "abstract": "Convolutional kernels are basic and vital components of deep Convolutional\nNeural Networks (CNN). In this paper, we equip convolutional kernels with shape\nattributes to generate the deep Irregular Convolutional Neural Networks (ICNN).\nCompared to traditional CNN applying regular convolutional kernels like\n${3\\times3}$, our approach trains irregular kernel shapes to better fit the\ngeometric variations of input features. In other words, shapes are learnable\nparameters in addition to weights. The kernel shapes and weights are learned\nsimultaneously during end-to-end training with the standard back-propagation\nalgorithm. Experiments for semantic segmentation are implemented to validate\nthe effectiveness of our proposed ICNN.Comment: 7 pages, 5 figures, 3 table",
        "versions": [],
        "rank": 190
    },
    {
        "authors": [
            "Murugan, S.",
            "Jeyakarthic, D."
        ],
        "title": "Optimal Deep Neural Network based Classification Model for Intrusion Detection in Mobile Adhoc Networks",
        "publication_date": "2019-10-31 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.5373/jardcs/v11sp10/20192983",
        "urls": [
            "http://dx.doi.org/10.5373/jardcs/v11sp10/20192983"
        ],
        "id": "id6938477133985653170",
        "abstract": "",
        "versions": [],
        "rank": 191
    },
    {
        "authors": [
            "Mahesh Subedar",
            "Nilesh Ahuja",
            "Ranganath Krishnan",
            "Ibrahima J. Ndiour, Omesh Tickoo"
        ],
        "title": "Deep Probabilistic Models to Detect Data Poisoning Attacks",
        "publication_date": "2019-12-03 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20200915025038/https://arxiv.org/pdf/1912.01206v1.pdf"
        ],
        "id": "id6283443345475653841",
        "abstract": "Data poisoning attacks compromise the integrity of machine-learning models by introducing malicious training samples to influence the results during test time. In this work, we investigate backdoor data poisoning attack on deep neural networks (DNNs) by inserting a backdoor pattern in the training images. The resulting attack will misclassify poisoned test samples while maintaining high accuracies for the clean test-set. We present two approaches for detection of such poisoned samples by quantifying the uncertainty estimates associated with the trained models. In the first approach, we model the outputs of the various layers (deep features) with parametric probability distributions learnt from the clean held-out dataset. At inference, the likelihoods of deep features w.r.t these distributions are calculated to derive uncertainty estimates. In the second approach, we use Bayesian deep neural networks trained with mean-field variational inference to estimate model uncertainty associated with the predictions. The uncertainty estimates from these methods are used to discriminate clean from the poisoned samples.",
        "versions": [],
        "rank": 192
    },
    {
        "authors": [
            "Wei Li",
            "Matthias Breier",
            "Dorit Merhof"
        ],
        "title": "Recycle deep features for better object detection",
        "publication_date": "2016-07-18 13:42:56+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1607.05066v1",
            "http://arxiv.org/abs/1607.05066v1",
            "http://arxiv.org/pdf/1607.05066v1"
        ],
        "id": "id2788895458290500571",
        "abstract": "Aiming at improving the performance of existing detection algorithms\ndeveloped for different applications, we propose a region regression-based\nmulti-stage class-agnostic detection pipeline, whereby the existing algorithms\nare employed for providing the initial detection proposals. Better detection is\nobtained by exploiting the power of deep learning in the region regress scheme\nwhile avoiding the requirement on a huge amount of reference data for training\ndeep neural networks. Additionally, a novel network architecture with recycled\ndeep features is proposed, which provides superior regression results compared\nto the commonly used architectures. As demonstrated on a data set with ~1200\nsamples of different classes, it is feasible to successfully train a deep\nneural network in our proposed architecture and use it to obtain the desired\ndetection performance. Since only slight modifications are required to common\nnetwork architectures and since the deep neural network is trained using the\nstandard hyperparameters, the proposed detection is well accessible and can be\neasily adopted to a broad variety of detection tasks.",
        "versions": [],
        "rank": 193
    },
    {
        "authors": [
            "Jauhar, Ahmad",
            "Marojevic, Vuk",
            "Reed, Jeffrey H.",
            "Tandiya, Nistha"
        ],
        "title": "Deep Predictive Coding Neural Network for RF Anomaly Detection in  Wireless Networks",
        "publication_date": "2018-03-15 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/iccw.2018.8403654",
        "urls": [
            "http://arxiv.org/abs/1803.06054"
        ],
        "id": "id7260442666708403698",
        "abstract": "Intrusion detection has become one of the most critical tasks in a wireless\nnetwork to prevent service outages that can take long to fix. The sheer variety\nof anomalous events necessitates adopting cognitive anomaly detection methods\ninstead of the traditional signature-based detection techniques. This paper\nproposes an anomaly detection methodology for wireless systems that is based on\nmonitoring and analyzing radio frequency (RF) spectrum activities. Our\ndetection technique leverages an existing solution for the video prediction\nproblem, and uses it on image sequences generated from monitoring the wireless\nspectrum. The deep predictive coding network is trained with images\ncorresponding to the normal behavior of the system, and whenever there is an\nanomaly, its detection is triggered by the deviation between the actual and\npredicted behavior. For our analysis, we use the images generated from the\ntime-frequency spectrograms and spectral correlation functions of the received\nRF signal. We test our technique on a dataset which contains anomalies such as\njamming, chirping of transmitters, spectrum hijacking, and node failure, and\nevaluate its performance using standard classifier metrics: detection ratio,\nand false alarm rate. Simulation results demonstrate that the proposed\nmethodology effectively detects many unforeseen anomalous events in real time.\nWe discuss the applications, which encompass industrial IoT, autonomous vehicle\ncontrol and mission-critical communications services.Comment: 7 pages, 7 figures, Communications Workshop ICC'1",
        "versions": [],
        "rank": 194
    },
    {
        "authors": [
            "Yaowu Chen",
            "Bolun Zheng",
            "Xiang Tian",
            "Hui Xue",
            "Rong Zhang",
            "Xiaodan Li",
            "Chuanlong Xie",
            "Yuefeng Chen",
            "Yao Zhu"
        ],
        "title": "Boosting Out-of-distribution Detection with Typical Features",
        "publication_date": "2022-10-09 00:00:00",
        "source": "SupportedSources.PAPERS_WITH_CODE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://arxiv.org/pdf/2210.04200v1.pdf",
            "https://github.com/alibaba/easyrobust"
        ],
        "id": "id-8849760938154050529",
        "abstract": "Out-of-distribution (OOD) detection is a critical task for ensuring the reliability and safety of deep neural networks in real-world scenarios. Different from most previous OOD detection methods that focus on designing OOD scores or introducing diverse outlier examples to retrain the model, we delve into the obstacle factors in OOD detection from the perspective of typicality and regard the feature's high-probability region of the deep model as the feature's typical set. We propose to rectify the feature into its typical set and calculate the OOD score with the typical features to achieve reliable uncertainty estimation. The feature rectification can be conducted as a {plug-and-play} module with various OOD scores. We evaluate the superiority of our method on both the commonly used benchmark (CIFAR) and the more challenging high-resolution benchmark with large label space (ImageNet). Notably, our approach outperforms state-of-the-art methods by up to 5.11$\\%$ in the average FPR95 on the ImageNet benchmark.",
        "versions": [
            {
                "year": 2022,
                "source": "SupportedSources.CORE",
                "title": "Boosting Out-of-distribution Detection with Typical Features",
                "journal": "",
                "urls": [
                    "http://arxiv.org/abs/2210.04200"
                ],
                "doi": null,
                "publication_date": "2022-10-09 00:00:00"
            }
        ],
        "rank": 195
    },
    {
        "authors": [
            "Alba Nogueira-Rodr\u00edguez",
            "Rub\u00e9n Dom\u00ednguez-Carbajales",
            "Fernando Campos-Tato",
            "J. Herrero",
            "Manuel Puga",
            "D. Remedios",
            "L. Rivas",
            "E. S\u00e1nchez",
            "\u00c1. Iglesias",
            "J. Cubiella",
            "F. Fdez-Riverola",
            "H. L\u00f3pez-Fern\u00e1ndez",
            "M. Reboiro-Jato",
            "D. Glez-Pe\u00f1a"
        ],
        "title": "Real-time polyp detection model using convolutional neural networks",
        "publication_date": "2021-09-21 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Neural Computing and Applications",
        "volume": "34",
        "doi": "10.1007/s00521-021-06496-4",
        "urls": [
            "https://www.semanticscholar.org/paper/f83c912a07745a89839d9f8dcf6bc621c133e892"
        ],
        "id": "id-1462407610483586988",
        "abstract": null,
        "versions": [],
        "rank": 196
    },
    {
        "authors": [
            "Amit, G.",
            "Levy, M.",
            "Rosenberg, I.",
            "Shabtai, A.",
            "Elovici, Y."
        ],
        "title": "FOOD: Fast Out-Of-Distribution Detector",
        "publication_date": "2021-07-18 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ijcnn52387.2021.9533465",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/9533266/9533267/09533465.pdf?arnumber=9533465",
            "http://dx.doi.org/10.1109/ijcnn52387.2021.9533465"
        ],
        "id": "id-5458683478147358802",
        "abstract": "",
        "versions": [],
        "rank": 197
    },
    {
        "authors": [
            "Michelucci, U."
        ],
        "title": "Advanced CNNs and Transfer Learning",
        "publication_date": "2019-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-1-4842-4976-5_4",
        "urls": [
            "http://link.springer.com/content/pdf/10.1007/978-1-4842-4976-5_4",
            "http://dx.doi.org/10.1007/978-1-4842-4976-5_4"
        ],
        "id": "id7301809709042701193",
        "abstract": "",
        "versions": [],
        "rank": 198
    },
    {
        "authors": [
            "Kunihiko Fukushima"
        ],
        "title": "Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position",
        "publication_date": "1980-01-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Biological Cybernetics",
        "volume": "36",
        "doi": "10.1007/bf00344251",
        "urls": [
            "https://openalex.org/W2101926813",
            "https://doi.org/10.1007/bf00344251"
        ],
        "id": "id8652890643859692305",
        "abstract": "",
        "versions": [],
        "rank": 199
    },
    {
        "authors": [
            "Cheng-Hung Lin",
            "Cheng-Shian Lin",
            "Po-Yung Chou",
            "Chen-Chien Hsu"
        ],
        "title": "An Efficient Data Augmentation Network for Out-of-Distribution Image Detection",
        "publication_date": "2021-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Institute of Electrical and Electronics Engineers (IEEE)",
        "volume": "",
        "doi": "10.1109/access.2021.3062187",
        "urls": [
            "https://web.archive.org/web/20210718043535/https://ieeexplore.ieee.org/ielx7/6287639/9312710/09363111.pdf"
        ],
        "id": "id1215024760804351428",
        "abstract": "Since deep neural networks may classify out-of-distribution image data into in-distribution classes with high confidence scores, this problem may cause serious or even fatal hazards in certain applications, such as autonomous vehicles and medical diagnosis. Therefore, out-of-distribution detection (also called anomaly detection or outlier detection) of image classification has become a critical issue for the successful development of neural networks. In other words, a successful neural network needs to be able to distinguish anomalous data that is significantly different from the data used in training. In this paper, we propose an efficient data augmentation network to detect out-of-distribution image data by introducing a set of common geometric operations into training and testing images. The output predicted probabilities of the augmented data are combined by an aggregation function to provide a confidence score to distinguish between in-distribution and out-of-distribution image data. Different from other approaches that use out-of-distribution image data for training networks, we only use in-distribution image data in the proposed data augmentation network. This advantage makes our approach more practical than other approaches, and can be easily applied to various neural networks to improve security in practical applications. The experimental results show that the proposed data augmentation network outperforms the state-ofthe-art approaches in various datasets. In addition, pre-training techniques can be integrated into the data augmentation network to make substantial improvements to large and complex data sets. The code is available at www.github.com/majic0626/Data-Augmentation-Network.git. INDEX TERMS Out-of-distribution detection, image classification, anomaly detection, outlier detection, data augmentation, deep neural networks.",
        "versions": [],
        "rank": 200
    },
    {
        "authors": [
            "Aria Khoshsirat"
        ],
        "title": "A Simple Framework to Quantify Different Types of Uncertainty in Deep Neural Networks for Image Classification",
        "publication_date": "2021-05-28 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20210528232627/https://arxiv.org/pdf/2011.08712v4.pdf"
        ],
        "id": "id-3170185614761920209",
        "abstract": "Quantifying uncertainty in a model's predictions is important as it enables the safety of an AI system to be increased by acting on the model's output in an informed manner. This is crucial for applications where the cost of an error is high, such as in autonomous vehicle control, medical image analysis, financial estimations or legal fields. Deep Neural Networks are powerful predictors that have recently achieved state-of-the-art performance on a wide spectrum of tasks. Quantifying predictive uncertainty in DNNs is a challenging and yet on-going problem. In this paper we propose a complete framework to capture and quantify three known types of uncertainty in DNNs for the task of image classification. This framework includes an ensemble of CNNs for model uncertainty, a supervised reconstruction auto-encoder to capture distributional uncertainty and using the output of activation functions in the last layer of the network, to capture data uncertainty. Finally we demonstrate the efficiency of our method on popular image datasets for classification.",
        "versions": [],
        "rank": 201
    },
    {
        "authors": [
            "S. Karthic",
            "S. M. Kumar"
        ],
        "title": "Hybrid Optimized Deep Neural Network with Enhanced Conditional Random Field Based Intrusion Detection on Wireless Sensor Network",
        "publication_date": "2022-06-24 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Neural Processing Letters",
        "volume": "55",
        "doi": "10.1007/s11063-022-10892-9",
        "urls": [
            "https://www.semanticscholar.org/paper/0d79c787b5b6e0f085c36a8a26b69e71d2dd8172"
        ],
        "id": "id-8646809337152364118",
        "abstract": null,
        "versions": [],
        "rank": 202
    },
    {
        "authors": [
            "Ritika Lohiya",
            "Ankit Thakkar"
        ],
        "title": "Intrusion Detection Using Deep Neural Network with AntiRectifier Layer",
        "publication_date": "None",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-981-33-6173-7_7",
        "urls": [
            "https://www.semanticscholar.org/paper/c45d7e05888975fdc278ebc50de11d423fed02ff"
        ],
        "id": "id-8286102261591506279",
        "abstract": null,
        "versions": [],
        "rank": 203
    },
    {
        "authors": [
            "Murat Sensoy",
            "Lance M. Kaplan",
            "Federico Cerutti",
            "Maryam Saleki"
        ],
        "title": "Uncertainty-Aware Deep Classifiers Using Generative Models",
        "publication_date": "2020-04-03 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Proceedings of the ... AAAI Conference on Artificial Intelligence",
        "volume": "34",
        "doi": "10.1609/aaai.v34i04.6015",
        "urls": [
            "https://openalex.org/W2997563872",
            "https://doi.org/10.1609/aaai.v34i04.6015",
            "https://ojs.aaai.org/index.php/AAAI/article/download/6015/5871"
        ],
        "id": "id4955486961745532211",
        "abstract": "",
        "versions": [
            {
                "year": 2020,
                "source": "SupportedSources.INTERNET_ARCHIVE",
                "title": "Uncertainty-Aware Deep Classifiers using Generative Models",
                "journal": "",
                "urls": [
                    "https://web.archive.org/web/20200610070344/https://arxiv.org/pdf/2006.04183v1.pdf"
                ],
                "doi": "",
                "publication_date": "2020-06-07 00:00:00"
            },
            {
                "year": 2020,
                "source": "SupportedSources.CORE",
                "title": "Uncertainty-Aware Deep Classifiers using Generative Models",
                "journal": "",
                "urls": [
                    "http://arxiv.org/abs/2006.04183"
                ],
                "doi": "10.1609/aaai.v34i04.6015",
                "publication_date": "2020-01-01 00:00:00"
            },
            {
                "year": 2020,
                "source": "SupportedSources.INTERNET_ARCHIVE",
                "title": "Uncertainty-Aware Deep Classifiers Using Generative Models",
                "journal": "Association for the Advancement of Artificial Intelligence (AAAI)",
                "urls": [
                    "https://web.archive.org/web/20201104123001/https://aaai.org/ojs/index.php/AAAI/article/download/6015/5871"
                ],
                "doi": "10.1609/aaai.v34i04.6015",
                "publication_date": "2020-04-03 00:00:00"
            }
        ],
        "rank": 204
    },
    {
        "authors": [
            "Huang, Mouxiao",
            "Qiao, Yu"
        ],
        "title": "Uncertainty-Estimation with Normalized Logits for Out-of-Distribution  Detection",
        "publication_date": "2023-02-15 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "http://arxiv.org/abs/2302.07608"
        ],
        "id": "id698185865397035635",
        "abstract": "Out-of-distribution (OOD) detection is critical for preventing deep learning\nmodels from making incorrect predictions to ensure the safety of artificial\nintelligence systems. Especially in safety-critical applications such as\nmedical diagnosis and autonomous driving, the cost of incorrect decisions is\nusually unbearable. However, neural networks often suffer from the\noverconfidence issue, making high confidence for OOD data which are never seen\nduring training process and may be irrelevant to training data, namely\nin-distribution (ID) data. Determining the reliability of the prediction is\nstill a difficult and challenging task. In this work, we propose\nUncertainty-Estimation with Normalized Logits (UE-NL), a robust learning method\nfor OOD detection, which has three main benefits. (1) Neural networks with\nUE-NL treat every ID sample equally by predicting the uncertainty score of\ninput data and the uncertainty is added into softmax function to adjust the\nlearning strength of easy and hard samples during training phase, making the\nmodel learn robustly and accurately. (2) UE-NL enforces a constant vector norm\non the logits to decouple the effect of the increasing output norm from\noptimization process, which causes the overconfidence issue to some extent. (3)\nUE-NL provides a new metric, the magnitude of uncertainty score, to detect OOD\ndata. Experiments demonstrate that UE-NL achieves top performance on common OOD\nbenchmarks and is more robust to noisy ID data that may be misjudged as OOD\ndata by other methods.Comment: 7 pages, 1 figure, 7 tables, preprin",
        "versions": [],
        "rank": 205
    },
    {
        "authors": [
            "R. Entezari",
            "O. Saukh"
        ],
        "title": "Class-dependent Pruning of Deep Neural Networks",
        "publication_date": "2020-04-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/SenSysML50931.2020.00010",
        "urls": [
            "https://www.semanticscholar.org/paper/8534a40f9a3a7b4ca99087cbc51f07224b4dbad1"
        ],
        "id": "id-354444904066235744",
        "abstract": "Today\u2019s deep neural networks require substantial computation resources for their training, storage and inference, which limits their effective use on resource-constrained devices. Many recent research activities explore different options for compressing and optimizing deep models. On the one hand, in many real-world applications we face the data imbalance challenge, i.e., when the number of labeled instances of one class considerably outweighs the number of labeled instances of the other class. On the other hand, applications may pose a class imbalance problem, i.e., higher number of false positives produced when training a model and optimizing its performance may be tolerable, yet the number of false negatives must stay low. The problem originates from the fact that some classes are more important for the application than others, e.g., detection problems in medical and surveillance domains. Motivated by the success of the lottery ticket hypothesis, in this paper we propose an iterative deep model compression technique, which keeps the number of false negatives of the compressed model close to the one of the original model at the price of increasing the number of false positives if necessary. Our experimental evaluation using two benchmark data sets shows that the resulting compressed sub-networks 1) achieve up to 35% lower number of false negatives than the compressed model without class optimization, 2) provide an overall higher AUC-ROC measure compared to conventional Lottery Ticket algorithm and three recent popular pruning methods, and 3) use up to 99% fewer parameters compared to the original network. The code is publicly available1.1https://github.com/rahimentezari/Sensys-ml2020",
        "versions": [],
        "rank": 206
    },
    {
        "authors": [
            "Collins, Maxwell D.",
            "Figurnov, Michael",
            "Huang, Jonathan",
            "Salakhutdinov, Ruslan",
            "Vetrov, Dmitry",
            "Zhang, Li",
            "Zhu, Yukun"
        ],
        "title": "Spatially Adaptive Computation Time for Residual Networks",
        "publication_date": "2017-07-02 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/cvpr.2017.194",
        "urls": [
            "http://arxiv.org/abs/1612.02297"
        ],
        "id": "id-5558644276768777629",
        "abstract": "This paper proposes a deep learning architecture based on Residual Network\nthat dynamically adjusts the number of executed layers for the regions of the\nimage. This architecture is end-to-end trainable, deterministic and\nproblem-agnostic. It is therefore applicable without any modifications to a\nwide range of computer vision problems such as image classification, object\ndetection and image segmentation. We present experimental results showing that\nthis model improves the computational efficiency of Residual Networks on the\nchallenging ImageNet classification and COCO object detection datasets.\nAdditionally, we evaluate the computation time maps on the visual saliency\ndataset cat2000 and find that they correlate surprisingly well with human eye\nfixation positions.Comment: CVPR 201",
        "versions": [],
        "rank": 207
    },
    {
        "authors": [
            "Minah Lee",
            "B. Mudassar",
            "S. Mukhopadhyay"
        ],
        "title": "Lightweight Model Uncertainty Estimation for Deep Neural Object Detection",
        "publication_date": "2022-07-18 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/IJCNN55064.2022.9892795",
        "urls": [
            "https://www.semanticscholar.org/paper/8c58f674ddd3ad0f13fbabfa0dc4235205bbf096"
        ],
        "id": "id2850615149378516683",
        "abstract": "Quantifying model uncertainty of Deep Neural Network (DNN) is important to understand the reliability of the model prediction and avoid risks in safety critical applications. Various approaches, including Bayesian neural networks, Monte-Carlo dropout, and ensembles, are suggested to measure the model uncertainty; but with huge computational cost. We present ModelNet, an Artificial Neural Network (ANN) that can estimate spatial/semantic model uncertainties of a DNN based object detection with less computation overhead. ModelNet is a deterministic ANN that distills the predictive distribution of stochastic DNN. Experimental results show that ModelNet can learn the uncertainty estimation from stochastic DNN in various architectures. ModelNet can perform as a probabilistic object detector with 39x-179x less number of operations, or as an uncertainty assistant to a task network with 1.4x more parameters and 38x less number of operations compared to stochastic DNN. Moreover, a case study of uncertainty driven adaptive sensor using ModelNet is presented.",
        "versions": [
            {
                "year": 2022,
                "source": "SupportedSources.CROSSREF",
                "title": "Lightweight Model Uncertainty Estimation for Deep Neural Object Detection",
                "journal": "",
                "urls": [
                    "http://xplorestaging.ieee.org/ielx7/9891857/9889787/09892795.pdf?arnumber=9892795",
                    "http://dx.doi.org/10.1109/ijcnn55064.2022.9892795"
                ],
                "doi": "10.1109/ijcnn55064.2022.9892795",
                "publication_date": "2022-07-18 00:00:00"
            }
        ],
        "rank": 208
    },
    {
        "authors": [
            "Mina Rezaei",
            "Haojin Yang",
            "Christoph Meinel"
        ],
        "title": "Brain Abnormality Detection by Deep Convolutional Neural Network",
        "publication_date": "2017-08-17 11:24:58+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1708.05206v1",
            "http://arxiv.org/abs/1708.05206v1",
            "http://arxiv.org/pdf/1708.05206v1"
        ],
        "id": "id2899908352156078190",
        "abstract": "In this paper, we describe our method for classification of brain magnetic\nresonance (MR) images into different abnormalities and healthy classes based on\nthe deep neural network. We propose our method to detect high and low-grade\nglioma, multiple sclerosis, and Alzheimer diseases as well as healthy cases.\nOur network architecture has ten learning layers that include seven\nconvolutional layers and three fully connected layers. We have achieved a\npromising result in five categories of brain images (classification task) with\n95.7% accuracy.",
        "versions": [],
        "rank": 209
    },
    {
        "authors": [
            "Meilu Zhu",
            "D. Shi",
            "Junbin Gao"
        ],
        "title": "Branched convolutional neural networks incorporated with Jacobian deep regression for facial landmark detection",
        "publication_date": "2019-10-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Neural networks : the official journal of the International Neural Network Society",
        "volume": "118",
        "doi": "10.1016/j.neunet.2019.04.002",
        "urls": [
            "https://www.semanticscholar.org/paper/990fe0eb342bdc4170fc9d583df3d072dd1b9712"
        ],
        "id": "id8026690131549623409",
        "abstract": null,
        "versions": [
            {
                "year": 2019,
                "source": "SupportedSources.CROSSREF",
                "title": "Branched convolutional neural networks incorporated with Jacobian deep regression for facial landmark detection",
                "journal": "",
                "urls": [
                    "https://api.elsevier.com/content/article/PII:S0893608019301005?httpAccept=text/xml",
                    "https://api.elsevier.com/content/article/PII:S0893608019301005?httpAccept=text/plain",
                    "http://dx.doi.org/10.1016/j.neunet.2019.04.002"
                ],
                "doi": "10.1016/j.neunet.2019.04.002",
                "publication_date": "2019-01-01 00:00:00"
            }
        ],
        "rank": 210
    },
    {
        "authors": [
            "Robin B. Chan",
            "Matthias Rottmann",
            "Hanno Gottschalk"
        ],
        "title": "Entropy Maximization and Meta Classification for Out-of-Distribution Detection in Semantic Segmentation",
        "publication_date": "2021-10-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "arXiv (Cornell University)",
        "volume": "",
        "doi": "10.1109/iccv48922.2021.00508",
        "urls": [
            "https://openalex.org/W3112906266",
            "https://doi.org/10.1109/iccv48922.2021.00508",
            "http://arxiv.org/pdf/2012.06575"
        ],
        "id": "id-1485682609060735339",
        "abstract": "",
        "versions": [],
        "rank": 211
    },
    {
        "authors": [
            "Ross Girshick",
            "Jeff Donahue",
            "Trevor Darrell",
            "Jitendra Malik"
        ],
        "title": "Region-Based Convolutional Networks for Accurate Object Detection and Segmentation",
        "publication_date": "2016-01-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
        "volume": "38",
        "doi": "10.1109/tpami.2015.2437384",
        "urls": [
            "https://openalex.org/W2183182206",
            "https://doi.org/10.1109/tpami.2015.2437384",
            "https://doi.org/10.1109/tpami.2015.2437384"
        ],
        "id": "id-8356278401151618510",
        "abstract": "",
        "versions": [],
        "rank": 212
    },
    {
        "authors": [
            "QingE E Wu",
            "Changsheng Fan",
            "Hu Chen",
            "Donghua Gu"
        ],
        "title": "Construction of a Neural Network and Its Application on Target Classification",
        "publication_date": "2019-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Institute of Electrical and Electronics Engineers (IEEE)",
        "volume": "",
        "doi": "10.1109/access.2019.2900578",
        "urls": [
            "https://web.archive.org/web/20210429070157/https://ieeexplore.ieee.org/ielx7/6287639/8600701/08648382.pdf"
        ],
        "id": "id-1409971859986819178",
        "abstract": "With the arrival of big data age, the deep convolutional neural networks (DCNNs) with more hidden layers have a more complex network structure and more powerful ability than traditional machine learning methods for feature learning and feature expression. This paper first proposes a model of the DCNN to discuss the basic structure of model, convolutional feature extraction and learning algorithm of convolutional neural network; then, mainly introduces several aspects, that is, the construction of the typical network structure, the training methods, and the parameter settings of network model to be improved and optimized. Moreover, the network model is applied to the classification and recognition of Antarctic hydrological features and compared with some existing classification methods. The novelty of this paper mainly includes two aspects, i.e., the one is that the design and construction of the structure of deep neural network based on deep learning method are performed, namely, connection, weight, calculator, learning training of network, and other design. The other is classifying hydrological characteristics of Pritz Bay in Antarctica's images by the DCNN. The results show that the correct recognition rate of the model method constructed by this paper is the highest. Finally, some problems in the current research are briefly summarized and discussed, and the new direction in the future development is forecasted. INDEX TERMS Deep learning, convolutional neural network, deep belief network, hydrological feature recognition.",
        "versions": [],
        "rank": 213
    },
    {
        "authors": [
            "Patric Hagmann",
            "Leila Cammoun",
            "Xavier Gigandet",
            "Reto Meuli",
            "Christopher J. Honey",
            "Van J. Wedeen",
            "Olaf Sporns"
        ],
        "title": "Mapping the Structural Core of Human Cerebral Cortex",
        "publication_date": "2008-07-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "PLOS Biology",
        "volume": "6",
        "doi": "10.1371/journal.pbio.0060159",
        "urls": [
            "https://openalex.org/W2159929956",
            "https://doi.org/10.1371/journal.pbio.0060159",
            "https://journals.plos.org/plosbiology/article/file?id=10.1371/journal.pbio.0060159&type=printable"
        ],
        "id": "id7371458517302761430",
        "abstract": "",
        "versions": [],
        "rank": 214
    },
    {
        "authors": [
            "Sungbin Lim",
            "Hyun-seok Min",
            "Hyungjoo Cho",
            "Minsuk Shin"
        ],
        "title": "Neural Bootstrapper",
        "publication_date": "2020-10-02 00:00:00",
        "source": "SupportedSources.PAPERS_WITH_CODE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://arxiv.org/pdf/2010.01051v4.pdf",
            "https://github.com/sungbinlim/neuboots",
            "http://proceedings.neurips.cc/paper/2021/file/8abfe8ac9ec214d68541fcb888c0b4c3-Paper.pdf"
        ],
        "id": "id6045337794903510021",
        "abstract": "Bootstrapping has been a primary tool for ensemble and uncertainty quantification in machine learning and statistics. However, due to its nature of multiple training and resampling, bootstrapping deep neural networks is computationally burdensome; hence it has difficulties in practical application to the uncertainty estimation and related tasks. To overcome this computational bottleneck, we propose a novel approach called \\emph{Neural Bootstrapper} (NeuBoots), which learns to generate bootstrapped neural networks through single model training. NeuBoots injects the bootstrap weights into the high-level feature layers of the backbone network and outputs the bootstrapped predictions of the target, without additional parameters and the repetitive computations from scratch. We apply NeuBoots to various machine learning tasks related to uncertainty quantification, including prediction calibrations in image classification and semantic segmentation, active learning, and detection of out-of-distribution samples. Our empirical results show that NeuBoots outperforms other bagging based methods under a much lower computational cost without losing the validity of bootstrapping.",
        "versions": [],
        "rank": 215
    },
    {
        "authors": [
            "Lile, C.",
            "Yiqun, L."
        ],
        "title": "Anomaly detection in thermal images using deep neural networks",
        "publication_date": "2017-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/icip.2017.8296692",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/8267582/8296222/08296692.pdf?arnumber=8296692",
            "http://dx.doi.org/10.1109/icip.2017.8296692"
        ],
        "id": "id-3716397289535587258",
        "abstract": "",
        "versions": [],
        "rank": 216
    },
    {
        "authors": [
            "Singh, A.",
            "Singh, J."
        ],
        "title": "Image forgery detection using Deep Neural Network",
        "publication_date": "2021-08-26 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/spin52536.2021.9565953",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/9565880/9565936/09565953.pdf?arnumber=9565953",
            "http://dx.doi.org/10.1109/spin52536.2021.9565953"
        ],
        "id": "id-6879957019769957135",
        "abstract": "",
        "versions": [],
        "rank": 217
    },
    {
        "authors": [
            "Benito-Gorr\u00f3n, Diego de",
            "Gonza\u0301lez-Rodri\u0301guez, Joaqui\u0301n",
            "Lozano-Di\u0301ez, Alicia",
            "Toledano, Doroteo T."
        ],
        "title": "Exploring convolutional, recurrent, and hybrid deep neural networks for speech and music detection in a large audio dataset",
        "publication_date": "2019-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1186/s13636-019-0152-1",
        "urls": [
            "https://repositorio.uam.es/bitstream/10486/690573/1/Exploring_benito_eurasip_2019.pdf"
        ],
        "id": "id2974268520147851622",
        "abstract": "Audio signals represent a wide diversity of acoustic events, from background environmental noise to spoken\r\ncommunication. Machine learning models such as neural networks have already been proposed for audio signal\r\nmodeling, where recurrent structures can take advantage of temporal dependencies. This work aims to study the\r\nimplementation of several neural network-based systems for speech and music event detection over a collection of\r\n77,937 10-second audio segments (216 h), selected from the Google AudioSet dataset. These segments belong to\r\nYouTube videos and have been represented as mel-spectrograms. We propose and compare two approaches. The\r\nfirst one is the training of two different neural networks, one for speech detection and another for music detection.\r\nThe second approach consists on training a single neural network to tackle both tasks at the same time. The studied\r\narchitectures include fully connected, convolutional and LSTM (long short-term memory) recurrent networks.\r\nComparative results are provided in terms of classification performance and model complexity. We would like to\r\nhighlight the performance of convolutional architectures, specially in combination with an LSTM stage. The hybrid\r\nconvolutional-LSTM models achieve the best overall results (85% accuracy) in the three proposed tasks. Furthermore,\r\na distractor analysis of the results has been carried out in order to identify which events in the ontology are the most\r\nharmful for the performance of the models, showing some difficult scenarios for the detection of music and speechThis work has been supported by project \u201cDSSL: Redes Profundas y Modelos\r\nde Subespacios para Deteccion y Seguimiento de Locutor, Idioma y\r\nEnfermedades Degenerativas a partir de la Voz\u201d (TEC2015-68172-C2-1-P),\r\nfunded by the Ministry of Economy and Competitivity of Spain and FEDE",
        "versions": [],
        "rank": 218
    },
    {
        "authors": [
            "Brody Huval",
            "Tao Wang",
            "Sameep Tandon",
            "Jeff Kiske",
            "Will Song",
            "Joel Pazhayampallil",
            "Mykhaylo Andriluka",
            "Pranav Rajpurkar",
            "Toki Migimatsu",
            "Royce Cheng-Yue",
            "Fernando Mujica",
            "Adam Coates",
            "Andrew Y. Ng"
        ],
        "title": "An Empirical Evaluation of Deep Learning on Highway Driving",
        "publication_date": "2015-04-07 19:41:59+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1504.01716v3",
            "http://arxiv.org/abs/1504.01716v3",
            "http://arxiv.org/pdf/1504.01716v3"
        ],
        "id": "id-8070762422738567145",
        "abstract": "Numerous groups have applied a variety of deep learning techniques to\ncomputer vision problems in highway perception scenarios. In this paper, we\npresented a number of empirical evaluations of recent deep learning advances.\nComputer vision, combined with deep learning, has the potential to bring about\na relatively inexpensive, robust solution to autonomous driving. To prepare\ndeep learning for industry uptake and practical applications, neural networks\nwill require large data sets that represent all possible driving environments\nand scenarios. We collect a large data set of highway data and apply deep\nlearning and computer vision algorithms to problems such as car and lane\ndetection. We show how existing convolutional neural networks (CNNs) can be\nused to perform lane and vehicle detection while running at frame rates\nrequired for a real-time system. Our results lend credence to the hypothesis\nthat deep learning holds promise for autonomous driving.",
        "versions": [],
        "rank": 219
    },
    {
        "authors": [
            "Parita Oza",
            "Paawan Sharma",
            "Samir Patel",
            "P. Kumar"
        ],
        "title": "Deep convolutional neural networks for computer-aided breast cancer diagnostic: a survey",
        "publication_date": "2022-01-11 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Neural Computing and Applications",
        "volume": "34",
        "doi": "10.1007/s00521-021-06804-y",
        "urls": [
            "https://www.semanticscholar.org/paper/a6dec82bac4fdd59892fd1397be20887682cf26f"
        ],
        "id": "id-1932363529635265053",
        "abstract": null,
        "versions": [],
        "rank": 220
    },
    {
        "authors": [
            "Julia Hornauer",
            "Vasileios Belagiannis"
        ],
        "title": "Heatmap-based Out-of-Distribution Detection",
        "publication_date": "2022-11-15 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20221116190046/https://arxiv.org/pdf/2211.08115v1.pdf"
        ],
        "id": "id-8151881511807868781",
        "abstract": "Our work investigates out-of-distribution (OOD) detection as a neural network output explanation problem. We learn a heatmap representation for detecting OOD images while visualizing in- and out-of-distribution image regions at the same time. Given a trained and fixed classifier, we train a decoder neural network to produce heatmaps with zero response for in-distribution samples and high response heatmaps for OOD samples, based on the classifier features and the class prediction. Our main innovation lies in the heatmap definition for an OOD sample, as the normalized difference from the closest in-distribution sample. The heatmap serves as a margin to distinguish between in- and out-of-distribution samples. Our approach generates the heatmaps not only for OOD detection, but also to indicate in- and out-of-distribution regions of the input image. In our evaluations, our approach mostly outperforms the prior work on fixed classifiers, trained on CIFAR-10, CIFAR-100 and Tiny ImageNet. The code is publicly available at: https://github.com/jhornauer/heatmap_ood.",
        "versions": [],
        "rank": 221
    },
    {
        "authors": [
            "David Krueger",
            "Irina Rish",
            "Kshitij Gupta",
            "Ethan Caballero"
        ],
        "title": "Broken Neural Scaling Laws",
        "publication_date": "2022-10-26 00:00:00",
        "source": "SupportedSources.PAPERS_WITH_CODE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://arxiv.org/pdf/2210.14891v10.pdf",
            "https://github.com/ethancaballero/broken_neural_scaling_laws"
        ],
        "id": "id6335216652431751466",
        "abstract": "We present a smoothly broken power law functional form (referred to by us as a Broken Neural Scaling Law (BNSL)) that accurately models and extrapolates the scaling behaviors of deep neural networks (i.e. how the evaluation metric of interest varies as the amount of compute used for training, number of model parameters, training dataset size, model input size, number of training steps, or upstream performance varies) for various architectures and for each of various tasks within a large and diverse set of upstream and downstream tasks, in zero-shot, prompted, and fine-tuned settings. This set includes large-scale vision, language, audio, video, diffusion, generative modeling, multimodal learning, contrastive learning, AI alignment, robotics, out-of-distribution (OOD) generalization, continual learning, transfer learning, uncertainty estimation / calibration, out-of-distribution detection, adversarial robustness, distillation, sparsity, retrieval, quantization, pruning, molecules, computer programming/coding, math word problems, \"emergent\" \"phase transitions / changes\", arithmetic, unsupervised/self-supervised learning, and reinforcement learning (single agent and multi-agent). When compared to other functional forms for neural scaling behavior, this functional form yields extrapolations of scaling behavior that are considerably more accurate on this set. Moreover, this functional form accurately models and extrapolates scaling behavior that other functional forms are incapable of expressing such as the non-monotonic transitions present in the scaling behavior of phenomena such as double descent and the delayed, sharp inflection points present in the scaling behavior of tasks such as arithmetic. Lastly, we use this functional form to glean insights about the limit of the predictability of scaling behavior. Code is available at https://github.com/ethancaballero/broken_neural_scaling_laws",
        "versions": [],
        "rank": 222
    },
    {
        "authors": [
            "Bewley, Alex",
            "Gurau, Corina",
            "Posner, Ingmar"
        ],
        "title": "Dropout Distillation for Efficiently Estimating Model Confidence",
        "publication_date": "2018-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "http://arxiv.org/abs/1809.10562"
        ],
        "id": "id-1623090588509064020",
        "abstract": "We propose an efficient way to output better calibrated uncertainty scores\nfrom neural networks. The Distilled Dropout Network (DDN) makes standard\n(non-Bayesian) neural networks more introspective by adding a new training loss\nwhich prevents them from being overconfident. Our method is more efficient than\nBayesian neural networks or model ensembles which, despite providing more\nreliable uncertainty scores, are more cumbersome to train and slower to test.\nWe evaluate DDN on the the task of image classification on the CIFAR-10 dataset\nand show that our calibration results are competitive even when compared to 100\nMonte Carlo samples from a dropout network while they also increase the\nclassification accuracy. We also propose better calibration within the state of\nthe art Faster R-CNN object detection framework and show, using the COCO\ndataset, that DDN helps train better calibrated object detectors",
        "versions": [],
        "rank": 223
    },
    {
        "authors": [
            "Archit Rathore",
            "Nithin Chalapathi",
            "Sourabh Palande",
            "Bei Wang"
        ],
        "title": "TopoAct: Visually Exploring the Shape of Activations in Deep Learning",
        "publication_date": "2019-12-13 06:15:08+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1912.06332v4",
            "http://arxiv.org/abs/1912.06332v4",
            "http://arxiv.org/pdf/1912.06332v4"
        ],
        "id": "id-6944748901490317068",
        "abstract": "Deep neural networks such as GoogLeNet, ResNet, and BERT have achieved\nimpressive performance in tasks such as image and text classification. To\nunderstand how such performance is achieved, we probe a trained deep neural\nnetwork by studying neuron activations, i.e., combinations of neuron firings,\nat various layers of the network in response to a particular input. With a\nlarge number of inputs, we aim to obtain a global view of what neurons detect\nby studying their activations. In particular, we develop visualizations that\nshow the shape of the activation space, the organizational principle behind\nneuron activations, and the relationships of these activations within a layer.\nApplying tools from topological data analysis, we present TopoAct, a visual\nexploration system to study topological summaries of activation vectors. We\npresent exploration scenarios using TopoAct that provide valuable insights into\nlearned representations of neural networks. We expect TopoAct to give a\ntopological perspective that enriches the current toolbox of neural network\nanalysis, and to provide a basis for network architecture diagnosis and data\nanomaly detection.",
        "versions": [],
        "rank": 224
    },
    {
        "authors": [
            "Jakob Gawlikowski",
            "Cedrique Rovile Njieutcheu Tassi",
            "Mohsin Ali",
            "Jongseok Lee",
            "Matthias Humt",
            "Jianxiang Feng",
            "Anna Kruspe",
            "Rudolph Triebel",
            "Peter Jung",
            "Ribana Roscher",
            "Muhammad Shahzad",
            "Wen Yang",
            "Richard Bamler",
            "Xiao Xiang Zhu"
        ],
        "title": "A Survey of Uncertainty in Deep Neural Networks",
        "publication_date": "2022-01-18 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20220127192259/https://arxiv.org/pdf/2107.03342v3.pdf"
        ],
        "id": "id-3114546417274851200",
        "abstract": "Due to their increasing spread, confidence in neural network predictions became more and more important. However, basic neural networks do not deliver certainty estimates or suffer from over or under confidence. Many researchers have been working on understanding and quantifying uncertainty in a neural network's prediction. As a result, different types and sources of uncertainty have been identified and a variety of approaches to measure and quantify uncertainty in neural networks have been proposed. This work gives a comprehensive overview of uncertainty estimation in neural networks, reviews recent advances in the field, highlights current challenges, and identifies potential research opportunities. It is intended to give anyone interested in uncertainty estimation in neural networks a broad overview and introduction, without presupposing prior knowledge in this field. A comprehensive introduction to the most crucial sources of uncertainty is given and their separation into reducible model uncertainty and not reducible data uncertainty is presented. The modeling of these uncertainties based on deterministic neural networks, Bayesian neural networks, ensemble of neural networks, and test-time data augmentation approaches is introduced and different branches of these fields as well as the latest developments are discussed. For a practical application, we discuss different measures of uncertainty, approaches for the calibration of neural networks and give an overview of existing baselines and implementations. Different examples from the wide spectrum of challenges in different fields give an idea of the needs and challenges regarding uncertainties in practical applications. Additionally, the practical limitations of current methods for mission- and safety-critical real world applications are discussed and an outlook on the next steps towards a broader usage of such methods is given.",
        "versions": [],
        "rank": 225
    },
    {
        "authors": [
            "Alzantot, M.",
            "Wang, Z.",
            "Srivastava, M."
        ],
        "title": "Deep Residual Neural Networks for Audio Spoofing Detection",
        "publication_date": "2019-09-15 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.21437/interspeech.2019-3174",
        "urls": [
            "http://dx.doi.org/10.21437/interspeech.2019-3174"
        ],
        "id": "id-9178228780050894469",
        "abstract": "",
        "versions": [],
        "rank": 226
    },
    {
        "authors": [
            "William Marfo",
            "Deepak K. Tosh",
            "Shirley V. Moore"
        ],
        "title": "Network Anomaly Detection Using Federated Learning",
        "publication_date": "2023-03-13 20:16:30+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2303.07452v1",
            "http://arxiv.org/abs/2303.07452v1",
            "http://arxiv.org/pdf/2303.07452v1"
        ],
        "id": "id1119244684836878235",
        "abstract": "Due to the veracity and heterogeneity in network traffic, detecting anomalous\nevents is challenging. The computational load on global servers is a\nsignificant challenge in terms of efficiency, accuracy, and scalability. Our\nprimary motivation is to introduce a robust and scalable framework that enables\nefficient network anomaly detection. We address the issue of scalability and\nefficiency for network anomaly detection by leveraging federated learning, in\nwhich multiple participants train a global model jointly. Unlike centralized\ntraining architectures, federated learning does not require participants to\nupload their training data to the server, preventing attackers from exploiting\nthe training data. Moreover, most prior works have focused on traditional\ncentralized machine learning, making federated machine learning under-explored\nin network anomaly detection. Therefore, we propose a deep neural network\nframework that could work on low to mid-end devices detecting network anomalies\nwhile checking if a request from a specific IP address is malicious or not.\nCompared to multiple traditional centralized machine learning models, the deep\nneural federated model reduces training time overhead. The proposed method\nperforms better than baseline machine learning techniques on the UNSW-NB15 data\nset as measured by experiments conducted with an accuracy of 97.21% and a\nfaster computation time.",
        "versions": [],
        "rank": 227
    },
    {
        "authors": [
            "Ricci, Elisa",
            "Sebe, Nicu",
            "Song, Jingkuan",
            "Xu, Dan",
            "Yan, Yan"
        ],
        "title": "Learning Deep Representations of Appearance and Motion for Anomalous  Event Detection",
        "publication_date": "2015-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.5244/c.29.8",
        "urls": [
            "http://arxiv.org/abs/1510.01553"
        ],
        "id": "id-2117658165552594229",
        "abstract": "We present a novel unsupervised deep learning framework for anomalous event\ndetection in complex video scenes. While most existing works merely use\nhand-crafted appearance and motion features, we propose Appearance and Motion\nDeepNet (AMDN) which utilizes deep neural networks to automatically learn\nfeature representations. To exploit the complementary information of both\nappearance and motion patterns, we introduce a novel double fusion framework,\ncombining both the benefits of traditional early fusion and late fusion\nstrategies. Specifically, stacked denoising autoencoders are proposed to\nseparately learn both appearance and motion features as well as a joint\nrepresentation (early fusion). Based on the learned representations, multiple\none-class SVM models are used to predict the anomaly scores of each input,\nwhich are then integrated with a late fusion strategy for final anomaly\ndetection. We evaluate the proposed method on two publicly available video\nsurveillance datasets, showing competitive performance with respect to state of\nthe art approaches.Comment: Oral paper in BMVC 201",
        "versions": [],
        "rank": 228
    },
    {
        "authors": [
            "Max Landauer",
            "Sebastian Onder",
            "Florian Skopik",
            "Markus Wurzenberger"
        ],
        "title": "Deep Learning for Anomaly Detection in Log Data: A Survey",
        "publication_date": "2022-07-08 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20220711035352/https://arxiv.org/pdf/2207.03820v1.pdf"
        ],
        "id": "id-5345735397867563686",
        "abstract": "Automatic log file analysis enables early detection of relevant incidents such as system failures. In particular, self-learning anomaly detection techniques capture patterns in log data and subsequently report unexpected log event occurrences to system operators without the need to provide or manually model anomalous scenarios in advance. Recently, an increasing number of approaches leveraging deep learning neural networks for this purpose have been presented. These approaches have demonstrated superior detection performance in comparison to conventional machine learning techniques and simultaneously resolve issues with unstable data formats. However, there exist many different architectures for deep learning and it is non-trivial to encode raw and unstructured log data to be analyzed by neural networks. We therefore carry out a systematic literature review that provides an overview of deployed models, data pre-processing mechanisms, anomaly detection techniques, and evaluations. The survey does not quantitatively compare existing approaches but instead aims to help readers understand relevant aspects of different model architectures and emphasizes open issues for future work.",
        "versions": [],
        "rank": 229
    },
    {
        "authors": [
            "Fedyanin, Kirill",
            "Panov, Maxim",
            "Tsymbalov, Evgenii"
        ],
        "title": "Dropout Strikes Back: Improved Uncertainty Estimation via Diversity  Sampling",
        "publication_date": "2020-06-26 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "http://arxiv.org/abs/2003.03274"
        ],
        "id": "id-7207702906714712230",
        "abstract": "Uncertainty estimation for machine learning models is of high importance in\nmany scenarios such as constructing the confidence intervals for model\npredictions and detection of out-of-distribution or adversarially generated\npoints. In this work, we show that modifying the sampling distributions for\ndropout layers in neural networks improves the quality of uncertainty\nestimation. Our main idea consists of two main steps: computing data-driven\ncorrelations between neurons and generating samples, which include maximally\ndiverse neurons. In a series of experiments on simulated and real-world data,\nwe demonstrate that the diversification via determinantal point processes-based\nsampling achieves state-of-the-art results in uncertainty estimation for\nregression and classification tasks. An important feature of our approach is\nthat it does not require any modification to the models or training procedures,\nallowing straightforward application to any deep learning model with dropout\nlayers",
        "versions": [],
        "rank": 230
    },
    {
        "authors": [
            "Nazarii Lutsiv",
            "Taras Maksymyuk",
            "Mykola Beshley",
            "Orest Lavriv",
            "Volodymyr Andrushchak",
            "Anatoliy Sachenko",
            "Liberios Vokorokos",
            "Juraj Gazda"
        ],
        "title": "Deep Semisupervised Learning-Based Network Anomaly Detection in Heterogeneous Information Systems",
        "publication_date": "2022-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Computers, Materials and Continua (Tech Science Press)",
        "volume": "",
        "doi": "10.32604/cmc.2022.018773",
        "urls": [
            "https://web.archive.org/web/20220225182616/https://www.techscience.com/ueditor/files/cmc/TSP_CMC_70-1/TSP_CMC_18773/TSP_CMC_18773.pdf"
        ],
        "id": "id-1974188092929909074",
        "abstract": "The extensive proliferation of modern information services and ubiquitous digitization of society have raised cybersecurity challenges to new levels. With the massive number of connected devices, opportunities for potential network attacks are nearly unlimited. An additional problem is that many low-cost devices are not equipped with effective security protection so that they are easily hacked and applied within a network of bots (botnet) to perform distributed denial of service (DDoS) attacks. In this paper, we propose a novel intrusion detection system (IDS) based on deep learning that aims to identify suspicious behavior in modern heterogeneous information systems. The proposed approach is based on a deep recurrent autoencoder that learns time series of normal network behavior and detects notable network anomalies. An additional feature of the proposed IDS is that it is trained with an optimized dataset, where the number of features is reduced by 94% without classification accuracy loss. Thus, the proposed IDS remains stable in response to slight system perturbations, which do not represent network anomalies. The proposed approach is evaluated under different simulation scenarios and provides a 99% detection accuracy over known datasets while reducing the training time by an order of magnitude.",
        "versions": [],
        "rank": 231
    },
    {
        "authors": [
            "Qiuyu Zhu",
            "Guohui Zheng",
            "Yingying Yan"
        ],
        "title": "Effective Out-of-Distribution Detection in Classifier Based on PEDCC-Loss",
        "publication_date": "2022-04-10 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20220622025444/https://arxiv.org/ftp/arxiv/papers/2204/2204.04665.pdf"
        ],
        "id": "id-408557831799266937",
        "abstract": "Deep neural networks suffer from the overconfidence issue in the open world, meaning that classifiers could yield confident, incorrect predictions for out-of-distribution (OOD) samples. Thus, it is an urgent and challenging task to detect these samples drawn far away from training distribution based on the security considerations of artificial intelligence. Many current methods based on neural networks mainly rely on complex processing strategies, such as temperature scaling and input preprocessing, to obtain satisfactory results. In this paper, we propose an effective algorithm for detecting out-of-distribution examples utilizing PEDCC-Loss. We mathematically analyze the nature of the confidence score output by the PEDCC (Predefined Evenly-Distribution Class Centroids) classifier, and then construct a more effective scoring function to distinguish in-distribution (ID) and out-of-distribution. In this method, there is no need to preprocess the input samples and the computational burden of the algorithm is reduced. Experiments demonstrate that our method can achieve better OOD detection performance.",
        "versions": [],
        "rank": 232
    },
    {
        "authors": [
            "Lyu, S.",
            "Wang, L.",
            "Zhou, Z."
        ],
        "title": "Improving generalization of deep neural networks by leveraging margin distribution",
        "publication_date": "2022-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1016/j.neunet.2022.03.019",
        "urls": [
            "https://api.elsevier.com/content/article/PII:S0893608022000971?httpAccept=text/xml",
            "https://api.elsevier.com/content/article/PII:S0893608022000971?httpAccept=text/plain",
            "http://dx.doi.org/10.1016/j.neunet.2022.03.019"
        ],
        "id": "id1732671784761875610",
        "abstract": "",
        "versions": [],
        "rank": 233
    },
    {
        "authors": [
            "Wenchi Ma",
            "Yuanwei Wu",
            "Zongbo Wang",
            "Guanghui Wang"
        ],
        "title": "MDCN: Multi-Scale, Deep Inception Convolutional Neural Networks for Efficient Object Detection",
        "publication_date": "2018-09-06 02:24:44+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": "IEEE ICPR2018",
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1809.01791v1",
            "http://arxiv.org/abs/1809.01791v1",
            "http://arxiv.org/pdf/1809.01791v1"
        ],
        "id": "id8460418502075860248",
        "abstract": "Object detection in challenging situations such as scale variation,\nocclusion, and truncation depends not only on feature details but also on\ncontextual information. Most previous networks emphasize too much on detailed\nfeature extraction through deeper and wider networks, which may enhance the\naccuracy of object detection to certain extent. However, the feature details\nare easily being changed or washed out after passing through complicated\nfiltering structures. To better handle these challenges, the paper proposes a\nnovel framework, multi-scale, deep inception convolutional neural network\n(MDCN), which focuses on wider and broader object regions by activating feature\nmaps produced in the deep part of the network. Instead of incepting inner\nlayers in the shallow part of the network, multi-scale inceptions are\nintroduced in the deep layers. The proposed framework integrates the contextual\ninformation into the learning process through a single-shot network structure.\nIt is computational efficient and avoids the hard training problem of previous\nmacro feature extraction network designed for shallow layers. Extensive\nexperiments demonstrate the effectiveness and superior performance of MDCN over\nthe state-of-the-art models.",
        "versions": [],
        "rank": 234
    },
    {
        "authors": [
            "Anais M\u00f6ller",
            "T. de Boissi\u00e8re"
        ],
        "title": "SuperNNova: an open-source framework for Bayesian, neural network-based supernova classification",
        "publication_date": "2020-01-21 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Monthly Notices of the Royal Astronomical Society",
        "volume": "491",
        "doi": "10.1093/mnras/stz3312",
        "urls": [
            "https://openalex.org/W2913871063",
            "https://doi.org/10.1093/mnras/stz3312",
            "http://arxiv.org/pdf/1901.06384"
        ],
        "id": "id8231792232912083213",
        "abstract": "",
        "versions": [],
        "rank": 235
    },
    {
        "authors": [
            "Tuan A. Tang",
            "D. McLernon",
            "L. Mhamdi",
            "Syed Ali Raza Zaidi",
            "M. Ghogho"
        ],
        "title": "Intrusion Detection in SDN-Based Networks: Deep Recurrent Neural Network Approach",
        "publication_date": "2019-08-15 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-3-030-13057-2_8",
        "urls": [
            "https://www.semanticscholar.org/paper/7ec8087f5a5cef658844fbbf50d696eacdab215a"
        ],
        "id": "id-6221236707786361119",
        "abstract": null,
        "versions": [],
        "rank": 236
    },
    {
        "authors": [
            "Baozhi Jia",
            "Weiguo Feng",
            "M. Zhu"
        ],
        "title": "Obstacle detection in single images with deep neural networks",
        "publication_date": "2016-09-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Signal, Image and Video Processing",
        "volume": "10",
        "doi": "10.1007/s11760-015-0855-4",
        "urls": [
            "https://www.semanticscholar.org/paper/82a7f64280cbb3c90570b2aff0c52ce9161bd942"
        ],
        "id": "id402977815136191637",
        "abstract": null,
        "versions": [],
        "rank": 237
    },
    {
        "authors": [
            "Zhaowei Cai",
            "Nuno Vasconcelos"
        ],
        "title": "Cascade R-CNN: Delving Into High Quality Object Detection",
        "publication_date": "2018-06-18 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "arXiv (Cornell University)",
        "volume": "",
        "doi": "10.1109/cvpr.2018.00644",
        "urls": [
            "https://openalex.org/W2964241181",
            "https://doi.org/10.1109/cvpr.2018.00644",
            "http://arxiv.org/pdf/1712.00726"
        ],
        "id": "id7124391458667712278",
        "abstract": "",
        "versions": [],
        "rank": 238
    },
    {
        "authors": [
            "A Zimek",
            "CC Chang",
            "D Baehrens",
            "DM Tax",
            "EJ Cand\u00e8s",
            "FE Grubbs",
            "G Montavon",
            "J Kim",
            "JJ Hull",
            "R Chalapathy",
            "S Shalev-Shwartz",
            "SM Erfani",
            "T Schlegl",
            "V Barnett",
            "V Chandola",
            "Y Bengio"
        ],
        "title": "Scalable and Interpretable One-class SVMs with Deep Learning and Random  Fourier features",
        "publication_date": "2018-10-14 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-3-030-10925-7_10",
        "urls": [
            "http://arxiv.org/abs/1804.04888"
        ],
        "id": "id8281476225932389864",
        "abstract": "One-class support vector machine (OC-SVM) for a long time has been one of the\nmost effective anomaly detection methods and extensively adopted in both\nresearch as well as industrial applications. The biggest issue for OC-SVM is\nyet the capability to operate with large and high-dimensional datasets due to\noptimization complexity. Those problems might be mitigated via dimensionality\nreduction techniques such as manifold learning or autoencoder. However,\nprevious work often treats representation learning and anomaly prediction\nseparately. In this paper, we propose autoencoder based one-class support\nvector machine (AE-1SVM) that brings OC-SVM, with the aid of random Fourier\nfeatures to approximate the radial basis kernel, into deep learning context by\ncombining it with a representation learning architecture and jointly exploit\nstochastic gradient descent to obtain end-to-end training. Interestingly, this\nalso opens up the possible use of gradient-based attribution methods to explain\nthe decision making for anomaly detection, which has ever been challenging as a\nresult of the implicit mappings between the input space and the kernel space.\nTo the best of our knowledge, this is the first work to study the\ninterpretability of deep learning in anomaly detection. We evaluate our method\non a wide range of unsupervised anomaly detection tasks in which our end-to-end\ntraining architecture achieves a performance significantly better than the\nprevious work using separate training.Comment: Accepted at European Conference on Machine Learning and Principles\n  and Practice of Knowledge Discovery in Databases (ECML-PKDD) 201",
        "versions": [],
        "rank": 239
    },
    {
        "authors": [
            "Gong Cheng",
            "Peicheng Zhou",
            "Junwei Han"
        ],
        "title": "Learning Rotation-Invariant Convolutional Neural Networks for Object Detection in VHR Optical Remote Sensing Images",
        "publication_date": "2016-09-05 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "IEEE Transactions on Geoscience and Remote Sensing",
        "volume": "54",
        "doi": "10.1109/tgrs.2016.2601622",
        "urls": [
            "https://openalex.org/W2512351403",
            "https://doi.org/10.1109/tgrs.2016.2601622"
        ],
        "id": "id5236627027991226857",
        "abstract": "",
        "versions": [],
        "rank": 240
    },
    {
        "authors": [
            "A. Ansari",
            "P. Cherian",
            "A. Caicedo",
            "G. Naulaers",
            "M. Vos",
            "S. Huffel"
        ],
        "title": "Neonatal Seizure Detection Using Deep Convolutional Neural Networks",
        "publication_date": "2019-05-15 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "International journal of neural systems",
        "volume": "29 4",
        "doi": "10.1142/s0129065718500119",
        "urls": [
            "https://www.semanticscholar.org/paper/c4d64331751231b2b40a8702239f7a735648dbdc"
        ],
        "id": "id8157604056011164981",
        "abstract": "Identifying a core set of features is one of the most important steps in the development of an automated seizure detector. In most of the published studies describing features and seizure classifiers, the features were hand-engineered, which may not be optimal. The main goal of the present paper is using deep convolutional neural networks (CNNs) and random forest to automatically optimize feature selection and classification. The input of the proposed classifier is raw multi-channel EEG and the output is the class label: seizure/nonseizure. By training this network, the required features are optimized, while fitting a nonlinear classifier on the features. After training the network with EEG recordings of 26 neonates, five end layers performing the classification were replaced with a random forest classifier in order to improve the performance. This resulted in a false alarm rate of 0.9 per hour and seizure detection rate of 77% using a test set of EEG recordings of 22 neonates that also included dubious seizures. The newly proposed CNN classifier outperformed three data-driven feature-based approaches and performed similar to a previously developed heuristic method.",
        "versions": [],
        "rank": 241
    },
    {
        "authors": [
            "Shisrut Rawat",
            "Aishwarya Srinivasan",
            "Vinayakumar R"
        ],
        "title": "Intrusion detection systems using classical machine learning techniques versus integrated unsupervised feature learning and deep neural network",
        "publication_date": "2019-10-01 23:48:20+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1910.01114v1",
            "http://arxiv.org/abs/1910.01114v1",
            "http://arxiv.org/pdf/1910.01114v1"
        ],
        "id": "id-7085766525332762175",
        "abstract": "Security analysts and administrators face a lot of challenges to detect and\nprevent network intrusions in their organizations, and to prevent network\nbreaches, detecting the breach on time is crucial. Challenges arise while\ndetecting unforeseen attacks. This work includes a performance comparison of\nclassical machine learning approaches that require vast feature engineering,\nversus integrated unsupervised feature learning and deep neural networks on the\nNSL-KDD dataset. Various trials of experiments were run to identify suitable\nhyper-parameters and network configurations of machine learning models. The DNN\nusing 15 features extracted using Principal Component analysis was the most\neffective modeling method. The further analysis using the Software Defined\nNetworking features also presented a good accuracy using Deep Neural network.",
        "versions": [],
        "rank": 242
    },
    {
        "authors": [
            "V. Navya",
            "J. Adithi",
            "Diksha Rudrawal",
            "Harshita Tailor",
            "Nileena James"
        ],
        "title": "Intrusion Detection System using Deep Neural Networks (DNN)",
        "publication_date": "2021-10-08 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ICAECA52838.2021.9675513",
        "urls": [
            "https://www.semanticscholar.org/paper/344a3692afd8d8ddf2c4ee1d7c21835cd3dde512"
        ],
        "id": "id1478092734186278209",
        "abstract": "Intrusions are quite a frequent scare especially with the exponential growth in improvement of technology. This project aims to detect such intrusions using certain algorithms in the domain of machine learning. Machine learning techniques are being widely used to develop an intrusion detection system (IDS) for detecting and classifying cyberattacks at the network-level and the host-level in a timely and automatic manner. Since there are many different types of intrusions happening on a large scale dynamically, this can be quite challenging. However, with the help of datasets and with constant updating, one can detect such intrusions. The one algorithm that stands out is the DNN (Deep Neural Network), which is a type of deep learning model, which helps to develop a flexible and effective Intrusion Detection System (IDS) to detect and classify unforeseen and unpredictable cyberattacks.",
        "versions": [],
        "rank": 243
    },
    {
        "authors": [
            "Ce Li",
            "Baochang Zhang",
            "Hanwen Hu",
            "Jing Dai"
        ],
        "title": "Enhanced Bird Detection from Low-Resolution Aerial Image Using Deep Neural Networks",
        "publication_date": "2018-06-18 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Neural Processing Letters",
        "volume": "49",
        "doi": "10.1007/s11063-018-9871-z",
        "urls": [
            "https://www.semanticscholar.org/paper/52ecbf77e82bcd2f3b93be30678ae152a79681ae"
        ],
        "id": "id-687370889033855312",
        "abstract": null,
        "versions": [],
        "rank": 244
    },
    {
        "authors": [
            "Hota, A.",
            "Irolla, P."
        ],
        "title": "Deep Neural Networks for Android Malware Detection",
        "publication_date": "2019-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.5220/0007617606570663",
        "urls": [
            "http://dx.doi.org/10.5220/0007617606570663"
        ],
        "id": "id1481666463129418682",
        "abstract": "",
        "versions": [],
        "rank": 245
    },
    {
        "authors": [
            "Bouslimi, Y.",
            "Gader, T.",
            "Echi, A."
        ],
        "title": "Prostate Cancer Detection, Segmentation, and Classification using Deep Neural Networks",
        "publication_date": "2023-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.5220/0011795100003411",
        "urls": [
            "http://dx.doi.org/10.5220/0011795100003411"
        ],
        "id": "id2441353353451705384",
        "abstract": "",
        "versions": [],
        "rank": 246
    },
    {
        "authors": [
            "Michelucci, U."
        ],
        "title": "Object Classification: An Introduction",
        "publication_date": "2019-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-1-4842-4976-5_6",
        "urls": [
            "http://link.springer.com/content/pdf/10.1007/978-1-4842-4976-5_6",
            "http://dx.doi.org/10.1007/978-1-4842-4976-5_6"
        ],
        "id": "id2695169304681112064",
        "abstract": "",
        "versions": [],
        "rank": 247
    },
    {
        "authors": [
            "Adrian Schwaiger",
            "Poulami Sinhamahapatra",
            "Jens Gansloser",
            "Karsten Roscher"
        ],
        "title": "Is Uncertainty Quantification in Deep Learning Sufficient for Out-of-Distribution Detection?",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20210616035322/http://ceur-ws.org/Vol-2640/paper_18.pdf"
        ],
        "id": "id-8865225109483562780",
        "abstract": "Reliable information about the uncertainty of predictions from deep neural networks could greatly facilitate their utilization in safety-critical applications. Current approaches for uncertainty quantification usually focus on in-distribution data, where a high uncertainty should be assigned to incorrect predictions. In contrast, we focus on out-ofdistribution data where a network cannot make correct predictions and therefore should always report high uncertainty. In this paper, we compare several state-of-the-art uncertainty quantification methods for deep neural networks regarding their ability to detect novel inputs. We evaluate them on image classification tasks with regard to metrics reflecting requirements important for safety-critical applications. Our results show that a portion of out-ofdistribution inputs can be detected with reasonable loss in overall accuracy. However, current uncertainty quantification approaches alone are not sufficient for an overall reliable out-of-distribution detection.",
        "versions": [],
        "rank": 248
    },
    {
        "authors": [
            "Mingjian Lei",
            "Xiaoyong Li",
            "Binsi Cai",
            "Yunfeng Li",
            "Limengwei Liu",
            "Wenping Kong"
        ],
        "title": "P-DNN: An Effective Intrusion Detection Method based on Pruning Deep Neural Network",
        "publication_date": "2020-07-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/IJCNN48605.2020.9206805",
        "urls": [
            "https://www.semanticscholar.org/paper/045f094c20c9ffa3998bbfe60034adfcbb9724a2"
        ],
        "id": "id6724625731975837861",
        "abstract": "Today, the scale of global Internet users continues to grow; the Internet has become the main driver of global economic growth; IoT technology is also constantly pushing the process of the Internet of Everything. However, the ever-changing cybersecurity situation is not optimistic and the people\u2019s demand for secure network is also increasing. In this paper, for the biggest challenge of building anomaly-based Network Intrusion Detection System: building a high-performance intrusion detection classifier model, we first propose an effective intrusion detection method based on pruning deep neural network: P-DNN. Firstly, we train a deep neural network with complex structure and good intrusion detection performance. Secondly, through the pruning operation, only the connections with more important information in the weight are reserved, reducing the complexity of the model. Finally, retrain the deep neural network to find the best model. We use the KDD Cup 99 dataset to evaluate the effectiveness of the method and achieve exciting results. The model constructed by P-DNN achieves a detection rate of 0.9904 for known attacks and a detection rate of 0.1050 for unknown attacks. By comparing with related work, the model achieves the best intrusion detection performance: COST is reduced to 0.1875 and ACC is increased to 0.9317.",
        "versions": [],
        "rank": 249
    },
    {
        "authors": [
            "Li, K.",
            "Meng, H."
        ],
        "title": "Mispronunciation detection and diagnosis in l2 english speech using multi-distribution Deep Neural Networks",
        "publication_date": "2014-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/iscslp.2014.6936724",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/6924027/6936571/06936724.pdf?arnumber=6936724",
            "http://dx.doi.org/10.1109/iscslp.2014.6936724"
        ],
        "id": "id1454254960278005895",
        "abstract": "",
        "versions": [],
        "rank": 250
    },
    {
        "authors": [
            "Ksibi, A.",
            "Zakariah, M.",
            "Almuqren, L.",
            "Alluhaidan, A."
        ],
        "title": "Deep Convolution Neural Networks and Image Processing for Malware Detection",
        "publication_date": "2023-01-27 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.21203/rs.3.rs-2508967/v1",
        "urls": [
            "https://www.researchsquare.com/article/rs-2508967/v1",
            "https://www.researchsquare.com/article/rs-2508967/v1.html",
            "http://dx.doi.org/10.21203/rs.3.rs-2508967/v1"
        ],
        "id": "id215619781274851006",
        "abstract": "",
        "versions": [],
        "rank": 251
    },
    {
        "authors": [
            "Jose Juan Almagro Armenteros",
            "Konstantinos D. Tsirigos",
            "Casper Kaae S\u00f8nderby",
            "Thomas S\u00f8birk Petersen",
            "Ole Winther",
            "S\u00f8ren Brunak",
            "Gunnar von Heijne",
            "Henrik Nielsen"
        ],
        "title": "SignalP 5.0 improves signal peptide predictions using deep neural networks",
        "publication_date": "2019-02-18 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Nature Biotechnology",
        "volume": "37",
        "doi": "10.1038/s41587-019-0036-z",
        "urls": [
            "https://openalex.org/W2912990441",
            "https://doi.org/10.1038/s41587-019-0036-z",
            "https://curis.ku.dk/ws/files/248820641/SignalP_5.0_improves_signal_peptide_predictions_using_deep_neural_networks_accepted_version_.pdf"
        ],
        "id": "id-8405884503345726517",
        "abstract": "",
        "versions": [
            {
                "year": 2019,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "SignalP 5.0 improves signal peptide predictions using deep neural networks",
                "journal": "Nature Biotechnology",
                "urls": [
                    "https://www.semanticscholar.org/paper/74261ae216e457a2d2635d06f0425db4a4ce1b1f"
                ],
                "doi": "10.1038/s41587-019-0036-z",
                "publication_date": "2019-02-18 00:00:00"
            }
        ],
        "rank": 252
    },
    {
        "authors": [
            "Chen Sun",
            "Abhinav Shrivastava",
            "Saurabh Singh",
            "Abhinav Gupta"
        ],
        "title": "Revisiting Unreasonable Effectiveness of Data in Deep Learning Era",
        "publication_date": "2017-07-10 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "International Conference on Computer Vision",
        "volume": "",
        "doi": "10.1109/iccv.2017.97",
        "urls": [
            "https://openalex.org/W2962843773",
            "https://doi.org/10.1109/iccv.2017.97",
            "http://arxiv.org/pdf/1707.02968"
        ],
        "id": "id-4957085128134256922",
        "abstract": "",
        "versions": [],
        "rank": 253
    },
    {
        "authors": [
            "Md. Ariful Haque",
            "Dr. Rajesh Palit"
        ],
        "title": "A review on Deep Neural Network for Computer Network Traffic Classification",
        "publication_date": "2022-05-22 14:05:34+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2205.10830v1",
            "http://arxiv.org/abs/2205.10830v1",
            "http://arxiv.org/pdf/2205.10830v1"
        ],
        "id": "id1703666137960512855",
        "abstract": "Focus on Deep Neural Network based malicious and normal computer Network\nTraffic classification. (such as attacks, phishing, any other illegal activity\nand normal traffic identification). In this paper, the main idea is to review,\nexisted Neural Network based network traffic classification. Which indicates\nintrusion activity classification and detection. It is very important to\nclassify network traffic to safeguard any system, connected to computer\nnetwork. There are a variety of NN architecture for it, with different rate of\naccuracy. On this paper we will do relative compression among them. Index\nTerms-Computer Network, Network traffic, Packet, Intrusion, DOS\n(Denial-of-service), unauthorized access, IDS (Intrusion Detection System), IPS\n(Intrusion Prevention Systems), R2L (Remote to Local Attack), Probing, U2R\n(User to Root Attack), DNN (Deep Neural Network), CRNN (Convolutional Recurrent\nNeural Network), RPROP (Resilient propagation).",
        "versions": [],
        "rank": 254
    },
    {
        "authors": [
            "Faramarzi, M."
        ],
        "title": "Road Damage Detection and Classification Using Deep Neural Networks (YOLOv4) with Smartphone Images",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.2139/ssrn.3627382",
        "urls": [
            "http://dx.doi.org/10.2139/ssrn.3627382"
        ],
        "id": "id7572351669801396013",
        "abstract": "",
        "versions": [],
        "rank": 255
    },
    {
        "authors": [
            "Gianni Franchi",
            "Andrei Bursuc",
            "Jean-Marc Martinez",
            "Geoffrey Daniel",
            "Enzo Tartaglione",
            "Adrien Lafage",
            "Olivier Laurent"
        ],
        "title": "Packed-Ensembles for Efficient Uncertainty Estimation",
        "publication_date": "2022-10-17 00:00:00",
        "source": "SupportedSources.PAPERS_WITH_CODE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://arxiv.org/pdf/2210.09184v2.pdf",
            "https://github.com/ensta-u2is/torch-uncertainty"
        ],
        "id": "id1029537768754444380",
        "abstract": "Deep Ensembles (DE) are a prominent approach for achieving excellent performance on key metrics such as accuracy, calibration, uncertainty estimation, and out-of-distribution detection. However, hardware limitations of real-world systems constrain to smaller ensembles and lower-capacity networks, significantly deteriorating their performance and properties. We introduce Packed-Ensembles (PE), a strategy to design and train lightweight structured ensembles by carefully modulating the dimension of their encoding space. We leverage grouped convolutions to parallelize the ensemble into a single shared backbone and forward pass to improve training and inference speeds. PE is designed to operate within the memory limits of a standard neural network. Our extensive research indicates that PE accurately preserves the properties of DE, such as diversity, and performs equally well in terms of accuracy, calibration, out-of-distribution detection, and robustness to distribution shift. We make our code available at https://github.com/ENSTA-U2IS/torch-uncertainty.",
        "versions": [],
        "rank": 256
    },
    {
        "authors": [
            "Marsola, T.",
            "Lorena, A."
        ],
        "title": "METEOR DETECTION USING DEEP CONVOLUTIONAL NEURAL NETWORKS",
        "publication_date": "2019-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.17648/sbai-2019-112456",
        "urls": [
            "http://dx.doi.org/10.17648/sbai-2019-112456"
        ],
        "id": "id6953153864791067519",
        "abstract": "",
        "versions": [],
        "rank": 257
    },
    {
        "authors": [
            "Tapia, N.",
            "Estevez, P."
        ],
        "title": "RED: Deep Recurrent Neural Networks for Sleep EEG Event Detection",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ijcnn48605.2020.9207719",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/9200848/9206590/09207719.pdf?arnumber=9207719",
            "http://dx.doi.org/10.1109/ijcnn48605.2020.9207719"
        ],
        "id": "id8381294665250492627",
        "abstract": "",
        "versions": [],
        "rank": 258
    },
    {
        "authors": [
            "Nicolas Coudray",
            "Paolo S. Ocampo",
            "Theodore Sakellaropoulos",
            "Navneet Narula",
            "Matija Snuderl",
            "David Feny\u00f6",
            "Andre L. Moreira",
            "Narges Razavian",
            "Aristotelis Tsirigos"
        ],
        "title": "Classification and mutation prediction from non\u2013small cell lung cancer histopathology images using deep learning",
        "publication_date": "2018-09-17 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Nature Medicine",
        "volume": "24",
        "doi": "10.1038/s41591-018-0177-5",
        "urls": [
            "https://openalex.org/W2760946358",
            "https://doi.org/10.1038/s41591-018-0177-5",
            "https://www.biorxiv.org/content/biorxiv/early/2017/10/03/197574.full.pdf"
        ],
        "id": "id6174813677694000789",
        "abstract": "",
        "versions": [],
        "rank": 259
    },
    {
        "authors": [
            "Darshit Doshi",
            "Aniket Shenoy",
            "Deep Sidhpura",
            "P. Gharpure"
        ],
        "title": "Diabetic retinopathy detection using deep convolutional neural networks",
        "publication_date": "2016-12-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/CAST.2016.7914977",
        "urls": [
            "https://www.semanticscholar.org/paper/938a7a3308b6eb901c2d2b3231ce0c66f9b723f3"
        ],
        "id": "id-4434264230410249268",
        "abstract": "Diabetic retinopathy is when damage occurs to the retina due to diabetes, which affects up to 80 percent of all patients who have had diabetes for 10 years or more. The expertise and equipment required are often lacking in areas where diabetic retinopathy detection is most needed. Most of the work in the field of diabetic retinopathy has been based on disease detection or manual extraction of features, but this paper aims at automatic diagnosis of the disease into its different stages using deep learning. This paper presents the design and implementation of GPU accelerated deep convolutional neural networks to automatically diagnose and thereby classify high-resolution retinal images into 5 stages of the disease based on severity. The single model accuracy of the convolutional neural networks presented in this paper is 0.386 on a quadratic weighted kappa metric and ensembling of three such similar models resulted in a score of 0.3996.",
        "versions": [
            {
                "year": 2016,
                "source": "SupportedSources.CROSSREF",
                "title": "Diabetic retinopathy detection using deep convolutional neural networks",
                "journal": "",
                "urls": [
                    "http://xplorestaging.ieee.org/ielx7/7910140/7914929/07914977.pdf?arnumber=7914977",
                    "http://dx.doi.org/10.1109/cast.2016.7914977"
                ],
                "doi": "10.1109/cast.2016.7914977",
                "publication_date": "2016-01-01 00:00:00"
            }
        ],
        "rank": 260
    },
    {
        "authors": [
            "Francisco J. Varela",
            "Jean-Philippe Lachaux",
            "Eugenio Rodriguez",
            "Jacques Martinerie"
        ],
        "title": "The brainweb: Phase synchronization and large-scale integration",
        "publication_date": "2001-04-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Nature Reviews Neuroscience",
        "volume": "2",
        "doi": "10.1038/35067550",
        "urls": [
            "https://openalex.org/W1603307924",
            "https://doi.org/10.1038/35067550"
        ],
        "id": "id969735509425453256",
        "abstract": "",
        "versions": [],
        "rank": 261
    },
    {
        "authors": [
            "Dong, Guoliang",
            "Sun, Jun",
            "Wang, Jingyi",
            "Wang, Xinyu",
            "Zhang, Peixin"
        ],
        "title": "Adversarial Sample Detection for Deep Neural Network through Model  Mutation Testing",
        "publication_date": "2019-01-18 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/icse.2019.00126",
        "urls": [
            "http://arxiv.org/abs/1812.05793"
        ],
        "id": "id-6851132526088715528",
        "abstract": "Deep neural networks (DNN) have been shown to be useful in a wide range of\napplications. However, they are also known to be vulnerable to adversarial\nsamples. By transforming a normal sample with some carefully crafted human\nimperceptible perturbations, even highly accurate DNN make wrong decisions.\nMultiple defense mechanisms have been proposed which aim to hinder the\ngeneration of such adversarial samples. However, a recent work show that most\nof them are ineffective. In this work, we propose an alternative approach to\ndetect adversarial samples at runtime. Our main observation is that adversarial\nsamples are much more sensitive than normal samples if we impose random\nmutations on the DNN. We thus first propose a measure of `sensitivity' and show\nempirically that normal samples and adversarial samples have distinguishable\nsensitivity. We then integrate statistical hypothesis testing and model\nmutation testing to check whether an input sample is likely to be normal or\nadversarial at runtime by measuring its sensitivity. We evaluated our approach\non the MNIST and CIFAR10 datasets. The results show that our approach detects\nadversarial samples generated by state-of-the-art attacking methods efficiently\nand accurately.Comment: Accepted by ICSE 201",
        "versions": [],
        "rank": 262
    },
    {
        "authors": [
            "Xijie Huang",
            "Moustafa Alzantot",
            "Mani Srivastava"
        ],
        "title": "NeuronInspect: Detecting Backdoors in Neural Networks via Output Explanations",
        "publication_date": "2019-11-18 02:27:10+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1911.07399v1",
            "http://arxiv.org/abs/1911.07399v1",
            "http://arxiv.org/pdf/1911.07399v1"
        ],
        "id": "id-5249024540064163261",
        "abstract": "Deep neural networks have achieved state-of-the-art performance on various\ntasks. However, lack of interpretability and transparency makes it easier for\nmalicious attackers to inject trojan backdoor into the neural networks, which\nwill make the model behave abnormally when a backdoor sample with a specific\ntrigger is input. In this paper, we propose NeuronInspect, a framework to\ndetect trojan backdoors in deep neural networks via output explanation\ntechniques. NeuronInspect first identifies the existence of backdoor attack\ntargets by generating the explanation heatmap of the output layer. We observe\nthat generated heatmaps from clean and backdoored models have different\ncharacteristics. Therefore we extract features that measure the attributes of\nexplanations from an attacked model namely: sparse, smooth and persistent. We\ncombine these features and use outlier detection to figure out the outliers,\nwhich is the set of attack targets. We demonstrate the effectiveness and\nefficiency of NeuronInspect on MNIST digit recognition dataset and GTSRB\ntraffic sign recognition dataset. We extensively evaluate NeuronInspect on\ndifferent attack scenarios and prove better robustness and effectiveness over\nstate-of-the-art trojan backdoor detection techniques Neural Cleanse by a great\nmargin.",
        "versions": [],
        "rank": 263
    },
    {
        "authors": [
            "Kumar, A.",
            "Vekariya, V."
        ],
        "title": "Deep Convolutional Neural Networks for Intrusion Detection in Automotive Ethernet Networks",
        "publication_date": "2022-12-14 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ic3i56241.2022.10073080",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/10072015/10072297/10073080.pdf?arnumber=10073080",
            "http://dx.doi.org/10.1109/ic3i56241.2022.10073080"
        ],
        "id": "id-6534973996314146539",
        "abstract": "",
        "versions": [],
        "rank": 264
    },
    {
        "authors": [
            "Reyes, E.",
            "Estevez, P."
        ],
        "title": "Transformation Based Deep Anomaly Detection in Astronomical Images",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ijcnn48605.2020.9206997",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/9200848/9206590/09206997.pdf?arnumber=9206997",
            "http://dx.doi.org/10.1109/ijcnn48605.2020.9206997"
        ],
        "id": "id1453258646974885946",
        "abstract": "",
        "versions": [],
        "rank": 265
    },
    {
        "authors": [
            "Paul A. Viola",
            "Michael P. Jones"
        ],
        "title": "Robust Real-Time Face Detection",
        "publication_date": "2004-05-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "International Journal of Computer Vision",
        "volume": "57",
        "doi": "10.1023/b:visi.0000013087.49260.fb",
        "urls": [
            "https://openalex.org/W3097096317",
            "https://doi.org/10.1023/b:visi.0000013087.49260.fb"
        ],
        "id": "id5594492813972815115",
        "abstract": "",
        "versions": [],
        "rank": 266
    },
    {
        "authors": [
            "Nicholas Carlini",
            "David Wagner"
        ],
        "title": "Adversarial Examples Are Not Easily Detected",
        "publication_date": "2017-11-03 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security",
        "volume": "",
        "doi": "10.1145/3128572.3140444",
        "urls": [
            "https://openalex.org/W2963564844",
            "https://doi.org/10.1145/3128572.3140444"
        ],
        "id": "id8086357821266218254",
        "abstract": "",
        "versions": [],
        "rank": 267
    },
    {
        "authors": [
            "Siyuan Qiao",
            "Zhe Lin",
            "Jianming Zhang",
            "Alan Yuille"
        ],
        "title": "Neural Rejuvenation: Improving Deep Network Training by Enhancing Computational Resource Utilization",
        "publication_date": "2018-12-02 22:43:47+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1812.00481v1",
            "http://arxiv.org/abs/1812.00481v1",
            "http://arxiv.org/pdf/1812.00481v1"
        ],
        "id": "id-7296762256086536758",
        "abstract": "In this paper, we study the problem of improving computational resource\nutilization of neural networks. Deep neural networks are usually\nover-parameterized for their tasks in order to achieve good performances, thus\nare likely to have underutilized computational resources. This observation\nmotivates a lot of research topics, e.g. network pruning, architecture search,\netc. As models with higher computational costs (e.g. more parameters or more\ncomputations) usually have better performances, we study the problem of\nimproving the resource utilization of neural networks so that their potentials\ncan be further realized. To this end, we propose a novel optimization method\nnamed Neural Rejuvenation. As its name suggests, our method detects dead\nneurons and computes resource utilization in real time, rejuvenates dead\nneurons by resource reallocation and reinitialization, and trains them with new\ntraining schemes. By simply replacing standard optimizers with Neural\nRejuvenation, we are able to improve the performances of neural networks by a\nvery large margin while using similar training efforts and maintaining their\noriginal resource usages.",
        "versions": [],
        "rank": 268
    },
    {
        "authors": [
            "ATHA, D.",
            "JAHANSHAHI, M."
        ],
        "title": "Corrosion Detection using Deep Convolutional Neural Networks",
        "publication_date": "2017-09-28 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.12783/shm2017/14227",
        "urls": [
            "http://www.dpi-proceedings.com/index.php/shm2017/article/viewFile/14227/13746",
            "http://dx.doi.org/10.12783/shm2017/14227"
        ],
        "id": "id-2623968701993595",
        "abstract": "",
        "versions": [],
        "rank": 269
    },
    {
        "authors": [
            "Karin de Langis",
            "Michael Fulton",
            "Junaed Sattar"
        ],
        "title": "An Analysis of Deep Object Detectors For Diver Detection",
        "publication_date": "2020-11-25 01:50:32+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2012.05701v1",
            "http://arxiv.org/abs/2012.05701v1",
            "http://arxiv.org/pdf/2012.05701v1"
        ],
        "id": "id-2631920580642481718",
        "abstract": "With the end goal of selecting and using diver detection models to support\nhuman-robot collaboration capabilities such as diver following, we thoroughly\nanalyze a large set of deep neural networks for diver detection. We begin by\nproducing a dataset of approximately 105,000 annotated images of divers sourced\nfrom videos -- one of the largest and most varied diver detection datasets ever\ncreated. Using this dataset, we train a variety of state-of-the-art deep neural\nnetworks for object detection, including SSD with Mobilenet, Faster R-CNN, and\nYOLO. Along with these single-frame detectors, we also train networks designed\nfor detection of objects in a video stream, using temporal information as well\nas single-frame image information. We evaluate these networks on typical\naccuracy and efficiency metrics, as well as on the temporal stability of their\ndetections. Finally, we analyze the failures of these detectors, pointing out\nthe most common scenarios of failure. Based on our results, we recommend SSDs\nor Tiny-YOLOv4 for real-time applications on robots and recommend further\ninvestigation of video object detection methods.",
        "versions": [],
        "rank": 270
    },
    {
        "authors": [
            "Athalye Anish",
            "Barreno Marco",
            "Bhagoji Arjun Nitin",
            "Carlini Nicholas",
            "Girshick Ross",
            "Ilyas Andrew",
            "Khrulkov Valentin",
            "Kurakin Alexey",
            "Mopuri Konda",
            "Mo\u0107kus J",
            "Rifai Salah",
            "Szegedy Christian",
            "Tram\u00e9r Florian",
            "Zhou Wen"
        ],
        "title": "Procedural Noise Adversarial Examples for Black-Box Attacks on Deep  Convolutional Networks",
        "publication_date": "2019-06-23 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1145/3319535.3345660",
        "urls": [
            "http://arxiv.org/abs/1810.00470"
        ],
        "id": "id6592848455005511954",
        "abstract": "Deep Convolutional Networks (DCNs) have been shown to be vulnerable to\nadversarial examples---perturbed inputs specifically designed to produce\nintentional errors in the learning algorithms at test time. Existing\ninput-agnostic adversarial perturbations exhibit interesting visual patterns\nthat are currently unexplained. In this paper, we introduce a structured\napproach for generating Universal Adversarial Perturbations (UAPs) with\nprocedural noise functions. Our approach unveils the systemic vulnerability of\npopular DCN models like Inception v3 and YOLO v3, with single noise patterns\nable to fool a model on up to 90% of the dataset. Procedural noise allows us to\ngenerate a distribution of UAPs with high universal evasion rates using only a\nfew parameters. Additionally, we propose Bayesian optimization to efficiently\nlearn procedural noise parameters to construct inexpensive untargeted black-box\nattacks. We demonstrate that it can achieve an average of less than 10 queries\nper successful attack, a 100-fold improvement on existing methods. We further\nmotivate the use of input-agnostic defences to increase the stability of models\nto adversarial perturbations. The universality of our attacks suggests that DCN\nmodels may be sensitive to aggregations of low-level class-agnostic features.\nThese findings give insight on the nature of some universal adversarial\nperturbations and how they could be generated in other applications.Comment: 16 pages, 10 figures. In Proceedings of the 2019 ACM SIGSAC\n  Conference on Computer and Communications Security (CCS '19",
        "versions": [],
        "rank": 271
    },
    {
        "authors": [
            "Akshatha Kamath and Dwaraknath Gnaneshwar and Matias Valdenegro-Toro"
        ],
        "title": "Know Where To Drop Your Weights: Towards Faster Uncertainty Estimation",
        "publication_date": "2020-10-27 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20201030190642/https://arxiv.org/pdf/2010.14019v1.pdf"
        ],
        "id": "id4395636612454746440",
        "abstract": "Estimating epistemic uncertainty of models used in low-latency applications and Out-Of-Distribution samples detection is a challenge due to the computationally demanding nature of uncertainty estimation techniques. Estimating model uncertainty using approximation techniques like Monte Carlo Dropout (MCD), DropConnect (MCDC) requires a large number of forward passes through the network, rendering them inapt for low-latency applications. We propose Select-DC which uses a subset of layers in a neural network to model epistemic uncertainty with MCDC. Through our experiments, we show a significant reduction in the GFLOPS required to model uncertainty, compared to Monte Carlo DropConnect, with marginal trade-off in performance. We perform a suite of experiments on CIFAR 10, CIFAR 100, and SVHN datasets with ResNet and VGG models. We further show how applying DropConnect to various layers in the network with different drop probabilities affects the networks performance and the entropy of the predictive distribution.",
        "versions": [],
        "rank": 272
    },
    {
        "authors": [
            "Jiachen Zhong",
            "Junying Chen",
            "A. Mian"
        ],
        "title": "DualConv: Dual Convolutional Kernels for Lightweight Deep Neural Networks",
        "publication_date": "2022-02-15 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "IEEE transactions on neural networks and learning systems",
        "volume": "PP",
        "doi": "10.1109/TNNLS.2022.3151138",
        "urls": [
            "https://www.semanticscholar.org/paper/4a465453e70669f981c79175526ec1a7f3070023"
        ],
        "id": "id-7478970700569655689",
        "abstract": "Convolutional neural network (CNN) architectures are generally heavy on memory and computational requirements which make them infeasible for embedded systems with limited hardware resources. We propose dual convolutional kernels (DualConv) for constructing lightweight deep neural networks. DualConv combines 3x 3 and 1x 1 convolutional kernels to process the same input feature map channels simultaneously and exploits the group convolution technique to efficiently arrange convolutional filters. DualConv can be employed in any CNN model such as VGG-16 and ResNet-50 for image classification, you only look once (YOLO) and R-CNN for object detection, or fully convolutional network (FCN) for semantic segmentation. In this work, we extensively test DualConv for classification since these network architectures form the backbone for many other tasks. We also test DualConv for image detection on YOLO-V3. Experimental results show that, combined with our structural innovations, DualConv significantly reduces the computational cost and number of parameters of deep neural networks while surprisingly achieving slightly higher accuracy than the original models in some cases. We use DualConv to further reduce the number of parameters of the lightweight MobileNetV2 by 54% with only 0.68% drop in accuracy on CIFAR-100 dataset. When the number of parameters is not an issue, DualConv increases the accuracy of MobileNetV1 by 4.11% on the same dataset. Furthermore, DualConv significantly improves the YOLO-V3 object detection speed and improves its accuracy by 4.4% on PASCAL visual object classes (VOC) dataset.",
        "versions": [],
        "rank": 273
    },
    {
        "authors": [
            "Murat Sensoy",
            "Maryam Saleki",
            "Simon Julier",
            "Reyhan Aydogan",
            "John Reid"
        ],
        "title": "Misclassification Risk and Uncertainty Quantification in Deep Classifiers",
        "publication_date": "2021-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "IEEE",
        "volume": "",
        "doi": "10.1109/wacv48630.2021.00253",
        "urls": [
            "https://web.archive.org/web/20210804164217/https://discovery.ucl.ac.uk/id/eprint/10132169/1/Sensoy_Misclassification_Risk_and_Uncertainty_Quantification_in_Deep_Classifiers_WACV_2021_paper.pdf"
        ],
        "id": "id-4444032357056433171",
        "abstract": "In this paper, we propose risk-calibrated evidential deep classifiers to reduce the costs associated with classification errors. We use two main approaches. The first is to develop methods to quantify the uncertainty of a classifier's predictions and reduce the likelihood of acting on erroneous predictions. The second is a novel way to train the classifier such that erroneous classifications are biased towards less risky categories. We combine these two approaches in a principled way. While doing this, we extend evidential deep learning with pignistic probabilities, which are used to quantify uncertainty of classification predictions and model rational decision making under uncertainty. We evaluate the performance of our approach on several image classification tasks. We demonstrate that our approach allows to (i) incorporate misclassification cost while training deep classifiers, (ii) accurately quantify the uncertainty of classification predictions, and (iii) simultaneously learn how to make classification decisions to minimize expected cost of classification errors.",
        "versions": [],
        "rank": 274
    },
    {
        "authors": [
            "Boracchi, Giacomo",
            "Gavarini, Gabriele",
            "Ruospo, Annachiara",
            "Sanchez, Ernesto",
            "Stucchi, Diego"
        ],
        "title": "Open-Set Recognition: an Inexpensive Strategy to Increase DNN Reliability",
        "publication_date": "2022-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/iolts56730.2022.9897805",
        "urls": [
            "https://core.ac.uk/download/539314825.pdf"
        ],
        "id": "id1716071167110977514",
        "abstract": "Deep Neural Networks (DNNs) are nowadays widely used in low-cost accelerators, characterized by limited computational resources. These models, and in particular DNNs for image classification, are becoming increasingly popular in safety-critical applications, where they are required to be highly reliable. Unfortunately, increasing DNNs reliability without computational overheads, which might not be affordable in low-power devices, is a non-trivial task. Our intuition is to detect network executions affected by faults as outliers with respect to the distribution of normal network's output. To this purpose, we propose to exploit Open-Set Recognition (OSR) techniques to perform Fault Detection in an extremely low-cost manner. In particuar, we analyze the Maximum Logit Score (MLS), which is an established Open-Set Recognition technique, and compare it against other well-known OSR methods, namely OpenMax, energy-based out-of-distribution detection and ODIN. Our experiments, performed on a ResNet-20 classifier trained on CIFAR-10 and SVHN datasets, demonstrate that MLS guarantees satisfactory detection performance while adding a negligible computational overhead. Most remarkably, MLS is extremely convenient to configure and deploy, as it does not require any modification or re-training of the existing network. A discussion of the advantages and limitations of the analysed solutions concludes the paper",
        "versions": [],
        "rank": 275
    },
    {
        "authors": [
            "Bianco, Simone",
            "Manessi, Franco",
            "Napoletano, Paolo",
            "Rozza, Alessandro",
            "Schettini, Raimondo"
        ],
        "title": "Automated Pruning for Deep Neural Network Compression",
        "publication_date": "2019-01-06 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/icpr.2018.8546129",
        "urls": [
            "http://arxiv.org/abs/1712.01721"
        ],
        "id": "id8554647693636023833",
        "abstract": "In this work we present a method to improve the pruning step of the current\nstate-of-the-art methodology to compress neural networks. The novelty of the\nproposed pruning technique is in its differentiability, which allows pruning to\nbe performed during the backpropagation phase of the network training. This\nenables an end-to-end learning and strongly reduces the training time. The\ntechnique is based on a family of differentiable pruning functions and a new\nregularizer specifically designed to enforce pruning. The experimental results\nshow that the joint optimization of both the thresholds and the network weights\npermits to reach a higher compression rate, reducing the number of weights of\nthe pruned network by a further 14% to 33% compared to the current\nstate-of-the-art. Furthermore, we believe that this is the first study where\nthe generalization capabilities in transfer learning tasks of the features\nextracted by a pruned network are analyzed. To achieve this goal, we show that\nthe representations learned using the proposed pruning methodology maintain the\nsame effectiveness and generality of those learned by the corresponding\nnon-compressed network on a set of different recognition tasks.Comment: 8 pages, 5 figures. Published as a conference paper at ICPR 201",
        "versions": [],
        "rank": 276
    },
    {
        "authors": [
            "Mateju, L.",
            "Cerva, P.",
            "Zdansky, J."
        ],
        "title": "Study on the Use of Deep Neural Networks for Speech Activity Detection in Broadcast Recordings",
        "publication_date": "2016-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.5220/0005952700450051",
        "urls": [
            "http://dx.doi.org/10.5220/0005952700450051"
        ],
        "id": "id-3195050932270902146",
        "abstract": "",
        "versions": [],
        "rank": 277
    },
    {
        "authors": [
            "Anisie Uwimana1",
            "Ransalu Senanayake"
        ],
        "title": "Out of Distribution Detection and Adversarial Attacks on Deep Neural Networks for Robust Medical Image Analysis",
        "publication_date": "2021-07-10 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20210715220514/https://arxiv.org/pdf/2107.04882v1.pdf"
        ],
        "id": "id-2599802173824985649",
        "abstract": "Deep learning models have become a popular choice for medical image analysis. However, the poor generalization performance of deep learning models limits them from being deployed in the real world as robustness is critical for medical applications. For instance, the state-of-the-art Convolutional Neural Networks (CNNs) fail to detect adversarial samples or samples drawn statistically far away from the training distribution. In this work, we experimentally evaluate the robustness of a Mahalanobis distance-based confidence score, a simple yet effective method for detecting abnormal input samples, in classifying malaria parasitized cells and uninfected cells. Results indicated that the Mahalanobis confidence score detector exhibits improved performance and robustness of deep learning models, and achieves stateof-the-art performance on both out-of-distribution (OOD) and adversarial samples.",
        "versions": [
            {
                "year": 2021,
                "source": "SupportedSources.OPENALEX",
                "title": "Out of Distribution Detection and Adversarial Attacks on Deep Neural Networks for Robust Medical Image Analysis",
                "journal": "International Conference on Machine Learning",
                "urls": [
                    "https://openalex.org/W3214961495"
                ],
                "doi": null,
                "publication_date": "2021-06-18 00:00:00"
            }
        ],
        "rank": 278
    },
    {
        "authors": [
            "Rana Abou Khamis",
            "A. Matrawy"
        ],
        "title": "Evaluation of Adversarial Training on Different Types of Neural Networks in Deep Learning-based IDSs",
        "publication_date": "2020-07-08 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ISNCC49221.2020.9297344",
        "urls": [
            "https://www.semanticscholar.org/paper/00f44fb92b02552208729e228f0f3a6e06cbdadd"
        ],
        "id": "id-4088400942535920537",
        "abstract": "Network security applications, including Intrusion Detection Systems (IDS) of deep neural networks (DNN), are increasing rapidly to make detection task of anomaly activities more accurate and robust. With the rapid increase of using DNN and the volume of data traveling through systems, different growing types of adversarial attacks to defeat DNN create a severe challenge. In this paper, we focus on investigating the effectiveness of different evasion attacks and how to train a resilience deep learning-based IDS using different Neural networks, e.g., Artificial Neural Network (ANN), Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN). We use the min-max formulation to formulate the problem of training robust intrusion detection systems against adversarial samples using two benchmark datasets. Our experiments on different deep learning algorithms and different benchmark datasets demonstrate that defense using adversarial training based min-max formulation increases the robustness of the network under the assumption of our threat model and five state-of-the-art adversarial attacks.",
        "versions": [
            {
                "year": 2020,
                "source": "SupportedSources.ARXIV",
                "title": "Evaluation of Adversarial Training on Different Types of Neural Networks in Deep Learning-based IDSs",
                "journal": null,
                "urls": [
                    "http://arxiv.org/pdf/2007.04472v1",
                    "http://arxiv.org/abs/2007.04472v1",
                    "http://arxiv.org/pdf/2007.04472v1"
                ],
                "doi": "",
                "publication_date": "2020-07-08 23:33:30+00:00"
            }
        ],
        "rank": 279
    },
    {
        "authors": [
            "Jesse Davis",
            "Mark Goadrich"
        ],
        "title": "The relationship between Precision-Recall and ROC curves",
        "publication_date": "2006-06-25 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "International Conference on Machine Learning",
        "volume": "",
        "doi": "10.1145/1143844.1143874",
        "urls": [
            "https://openalex.org/W1976526581",
            "https://doi.org/10.1145/1143844.1143874",
            "http://www.biostat.wisc.edu/~page/rocpr.pdf"
        ],
        "id": "id1291702451330197612",
        "abstract": "",
        "versions": [],
        "rank": 280
    },
    {
        "authors": [
            "Will Y. Zou",
            "Xiaoyu Wang",
            "Miao Sun",
            "Yuanqing Lin"
        ],
        "title": "Generic Object Detection With Dense Neural Patterns and Regionlets",
        "publication_date": "2014-04-16 17:23:47+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1404.4316v1",
            "http://arxiv.org/abs/1404.4316v1",
            "http://arxiv.org/pdf/1404.4316v1"
        ],
        "id": "id-872485476527421676",
        "abstract": "This paper addresses the challenge of establishing a bridge between deep\nconvolutional neural networks and conventional object detection frameworks for\naccurate and efficient generic object detection. We introduce Dense Neural\nPatterns, short for DNPs, which are dense local features derived from\ndiscriminatively trained deep convolutional neural networks. DNPs can be easily\nplugged into conventional detection frameworks in the same way as other dense\nlocal features(like HOG or LBP). The effectiveness of the proposed approach is\ndemonstrated with the Regionlets object detection framework. It achieved 46.1%\nmean average precision on the PASCAL VOC 2007 dataset, and 44.1% on the PASCAL\nVOC 2010 dataset, which dramatically improves the original Regionlets approach\nwithout DNPs.",
        "versions": [],
        "rank": 281
    },
    {
        "authors": [
            "Gebhard, Timothy D.",
            "Harry, Ian",
            "Kilbertus, Niki",
            "Sch\u00f6lkopf, Bernhard"
        ],
        "title": "Convolutional neural networks: a magic bullet for gravitational-wave  detection?",
        "publication_date": "2019-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1103/physrevd.100.063015",
        "urls": [
            "https://core.ac.uk/download/227487708.pdf"
        ],
        "id": "id-1611880720373167602",
        "abstract": "In the last few years, machine learning techniques, in particular\nconvolutional neural networks, have been investigated as a method to replace or\ncomplement traditional matched filtering techniques that are used to detect the\ngravitational-wave signature of merging black holes. However, to date, these\nmethods have not yet been successfully applied to the analysis of long\nstretches of data recorded by the Advanced LIGO and Virgo gravitational-wave\nobservatories. In this work, we critically examine the use of convolutional\nneural networks as a tool to search for merging black holes. We identify the\nstrengths and limitations of this approach, highlight some common pitfalls in\ntranslating between machine learning and gravitational-wave astronomy, and\ndiscuss the interdisciplinary challenges. In particular, we explain in detail\nwhy convolutional neural networks alone cannot be used to claim a statistically\nsignificant gravitational-wave detection. However, we demonstrate how they can\nstill be used to rapidly flag the times of potential signals in the data for a\nmore detailed follow-up. Our convolutional neural network architecture as well\nas the proposed performance metrics are better suited for this task than a\nstandard binary classifications scheme. A detailed evaluation of our approach\non Advanced LIGO data demonstrates the potential of such systems as trigger\ngenerators. Finally, we sound a note of caution by constructing adversarial\nexamples, which showcase interesting \"failure modes\" of our model, where inputs\nwith no visible resemblance to real gravitational-wave signals are identified\nas such by the network with high confidence.Comment: First two authors contributed equally; appeared at Phys. Rev. ",
        "versions": [],
        "rank": 282
    },
    {
        "authors": [
            "Kai Kang",
            "Wanli Ouyang",
            "Hongsheng Li",
            "Xiaogang Wang"
        ],
        "title": "Object Detection from Video Tubelets with Convolutional Neural Networks",
        "publication_date": "2016-04-14 07:22:44+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": "Computer Vision and Pattern Recognition (CVPR), 2016 IEEE\n  Conference on (pp. 817-825)",
        "volume": "",
        "doi": "10.1109/CVPR.2016.95",
        "urls": [
            "http://arxiv.org/pdf/1604.04053v1",
            "http://dx.doi.org/10.1109/CVPR.2016.95",
            "http://arxiv.org/abs/1604.04053v1",
            "http://arxiv.org/pdf/1604.04053v1"
        ],
        "id": "id-2769008222699952265",
        "abstract": "Deep Convolution Neural Networks (CNNs) have shown impressive performance in\nvarious vision tasks such as image classification, object detection and\nsemantic segmentation. For object detection, particularly in still images, the\nperformance has been significantly increased last year thanks to powerful deep\nnetworks (e.g. GoogleNet) and detection frameworks (e.g. Regions with CNN\nfeatures (R-CNN)). The lately introduced ImageNet task on object detection from\nvideo (VID) brings the object detection task into the video domain, in which\nobjects' locations at each frame are required to be annotated with bounding\nboxes. In this work, we introduce a complete framework for the VID task based\non still-image object detection and general object tracking. Their relations\nand contributions in the VID task are thoroughly studied and evaluated. In\naddition, a temporal convolution network is proposed to incorporate temporal\ninformation to regularize the detection results and shows its effectiveness for\nthe task.",
        "versions": [],
        "rank": 283
    },
    {
        "authors": [
            "Fco. Javier Ord\u00f3\u00f1ez",
            "Daniel Roggen"
        ],
        "title": "Deep Convolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity Recognition",
        "publication_date": "2016-01-18 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Sensors",
        "volume": "16",
        "doi": "10.3390/s16010115",
        "urls": [
            "https://openalex.org/W2270470215",
            "https://doi.org/10.3390/s16010115",
            "https://www.mdpi.com/1424-8220/16/1/115/pdf?version=1453111475"
        ],
        "id": "id-6324425471189928374",
        "abstract": "",
        "versions": [],
        "rank": 284
    },
    {
        "authors": [
            "Christian Bartz",
            "Haojin Yang",
            "Christoph Meinel"
        ],
        "title": "STN-OCR: A single Neural Network for Text Detection and Text Recognition",
        "publication_date": "2017-07-27 12:22:34+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1707.08831v1",
            "http://arxiv.org/abs/1707.08831v1",
            "http://arxiv.org/pdf/1707.08831v1"
        ],
        "id": "id-3424244774651785039",
        "abstract": "Detecting and recognizing text in natural scene images is a challenging, yet\nnot completely solved task. In re- cent years several new systems that try to\nsolve at least one of the two sub-tasks (text detection and text recognition)\nhave been proposed. In this paper we present STN-OCR, a step towards\nsemi-supervised neural networks for scene text recognition, that can be\noptimized end-to-end. In contrast to most existing works that consist of\nmultiple deep neural networks and several pre-processing steps we propose to\nuse a single deep neural network that learns to detect and recognize text from\nnatural images in a semi-supervised way. STN-OCR is a network that integrates\nand jointly learns a spatial transformer network, that can learn to detect text\nregions in an image, and a text recognition network that takes the identified\ntext regions and recognizes their textual content. We investigate how our model\nbehaves on a range of different tasks (detection and recognition of characters,\nand lines of text). Experimental results on public benchmark datasets show the\nability of our model to handle a variety of different tasks, without\nsubstantial changes in its overall network structure.",
        "versions": [],
        "rank": 285
    },
    {
        "authors": [
            "Michelucci, U."
        ],
        "title": "TensorFlow: Advanced Topics",
        "publication_date": "2019-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-1-4842-4976-5_2",
        "urls": [
            "http://link.springer.com/content/pdf/10.1007/978-1-4842-4976-5_2",
            "http://dx.doi.org/10.1007/978-1-4842-4976-5_2"
        ],
        "id": "id-6158925629905613628",
        "abstract": "",
        "versions": [],
        "rank": 286
    },
    {
        "authors": [
            "Mehmet S\u00fczen"
        ],
        "title": "Equivalence in Deep Neural Networks via Conjugate Matrix Ensembles",
        "publication_date": "2020-06-14 12:34:13+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2006.13687v2",
            "http://arxiv.org/abs/2006.13687v2",
            "http://arxiv.org/pdf/2006.13687v2"
        ],
        "id": "id-6653170020021990099",
        "abstract": "A numerical approach is developed for detecting the equivalence of deep\nlearning architectures. The method is based on generating Mixed Matrix\nEnsembles (MMEs) out of deep neural network weight matrices and {\\it conjugate\ncircular ensemble} matching the neural architecture topology. Following this,\nthe empirical evidence supports the {\\it phenomenon} that difference between\nspectral densities of neural architectures and corresponding {\\it conjugate\ncircular ensemble} are vanishing with different decay rates at the long\npositive tail part of the spectrum i.e., cumulative Circular Spectral\nDifference (CSD). This finding can be used in establishing equivalences among\ndifferent neural architectures via analysis of fluctuations in CSD. We\ninvestigated this phenomenon for a wide range of deep learning vision\narchitectures and with circular ensembles originating from statistical quantum\nmechanics. Practical implications of the proposed method for artificial and\nnatural neural architectures discussed such as the possibility of using the\napproach in Neural Architecture Search (NAS) and classification of biological\nneural networks.",
        "versions": [],
        "rank": 287
    },
    {
        "authors": [
            "Choudhary, Chhaya",
            "De Cock, Martine",
            "Gray, Daniel",
            "Hu, Jiaming",
            "Nascimento, Anderson C. A.",
            "Pan, Jie",
            "Yu, Bin"
        ],
        "title": "Weakly supervised deep learning for the detection of domain generation algorithms",
        "publication_date": "2019-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/access.2019.2911522",
        "urls": [
            "https://core.ac.uk/download/237011209.pdf"
        ],
        "id": "id-4031678601781922926",
        "abstract": "Domain generation algorithms (DGAs) have become commonplace in malware that seeks to establish command and control communication between an infected machine and the botmaster. DGAs dynamically and consistently generate large volumes of malicious domain names, only a few of which are registered by the botmaster, within a short time window around their generation time, and subsequently resolved when the malware on the infected machine tries to access them. Deep neural networks that can classify domain names as benign or malicious are of great interest in the real-time defense against DGAs. In contrast with traditional machine learning models, deep networks do not rely on human engineered features. Instead, they can learn features automatically from data, provided that they are supplied with sufficiently large amounts of suitable training data. Obtaining cleanly labeled ground truth data is difficult and time consuming. Heuristically labeled data could potentially provide a source of training data for weakly supervised training of DGA detectors. We propose a set of heuristics for automatically labeling domain names monitored in real traffic, and then train and evaluate classifiers with the proposed heuristically labeled dataset. We show through experiments on a dataset with 50 million domain names that such heuristically labeled data is very useful in practice to improve the predictive accuracy of deep learning-based DGA classifiers, and that these deep neural networks significantly outperform a random forest classifier with human engineered features",
        "versions": [],
        "rank": 288
    },
    {
        "authors": [
            "Dong, Jingming",
            "Karianakis, Nikolaos",
            "Soatto, Stefano"
        ],
        "title": "An Empirical Evaluation of Current Convolutional Architectures' Ability  to Manage Nuisance Location and Scale Variability",
        "publication_date": "2016-04-28 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/cvpr.2016.481",
        "urls": [
            "http://arxiv.org/abs/1505.06795"
        ],
        "id": "id-2260065923631152929",
        "abstract": "We conduct an empirical study to test the ability of Convolutional Neural\nNetworks (CNNs) to reduce the effects of nuisance transformations of the input\ndata, such as location, scale and aspect ratio. We isolate factors by adopting\na common convolutional architecture either deployed globally on the image to\ncompute class posterior distributions, or restricted locally to compute class\nconditional distributions given location, scale and aspect ratios of bounding\nboxes determined by proposal heuristics. In theory, averaging the latter should\nyield inferior performance compared to proper marginalization. Yet empirical\nevidence suggests the converse, leading us to conclude that - at the current\nlevel of complexity of convolutional architectures and scale of the data sets\nused to train them - CNNs are not very effective at marginalizing nuisance\nvariability. We also quantify the effects of context on the overall\nclassification task and its impact on the performance of CNNs, and propose\nimproved sampling techniques for heuristic proposal schemes that improve\nend-to-end performance to state-of-the-art levels. We test our hypothesis on a\nclassification task using the ImageNet Challenge benchmark and on a\nwide-baseline matching task using the Oxford and Fischer's datasets.Comment: 10 pages, 5 figures, 3 tables -- CVPR 2016, camera-ready versio",
        "versions": [],
        "rank": 289
    },
    {
        "authors": [
            "Rickard Sj\u00f6gren",
            "Johan Trygg"
        ],
        "title": "Out-of-Distribution Example Detection in Deep Neural Networks using Distance to Modelled Embedding",
        "publication_date": "2021-08-24 12:28:04+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2108.10673v1",
            "http://arxiv.org/abs/2108.10673v1",
            "http://arxiv.org/pdf/2108.10673v1"
        ],
        "id": "id-482756696796501230",
        "abstract": "Adoption of deep learning in safety-critical systems raise the need for\nunderstanding what deep neural networks do not understand after models have\nbeen deployed. The behaviour of deep neural networks is undefined for so called\nout-of-distribution examples. That is, examples from another distribution than\nthe training set. Several methodologies to detect out-of-distribution examples\nduring prediction-time have been proposed, but these methodologies constrain\neither neural network architecture, how the neural network is trained, suffer\nfrom performance overhead, or assume that the nature of out-of-distribution\nexamples are known a priori. We present Distance to Modelled Embedding (DIME)\nthat we use to detect out-of-distribution examples during prediction time. By\napproximating the training set embedding into feature space as a linear\nhyperplane, we derive a simple, unsupervised, highly performant and\ncomputationally efficient method. DIME allows us to add prediction-time\ndetection of out-of-distribution examples to neural network models without\naltering architecture or training while imposing minimal constraints on when it\nis applicable. In our experiments, we demonstrate that by using DIME as an\nadd-on after training, we efficiently detect out-of-distribution examples\nduring prediction and match state-of-the-art methods while being more versatile\nand introducing negligible computational overhead.",
        "versions": [
            {
                "year": 2021,
                "source": "SupportedSources.PAPERS_WITH_CODE",
                "title": "Out-of-Distribution Example Detection in Deep Neural Networks using Distance to Modelled Embedding",
                "journal": "",
                "urls": [
                    "https://arxiv.org/pdf/2108.10673v1.pdf",
                    "https://github.com/sartorius-research/dime.pytorch",
                    "https://arxiv.org/pdf/2108.10673"
                ],
                "doi": "",
                "publication_date": "2021-08-24 00:00:00"
            },
            {
                "year": 2021,
                "source": "SupportedSources.INTERNET_ARCHIVE",
                "title": "Out-of-Distribution Example Detection in Deep Neural Networks using Distance to Modelled Embedding",
                "journal": "",
                "urls": [
                    "https://web.archive.org/web/20210829185045/https://arxiv.org/pdf/2108.10673v1.pdf"
                ],
                "doi": "",
                "publication_date": "2021-08-24 00:00:00"
            }
        ],
        "rank": 290
    },
    {
        "authors": [
            "Yichen Shen",
            "Nicholas B. Harris",
            "Scott Skirlo",
            "Dirk Englund",
            "Marin Soljacic"
        ],
        "title": "Deep learning with coherent nanophotonic circuits",
        "publication_date": "2017-07-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Nature Photonics",
        "volume": "11",
        "doi": "10.1038/nphoton.2017.93",
        "urls": [
            "https://openalex.org/W2752849906",
            "https://doi.org/10.1038/nphoton.2017.93",
            "http://arxiv.org/pdf/1610.02365"
        ],
        "id": "id-7367206195019712462",
        "abstract": "",
        "versions": [],
        "rank": 291
    },
    {
        "authors": [
            "Oliver Stegle",
            "Tanel P\u00e4rnamaa",
            "Leopold Parts"
        ],
        "title": "Deep learning for computational biology",
        "publication_date": "2016-07-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Molecular Systems Biology",
        "volume": "12",
        "doi": "10.15252/msb.20156651",
        "urls": [
            "https://openalex.org/W2502949459",
            "https://doi.org/10.15252/msb.20156651",
            "https://doi.org/10.15252/msb.20156651"
        ],
        "id": "id5813978548668892238",
        "abstract": "",
        "versions": [],
        "rank": 292
    },
    {
        "authors": [
            "Hyeonwoo Noh",
            "Seunghoon Hong",
            "Bohyung Han"
        ],
        "title": "Learning Deconvolution Network for Semantic Segmentation",
        "publication_date": "2015-12-07 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "arXiv (Cornell University)",
        "volume": "",
        "doi": "10.1109/iccv.2015.178",
        "urls": [
            "https://openalex.org/W1745334888",
            "https://doi.org/10.1109/iccv.2015.178",
            "http://arxiv.org/pdf/1505.04366"
        ],
        "id": "id6834983715020287474",
        "abstract": "",
        "versions": [],
        "rank": 293
    },
    {
        "authors": [
            "Federico Monti",
            "Davide Boscaini",
            "Jonathan Masci",
            "Emanuele Rodol\u00e0",
            "Jan Svoboda",
            "Michael M. Bronstein"
        ],
        "title": "Geometric Deep Learning on Graphs and Manifolds Using Mixture Model CNNs",
        "publication_date": "2017-07-21 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Computer Vision and Pattern Recognition",
        "volume": "",
        "doi": "10.1109/cvpr.2017.576",
        "urls": [
            "https://openalex.org/W2558460151",
            "https://doi.org/10.1109/cvpr.2017.576",
            "http://arxiv.org/pdf/1611.08402"
        ],
        "id": "id-2667240136383609874",
        "abstract": "",
        "versions": [],
        "rank": 294
    },
    {
        "authors": [
            "Blond Stevens Le",
            "Brown Peter F.",
            "Chua Zheng Leong",
            "Gu Guofei",
            "Ho Grant",
            "Liu Yang",
            "Melicher William",
            "Provos Niels",
            "Provos Niels",
            "Richard Shin Eui Chul",
            "Sabottke Carl",
            "Soska Kyle"
        ],
        "title": "Tiresias: Predicting Security Events Through Deep Learning",
        "publication_date": "2018-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1145/3243734.3243811",
        "urls": [
            "http://arxiv.org/abs/1905.10328"
        ],
        "id": "id7886746016285136429",
        "abstract": "With the increased complexity of modern computer attacks, there is a need for\ndefenders not only to detect malicious activity as it happens, but also to\npredict the specific steps that will be taken by an adversary when performing\nan attack. However this is still an open research problem, and previous\nresearch in predicting malicious events only looked at binary outcomes (e.g.,\nwhether an attack would happen or not), but not at the specific steps that an\nattacker would undertake. To fill this gap we present Tiresias, a system that\nleverages Recurrent Neural Networks (RNNs) to predict future events on a\nmachine, based on previous observations. We test Tiresias on a dataset of 3.4\nbillion security events collected from a commercial intrusion prevention\nsystem, and show that our approach is effective in predicting the next event\nthat will occur on a machine with a precision of up to 0.93. We also show that\nthe models learned by Tiresias are reasonably stable over time, and provide a\nmechanism that can identify sudden drops in precision and trigger a retraining\nof the system. Finally, we show that the long-term memory typical of RNNs is\nkey in performing event prediction, rendering simpler methods not up to the\ntask",
        "versions": [],
        "rank": 295
    },
    {
        "authors": [
            "Gurevych, Iryna",
            "Reimers, Nils"
        ],
        "title": "Reporting Score Distributions Makes a Difference: Performance Study of  LSTM-networks for Sequence Tagging",
        "publication_date": "2017-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.18653/v1/d17-1035",
        "urls": [
            "http://arxiv.org/abs/1707.09861"
        ],
        "id": "id-2472912670585955105",
        "abstract": "In this paper we show that reporting a single performance score is\ninsufficient to compare non-deterministic approaches. We demonstrate for common\nsequence tagging tasks that the seed value for the random number generator can\nresult in statistically significant (p < 10^-4) differences for\nstate-of-the-art systems. For two recent systems for NER, we observe an\nabsolute difference of one percentage point F1-score depending on the selected\nseed value, making these systems perceived either as state-of-the-art or\nmediocre. Instead of publishing and reporting single performance scores, we\npropose to compare score distributions based on multiple executions. Based on\nthe evaluation of 50.000 LSTM-networks for five sequence tagging tasks, we\npresent network architectures that produce both superior performance as well as\nare more stable with respect to the remaining hyperparameters.Comment: Accepted at EMNLP 201",
        "versions": [],
        "rank": 296
    },
    {
        "authors": [
            "Albert-L\u00e1szl\u00f3 Barab\u00e1si",
            "Zolt\u00e1n N. Oltvai"
        ],
        "title": "Network biology: understanding the cell's functional organization",
        "publication_date": "2004-02-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Nature Reviews Genetics",
        "volume": "5",
        "doi": "10.1038/nrg1272",
        "urls": [
            "https://openalex.org/W2163480486",
            "https://doi.org/10.1038/nrg1272"
        ],
        "id": "id-3952145223109481447",
        "abstract": "",
        "versions": [],
        "rank": 297
    },
    {
        "authors": [
            "Schranko de Oliveira, A.",
            "Sassi, R."
        ],
        "title": "Behavioral Malware Detection Using Deep Graph Convolutional Neural Networks",
        "publication_date": "2019-11-02 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.36227/techrxiv.10043099",
        "urls": [
            "https://ndownloader.figshare.com/files/18101063",
            "http://dx.doi.org/10.36227/techrxiv.10043099"
        ],
        "id": "id-2743342976258176804",
        "abstract": "",
        "versions": [],
        "rank": 298
    },
    {
        "authors": [
            "Schranko de Oliveira, A.",
            "Sassi, R."
        ],
        "title": "Behavioral Malware Detection Using Deep Graph Convolutional Neural Networks",
        "publication_date": "2019-11-02 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.36227/techrxiv.10043099.v1",
        "urls": [
            "https://ndownloader.figshare.com/files/18101063",
            "http://dx.doi.org/10.36227/techrxiv.10043099.v1"
        ],
        "id": "id-104873866734761452",
        "abstract": "",
        "versions": [],
        "rank": 299
    },
    {
        "authors": [
            "Arnoud, Sacha",
            "Bulatov, Yaroslav",
            "Goodfellow, Ian J.",
            "Ibarz, Julian",
            "Shet, Vinay"
        ],
        "title": "Multi-digit Number Recognition from Street View Imagery using Deep  Convolutional Neural Networks",
        "publication_date": "2014-04-14 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "http://arxiv.org/abs/1312.6082"
        ],
        "id": "id7997254053086624877",
        "abstract": "Recognizing arbitrary multi-character text in unconstrained natural\nphotographs is a hard problem. In this paper, we address an equally hard\nsub-problem in this domain viz. recognizing arbitrary multi-digit numbers from\nStreet View imagery. Traditional approaches to solve this problem typically\nseparate out the localization, segmentation, and recognition steps. In this\npaper we propose a unified approach that integrates these three steps via the\nuse of a deep convolutional neural network that operates directly on the image\npixels. We employ the DistBelief implementation of deep neural networks in\norder to train large, distributed neural networks on high quality images. We\nfind that the performance of this approach increases with the depth of the\nconvolutional network, with the best performance occurring in the deepest\narchitecture we trained, with eleven hidden layers. We evaluate this approach\non the publicly available SVHN dataset and achieve over $96\\%$ accuracy in\nrecognizing complete street numbers. We show that on a per-digit recognition\ntask, we improve upon the state-of-the-art, achieving $97.84\\%$ accuracy. We\nalso evaluate this approach on an even more challenging dataset generated from\nStreet View imagery containing several tens of millions of street number\nannotations and achieve over $90\\%$ accuracy. To further explore the\napplicability of the proposed system to broader text recognition tasks, we\napply it to synthetic distorted text from reCAPTCHA. reCAPTCHA is one of the\nmost secure reverse turing tests that uses distorted text to distinguish humans\nfrom bots. We report a $99.8\\%$ accuracy on the hardest category of reCAPTCHA.\nOur evaluations on both tasks indicate that at specific operating thresholds,\nthe performance of the proposed system is comparable to, and in some cases\nexceeds, that of human operators",
        "versions": [],
        "rank": 300
    },
    {
        "authors": [
            "Aliaksandr Barushka",
            "P. H\u00e1jek"
        ],
        "title": "Spam detection on social networks using cost-sensitive feature selection and ensemble-based regularized deep neural networks",
        "publication_date": "2019-07-02 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Neural Computing and Applications",
        "volume": "32",
        "doi": "10.1007/s00521-019-04331-5",
        "urls": [
            "https://www.semanticscholar.org/paper/2bb13ce8aeb211c909b9c76bf20cd9e7514ac4d2"
        ],
        "id": "id-6084785825041228052",
        "abstract": null,
        "versions": [
            {
                "year": 2019,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Spam detection on social networks using cost-sensitive feature selection and ensemble-based regularized deep neural networks",
                "journal": "Neural Computing and Applications",
                "urls": [
                    "https://www.semanticscholar.org/paper/1059333af0d9e21ae8614b3608936fd2103ccc9e"
                ],
                "doi": "10.1007/s00521-019-04331-5",
                "publication_date": "2019-07-02 00:00:00"
            }
        ],
        "rank": 301
    },
    {
        "authors": [
            "Hrithika Dodia"
        ],
        "title": "Detecting residues of cosmic events using residual neural network",
        "publication_date": "2021-01-01 08:44:58+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2101.00195v1",
            "http://arxiv.org/abs/2101.00195v1",
            "http://arxiv.org/pdf/2101.00195v1"
        ],
        "id": "id-1797828642522640568",
        "abstract": "The detection of gravitational waves is considered to be one of the most\nmagnificent discoveries of the century. Due to the high computational cost of\nmatched filtering pipeline, there is a hunt for an alternative powerful system.\nI present, for the first time, the use of 1D residual neural network for\ndetection of gravitational waves. Residual networks have transformed many\nfields like image classification, face recognition and object detection with\ntheir robust structure. With increase in sensitivity of LIGO detectors we\nexpect many more sources of gravitational waves in the universe to be detected.\nHowever, deep learning networks are trained only once. When used for\nclassification task, deep neural networks are trained to predict only a fixed\nnumber of classes. Therefore, when a new type of gravitational wave is to be\ndetected, this turns out to be a drawback of deep learning. Shallow neural\nnetworks can be used to learn data with simple patterns but fail to give good\nresults with increase in complexity of data. Remodelling the neural network\nwith detection of each new type of GW is highly infeasible. In this letter, I\nalso discuss ways to reduce the time required to adapt to such changes in\ndetection of gravitational waves for deep learning methods. Primarily, I aim to\ncreate a custom residual neural network for 1-dimensional time series inputs,\nwhich can learn a ton of features from dataset without giving up on increasing\nthe number of classes or increasing the complexity of data. I use the two class\nof binary coalescence signals (Binary Black Hole Merger and Binary Neutron Star\nMerger signals) detected by LIGO to check the performance of residual structure\non gravitational waves detection.",
        "versions": [],
        "rank": 302
    },
    {
        "authors": [
            "Ioannis D. Apostolopoulos",
            "Tzani Bessiana"
        ],
        "title": "Covid-19: automatic detection from X-ray images utilizing transfer learning with convolutional neural networks",
        "publication_date": "2020-03-25 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Physical and Engineering Sciences in Medicine",
        "volume": "43",
        "doi": "10.1007/s13246-020-00865-4",
        "urls": [
            "https://www.semanticscholar.org/paper/770b665c6941f8ae96cc7ef4ec434b059108bdac"
        ],
        "id": "id-8179203034072410861",
        "abstract": null,
        "versions": [],
        "rank": 303
    },
    {
        "authors": [
            "Arkar Min Aung",
            "Yousef Fadila",
            "Radian Gondokaryono",
            "Luis Gonzalez"
        ],
        "title": "Building Robust Deep Neural Networks for Road Sign Detection",
        "publication_date": "2017-12-26 18:52:41+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1712.09327v1",
            "http://arxiv.org/abs/1712.09327v1",
            "http://arxiv.org/pdf/1712.09327v1"
        ],
        "id": "id-5851798302305655969",
        "abstract": "Deep Neural Networks are built to generalize outside of training set in mind\nby using techniques such as regularization, early stopping and dropout. But\nconsiderations to make them more resilient to adversarial examples are rarely\ntaken. As deep neural networks become more prevalent in mission-critical and\nreal-time systems, miscreants start to attack them by intentionally making deep\nneural networks to misclassify an object of one type to be seen as another\ntype. This can be catastrophic in some scenarios where the classification of a\ndeep neural network can lead to a fatal decision by a machine. In this work, we\nused GTSRB dataset to craft adversarial samples by Fast Gradient Sign Method\nand Jacobian Saliency Method, used those crafted adversarial samples to attack\nanother Deep Convolutional Neural Network and built the attacked network to be\nmore resilient against adversarial attacks by making it more robust by\nDefensive Distillation and Adversarial Training",
        "versions": [],
        "rank": 304
    },
    {
        "authors": [
            "Martin Zurowietz",
            "T. Nattkemper"
        ],
        "title": "An Interactive Visualization for Feature Localization in Deep Neural Networks",
        "publication_date": "2020-07-23 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Frontiers in Artificial Intelligence",
        "volume": "3",
        "doi": "10.3389/frai.2020.00049",
        "urls": [
            "https://www.semanticscholar.org/paper/5273da7549f88ab21839a4a0d3568b2f71ec5385"
        ],
        "id": "id889434200318386733",
        "abstract": "Deep artificial neural networks have become the go-to method for many machine learning tasks. In the field of computer vision, deep convolutional neural networks achieve state-of-the-art performance for tasks such as classification, object detection, or instance segmentation. As deep neural networks become more and more complex, their inner workings become more and more opaque, rendering them a \u201cblack box\u201d whose decision making process is no longer comprehensible. In recent years, various methods have been presented that attempt to peek inside the black box and to visualize the inner workings of deep neural networks, with a focus on deep convolutional neural networks for computer vision. These methods can serve as a toolbox to facilitate the design and inspection of neural networks for computer vision and the interpretation of the decision making process of the network. Here, we present the new tool Interactive Feature Localization in Deep neural networks (IFeaLiD) which provides a novel visualization approach to convolutional neural network layers. The tool interprets neural network layers as multivariate feature maps and visualizes the similarity between the feature vectors of individual pixels of an input image in a heat map display. The similarity display can reveal how the input image is perceived by different layers of the network and how the perception of one particular image region compares to the perception of the remaining image. IFeaLiD runs interactively in a web browser and can process even high resolution feature maps in real time by using GPU acceleration with WebGL 2. We present examples from four computer vision datasets with feature maps from different layers of a pre-trained ResNet101. IFeaLiD is open source and available online at https://ifealid.cebitec.uni-bielefeld.de.",
        "versions": [],
        "rank": 305
    },
    {
        "authors": [
            "Hoang-Quoc Nguyen-Son",
            "T. Thao",
            "Seira Hidano",
            "Vanessa Bracamonte",
            "S. Kiyomoto",
            "R. Yamaguchi"
        ],
        "title": "OPA2D: One-Pixel Attack, Detection, and Defense in Deep Neural Networks",
        "publication_date": "2021-07-18 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/IJCNN52387.2021.9534332",
        "urls": [
            "https://www.semanticscholar.org/paper/cd82df2384d23fc597821adf4656807c86fbce75"
        ],
        "id": "id6684326540925977531",
        "abstract": "Adversarial images have been proposed to deceive deep neural networks (DNNs) by adding perturbations to the pixels. Unlike existing attacks, Su et al. [1] analyzed an attack in an extremely limited constraint where only one pixel was modified. However, their one-pixel attack is easy to recognize by humans. In this paper, we improve the attack to enable the deceit of both DNNs and humans. We conducted a human recognition analysis to prove our attack's effect. We then propose detection and defense methods against the attack by re-attacking the adversarial images. Our experimental results on the six most recent convolutional neural networks show that while our attack achieved approximately the same success rates and confidence scores as in the existing attack, our attack achieves a higher success rate for deceiving humans. Only 49.41 % of participants can recognize our attack even though 81.04 % participants have recognized the existing attack. OPA2D detects 99.33% of the existing attack and 100% of our attack and defends 92.00% of the existing attack and 95.33 % of our attack.",
        "versions": [],
        "rank": 306
    },
    {
        "authors": [
            "Zhao, M.",
            "Barati, M."
        ],
        "title": "A Real-Time Fault Localization in Power Distribution Grid for Wildfire Detection Through Deep Convolutional Neural Networks",
        "publication_date": "2021-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/tia.2021.3083645",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/28/9488254/09440767.pdf?arnumber=9440767",
            "http://dx.doi.org/10.1109/tia.2021.3083645"
        ],
        "id": "id-8743414940974863417",
        "abstract": "",
        "versions": [],
        "rank": 307
    },
    {
        "authors": [
            "Thomas Gebhart",
            "Paul Schrater"
        ],
        "title": "Adversary Detection in Neural Networks via Persistent Homology",
        "publication_date": "2017-11-28 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "arXiv (Cornell University)",
        "volume": "",
        "doi": null,
        "urls": [
            "https://openalex.org/W2770859475"
        ],
        "id": "id-5165430571531179151",
        "abstract": "",
        "versions": [
            {
                "year": 2017,
                "source": "SupportedSources.ARXIV",
                "title": "Adversary Detection in Neural Networks via Persistent Homology",
                "journal": null,
                "urls": [
                    "http://arxiv.org/pdf/1711.10056v1",
                    "http://arxiv.org/abs/1711.10056v1",
                    "http://arxiv.org/pdf/1711.10056v1"
                ],
                "doi": "",
                "publication_date": "2017-11-28 00:08:10+00:00"
            }
        ],
        "rank": 308
    },
    {
        "authors": [
            "Yao Xiao"
        ],
        "title": "Vehicle Detection in Deep Learning",
        "publication_date": "2019-05-29 00:33:28+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1905.13390v1",
            "http://arxiv.org/abs/1905.13390v1",
            "http://arxiv.org/pdf/1905.13390v1"
        ],
        "id": "id3432447505230726342",
        "abstract": "Computer vision is developing rapidly with the support of deep learning\ntechniques. This thesis proposes an advanced vehicle-detection model based on\nan improvement to classical convolutional neural networks. The advanced model\nwas applied against a vehicle detection benchmark and was built to detect\non-road objects. First, we propose a high-level architecture for our advanced\nmodel, which utilizes different state-of-the-art deep learning techniques.\nThen, we utilize the residual neural networks and region proposal network to\nachieve competitive performance according to the vehicle detection benchmark.\nLastly, we describe the developing trend of vehicle detection techniques and\nthe future direction of research.",
        "versions": [],
        "rank": 309
    },
    {
        "authors": [
            "Andriluka, Mykhaylo",
            "Fei-Fei, Li",
            "Jin, Ning",
            "Mori, Greg",
            "Russakovsky, Olga",
            "Yeung, Serena"
        ],
        "title": "Every Moment Counts: Dense Detailed Labeling of Actions in Complex  Videos",
        "publication_date": "2017-06-09 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1007/s11263-017-1013-y",
        "urls": [
            "http://arxiv.org/abs/1507.05738"
        ],
        "id": "id-9168668763739612697",
        "abstract": "Every moment counts in action recognition. A comprehensive understanding of\nhuman activity in video requires labeling every frame according to the actions\noccurring, placing multiple labels densely over a video sequence. To study this\nproblem we extend the existing THUMOS dataset and introduce MultiTHUMOS, a new\ndataset of dense labels over unconstrained internet videos. Modeling multiple,\ndense labels benefits from temporal relations within and across classes. We\ndefine a novel variant of long short-term memory (LSTM) deep networks for\nmodeling these temporal relations via multiple input and output connections. We\nshow that this model improves action labeling accuracy and further enables\ndeeper understanding tasks ranging from structured retrieval to action\nprediction.Comment: To appear in IJC",
        "versions": [],
        "rank": 310
    },
    {
        "authors": [
            "Kolouri, Soheil",
            "Rohde, Gustavo K.",
            "Yin, Xuwang"
        ],
        "title": "Adversarial Example Detection and Classification With Asymmetrical  Adversarial Training",
        "publication_date": "2020-02-22 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "http://arxiv.org/abs/1905.11475"
        ],
        "id": "id-3120664874175074676",
        "abstract": "The vulnerabilities of deep neural networks against adversarial examples have\nbecome a significant concern for deploying these models in sensitive domains.\nDevising a definitive defense against such attacks is proven to be challenging,\nand the methods relying on detecting adversarial samples are only valid when\nthe attacker is oblivious to the detection mechanism. In this paper we first\npresent an adversarial example detection method that provides performance\nguarantee to norm constrained adversaries. The method is based on the idea of\ntraining adversarial robust subspace detectors using asymmetrical adversarial\ntraining (AAT). The novel AAT objective presents a minimax problem similar to\nthat of GANs; it has the same convergence property, and consequently supports\nthe learning of class conditional distributions. We first demonstrate that the\nminimax problem could be reasonably solved by PGD attack, and then use the\nlearned class conditional generative models to define generative\ndetection/classification models that are both robust and more interpretable. We\nprovide comprehensive evaluations of the above methods, and demonstrate their\ncompetitive performances and compelling properties on adversarial detection and\nrobust classification problems.Comment: ICLR 202",
        "versions": [],
        "rank": 311
    },
    {
        "authors": [
            "Xu, X."
        ],
        "title": "Deep Neural Networks for Fake News Detection",
        "publication_date": "2022-12-11 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/tocs56154.2022.10016102",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/10015896/10015907/10016102.pdf?arnumber=10016102",
            "http://dx.doi.org/10.1109/tocs56154.2022.10016102"
        ],
        "id": "id4707719832775566445",
        "abstract": "",
        "versions": [],
        "rank": 312
    },
    {
        "authors": [
            "Marcos Vendramini and Hugo Oliveira and Alexei Machado and Jefersson A. dos Santos"
        ],
        "title": "Opening Deep Neural Networks with Generative Models",
        "publication_date": "2021-06-30 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20210702012206/https://arxiv.org/pdf/2105.10013v3.pdf"
        ],
        "id": "id2128353116227733733",
        "abstract": "Image classification methods are usually trained to perform predictions taking into account a predefined group of known classes. Real-world problems, however, may not allow for a full knowledge of the input and label spaces, making failures in recognition a hazard to deep visual learning. Open set recognition methods are characterized by the ability to correctly identify inputs of known and unknown classes. In this context, we propose GeMOS: simple and plug-and-play open set recognition modules that can be attached to pretrained Deep Neural Networks for visual recognition. The GeMOS framework pairs pre-trained Convolutional Neural Networks with generative models for open set recognition to extract open set scores for each sample, allowing for failure recognition in object recognition tasks. We conduct a thorough evaluation of the proposed method in comparison with state-of-the-art open set algorithms, finding that GeMOS either outperforms or is statistically indistinguishable from more complex and costly models.",
        "versions": [],
        "rank": 313
    },
    {
        "authors": [
            "Alexander Toshev",
            "Christian Szegedy"
        ],
        "title": "DeepPose: Human Pose Estimation via Deep Neural Networks",
        "publication_date": "2014-06-23 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "arXiv (Cornell University)",
        "volume": "",
        "doi": "10.1109/cvpr.2014.214",
        "urls": [
            "https://openalex.org/W2113325037",
            "https://doi.org/10.1109/cvpr.2014.214",
            "http://arxiv.org/pdf/1312.4659"
        ],
        "id": "id-3272086944784243455",
        "abstract": "",
        "versions": [],
        "rank": 314
    },
    {
        "authors": [
            "L. F. Abbott",
            "Sacha B. Nelson"
        ],
        "title": "Synaptic plasticity: taming the beast",
        "publication_date": "2000-11-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Nature Neuroscience",
        "volume": "3",
        "doi": "10.1038/81453",
        "urls": [
            "https://openalex.org/W1489333352",
            "https://doi.org/10.1038/81453"
        ],
        "id": "id6199049528663786922",
        "abstract": "",
        "versions": [],
        "rank": 315
    },
    {
        "authors": [
            "D. Jain",
            "Akshi Kumar",
            "Akshat Shrivastava"
        ],
        "title": "CanarDeep: a hybrid deep neural model with mixed fusion for rumour detection in social data streams",
        "publication_date": "2022-01-08 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Neural Computing & Applications",
        "volume": "34",
        "doi": "10.1007/s00521-021-06743-8",
        "urls": [
            "https://www.semanticscholar.org/paper/4bedd0ebd39b91c3e60bceadec5001cc474e052d"
        ],
        "id": "id-4100119478144422715",
        "abstract": null,
        "versions": [],
        "rank": 316
    },
    {
        "authors": [
            "Wei, F.",
            "Nguyen, T."
        ],
        "title": "A Lightweight Deep Neural Model for SMS Spam Detection",
        "publication_date": "2020-10-20 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/isncc49221.2020.9297350",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/9297148/9297168/09297350.pdf?arnumber=9297350",
            "http://dx.doi.org/10.1109/isncc49221.2020.9297350"
        ],
        "id": "id-6711550848241322419",
        "abstract": "",
        "versions": [],
        "rank": 317
    },
    {
        "authors": [
            "Sebastian Cygert",
            "A. Czy\u017cewski"
        ],
        "title": "Robustness in Compressed Neural Networks for Object Detection",
        "publication_date": "2021-02-10 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/IJCNN52387.2021.9533773",
        "urls": [
            "https://www.semanticscholar.org/paper/8a79fb0a80564949cc4edd477adae71ac71f6003"
        ],
        "id": "id-1001809548941637032",
        "abstract": "Model compression techniques allow to significantly reduce the computational cost associated with data processing by deep neural networks with only a minor decrease in average accuracy. Simultaneously, reducing the model size may have a large effect on noisy cases or objects belonging to less frequent classes. It is a crucial problem from the perspective of the models' safety, especially for object detection in the autonomous driving setting, which is considered in this work. It was shown in the paper that the sensitivity of compressed models to different distortion types is nuanced, and some of the corruptions are heavily impacted by the compression methods (i.e., additive noise), while others (blur effect) are only slightly affected. A common way to improve the robustness of models is to use data augmentation, which was confirmed to positively affect models' robustness, also for highly compressed models. It was further shown that while data imbalance methods brought only a slight increase in accuracy for the baseline model (without compression), the impact was more striking at higher compression rates for the structured pruning. Finally, methods for handling data imbalance brought a significant improvement of the pruned models' worst-detected class accuracy.",
        "versions": [],
        "rank": 318
    },
    {
        "authors": [
            "Hwanjo Yu",
            "Sehun Yu",
            "Dongha Lee"
        ],
        "title": "Multi-Class Data Description for Out-of-distribution Detection",
        "publication_date": "2021-04-02 00:00:00",
        "source": "SupportedSources.PAPERS_WITH_CODE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://arxiv.org/pdf/2104.00941v1.pdf",
            "https://github.com/donalee/DeepMCDD"
        ],
        "id": "id381756536634428693",
        "abstract": "The capability of reliably detecting out-of-distribution samples is one of the key factors in deploying a good classifier, as the test distribution always does not match with the training distribution in most real-world applications. In this work, we present a deep multi-class data description, termed as Deep-MCDD, which is effective to detect out-of-distribution (OOD) samples as well as classify in-distribution (ID) samples. Unlike the softmax classifier that only focuses on the linear decision boundary partitioning its latent space into multiple regions, our Deep-MCDD aims to find a spherical decision boundary for each class which determines whether a test sample belongs to the class or not. By integrating the concept of Gaussian discriminant analysis into deep neural networks, we propose a deep learning objective to learn class-conditional distributions that are explicitly modeled as separable Gaussian distributions. Thereby, we can define the confidence score by the distance of a test sample from each class-conditional distribution, and utilize it for identifying OOD samples. Our empirical evaluation on multi-class tabular and image datasets demonstrates that Deep-MCDD achieves the best performances in distinguishing OOD samples while showing the classification accuracy as high as the other competitors.",
        "versions": [],
        "rank": 319
    },
    {
        "authors": [
            "Tsung-Yi Lin",
            "Priya Goyal",
            "Ross Girshick",
            "Kaiming He",
            "Piotr Doll\u00e1r"
        ],
        "title": "Focal Loss for Dense Object Detection",
        "publication_date": "2017-08-07 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "arXiv (Cornell University)",
        "volume": "",
        "doi": "10.1109/iccv.2017.324",
        "urls": [
            "https://openalex.org/W2963351448",
            "https://doi.org/10.1109/iccv.2017.324",
            "http://arxiv.org/pdf/1708.02002"
        ],
        "id": "id-2623687994012492830",
        "abstract": "",
        "versions": [],
        "rank": 320
    },
    {
        "authors": [
            "Tsung-Yi Lin",
            "Priya Goyal",
            "Ross Girshick",
            "Kaiming He",
            "Piotr Doll\u00e1r"
        ],
        "title": "Focal Loss for Dense Object Detection",
        "publication_date": "2020-02-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
        "volume": "42",
        "doi": "10.1109/tpami.2018.2858826",
        "urls": [
            "https://openalex.org/W2884561390",
            "https://doi.org/10.1109/tpami.2018.2858826",
            "http://arxiv.org/pdf/1708.02002"
        ],
        "id": "id1780443660270496133",
        "abstract": "",
        "versions": [],
        "rank": 321
    },
    {
        "authors": [
            "Carl Doersch",
            "Abhinav Gupta",
            "Alexei A. Efros"
        ],
        "title": "Unsupervised Visual Representation Learning by Context Prediction",
        "publication_date": "2015-12-07 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "International Conference on Computer Vision",
        "volume": "",
        "doi": "10.1109/iccv.2015.167",
        "urls": [
            "https://openalex.org/W343636949",
            "https://doi.org/10.1109/iccv.2015.167",
            "http://arxiv.org/pdf/1505.05192"
        ],
        "id": "id1400933485344222696",
        "abstract": "",
        "versions": [],
        "rank": 322
    },
    {
        "authors": [
            "Folino, G.",
            "Guarascio, M.",
            "Chiaravalloti, F."
        ],
        "title": "Learning ensembles of deep neural networks for extreme rainfall event detection",
        "publication_date": "2023-01-24 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/s00521-023-08238-0",
        "urls": [
            "https://link.springer.com/content/pdf/10.1007/s00521-023-08238-0.pdf",
            "https://link.springer.com/article/10.1007/s00521-023-08238-0/fulltext.html",
            "https://link.springer.com/content/pdf/10.1007/s00521-023-08238-0.pdf",
            "http://dx.doi.org/10.1007/s00521-023-08238-0"
        ],
        "id": "id-1342746577408961913",
        "abstract": "",
        "versions": [],
        "rank": 323
    },
    {
        "authors": [
            "Biggio, Battista",
            "Roli, Fabio"
        ],
        "title": "Wild Patterns: Ten Years After the Rise of Adversarial Machine Learning",
        "publication_date": "2018-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": null,
        "volume": "",
        "doi": "10.1016/j.patcog.2018.07.023",
        "urls": [
            "https://core.ac.uk/download/160465850.pdf"
        ],
        "id": "id7150819445340352577",
        "abstract": "Learning-based pattern classifiers, including deep networks, have shown\nimpressive performance in several application domains, ranging from computer\nvision to cybersecurity. However, it has also been shown that adversarial input\nperturbations carefully crafted either at training or at test time can easily\nsubvert their predictions. The vulnerability of machine learning to such wild\npatterns (also referred to as adversarial examples), along with the design of\nsuitable countermeasures, have been investigated in the research field of\nadversarial machine learning. In this work, we provide a thorough overview of\nthe evolution of this research area over the last ten years and beyond,\nstarting from pioneering, earlier work on the security of non-deep learning\nalgorithms up to more recent work aimed to understand the security properties\nof deep learning algorithms, in the context of computer vision and\ncybersecurity tasks. We report interesting connections between these\napparently-different lines of work, highlighting common misconceptions related\nto the security evaluation of machine-learning algorithms. We review the main\nthreat models and attacks defined to this end, and discuss the main limitations\nof current work, along with the corresponding future challenges towards the\ndesign of more secure learning algorithms.Comment: Accepted for publication on Pattern Recognition, 201",
        "versions": [],
        "rank": 324
    },
    {
        "authors": [
            "Marti A. Hearst",
            "Susan T. Dumais",
            "Emelia Osman",
            "Jeffrey L. Platt",
            "Bernhard Sch\u00f6lkopf"
        ],
        "title": "Support vector machines",
        "publication_date": "1998-07-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "IEEE Intelligent Systems & Their Applications",
        "volume": "13",
        "doi": "10.1109/5254.708428",
        "urls": [
            "https://openalex.org/W2008056655",
            "https://doi.org/10.1109/5254.708428"
        ],
        "id": "id3916665018893665644",
        "abstract": "",
        "versions": [],
        "rank": 325
    },
    {
        "authors": [
            "M. S. Badea",
            "I. I. Felea",
            "L. M. Florea",
            "C. Vertan"
        ],
        "title": "The use of deep learning in image segmentation, classification and detection",
        "publication_date": "2016-05-31 13:09:40+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1605.09612v1",
            "http://arxiv.org/abs/1605.09612v1",
            "http://arxiv.org/pdf/1605.09612v1"
        ],
        "id": "id-3834334438502014400",
        "abstract": "Recent years have shown that deep learned neural networks are a valuable tool\nin the field of computer vision. This paper addresses the use of two different\nkinds of network architectures, namely LeNet and Network in Network (NiN). They\nwill be compared in terms of both performance and computational efficiency by\naddressing the classification and detection problems. In this paper, multiple\ndatabases will be used to test the networks. One of them contains images\ndepicting burn wounds from pediatric cases, another one contains an extensive\nnumber of art images and other facial databases were used for facial keypoints\ndetection.",
        "versions": [],
        "rank": 326
    },
    {
        "authors": [
            "Debaditya Roy",
            "Vangjush Komini",
            "Sarunas Girdzijauskas"
        ],
        "title": "Out of distribution in Human Activity Recognition",
        "publication_date": "2022-06-13 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Zenodo",
        "volume": "",
        "doi": "10.5281/zenodo.7224708",
        "urls": [
            "https://web.archive.org/web/20221129162234/https://zenodo.org/record/7224708/files/Out-of-distribution_in_Human_Activity_Recognition.pdf"
        ],
        "id": "id1171672316094459178",
        "abstract": "With the growing interest of the research community in making deep learning (DL) robust and reliable, detecting out-of-distribution (OOD) data has become critical. Detecting OOD inputs during test/prediction allows the model to account for discriminative features unknown to the model. This capability increases the model's reliability since this model provides a class prediction solely at incoming data similar to the training one. OOD detection is well-established in computer vision problems. However, it remains relatively under-explored in other domains such as time series (i.e., Human Activity Recognition (HAR)). Since uncertainty has been a critical driver for OOD in vision-based models, the same component has proven effective in time-series applications. We plan to address the OOD detection problem in HAR with time-series data in this work. To test the capability of the proposed method, we define different types of OOD for HAR that arise from realistic scenarios. We apply an ensemble-based temporal learning framework that incorporates uncertainty and detects OOD for the defined HAR workloads. In particular, we extract OODs from popular benchmark HAR datasets and use the framework to separate those OODs from the in-distribution (ID) data. Across all the datasets, the ensemble framework outperformed the traditional deep-learning method (our baseline) on the OOD detection task.",
        "versions": [],
        "rank": 327
    },
    {
        "authors": [
            "Li, X.",
            "Desrosiers, C.",
            "Liu, X."
        ],
        "title": "Deep Neural Forest for Out-of-Distribution Detection of Skin Lesion Images",
        "publication_date": "2023-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/jbhi.2022.3171582",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/6221020/10006388/09767570.pdf?arnumber=9767570",
            "http://dx.doi.org/10.1109/jbhi.2022.3171582"
        ],
        "id": "id3320862584429309525",
        "abstract": "",
        "versions": [],
        "rank": 328
    },
    {
        "authors": [
            "Fadhel, Mariem Ben",
            "Nyarko, Kofi"
        ],
        "title": "GAN Augmented Text Anomaly Detection with Sequences of Deep Statistics",
        "publication_date": "2019-04-24 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ciss.2019.8693024",
        "urls": [
            "http://arxiv.org/abs/1904.11094"
        ],
        "id": "id-6373378240399919001",
        "abstract": "Anomaly detection is the process of finding data points that deviate from a\nbaseline. In a real-life setting, anomalies are usually unknown or extremely\nrare. Moreover, the detection must be accomplished in a timely manner or the\nrisk of corrupting the system might grow exponentially. In this work, we\npropose a two level framework for detecting anomalies in sequences of discrete\nelements. First, we assess whether we can obtain enough information from the\nstatistics collected from the discriminator's layers to discriminate between\nout of distribution and in distribution samples. We then build an unsupervised\nanomaly detection module based on these statistics. As to augment the data and\nkeep track of classes of known data, we lean toward a semi-supervised\nadversarial learning applied to discrete elements.Comment: 5 pages, 53rd Annual Conference on Information Sciences and Systems,\n  CISS 201",
        "versions": [],
        "rank": 329
    },
    {
        "authors": [
            "Otkrist Gupta",
            "Ramesh Raskar"
        ],
        "title": "Distributed learning of deep neural network over multiple agents",
        "publication_date": "2018-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Elsevier BV",
        "volume": "",
        "doi": "10.1016/j.jnca.2018.05.003",
        "urls": [
            "https://web.archive.org/web/20200320124338/http://tsp.techscience.com/uploads/attached/file/20190628/20190628004305_71836.pdf"
        ],
        "id": "id944113893666489345",
        "abstract": "Deep Learning presents a critical capability to be geared into environments being constantly changed and ongoing learning dynamic, which is especially relevant in Network Intrusion Detection. In this paper, as enlightened by the theory of Deep Learning Neural Networks, Hierarchy Distributed-Agents Model for Network Risk Evaluation, a newly developed model, is proposed. The architecture taken on by the distributed-agents model are given, as well as the approach of analyzing network intrusion detection using Deep Learning, the mechanism of sharing hyper-parameters to improve the efficiency of learning is presented, and the hierarchical evaluative framework for Network Risk Evaluation of the proposed model is built. Furthermore, to examine the proposed model, a series of experiments were conducted in terms of NSL-KDD datasets. The proposed model was able to differentiate between normal and abnormal network activities with an accuracy of 97.60% on NSL-KDD datasets. As the results acquired from the experiment indicate, the model developed in this paper is characterized by high-speed and high-accuracy processing which shall offer a preferable solution with regard to the Risk Evaluation in Network.",
        "versions": [],
        "rank": 330
    },
    {
        "authors": [
            "Shahrzad Faghih-Roohi",
            "S. Hajizadeh",
            "A. N\u00fa\u00f1ez",
            "R. Babu\u0161ka",
            "B. Schutter"
        ],
        "title": "Deep convolutional neural networks for detection of rail surface defects",
        "publication_date": "2016-07-24 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/IJCNN.2016.7727522",
        "urls": [
            "https://www.semanticscholar.org/paper/5f86851ccdcbdb0d5a939e216ad8425d8a0887b4"
        ],
        "id": "id5750118983208477447",
        "abstract": "In this paper, we propose a deep convolutional neural network solution to the analysis of image data for the detection of rail surface defects. The images are obtained from many hours of automated video recordings. This huge amount of data makes it impossible to manually inspect the images and detect rail surface defects. Therefore, automated detection of rail defects can help to save time and costs, and to ensure rail transportation safety. However, one major challenge is that the extraction of suitable features for detection of rail surface defects is a non-trivial and difficult task. Therefore, we propose to use convolutional neural networks as a viable technique for feature learning. Deep convolutional neural networks have recently been applied to a number of similar domains with success. We compare the results of different network architectures characterized by different sizes and activation functions. In this way, we explore the efficiency of the proposed deep convolutional neural network for detection and classification. The experimental results are promising and demonstrate the capability of the proposed approach.",
        "versions": [
            {
                "year": 2016,
                "source": "SupportedSources.CROSSREF",
                "title": "Deep convolutional neural networks for detection of rail surface defects",
                "journal": "",
                "urls": [
                    "http://xplorestaging.ieee.org/ielx7/7593175/7726591/07727522.pdf?arnumber=7727522",
                    "http://dx.doi.org/10.1109/ijcnn.2016.7727522"
                ],
                "doi": "10.1109/ijcnn.2016.7727522",
                "publication_date": "2016-01-01 00:00:00"
            }
        ],
        "rank": 331
    },
    {
        "authors": [
            "D Hoiem",
            "H Li",
            "J Xu",
            "M Everingham",
            "P Agrawal",
            "Y Bengio"
        ],
        "title": "What is Holding Back Convnets for Detection?",
        "publication_date": "2015-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": null,
        "volume": "",
        "doi": "10.1007/978-3-319-24947-6_43",
        "urls": [
            "http://arxiv.org/abs/1508.02844"
        ],
        "id": "id-6292475357296865532",
        "abstract": "Convolutional neural networks have recently shown excellent results in\ngeneral object detection and many other tasks. Albeit very effective, they\ninvolve many user-defined design choices. In this paper we want to better\nunderstand these choices by inspecting two key aspects \"what did the network\nlearn?\", and \"what can the network learn?\". We exploit new annotations\n(Pascal3D+), to enable a new empirical analysis of the R-CNN detector. Despite\ncommon belief, our results indicate that existing state-of-the-art convnet\narchitectures are not invariant to various appearance factors. In fact, all\nconsidered networks have similar weak points which cannot be mitigated by\nsimply increasing the training data (architectural changes are needed). We show\nthat overall performance can improve when using image renderings for data\naugmentation. We report the best known results on the Pascal3D+ detection and\nview-point estimation tasks",
        "versions": [],
        "rank": 332
    },
    {
        "authors": [
            "Benito Picazo, Jes\u00fas",
            "Dom\u00ednguez-Merino, Enrique",
            "L\u00f3pez-Rubio, Ezequiel",
            "Ortiz-de-lazcano-Lobato, Juan Miguel",
            "Palomo, Esteban J."
        ],
        "title": "Deep learning-based anomalous object detection system powered by microcontroller for PTZ cameras",
        "publication_date": "2018-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ijcnn.2018.8489437",
        "urls": [
            "https://core.ac.uk/download/214840920.pdf"
        ],
        "id": "id1526753127205231193",
        "abstract": "Automatic video surveillance systems are usually designed to detect anomalous objects being present in a scene or behaving dangerously. In order to perform adequately, they must incorporate models able to achieve accurate pattern recognition\r\nin an image, and deep learning neural networks excel at this task. However, exhaustive scan of the full image results in multiple image blocks or windows to analyze, which could make the time performance of the system very poor when implemented on low cost devices. This paper presents a system which attempts to\r\ndetect abnormal moving objects within an area covered by a PTZ camera while it is panning. The decision about the block of the image to analyze is based on a mixture distribution composed of two components: a uniform probability distribution, which\r\nrepresents a blind random selection, and a mixture of Gaussian probability distributions. Gaussian distributions represent windows in the image where anomalous objects were detected previously and contribute to generate the next window to analyze close to those windows of interest. The system is implemented on\r\na Raspberry Pi microcontroller-based board, which enables the design and implementation of a low-cost monitoring system that is able to perform image processing.Universidad de M\u00e1laga. Campus de Excelencia Internacional Andaluc\u00eda Tech",
        "versions": [],
        "rank": 333
    },
    {
        "authors": [
            "Clement Farabet",
            "Camille Couprie",
            "Laurent Najman",
            "Yann LeCun"
        ],
        "title": "Learning Hierarchical Features for Scene Labeling",
        "publication_date": "2013-08-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
        "volume": "35",
        "doi": "10.1109/tpami.2012.231",
        "urls": [
            "https://openalex.org/W2022508996",
            "https://doi.org/10.1109/tpami.2012.231",
            "http://yann.lecun.com/exdb/publis/pdf/farabet-pami-13.pdf"
        ],
        "id": "id-7513733665866155917",
        "abstract": "",
        "versions": [],
        "rank": 334
    },
    {
        "authors": [
            "Jacob Biamonte",
            "Peter Wittek",
            "Nicola Pancotti",
            "Patrick Rebentrost",
            "Nathan Wiebe",
            "Seth Lloyd"
        ],
        "title": "Quantum machine learning",
        "publication_date": "2017-09-13 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Nature",
        "volume": "549",
        "doi": "10.1038/nature23474",
        "urls": [
            "https://openalex.org/W2559394418",
            "https://doi.org/10.1038/nature23474",
            "http://arxiv.org/pdf/1611.09347"
        ],
        "id": "id-1501515260361918270",
        "abstract": "",
        "versions": [],
        "rank": 335
    },
    {
        "authors": [
            "Elflein, Sven"
        ],
        "title": "Master's Thesis: Out-of-distribution Detection with Energy-based Models",
        "publication_date": "2023-03-24 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "http://arxiv.org/abs/2302.12002"
        ],
        "id": "id2879100269649051342",
        "abstract": "Today, deep learning is increasingly applied in security-critical situations\nsuch as autonomous driving and medical diagnosis. Despite its success, the\nbehavior and robustness of deep networks are not fully understood yet, posing a\nsignificant risk. In particular, researchers recently found that neural\nnetworks are overly confident in their predictions, even on data they have\nnever seen before. To tackle this issue, one can differentiate two approaches\nin the literature. One accounts for uncertainty in the predictions, while the\nsecond estimates the underlying density of the training data to decide whether\na given input is close to the training data, and thus the network is able to\nperform as expected.In this thesis, we investigate the capabilities of EBMs at\nthe task of fitting the training data distribution to perform detection of\nout-of-distribution (OOD) inputs. We find that on most datasets, EBMs do not\ninherently outperform other density estimators at detecting OOD data despite\ntheir flexibility. Thus, we additionally investigate the effects of\nsupervision, dimensionality reduction, and architectural modifications on the\nperformance of EBMs. Further, we propose Energy-Prior Network (EPN) which\nenables estimation of various uncertainties within an EBM for classification,\nbridging the gap between two approaches for tackling the OOD detection problem.\nWe identify a connection between the concentration parameters of the Dirichlet\ndistribution and the joint energy in an EBM. Additionally, this allows\noptimization without a held-out OOD dataset, which might not be available or\ncostly to collect in some applications. Finally, we empirically demonstrate\nthat Energy-Prior Network (EPN) is able to detect OOD inputs, datasets shifts,\nand adversarial examples. Theoretically, EPN offers favorable properties for\nthe asymptotic case when inputs are far from the training data.Comment: Master's Thesi",
        "versions": [],
        "rank": 336
    },
    {
        "authors": [
            "Balaji Lakshminarayanan",
            "Dustin Tran",
            "Jasper Snoek",
            "Zack Nado",
            "Ghassen Jerfel",
            "Yeming Wen",
            "Zi Lin",
            "Jie Ren",
            "Shreyas Padhy",
            "Jeremiah Zhe Liu"
        ],
        "title": "A Simple Approach to Improve Single-Model Deep Uncertainty via Distance-Awareness",
        "publication_date": "2022-05-01 00:00:00",
        "source": "SupportedSources.PAPERS_WITH_CODE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://arxiv.org/pdf/2205.00403v2.pdf",
            "https://github.com/google/uncertainty-baselines"
        ],
        "id": "id-61639756824815647",
        "abstract": "Accurate uncertainty quantification is a major challenge in deep learning, as neural networks can make overconfident errors and assign high confidence predictions to out-of-distribution (OOD) inputs. The most popular approaches to estimate predictive uncertainty in deep learning are methods that combine predictions from multiple neural networks, such as Bayesian neural networks (BNNs) and deep ensembles. However their practicality in real-time, industrial-scale applications are limited due to the high memory and computational cost. Furthermore, ensembles and BNNs do not necessarily fix all the issues with the underlying member networks. In this work, we study principled approaches to improve uncertainty property of a single network, based on a single, deterministic representation. By formalizing the uncertainty quantification as a minimax learning problem, we first identify distance awareness, i.e., the model's ability to quantify the distance of a testing example from the training data, as a necessary condition for a DNN to achieve high-quality (i.e., minimax optimal) uncertainty estimation. We then propose Spectral-normalized Neural Gaussian Process (SNGP), a simple method that improves the distance-awareness ability of modern DNNs with two simple changes: (1) applying spectral normalization to hidden weights to enforce bi-Lipschitz smoothness in representations and (2) replacing the last output layer with a Gaussian process layer. On a suite of vision and language understanding benchmarks, SNGP outperforms other single-model approaches in prediction, calibration and out-of-domain detection. Furthermore, SNGP provides complementary benefits to popular techniques such as deep ensembles and data augmentation, making it a simple and scalable building block for probabilistic deep learning. Code is open-sourced at https://github.com/google/uncertainty-baselines",
        "versions": [],
        "rank": 337
    },
    {
        "authors": [
            "Ayub, Afsheen",
            "Elahi, Hassan",
            "Frezza, Fabrizio",
            "Munir, Khushboo",
            "Rizzi, Antonello"
        ],
        "title": "Cancer diagnosis using deep learning: A bibliographic review",
        "publication_date": "2019-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.3390/cancers11091235",
        "urls": [
            "https://core.ac.uk/download/231746843.pdf"
        ],
        "id": "id-8516577240824559051",
        "abstract": "In this paper, we first describe the basics of the field of cancer diagnosis, which includes steps of cancer diagnosis followed by the typical classification methods used by doctors, providing a historical idea of cancer classification techniques to the readers. These methods include Asymmetry, Border, Color and Diameter (ABCD) method, seven-point detection method, Menzies method, and pattern analysis. They are used regularly by doctors for cancer diagnosis, although they are not considered very efficient for obtaining better performance. Moreover, considering all types of audience, the basic evaluation criteria are also discussed. The criteria include the receiver operating characteristic curve (ROC curve), Area under the ROC curve (AUC), F1 score, accuracy, specificity, sensitivity, precision, dice-coefficient, average accuracy, and Jaccard index. Previously used methods are considered inefficient, asking for better and smarter methods for cancer diagnosis. Artificial intelligence and cancer diagnosis are gaining attention as a way to define better diagnostic tools. In particular, deep neural networks can be successfully used for intelligent image analysis. The basic framework of how this machine learning works on medical imaging is provided in this study, i.e., pre-processing, image segmentation and post-processing. The second part of this manuscript describes the different deep learning techniques, such as convolutional neural networks (CNNs), generative adversarial models (GANs), deep autoencoders (DANs), restricted Boltzmann\u2019s machine (RBM), stacked autoencoders (SAE), convolutional autoencoders (CAE), recurrent neural networks (RNNs), long short-term memory (LTSM), multi-scale convolutional neural network (M-CNN), multi-instance learning convolutional neural network (MIL-CNN). For each technique, we provide Python codes, to allow interested readers to experiment with the cited algorithms on their own diagnostic problems. The third part of this manuscript compiles the successfully applied deep learning models for different types of cancers. Considering the length of the manuscript, we restrict ourselves to the discussion of breast cancer, lung cancer, brain cancer, and skin cancer. The purpose of this bibliographic review is to provide researchers opting to work in implementing deep learning and artificial neural networks for cancer diagnosis a knowledge from scratch of the state-of-the-art achievements",
        "versions": [],
        "rank": 338
    },
    {
        "authors": [
            "Tao Ma",
            "Fen Wang",
            "Jianjun Cheng",
            "Yang Yu",
            "Xiaoyun Chen"
        ],
        "title": "A Hybrid Spectral Clustering and Deep Neural Network Ensemble Algorithm for Intrusion Detection in Sensor Networks",
        "publication_date": "2016-10-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Sensors (Basel, Switzerland)",
        "volume": "16",
        "doi": "10.3390/s16101701",
        "urls": [
            "https://www.semanticscholar.org/paper/70f1a7c7a09f56257aea7189ffccc4cebba9752c"
        ],
        "id": "id8773960885974648615",
        "abstract": "The development of intrusion detection systems (IDS) that are adapted to allow routers and network defence systems to detect malicious network traffic disguised as network protocols or normal access is a critical challenge. This paper proposes a novel approach called SCDNN, which combines spectral clustering (SC) and deep neural network (DNN) algorithms. First, the dataset is divided into k subsets based on sample similarity using cluster centres, as in SC. Next, the distance between data points in a testing set and the training set is measured based on similarity features and is fed into the deep neural network algorithm for intrusion detection. Six KDD-Cup99 and NSL-KDD datasets and a sensor network dataset were employed to test the performance of the model. These experimental results indicate that the SCDNN classifier not only performs better than backpropagation neural network (BPNN), support vector machine (SVM), random forest (RF) and Bayes tree models in detection accuracy and the types of abnormal attacks found. It also provides an effective tool of study and analysis of intrusion detection in large networks.",
        "versions": [],
        "rank": 339
    },
    {
        "authors": [
            "Lingkai Kong",
            "Jimeng Sun",
            "Chao Zhang"
        ],
        "title": "SDE-Net: Equipping Deep Neural Networks with Uncertainty Estimates",
        "publication_date": "2020-08-24 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20200909043631/https://arxiv.org/pdf/2008.10546v1.pdf"
        ],
        "id": "id-357605135635654577",
        "abstract": "Uncertainty quantification is a fundamental yet unsolved problem for deep learning. The Bayesian framework provides a principled way of uncertainty estimation but is often not scalable to modern deep neural nets (DNNs) that have a large number of parameters. Non-Bayesian methods are simple to implement but often conflate different sources of uncertainties and require huge computing resources. We propose a new method for quantifying uncertainties of DNNs from a dynamical system perspective. The core of our method is to view DNN transformations as state evolution of a stochastic dynamical system and introduce a Brownian motion term for capturing epistemic uncertainty. Based on this perspective, we propose a neural stochastic differential equation model (SDE-Net) which consists of (1) a drift net that controls the system to fit the predictive function; and (2) a diffusion net that captures epistemic uncertainty. We theoretically analyze the existence and uniqueness of the solution to SDE-Net. Our experiments demonstrate that the SDE-Net model can outperform existing uncertainty estimation methods across a series of tasks where uncertainty plays a fundamental role.",
        "versions": [],
        "rank": 340
    },
    {
        "authors": [
            "Pedro Vin\u00edcius A. B. de Ven\u00e2ncio",
            "A. C. Lisboa",
            "A. V. Barbosa"
        ],
        "title": "An automatic fire detection system based on deep convolutional neural networks for low-power, resource-constrained devices",
        "publication_date": "2022-06-30 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Neural Computing and Applications",
        "volume": "34",
        "doi": "10.1007/s00521-022-07467-z",
        "urls": [
            "https://www.semanticscholar.org/paper/2390b3e87983943f801209bbbabd9788632052f6"
        ],
        "id": "id-3066419648834199798",
        "abstract": null,
        "versions": [],
        "rank": 341
    },
    {
        "authors": [
            "Yunjie Liu",
            "Evan Racah",
            "Prabhat",
            "Joaquin Correa",
            "Amir Khosrowshahi",
            "David Lavers",
            "Kenneth Kunkel",
            "Michael Wehner",
            "William Collins"
        ],
        "title": "Application of Deep Convolutional Neural Networks for Detecting Extreme Weather in Climate Datasets",
        "publication_date": "2016-05-04 06:38:19+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1605.01156v1",
            "http://arxiv.org/abs/1605.01156v1",
            "http://arxiv.org/pdf/1605.01156v1"
        ],
        "id": "id-1512940481788068197",
        "abstract": "Detecting extreme events in large datasets is a major challenge in climate\nscience research. Current algorithms for extreme event detection are build upon\nhuman expertise in defining events based on subjective thresholds of relevant\nphysical variables. Often, multiple competing methods produce vastly different\nresults on the same dataset. Accurate characterization of extreme events in\nclimate simulations and observational data archives is critical for\nunderstanding the trends and potential impacts of such events in a climate\nchange content. This study presents the first application of Deep Learning\ntechniques as alternative methodology for climate extreme events detection.\nDeep neural networks are able to learn high-level representations of a broad\nclass of patterns from labeled data. In this work, we developed deep\nConvolutional Neural Network (CNN) classification system and demonstrated the\nusefulness of Deep Learning technique for tackling climate pattern detection\nproblems. Coupled with Bayesian based hyper-parameter optimization scheme, our\ndeep CNN system achieves 89\\%-99\\% of accuracy in detecting extreme events\n(Tropical Cyclones, Atmospheric Rivers and Weather Fronts",
        "versions": [],
        "rank": 342
    },
    {
        "authors": [
            "Hu, Peiyun",
            "Ramanan, Deva"
        ],
        "title": "Bottom-Up and Top-Down Reasoning with Hierarchical Rectified Gaussians",
        "publication_date": "2016-05-04 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/cvpr.2016.604",
        "urls": [
            "http://arxiv.org/abs/1507.05699"
        ],
        "id": "id6114047488403570541",
        "abstract": "Convolutional neural nets (CNNs) have demonstrated remarkable performance in\nrecent history. Such approaches tend to work in a unidirectional bottom-up\nfeed-forward fashion. However, practical experience and biological evidence\ntells us that feedback plays a crucial role, particularly for detailed spatial\nunderstanding tasks. This work explores bidirectional architectures that also\nreason with top-down feedback: neural units are influenced by both lower and\nhigher-level units.\n  We do so by treating units as rectified latent variables in a quadratic\nenergy function, which can be seen as a hierarchical Rectified Gaussian model\n(RGs). We show that RGs can be optimized with a quadratic program (QP), that\ncan in turn be optimized with a recurrent neural network (with rectified linear\nunits). This allows RGs to be trained with GPU-optimized gradient descent. From\na theoretical perspective, RGs help establish a connection between CNNs and\nhierarchical probabilistic models. From a practical perspective, RGs are well\nsuited for detailed spatial tasks that can benefit from top-down reasoning. We\nillustrate them on the challenging task of keypoint localization under\nocclusions, where local bottom-up evidence may be misleading. We demonstrate\nstate-of-the-art results on challenging benchmarks.Comment: To appear in CVPR 201",
        "versions": [],
        "rank": 343
    },
    {
        "authors": [
            "Yang, Y.",
            "Eshraghian, J.",
            "Truong, N.",
            "Nikpour, A.",
            "Kavehei, O."
        ],
        "title": "Neuromorphic Deep Spiking Neural Networks for Seizure Detection",
        "publication_date": "2022-08-11 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.36227/techrxiv.20444970",
        "urls": [
            "https://ndownloader.figshare.com/files/36583380",
            "http://dx.doi.org/10.36227/techrxiv.20444970"
        ],
        "id": "id-2961056392315090886",
        "abstract": "",
        "versions": [],
        "rank": 344
    },
    {
        "authors": [
            "Yang, Y.",
            "Eshraghian, J.",
            "Truong, N.",
            "Nikpour, A.",
            "Kavehei, O."
        ],
        "title": "Neuromorphic Deep Spiking Neural Networks for Seizure Detection",
        "publication_date": "2022-08-11 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.36227/techrxiv.20444970.v1",
        "urls": [
            "https://ndownloader.figshare.com/files/36583380",
            "http://dx.doi.org/10.36227/techrxiv.20444970.v1"
        ],
        "id": "id-6357840364191511593",
        "abstract": "",
        "versions": [],
        "rank": 345
    },
    {
        "authors": [
            "K. R. M. Fernando",
            "Cris P Tsokos"
        ],
        "title": "Dynamically Weighted Balanced Loss: Class Imbalanced Learning and Confidence Calibration of Deep Neural Networks",
        "publication_date": "2021-01-14 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "IEEE Transactions on Neural Networks and Learning Systems",
        "volume": "33",
        "doi": "10.1109/TNNLS.2020.3047335",
        "urls": [
            "https://www.semanticscholar.org/paper/96f350e5a03276b865b3668110f3f37909646f11"
        ],
        "id": "id-8852933391955211198",
        "abstract": "Imbalanced class distribution is an inherent problem in many real-world classification tasks where the minority class is the class of interest. Many conventional statistical and machine learning classification algorithms are subject to frequency bias, and learning discriminating boundaries between the minority and majority classes could be challenging. To address the class distribution imbalance in deep learning, we propose a class rebalancing strategy based on a class-balanced dynamically weighted loss function where weights are assigned based on the class frequency and predicted probability of ground-truth class. The ability of dynamic weighting scheme to self-adapt its weights depending on the prediction scores allows the model to adjust for instances with varying levels of difficulty resulting in gradient updates driven by hard minority class samples. We further show that the proposed loss function is classification calibrated. Experiments conducted on highly imbalanced data across different applications of cyber intrusion detection (CICIDS2017 data set) and medical imaging (ISIC2019 data set) show robust generalization. Theoretical results supported by superior empirical performance provide justification for the validity of the proposed dynamically weighted balanced (DWB) loss function.",
        "versions": [],
        "rank": 346
    },
    {
        "authors": [
            "Abdoulwase M. Obaid Al-Azzani",
            "Ali Mohammed Afif"
        ],
        "title": "Intrusion Detection System using Deep Neural Networks and Principal Component Analysis",
        "publication_date": "2021-05-30 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Zain Publications",
        "volume": "",
        "doi": "10.47760/ijcsmc.2021.v10i05.012",
        "urls": [
            "https://web.archive.org/web/20220310030432/https://ijcsmc.com/docs/papers/May2021/V10I5202119.pdf"
        ],
        "id": "id216641434478905658",
        "abstract": "The amount of data on the internet is growing daily, because of using the smart phones, social network, and IoT. This growing had impact on data security. Therefore security become the biggest challenge for researchers and developers, moreover, most of security tools (firewall, IDS, IPS, etc.) have limitations to detect all threats. Deep Learning is one of Machine Learning approach, it is an efficient artifice that can be applied to intrusion detection, to ascertain a new outline from the massive network data, as well as it used to reduce the strain of the manual compilations of the normal and abnormal behaviour patterns. In this paper we build a model for detect threats based on Principal Component Analysis (PCA) for reduction dimensions of dataset, and deep neural network for the classification. We used KDD99 dataset and 10_ percentage of KDD99 dataset to train and test the model in Spark environment. In experiment DNN of layers ranging from 1 to 3 with 300 number of epotch. The results were compared and concluded that a DNN of 1 layer has superior performance with 0.929 as accuracy.",
        "versions": [],
        "rank": 347
    },
    {
        "authors": [
            "David Novoa-Paradela",
            "Oscar Romero-Fontenla",
            "Bertha Guijarro-Berdi\u00f1as"
        ],
        "title": "Fast Deep Autoencoder for Federated learning",
        "publication_date": "2022-06-13 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20220706045342/https://arxiv.org/pdf/2206.05136v2.pdf"
        ],
        "id": "id1794369057516305202",
        "abstract": "This paper presents a novel, fast and privacy preserving implementation of deep autoencoders. DAEF (Deep Autoencoder for Federated learning), unlike traditional neural networks, trains a deep autoencoder network in a non-iterative way, which drastically reduces its training time. Its training can be carried out in a distributed way (several partitions of the dataset in parallel) and incrementally (aggregation of partial models), and due to its mathematical formulation, the data that is exchanged does not endanger the privacy of the users. This makes DAEF a valid method for edge computing and federated learning scenarios. The method has been evaluated and compared to traditional (iterative) deep autoencoders using seven real anomaly detection datasets, and their performance have been shown to be similar despite DAEF's faster training.",
        "versions": [],
        "rank": 348
    },
    {
        "authors": [
            "Arcos Garc\u00eda, \u00c1lvaro",
            "Soria Morillo, Luis Miguel",
            "\u00c1lvarez Garc\u00eda, Juan Antonio"
        ],
        "title": "Deep neural network for traffic sign recognition systems: An analysis of spatial transformers and stochastic optimisation methods",
        "publication_date": "2018-03-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": null,
        "volume": "",
        "doi": "10.1016/j.neunet.2018.01.005",
        "urls": [
            "https://core.ac.uk/download/185608258.pdf"
        ],
        "id": "id9046569128524611188",
        "abstract": "This paper presents a Deep Learning approach for traffic sign recognition systems. Several classification experiments are conducted over publicly available traffic sign datasets from Germany and Belgium using a Deep Neural Network which comprises Convolutional layers and Spatial Transformer Networks. Such trials are built to measure the impact of diverse factors with the end goal of designing a Convolutional Neural Network that can improve the state-of-the-art of traffic sign classification task. First, different adaptive and non-adaptive stochastic gradient descent optimisation algorithms such as SGD, SGD-Nesterov, RMSprop and Adam are evaluated. Subsequently, multiple combinations of Spatial Transformer Networks placed at distinct positions within the main neural network are analysed. The recognition rate of the proposed Convolutional Neural Network reports an accuracy of 99.71% in the German Traffic Sign Recognition Benchmark, outperforming previous state-of-the-art methods and also being more efficient in terms of memory requirements.Ministerio de Econom\u00eda y Competitividad TIN2017-82113-C2-1-RMinisterio de Econom\u00eda y Competitividad TIN2013-46801-C4-1-",
        "versions": [],
        "rank": 349
    },
    {
        "authors": [
            "Rana Abou Khamis",
            "Omair Shafiq",
            "Ashraf Matrawy"
        ],
        "title": "Investigating Resistance of Deep Learning-based IDS against Adversaries using min-max Optimization",
        "publication_date": "2019-10-30 19:55:26+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1910.14107v1",
            "http://arxiv.org/abs/1910.14107v1",
            "http://arxiv.org/pdf/1910.14107v1"
        ],
        "id": "id-6586218802590675729",
        "abstract": "With the growth of adversarial attacks against machine learning models,\nseveral concerns have emerged about potential vulnerabilities in designing deep\nneural network-based intrusion detection systems (IDS). In this paper, we study\nthe resilience of deep learning-based intrusion detection systems against\nadversarial attacks. We apply the min-max (or saddle-point) approach to train\nintrusion detection systems against adversarial attack samples in NSW-NB 15\ndataset. We have the max approach for generating adversarial samples that\nachieves maximum loss and attack deep neural networks. On the other side, we\nutilize the existing min approach [2] [9] as a defense strategy to optimize\nintrusion detection systems that minimize the loss of the incorporated\nadversarial samples during the adversarial training. We study and measure the\neffectiveness of the adversarial attack methods as well as the resistance of\nthe adversarially trained models against such attacks. We find that the\nadversarial attack methods that were designed in binary domains can be used in\ncontinuous domains and exhibit different misclassification levels. We finally\nshow that principal component analysis (PCA) based feature reduction can boost\nthe robustness in intrusion detection system (IDS) using a deep neural network\n(DNN).",
        "versions": [],
        "rank": 350
    },
    {
        "authors": [
            "Xing Su",
            "Shan Xue",
            "Fanzhen Liu",
            "Jia Wu",
            "Jian Yang",
            "Chuan Zhou",
            "Wenbin Hu",
            "Cecile Paris",
            "Surya Nepal",
            "Di Jin",
            "Quan Z. Sheng",
            "Philip S. Yu"
        ],
        "title": "A Comprehensive Survey on Community Detection with Deep Learning",
        "publication_date": "2021-05-26 14:37:07+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": "IEEE Transactions on Neural Networks and Learning Systems, 2022:\n  1-21",
        "volume": "",
        "doi": "10.1109/TNNLS.2021.3137396",
        "urls": [
            "http://arxiv.org/pdf/2105.12584v2",
            "http://dx.doi.org/10.1109/TNNLS.2021.3137396",
            "http://arxiv.org/abs/2105.12584v2",
            "http://arxiv.org/pdf/2105.12584v2"
        ],
        "id": "id-4176263462377297498",
        "abstract": "A community reveals the features and connections of its members that are\ndifferent from those in other communities in a network. Detecting communities\nis of great significance in network analysis. Despite the classical spectral\nclustering and statistical inference methods, we notice a significant\ndevelopment of deep learning techniques for community detection in recent years\nwith their advantages in handling high dimensional network data. Hence, a\ncomprehensive overview of community detection's latest progress through deep\nlearning is timely to academics and practitioners. This survey devises and\nproposes a new taxonomy covering different state-of-the-art methods, including\ndeep learning-based models upon deep neural networks, deep nonnegative matrix\nfactorization and deep sparse filtering. The main category, i.e., deep neural\nnetworks, is further divided into convolutional networks, graph attention\nnetworks, generative adversarial networks and autoencoders. The survey also\nsummarizes the popular benchmark data sets, evaluation metrics, and open-source\nimplementations to address experimentation settings. We then discuss the\npractical applications of community detection in various domains and point to\nimplementation scenarios. Finally, we outline future directions by suggesting\nchallenging topics in this fast-growing deep learning field.",
        "versions": [],
        "rank": 351
    },
    {
        "authors": [
            "Wang, F.",
            "Liao, F.",
            "Zhu, H."
        ],
        "title": "FPA-DNN: A Forward Propagation Acceleration based Deep Neural Network for Ship Detection",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ijcnn48605.2020.9207603",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/9200848/9206590/09207603.pdf?arnumber=9207603",
            "http://dx.doi.org/10.1109/ijcnn48605.2020.9207603"
        ],
        "id": "id-3346484952092294567",
        "abstract": "",
        "versions": [],
        "rank": 352
    },
    {
        "authors": [
            "Nicolai Wojke",
            "Alex Bewley",
            "Dietrich Paulus"
        ],
        "title": "Simple online and realtime tracking with a deep association metric",
        "publication_date": "2017-03-21 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "International Conference on Image Processing",
        "volume": "",
        "doi": "10.1109/icip.2017.8296962",
        "urls": [
            "https://openalex.org/W2603203130",
            "https://doi.org/10.1109/icip.2017.8296962",
            "http://arxiv.org/pdf/1703.07402"
        ],
        "id": "id-3867700368476033425",
        "abstract": "",
        "versions": [],
        "rank": 353
    },
    {
        "authors": [
            "J. Talukdar",
            "S. Gupta",
            "P. Rajpura",
            "R. Hegde"
        ],
        "title": "Transfer Learning for Object Detection using State-of-the-Art Deep Neural Networks",
        "publication_date": "2018-02-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/SPIN.2018.8474198",
        "urls": [
            "https://www.semanticscholar.org/paper/32324fa4ce1496f86bfa3cd5da104dd9c2df7f55"
        ],
        "id": "id6263261517030981692",
        "abstract": "Transfer learning through the use of synthetic images and pretrained convolutional neural networks offers a promising approach to improve the object detection performance of deep neural networks. In this paper, we explore different strategies to generate synthetic datasets and subsequently improve them to achieve better object detection accuracy (mAP) when trained with state-of-the-art deep neural networks, focusing on detection of packed food products in a refrigerator. We develop novel techniques like dynamic stacking, pseudo random placement, variable object pose, distractor noise etc. which not only aid in diversifying the synthetic data but also help in improving the overall object detection mAP by more than 40%. The synthetic images, generated using Blender-Python API, are clustered in a variety of configurations to cater to the diversity of real scenes. These datasets are then utilized to train TensorFlow implementations of state-of-the-art deep neural networks like Faster-RCNN, R-FCN, and SSD and their performance is tested on real scenes. The object detection performance of various deep CNN architectures is also studied, with Faster-RCNN proving to be the most suitable choice, achieving the highest mAP of 70.67.",
        "versions": [],
        "rank": 354
    },
    {
        "authors": [
            "Baihong Jin",
            "Dan Li",
            "Seshadhri Srinivasan",
            "See-Kiong Ng",
            "Kameshwar Poolla",
            "Alberto Sangiovanni-Vincentelli"
        ],
        "title": "Detecting and Diagnosing Incipient Building Faults Using Uncertainty Information from Deep Neural Networks",
        "publication_date": "2019-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "IEEE",
        "volume": "",
        "doi": "10.1109/icphm.2019.8819438",
        "urls": [
            "https://web.archive.org/web/20200313133636/https://escholarship.org/content/qt2qw0v3z4/qt2qw0v3z4.pdf?t=q04pxp"
        ],
        "id": "id7904098779386781685",
        "abstract": "Early detection of incipient faults is of vital importance to reducing maintenance costs, saving energy, and enhancing occupant comfort in buildings. Popular supervised learning models such as deep neural networks are considered promising due to their ability to directly learn from labeled fault data; however, it is known that the performance of supervised learning approaches highly relies on the availability and quality of labeled training data. In Fault Detection and Diagnosis (FDD) applications, the lack of labeled incipient fault data has posed a major challenge to applying these supervised learning techniques to commercial buildings. To overcome this challenge, this paper proposes using Monte Carlo dropout (MC-dropout) to enhance the supervised learning pipeline, so that the resulting neural network is able to detect and diagnose unseen incipient fault examples. We also examine the proposed MC-dropout method on the RP-1043 dataset to demonstrate its effectiveness in indicating the most likely incipient fault types.",
        "versions": [
            {
                "year": 2019,
                "source": "SupportedSources.INTERNET_ARCHIVE",
                "title": "Detecting and Diagnosing Incipient Building Faults Using Uncertainty Information from Deep Neural Networks",
                "journal": "",
                "urls": [
                    "https://web.archive.org/web/20200915134229/https://arxiv.org/pdf/1902.06366v1.pdf"
                ],
                "doi": "",
                "publication_date": "2019-02-18 00:00:00"
            }
        ],
        "rank": 355
    },
    {
        "authors": [
            "Alahari, Karteek",
            "Schmid, Cordelia",
            "Shmelkov, Konstantin"
        ],
        "title": "Incremental Learning of Object Detectors without Catastrophic Forgetting",
        "publication_date": "2017-08-23 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/iccv.2017.368",
        "urls": [
            "https://core.ac.uk/download/87858390.pdf"
        ],
        "id": "id-6888812615302305424",
        "abstract": "Despite their success for object detection, convolutional neural networks are\nill-equipped for incremental learning, i.e., adapting the original model\ntrained on a set of classes to additionally detect objects of new classes, in\nthe absence of the initial training data. They suffer from \"catastrophic\nforgetting\" - an abrupt degradation of performance on the original set of\nclasses, when the training objective is adapted to the new classes. We present\na method to address this issue, and learn object detectors incrementally, when\nneither the original training data nor annotations for the original classes in\nthe new training set are available. The core of our proposed solution is a loss\nfunction to balance the interplay between predictions on the new classes and a\nnew distillation loss which minimizes the discrepancy between responses for old\nclasses from the original and the updated networks. This incremental learning\ncan be performed multiple times, for a new set of classes in each step, with a\nmoderate drop in performance compared to the baseline network trained on the\nensemble of data. We present object detection results on the PASCAL VOC 2007\nand COCO datasets, along with a detailed empirical analysis of the approach.Comment: To appear in ICCV 201",
        "versions": [],
        "rank": 356
    },
    {
        "authors": [
            "Lan Liu",
            "Pengcheng Wang",
            "Jun Lin",
            "Langzhou Liu"
        ],
        "title": "Intrusion Detection of Imbalanced Network Traffic Based on Machine Learning and Deep Learning",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Institute of Electrical and Electronics Engineers (IEEE)",
        "volume": "",
        "doi": "10.1109/access.2020.3048198",
        "urls": [
            "https://web.archive.org/web/20210429113005/https://ieeexplore.ieee.org/ielx7/6287639/9312710/09311173.pdf"
        ],
        "id": "id4710426601860977468",
        "abstract": "In imbalanced network traffic, malicious cyber-attacks can often hide in large amounts of normal data. It exhibits a high degree of stealth and obfuscation in cyberspace, making it difficult for Network Intrusion Detection System(NIDS) to ensure the accuracy and timeliness of detection. This paper researches machine learning and deep learning for intrusion detection in imbalanced network traffic. It proposes a novel Difficult Set Sampling Technique(DSSTE) algorithm to tackle the class imbalance problem. First, use the Edited Nearest Neighbor(ENN) algorithm to divide the imbalanced training set into the difficult set and the easy set. Next, use the KMeans algorithm to compress the majority samples in the difficult set to reduce the majority. Zoom in and out the minority samples' continuous attributes in the difficult set synthesize new samples to increase the minority number. Finally, the easy set, the compressed set of majority in the difficult, and the minority in the difficult set are combined with its augmentation samples to make up a new training set. The algorithm reduces the imbalance of the original training set and provides targeted data augment for the minority class that needs to learn. It enables the classifier to learn the differences in the training stage better and improve classification performance. To verify the proposed method, we conduct experiments on the classic intrusion dataset NSL-KDD and the newer and comprehensive intrusion dataset CSE-CIC-IDS2018. We use classical classification models: random forest(RF), Support Vector Machine(SVM), XGBoost, Long and Short-term Memory(LSTM), AlexNet, Mini-VGGNet. We compare the other 24 methods; the experimental results demonstrate that our proposed DSSTE algorithm outperforms the other methods. INDEX TERMS IDS, imbalanced network traffic, machine learning, deep learning, CSE-CIC-IDS2018.",
        "versions": [],
        "rank": 357
    },
    {
        "authors": [
            "Keji Zheng",
            "W. Yan",
            "P. Nand"
        ],
        "title": "Video Dynamics Detection Using Deep Neural Networks",
        "publication_date": "2018-06-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "IEEE Transactions on Emerging Topics in Computational Intelligence",
        "volume": "2",
        "doi": "10.1109/TETCI.2017.2778716",
        "urls": [
            "https://www.semanticscholar.org/paper/2c5fc4f7654e6b092cf1e2229af59c85cf93211a"
        ],
        "id": "id8304338057646914338",
        "abstract": "In recent years, deep neural networks (DNNs) have achieved a remarkable progression in solving many complex problems. DNNs are suitable for dealing with the problems related to time series, such as speech recognition and natural language processing. Video dynamics detection, for instance, is time dependent. Apparently, video dynamics detection needs to utilize the present, previous, and next frames of a given video. If a frame change occurs, it triggers whether a video event happens or not. In this paper, video dynamics detection based on deep learning is implemented and our contributions are to effectively improve the accuracy of video dynamics detection. The contributions of this paper are as follows: 1) increasing the accuracy rate to 96% compared to an FSM-based video dynamics detection in real time; 2) By combining convolutional neural network and recurrent neural network (RNN) together, the training time is greatly reduced as we expected.",
        "versions": [],
        "rank": 358
    },
    {
        "authors": [
            "Bourebaa, F.",
            "Benmohammed, M."
        ],
        "title": "Android Malware Detection using Convolutional Deep Neural Networks",
        "publication_date": "2020-11-28 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/icaase51408.2020.9380104",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/9380088/9380101/09380104.pdf?arnumber=9380104",
            "http://dx.doi.org/10.1109/icaase51408.2020.9380104"
        ],
        "id": "id6336308970368241190",
        "abstract": "",
        "versions": [],
        "rank": 359
    },
    {
        "authors": [
            "Hengshuang Zhao",
            "Jianping Shi",
            "Xiaojuan Qi",
            "Xiaogang Wang",
            "Jiaya Jia"
        ],
        "title": "Pyramid Scene Parsing Network",
        "publication_date": "2017-07-21 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Computer Vision and Pattern Recognition",
        "volume": "",
        "doi": "10.1109/cvpr.2017.660",
        "urls": [
            "https://openalex.org/W2560023338",
            "https://doi.org/10.1109/cvpr.2017.660",
            "http://arxiv.org/pdf/1612.01105"
        ],
        "id": "id-2058004254490914589",
        "abstract": "",
        "versions": [],
        "rank": 360
    },
    {
        "authors": [
            "Joseph Redmon",
            "Ali Farhadi"
        ],
        "title": "YOLO9000: Better, Faster, Stronger",
        "publication_date": "2017-07-21 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Computer Vision and Pattern Recognition",
        "volume": "",
        "doi": "10.1109/cvpr.2017.690",
        "urls": [
            "https://openalex.org/W2570343428",
            "https://doi.org/10.1109/cvpr.2017.690",
            "http://arxiv.org/pdf/1612.08242"
        ],
        "id": "id191628624040330750",
        "abstract": "",
        "versions": [],
        "rank": 361
    },
    {
        "authors": [
            "Heittola, Toni",
            "Huttunen, Heikki",
            "Parascandolo, Giambattista",
            "Virtanen, Tuomas",
            "\u00c7ak\u0131r, Emre"
        ],
        "title": "Convolutional Recurrent Neural Networks for Polyphonic Sound Event  Detection",
        "publication_date": "2017-02-21 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "IEEE/ACM Transactions on Audio Speech and Language Processing",
        "volume": "",
        "doi": "10.1109/taslp.2017.2690575",
        "urls": [
            "https://core.ac.uk/download/417848943.pdf"
        ],
        "id": "id3802396520451563282",
        "abstract": "Sound events often occur in unstructured environments where they exhibit wide\nvariations in their frequency content and temporal structure. Convolutional\nneural networks (CNN) are able to extract higher level features that are\ninvariant to local spectral and temporal variations. Recurrent neural networks\n(RNNs) are powerful in learning the longer term temporal context in the audio\nsignals. CNNs and RNNs as classifiers have recently shown improved performances\nover established methods in various sound recognition tasks. We combine these\ntwo approaches in a Convolutional Recurrent Neural Network (CRNN) and apply it\non a polyphonic sound event detection task. We compare the performance of the\nproposed CRNN method with CNN, RNN, and other established methods, and observe\na considerable improvement for four different datasets consisting of everyday\nsound events.Comment: Accepted for IEEE Transactions on Audio, Speech and Language\n  Processing, Special Issue on Sound Scene and Event Analysi",
        "versions": [],
        "rank": 362
    },
    {
        "authors": [
            "Lorraine Chambers",
            "Mohamed Medhat Gaber",
            "Zahraa S. Abdallah"
        ],
        "title": "DeepStreamCE: A Streaming Approach to Concept Evolution Detection in Deep Neural Networks",
        "publication_date": "2020-04-08 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20200415195301/https://arxiv.org/pdf/2004.04116v1.pdf"
        ],
        "id": "id8038749888620104314",
        "abstract": "Deep neural networks have experimentally demonstrated superior performance over other machine learning approaches in decision-making predictions. However, one major concern is the closed set nature of the classification decision on the trained classes, which can have serious consequences in safety critical systems. When the deep neural network is in a streaming environment, fast interpretation of this classification is required to determine if the classification result is trusted. Un-trusted classifications can occur when the input data to the deep neural network changes over time. One type of change that can occur is concept evolution, where a new class is introduced that the deep neural network was not trained on. In the majority of deep neural network architectures, the only option is to assign this instance to one of the classes it was trained on, which would be incorrect. The aim of this research is to detect the arrival of a new class in the stream. Existing work on interpreting deep neural networks often focuses on neuron activations to provide visual interpretation and feature extraction. Our novel approach, coined DeepStreamCE, uses streaming approaches for real-time concept evolution detection in deep neural networks. DeepStreamCE applies neuron activation reduction using an autoencoder and MCOD stream-based clustering in the offline phase. Both outputs are used in the online phase to analyse the neuron activations in the evolving stream in order to detect concept evolution occurrence in real time. We evaluate DeepStreamCE by training VGG16 convolutional neural networks on combinations of data from the CIFAR-10 dataset, holding out some classes to be used as concept evolution. For comparison, we apply the data and VGG16 networks to an open-set deep network solution - OpenMax. DeepStreamCE outperforms OpenMax when identifying concept evolution for our datasets.",
        "versions": [
            {
                "year": 2020,
                "source": "SupportedSources.ARXIV",
                "title": "DeepStreamCE: A Streaming Approach to Concept Evolution Detection in Deep Neural Networks",
                "journal": null,
                "urls": [
                    "http://arxiv.org/pdf/2004.04116v1",
                    "http://arxiv.org/abs/2004.04116v1",
                    "http://arxiv.org/pdf/2004.04116v1"
                ],
                "doi": "",
                "publication_date": "2020-04-08 16:53:26+00:00"
            }
        ],
        "rank": 363
    },
    {
        "authors": [
            "Mesut To\u011fa\u00e7ar",
            "B. Ergen",
            "Zafer C\u00f6mert"
        ],
        "title": "Detection of weather images by using spiking neural networks of deep learning models",
        "publication_date": "2020-10-08 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Neural Computing and Applications",
        "volume": "33",
        "doi": "10.1007/s00521-020-05388-3",
        "urls": [
            "https://www.semanticscholar.org/paper/c06a6e573041716a227034591baf81de8d66a364"
        ],
        "id": "id-2112564246064972162",
        "abstract": null,
        "versions": [],
        "rank": 364
    },
    {
        "authors": [
            "Li, K.",
            "Mao, S.",
            "Li, X.",
            "Wu, Z.",
            "Meng, H."
        ],
        "title": "Automatic lexical stress and pitch accent detection for L2 English speech using multi-distribution deep neural networks",
        "publication_date": "2018-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1016/j.specom.2017.11.003",
        "urls": [
            "https://api.elsevier.com/content/article/PII:S0167639315300637?httpAccept=text/xml",
            "https://api.elsevier.com/content/article/PII:S0167639315300637?httpAccept=text/plain",
            "http://dx.doi.org/10.1016/j.specom.2017.11.003"
        ],
        "id": "id-3127992622855887049",
        "abstract": "",
        "versions": [],
        "rank": 365
    },
    {
        "authors": [
            "Ashcraft, Nathan",
            "Cook, Matthew",
            "Djerekarov, Emil",
            "Luckow, Andre",
            "Vorster, Bennie",
            "Weill, Edwin"
        ],
        "title": "Deep Learning in the Automotive Industry: Applications and Tools",
        "publication_date": "2017-04-30 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/bigdata.2016.7841045",
        "urls": [
            "http://arxiv.org/abs/1705.00346"
        ],
        "id": "id8287821500489644754",
        "abstract": "Deep Learning refers to a set of machine learning techniques that utilize\nneural networks with many hidden layers for tasks, such as image\nclassification, speech recognition, language understanding. Deep learning has\nbeen proven to be very effective in these domains and is pervasively used by\nmany Internet services. In this paper, we describe different automotive uses\ncases for deep learning in particular in the domain of computer vision. We\nsurveys the current state-of-the-art in libraries, tools and infrastructures\n(e.\\,g.\\ GPUs and clouds) for implementing, training and deploying deep neural\nnetworks. We particularly focus on convolutional neural networks and computer\nvision use cases, such as the visual inspection process in manufacturing plants\nand the analysis of social media data. To train neural networks, curated and\nlabeled datasets are essential. In particular, both the availability and scope\nof such datasets is typically very limited. A main contribution of this paper\nis the creation of an automotive dataset, that allows us to learn and\nautomatically recognize different vehicle properties. We describe an end-to-end\ndeep learning application utilizing a mobile app for data collection and\nprocess support, and an Amazon-based cloud backend for storage and training.\nFor training we evaluate the use of cloud and on-premises infrastructures\n(including multiple GPUs) in conjunction with different neural network\narchitectures and frameworks. We assess both the training times as well as the\naccuracy of the classifier. Finally, we demonstrate the effectiveness of the\ntrained classifier in a real world setting during manufacturing process.Comment: 10 page",
        "versions": [],
        "rank": 366
    },
    {
        "authors": [
            "Haonan Wang",
            "Yijia Chen"
        ],
        "title": "Research on Application of Artificial Neural Network in Fault Diagnosis of Chemical Process",
        "publication_date": "2021-12-19 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Sciencedomain International",
        "volume": "",
        "doi": "10.9734/ajocs/2021/v10i419108",
        "urls": [
            "https://web.archive.org/web/20220423085708/https://journalajocs.com/index.php/AJOCS/article/download/19108/35239"
        ],
        "id": "id7561293645654325064",
        "abstract": "Chemical processes are usually toxic, corrosive, flammable and explosive. If the process fails, the danger is extremely high. Traditional model-based fault diagnosis methods need to establish an accurate mathematical model of the system, while modern engineering processes are usually large in scale and complex, and it is difficult to establish an accurate mathematical model. Artificial neural network has been widely used in chemical process because of its advantages of parallel processing, self-adaptation, robustness, learnability and fault tolerance. Artificial neural networks based on \"deep learning\" have been successfully applied to fault diagnosis in various chemical processes. This article summarizes the principle and development process of artificial neural networks, and analyzes the research progress and application status of deep neural networks in chemical process fault diagnosis based on cases. Finally, it is pointed out that deep neural network in the field of chemical process fault diagnosis is of great significance in solving the impact of less fault data and system state changes on the fault detection rate, and promoting the industrial application of fault diagnosis models.",
        "versions": [],
        "rank": 367
    },
    {
        "authors": [
            "Alexander Wong",
            "Mahmoud Famuori",
            "Mohammad Javad Shafiee",
            "Francis Li",
            "Brendan Chwyl",
            "Jonathan Chung"
        ],
        "title": "YOLO Nano: a Highly Compact You Only Look Once Convolutional Neural Network for Object Detection",
        "publication_date": "2019-10-03 01:29:26+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1910.01271v1",
            "http://arxiv.org/abs/1910.01271v1",
            "http://arxiv.org/pdf/1910.01271v1"
        ],
        "id": "id893442999831827097",
        "abstract": "Object detection remains an active area of research in the field of computer\nvision, and considerable advances and successes has been achieved in this area\nthrough the design of deep convolutional neural networks for tackling object\ndetection. Despite these successes, one of the biggest challenges to widespread\ndeployment of such object detection networks on edge and mobile scenarios is\nthe high computational and memory requirements. As such, there has been growing\nresearch interest in the design of efficient deep neural network architectures\ncatered for edge and mobile usage. In this study, we introduce YOLO Nano, a\nhighly compact deep convolutional neural network for the task of object\ndetection. A human-machine collaborative design strategy is leveraged to create\nYOLO Nano, where principled network design prototyping, based on design\nprinciples from the YOLO family of single-shot object detection network\narchitectures, is coupled with machine-driven design exploration to create a\ncompact network with highly customized module-level macroarchitecture and\nmicroarchitecture designs tailored for the task of embedded object detection.\nThe proposed YOLO Nano possesses a model size of ~4.0MB (>15.1x and >8.3x\nsmaller than Tiny YOLOv2 and Tiny YOLOv3, respectively) and requires 4.57B\noperations for inference (>34% and ~17% lower than Tiny YOLOv2 and Tiny YOLOv3,\nrespectively) while still achieving an mAP of ~69.1% on the VOC 2007 dataset\n(~12% and ~10.7% higher than Tiny YOLOv2 and Tiny YOLOv3, respectively).\nExperiments on inference speed and power efficiency on a Jetson AGX Xavier\nembedded module at different power budgets further demonstrate the efficacy of\nYOLO Nano for embedded scenarios.",
        "versions": [],
        "rank": 368
    },
    {
        "authors": [
            "Alex D'Amour",
            "David Madras",
            "James Atwood"
        ],
        "title": "Detecting Underspecification with Local Ensembles",
        "publication_date": "2019-10-21 00:00:00",
        "source": "SupportedSources.PAPERS_WITH_CODE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://arxiv.org/pdf/1910.09573v2.pdf",
            "https://github.com/StanfordASL/SCOD",
            "https://openreview.net/pdf?id=BJl6bANtwH"
        ],
        "id": "id-4028796355763767757",
        "abstract": "We present local ensembles, a method for detecting underspecification -- when many possible predictors are consistent with the training data and model class -- at test time in a pre-trained model. Our method uses local second-order information to approximate the variance of predictions across an ensemble of models from the same class. We compute this approximation by estimating the norm of the component of a test point's gradient that aligns with the low-curvature directions of the Hessian, and provide a tractable method for estimating this quantity. Experimentally, we show that our method is capable of detecting when a pre-trained model is underspecified on test data, with applications to out-of-distribution detection, detecting spurious correlates, and active learning.",
        "versions": [],
        "rank": 369
    },
    {
        "authors": [
            "Muralidharan, T.",
            "Nissim, N."
        ],
        "title": "Improving malicious email detection through novel designated deep-learning architectures utilizing entire email",
        "publication_date": "2023-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1016/j.neunet.2022.09.002",
        "urls": [
            "https://api.elsevier.com/content/article/PII:S0893608022003367?httpAccept=text/xml",
            "https://api.elsevier.com/content/article/PII:S0893608022003367?httpAccept=text/plain",
            "http://dx.doi.org/10.1016/j.neunet.2022.09.002"
        ],
        "id": "id5113344443285063221",
        "abstract": "",
        "versions": [],
        "rank": 370
    },
    {
        "authors": [
            "Marshall, David",
            "Schroeter, Julien",
            "Sidorov, Kirill"
        ],
        "title": "Weakly-Supervised Temporal Localization via Occurrence Count Learning",
        "publication_date": "2019-05-17 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "https://core.ac.uk/download/227034960.pdf"
        ],
        "id": "id4767026528444525636",
        "abstract": "We propose a novel model for temporal detection and localization which allows\nthe training of deep neural networks using only counts of event occurrences as\ntraining labels. This powerful weakly-supervised framework alleviates the\nburden of the imprecise and time-consuming process of annotating event\nlocations in temporal data. Unlike existing methods, in which localization is\nexplicitly achieved by design, our model learns localization implicitly as a\nbyproduct of learning to count instances. This unique feature is a direct\nconsequence of the model's theoretical properties. We validate the\neffectiveness of our approach in a number of experiments (drum hit and piano\nonset detection in audio, digit detection in images) and demonstrate\nperformance comparable to that of fully-supervised state-of-the-art methods,\ndespite much weaker training requirements.Comment: Accepted at ICML 201",
        "versions": [],
        "rank": 371
    },
    {
        "authors": [
            "Patricia K. Kuhl"
        ],
        "title": "Early language acquisition: cracking the speech code",
        "publication_date": "2004-11-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Nature Reviews Neuroscience",
        "volume": "5",
        "doi": "10.1038/nrn1533",
        "urls": [
            "https://openalex.org/W2020944885",
            "https://doi.org/10.1038/nrn1533"
        ],
        "id": "id7346210571129467728",
        "abstract": "",
        "versions": [],
        "rank": 372
    },
    {
        "authors": [
            "Andrej Karpathy",
            "Li Fei-Fei"
        ],
        "title": "Deep visual-semantic alignments for generating image descriptions",
        "publication_date": "2015-06-07 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Computer Vision and Pattern Recognition",
        "volume": "",
        "doi": "10.1109/cvpr.2015.7298932",
        "urls": [
            "https://openalex.org/W1905882502",
            "https://doi.org/10.1109/cvpr.2015.7298932",
            "http://arxiv.org/pdf/1412.2306"
        ],
        "id": "id-7123096165887116162",
        "abstract": "",
        "versions": [],
        "rank": 373
    },
    {
        "authors": [
            "Quazi Marufur Rahman",
            "Peter Corke",
            "Feras Dayoub"
        ],
        "title": "Run-Time Monitoring of Machine Learning for Robotic Perception: A Survey of Emerging Trends",
        "publication_date": "2021-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Institute of Electrical and Electronics Engineers (IEEE)",
        "volume": "",
        "doi": "10.1109/access.2021.3055015",
        "urls": [
            "https://web.archive.org/web/20210429110924/https://ieeexplore.ieee.org/ielx7/6287639/6514899/09336665.pdf"
        ],
        "id": "id-4489692436097331252",
        "abstract": "",
        "versions": [],
        "rank": 374
    },
    {
        "authors": [
            "Sokolova, A.",
            "Savchenko, A."
        ],
        "title": "Open-Set Face Identification with Sequential Analysis and Out-of-Distribution Data Detection",
        "publication_date": "2022-07-18 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ijcnn55064.2022.9892508",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/9891857/9889787/09892508.pdf?arnumber=9892508",
            "http://dx.doi.org/10.1109/ijcnn55064.2022.9892508"
        ],
        "id": "id2129476095310829877",
        "abstract": "",
        "versions": [],
        "rank": 375
    },
    {
        "authors": [
            "Pedro Garc\u00eda-Teodoro",
            "Jes\u00fas E. D\u00edaz-Verdejo",
            "Gabriel Maci\u00e1-Fern\u00e1ndez",
            "E. V\u00e1zquez"
        ],
        "title": "Anomaly-based network intrusion detection: Techniques, systems and challenges",
        "publication_date": "2009-02-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Computers & Security",
        "volume": "28",
        "doi": "10.1016/j.cose.2008.08.003",
        "urls": [
            "https://openalex.org/W2142889610",
            "https://doi.org/10.1016/j.cose.2008.08.003"
        ],
        "id": "id5663396200709060197",
        "abstract": "",
        "versions": [],
        "rank": 376
    },
    {
        "authors": [
            "Aengus Daly",
            "Alison O'Shea",
            "G. Lightbody",
            "A. Temko"
        ],
        "title": "Towards Deeper Neural Networks for Neonatal Seizure Detection",
        "publication_date": "2021-11-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/EMBC46164.2021.9629485",
        "urls": [
            "https://www.semanticscholar.org/paper/2c2bfeede5c8e4d869c5217248ec63913ebf6432"
        ],
        "id": "id120207670779058246",
        "abstract": "Machine learning and more recently deep learning have become valuable tools in clinical decision making for neonatal seizure detection. This work proposes a deep neural network architecture which is capable of extracting information from long segments of EEG. Residual connections as well as data augmentation and a more robust optimizer are efficiently exploited to train a deeper architecture with an increased receptive field and longer EEG input. The proposed system is tested on a large clinical dataset of 4,570 hours of duration and benchmarked on a publicly available Helsinki dataset of 112 hours duration. The performance has improved from an AUC of 95.41% to an AUC of 97.73% when compared to a deep learning baseline.",
        "versions": [],
        "rank": 377
    },
    {
        "authors": [
            "Kaiming He",
            "Xiangyu Zhang",
            "Shaoqing Ren",
            "Jian Sun"
        ],
        "title": "Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition",
        "publication_date": "2014-06-18 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Lecture Notes in Computer Science",
        "volume": "",
        "doi": "10.1007/978-3-319-10578-9_23",
        "urls": [
            "https://openalex.org/W2179352600",
            "https://doi.org/10.1007/978-3-319-10578-9_23",
            "http://arxiv.org/pdf/1406.4729"
        ],
        "id": "id6712978240056646803",
        "abstract": "",
        "versions": [],
        "rank": 378
    },
    {
        "authors": [
            "Alexander Wong",
            "Zhong Qiu Lin",
            "Brendan Chwyl"
        ],
        "title": "AttoNets: Compact and Efficient Deep Neural Networks for the Edge via Human-Machine Collaborative Design",
        "publication_date": "2019-03-18 00:16:04+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1903.07209v2",
            "http://arxiv.org/abs/1903.07209v2",
            "http://arxiv.org/pdf/1903.07209v2"
        ],
        "id": "id-2613549050171399686",
        "abstract": "While deep neural networks have achieved state-of-the-art performance across\na large number of complex tasks, it remains a big challenge to deploy such\nnetworks for practical, on-device edge scenarios such as on mobile devices,\nconsumer devices, drones, and vehicles. In this study, we take a deeper\nexploration into a human-machine collaborative design approach for creating\nhighly efficient deep neural networks through a synergy between principled\nnetwork design prototyping and machine-driven design exploration. The efficacy\nof human-machine collaborative design is demonstrated through the creation of\nAttoNets, a family of highly efficient deep neural networks for on-device edge\ndeep learning. Each AttoNet possesses a human-specified network-level\nmacro-architecture comprising of custom modules with unique machine-designed\nmodule-level macro-architecture and micro-architecture designs, all driven by\nhuman-specified design requirements. Experimental results for the task of\nobject recognition showed that the AttoNets created via human-machine\ncollaborative design has significantly fewer parameters and computational costs\nthan state-of-the-art networks designed for efficiency while achieving\nnoticeably higher accuracy (with the smallest AttoNet achieving ~1.8% higher\naccuracy while requiring ~10x fewer multiply-add operations and parameters than\nMobileNet-V1). Furthermore, the efficacy of the AttoNets is demonstrated for\nthe task of instance-level object segmentation and object detection, where an\nAttoNet-based Mask R-CNN network was constructed with significantly fewer\nparameters and computational costs (~5x fewer multiply-add operations and ~2x\nfewer parameters) than a ResNet-50 based Mask R-CNN network.",
        "versions": [],
        "rank": 379
    },
    {
        "authors": [
            "Kaniz Farhana",
            "Maqsudur Rahman",
            "Md. Tofael Ahmed"
        ],
        "title": "An intrusion detection system for packet and flow based networks using deep neural network approach",
        "publication_date": "2020-10-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Institute of Advanced Engineering and Science",
        "volume": "",
        "doi": "10.11591/ijece.v10i5.pp5514-5525",
        "urls": [
            "https://web.archive.org/web/20200623182521/http://ijece.iaescore.com/index.php/IJECE/article/download/22021/14277"
        ],
        "id": "id-5738620933088470205",
        "abstract": "Study on deep neural networks and big data is merging now by several aspects to enhance the capabilities of intrusion detection system (IDS). Many IDS models has been introduced to provide security over big data. This study focuses on the intrusion detection in computer networks using big datasets. The advent of big data has agitated the comprehensive assistance in cyber security by forwarding a brunch of affluent algorithms to classify and analysis patterns and making a better prediction more efficiently. In this study, to detect intrusion a detection model has been propounded applying deep neural networks. We applied the suggested model on the latest data set available at online, formatted with packet based, flow based data and some additional metadata. The data set is labeled and imbalanced with 79 attributes and some classes having much less training samples compared to other classes. The proposed model is build using Keras and Google Tensorflow deep learning environment. Experimental result shows that intrusions are detected with the accuracy over 99% for both binary and multi-class classification with selected best features. Receiver operating characteristics (ROC) and precision-recall curve average score is also 1. The outcome implies that Deep Neural Networks offers a novel research model with great accuracy for intrusion detection model, better than some models presented in the literature.",
        "versions": [],
        "rank": 380
    },
    {
        "authors": [
            "David O. E.",
            "Kolosnjaji Bojan",
            "Lin Chih-Ta",
            "Pascanu R.",
            "Sahay Sanjay K.",
            "Siddiqui Muazzam",
            "Srivastava Nitish"
        ],
        "title": "An investigation of a deep learning based malware detection system",
        "publication_date": "2018-09-16 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1145/3230833.3230835",
        "urls": [
            "http://arxiv.org/abs/1809.05888"
        ],
        "id": "id-2197159916335216828",
        "abstract": "We investigate a Deep Learning based system for malware detection. In the\ninvestigation, we experiment with different combination of Deep Learning\narchitectures including Auto-Encoders, and Deep Neural Networks with varying\nlayers over Malicia malware dataset on which earlier studies have obtained an\naccuracy of (98%) with an acceptable False Positive Rates (1.07%). But these\nresults were done using extensive man-made custom domain features and investing\ncorresponding feature engineering and design efforts. In our proposed approach,\nbesides improving the previous best results (99.21% accuracy and a False\nPositive Rate of 0.19%) indicates that Deep Learning based systems could\ndeliver an effective defense against malware. Since it is good in automatically\nextracting higher conceptual features from the data, Deep Learning based\nsystems could provide an effective, general and scalable mechanism for\ndetection of existing and unknown malware.Comment: 13 Pages, 4 figure",
        "versions": [],
        "rank": 381
    },
    {
        "authors": [
            "Chen Li",
            "Gaoqi Liang",
            "Huan Zhao",
            "Guo Chen"
        ],
        "title": "A Demand-Side Load Event Detection Algorithm Based on Wide-Deep Neural Networks and Randomized Sparse Backpropagation",
        "publication_date": "2021-12-20 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.3389/fenrg.2021.720831",
        "urls": [
            "https://www.semanticscholar.org/paper/ea9ea72398423aab799a39bb9b7d45d86907364a"
        ],
        "id": "id-6766140854200011555",
        "abstract": "Event detection is an important application in demand-side management. Precise event detection algorithms can improve the accuracy of non-intrusive load monitoring (NILM) and energy disaggregation models. Existing event detection algorithms can be divided into four categories: rule-based, statistics-based, conventional machine learning, and deep learning. The rule-based approach entails hand-crafted feature engineering and carefully calibrated thresholds; the accuracies of statistics-based and conventional machine learning methods are inferior to the deep learning algorithms due to their limited ability to extract complex features. Deep learning models require a long training time and are hard to interpret. This paper proposes a novel algorithm for load event detection in smart homes based on wide and deep learning that combines the convolutional neural network (CNN) and the soft-max regression (SMR). The deep model extracts the power time series patterns and the wide model utilizes the percentile information of the power time series. A randomized sparse backpropagation (RSB) algorithm for weight filters is proposed to improve the robustness of the standard wide-deep model. Compared to the standard wide-deep, pure CNN, and SMR models, the hybrid wide-deep model powered by RSB demonstrates its superiority in terms of accuracy, convergence speed, and robustness.",
        "versions": [],
        "rank": 382
    },
    {
        "authors": [
            "Ashfahani, Andri",
            "Pratama, Mahardhika"
        ],
        "title": "Autonomous Deep Learning: Continual Learning Approach for Dynamic  Environments",
        "publication_date": "2020-01-09 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1137/1.9781611975673.75",
        "urls": [
            "http://arxiv.org/abs/1810.07348"
        ],
        "id": "id7013047752879813632",
        "abstract": "The feasibility of deep neural networks (DNNs) to address data stream\nproblems still requires intensive study because of the static and offline\nnature of conventional deep learning approaches. A deep continual learning\nalgorithm, namely autonomous deep learning (ADL), is proposed in this paper.\nUnlike traditional deep learning methods, ADL features a flexible structure\nwhere its network structure can be constructed from scratch with the absence of\nan initial network structure via the self-constructing network structure. ADL\nspecifically addresses catastrophic forgetting by having a different-depth\nstructure which is capable of achieving a trade-off between plasticity and\nstability. Network significance (NS) formula is proposed to drive the hidden\nnodes growing and pruning mechanism. Drift detection scenario (DDS) is put\nforward to signal distributional changes in data streams which induce the\ncreation of a new hidden layer. The maximum information compression index\n(MICI) method plays an important role as a complexity reduction module\neliminating redundant layers. The efficacy of ADL is numerically validated\nunder the prequential test-then-train procedure in lifelong environments using\nnine popular data stream problems. The numerical results demonstrate that ADL\nconsistently outperforms recent continual learning methods while characterizing\nthe automatic construction of network structures",
        "versions": [],
        "rank": 383
    },
    {
        "authors": [
            "Landman, T.",
            "Nissim, N."
        ],
        "title": "Deep-Hook: A trusted deep learning-based framework for unknown malware detection and classification in Linux cloud environments",
        "publication_date": "2021-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1016/j.neunet.2021.09.019",
        "urls": [
            "https://api.elsevier.com/content/article/PII:S0893608021003695?httpAccept=text/xml",
            "https://api.elsevier.com/content/article/PII:S0893608021003695?httpAccept=text/plain",
            "http://dx.doi.org/10.1016/j.neunet.2021.09.019"
        ],
        "id": "id-8066660724714256844",
        "abstract": "",
        "versions": [],
        "rank": 384
    },
    {
        "authors": [
            "Alexander Wong",
            "Mohammad Javad Shafiee",
            "Francis Li",
            "Brendan Chwyl"
        ],
        "title": "Tiny SSD: A Tiny Single-shot Detection Deep Convolutional Neural Network for Real-time Embedded Object Detection",
        "publication_date": "2018-02-19 01:57:46+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1802.06488v1",
            "http://arxiv.org/abs/1802.06488v1",
            "http://arxiv.org/pdf/1802.06488v1"
        ],
        "id": "id-5199993176806569780",
        "abstract": "Object detection is a major challenge in computer vision, involving both\nobject classification and object localization within a scene. While deep neural\nnetworks have been shown in recent years to yield very powerful techniques for\ntackling the challenge of object detection, one of the biggest challenges with\nenabling such object detection networks for widespread deployment on embedded\ndevices is high computational and memory requirements. Recently, there has been\nan increasing focus in exploring small deep neural network architectures for\nobject detection that are more suitable for embedded devices, such as Tiny YOLO\nand SqueezeDet. Inspired by the efficiency of the Fire microarchitecture\nintroduced in SqueezeNet and the object detection performance of the\nsingle-shot detection macroarchitecture introduced in SSD, this paper\nintroduces Tiny SSD, a single-shot detection deep convolutional neural network\nfor real-time embedded object detection that is composed of a highly optimized,\nnon-uniform Fire sub-network stack and a non-uniform sub-network stack of\nhighly optimized SSD-based auxiliary convolutional feature layers designed\nspecifically to minimize model size while maintaining object detection\nperformance. The resulting Tiny SSD possess a model size of 2.3MB (~26X smaller\nthan Tiny YOLO) while still achieving an mAP of 61.3% on VOC 2007 (~4.2% higher\nthan Tiny YOLO). These experimental results show that very small deep neural\nnetwork architectures can be designed for real-time object detection that are\nwell-suited for embedded scenarios.",
        "versions": [],
        "rank": 385
    },
    {
        "authors": [
            "Matthias Hein",
            "Julian Bitterwolf",
            "Alexander Meinke"
        ],
        "title": "Provably Robust Detection of Out-of-distribution Data (almost) for free",
        "publication_date": "2021-06-08 00:00:00",
        "source": "SupportedSources.PAPERS_WITH_CODE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://arxiv.org/pdf/2106.04260v2.pdf",
            "https://github.com/AlexMeinke/Provable-OOD-Detection",
            "https://openreview.net/pdf?id=qDx6DXD3Fzt"
        ],
        "id": "id8061953708577946489",
        "abstract": "The application of machine learning in safety-critical systems requires a reliable assessment of uncertainty. However, deep neural networks are known to produce highly overconfident predictions on out-of-distribution (OOD) data. Even if trained to be non-confident on OOD data, one can still adversarially manipulate OOD data so that the classifier again assigns high confidence to the manipulated samples. We show that two previously published defenses can be broken by better adapted attacks, highlighting the importance of robustness guarantees around OOD data. Since the existing method for this task is hard to train and significantly limits accuracy, we construct a classifier that can simultaneously achieve provably adversarially robust OOD detection and high clean accuracy. Moreover, by slightly modifying the classifier's architecture our method provably avoids the asymptotic overconfidence problem of standard neural networks. We provide code for all our experiments.",
        "versions": [],
        "rank": 386
    },
    {
        "authors": [
            "Anatol Maier",
            "Benedikt Lorch",
            "Christian Riess"
        ],
        "title": "Toward Reliable Models for Authenticating Multimedia Content: Detecting Resampling Artifacts With Bayesian Neural Networks",
        "publication_date": "2020-07-28 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20200730221138/https://arxiv.org/pdf/2007.14132v1.pdf"
        ],
        "id": "id-3594486184362415697",
        "abstract": "In multimedia forensics, learning-based methods provide state-of-the-art performance in determining origin and authenticity of images and videos. However, most existing methods are challenged by out-of-distribution data, i.e., with characteristics that are not covered in the training set. This makes it difficult to know when to trust a model, particularly for practitioners with limited technical background. In this work, we make a first step toward redesigning forensic algorithms with a strong focus on reliability. To this end, we propose to use Bayesian neural networks (BNN), which combine the power of deep neural networks with the rigorous probabilistic formulation of a Bayesian framework. Instead of providing a point estimate like standard neural networks, BNNs provide distributions that express both the estimate and also an uncertainty range. We demonstrate the usefulness of this framework on a classical forensic task: resampling detection. The BNN yields state-of-the-art detection performance, plus excellent capabilities for detecting out-of-distribution samples. This is demonstrated for three pathologic issues in resampling detection, namely unseen resampling factors, unseen JPEG compression, and unseen resampling algorithms. We hope that this proposal spurs further research toward reliability in multimedia forensics.",
        "versions": [],
        "rank": 387
    },
    {
        "authors": [
            "Mark A. DePristo",
            "Peter J. Liu",
            "Joshua V. Dillon",
            "Balaji Lakshminarayanan",
            "Ryan Poplin",
            "Jie Ren",
            "Jasper Snoek",
            "Emily Fertig"
        ],
        "title": "Likelihood Ratios for Out-of-Distribution Detection",
        "publication_date": "2019-06-07 00:00:00",
        "source": "SupportedSources.PAPERS_WITH_CODE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://arxiv.org/pdf/1906.02845v2.pdf",
            "https://github.com/google-research/google-research/tree/master/genomics_ood",
            "http://papers.nips.cc/paper/9611-likelihood-ratios-for-out-of-distribution-detection.pdf"
        ],
        "id": "id-2361131407049049876",
        "abstract": "Discriminative neural networks offer little or no performance guarantees when deployed on data not generated by the same process as the training distribution. On such out-of-distribution (OOD) inputs, the prediction may not only be erroneous, but confidently so, limiting the safe deployment of classifiers in real-world applications. One such challenging application is bacteria identification based on genomic sequences, which holds the promise of early detection of diseases, but requires a model that can output low confidence predictions on OOD genomic sequences from new bacteria that were not present in the training data. We introduce a genomics dataset for OOD detection that allows other researchers to benchmark progress on this important problem. We investigate deep generative model based approaches for OOD detection and observe that the likelihood score is heavily affected by population level background statistics. We propose a likelihood ratio method for deep generative models which effectively corrects for these confounding background statistics. We benchmark the OOD detection performance of the proposed method against existing approaches on the genomics dataset and show that our method achieves state-of-the-art performance. We demonstrate the generality of the proposed method by showing that it significantly improves OOD detection when applied to deep generative models of images.",
        "versions": [],
        "rank": 388
    },
    {
        "authors": [
            "Fritjof Helmchen",
            "Winfried Denk"
        ],
        "title": "Deep tissue two-photon microscopy",
        "publication_date": "2005-12-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Nature Methods",
        "volume": "2",
        "doi": "10.1038/nmeth818",
        "urls": [
            "https://openalex.org/W2147607085",
            "https://doi.org/10.1038/nmeth818"
        ],
        "id": "id-267332693258588204",
        "abstract": "",
        "versions": [],
        "rank": 389
    },
    {
        "authors": [
            "Zhi-wen Chen",
            "Ketian Liang",
            "S. Ding",
            "Chao Yang",
            "Tao Peng",
            "Xiaofeng Yuan"
        ],
        "title": "A Comparative Study of Deep Neural Network-Aided Canonical Correlation Analysis-Based Process Monitoring and Fault Detection Methods",
        "publication_date": "2021-04-22 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "IEEE Transactions on Neural Networks and Learning Systems",
        "volume": "33",
        "doi": "10.1109/TNNLS.2021.3072491",
        "urls": [
            "https://www.semanticscholar.org/paper/e7afb90edc9e04881847e3a129ed00a74a46a332"
        ],
        "id": "id-3989776929313426403",
        "abstract": "Multivariate analysis is an important kind of method in process monitoring and fault detection, in which the canonical correlation analysis (CCA) makes use of the correlation change between two groups of variables to distinguish the system status and has been greatly studied and applied. For the monitoring of nonlinear dynamic systems, the deep neural network-aided CCA (DNN-CCA) has received much attention recently, but it lacks a general definition and comparative study of different network structures. Therefore, this article first introduces four deep neural network (DNN) models that are suitable to combine with CCA, and the general form of DNN-CCA is given in detail. Then, the experimental comparison of these methods is conducted through three cases, so as to analyze the characteristics and distinctions of CCA aided by each DNN model. Finally, some suggestions on method selection are summarized, and the existed open issues in the current DNN-CCA form and future directions are discussed.",
        "versions": [],
        "rank": 390
    },
    {
        "authors": [
            "Levine, Martin D.",
            "Liu, Yuguang"
        ],
        "title": "Multi-Path Region-Based Convolutional Neural Network for Accurate  Detection of Unconstrained \"Hard Faces\"",
        "publication_date": "2017-03-27 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/crv.2017.20",
        "urls": [
            "http://arxiv.org/abs/1703.09145"
        ],
        "id": "id3822817181216497334",
        "abstract": "Large-scale variations still pose a challenge in unconstrained face\ndetection. To the best of our knowledge, no current face detection algorithm\ncan detect a face as large as 800 x 800 pixels while simultaneously detecting\nanother one as small as 8 x 8 pixels within a single image with equally high\naccuracy. We propose a two-stage cascaded face detection framework, Multi-Path\nRegion-based Convolutional Neural Network (MP-RCNN), that seamlessly combines a\ndeep neural network with a classic learning strategy, to tackle this challenge.\nThe first stage is a Multi-Path Region Proposal Network (MP-RPN) that proposes\nfaces at three different scales. It simultaneously utilizes three parallel\noutputs of the convolutional feature maps to predict multi-scale candidate face\nregions. The \"atrous\" convolution trick (convolution with up-sampled filters)\nand a newly proposed sampling layer for \"hard\" examples are embedded in MP-RPN\nto further boost its performance. The second stage is a Boosted Forests\nclassifier, which utilizes deep facial features pooled from inside the\ncandidate face regions as well as deep contextual features pooled from a larger\nregion surrounding the candidate face regions. This step is included to further\nremove hard negative samples. Experiments show that this approach achieves\nstate-of-the-art face detection performance on the WIDER FACE dataset \"hard\"\npartition, outperforming the former best result by 9.6% for the Average\nPrecision.Comment: 11 pages, 7 figures, to be presented at CRV 201",
        "versions": [],
        "rank": 391
    },
    {
        "authors": [
            "Dimitra Chamou",
            "Petros Toupas",
            "Eleni Ketzaki",
            "Stavros Papadopoulos",
            "K. M. Giannoutakis",
            "A. Drosou",
            "D. Tzovaras"
        ],
        "title": "Intrusion Detection System Based on Network Traffic Using Deep Neural Networks",
        "publication_date": "2019-09-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/CAMAD.2019.8858475",
        "urls": [
            "https://www.semanticscholar.org/paper/bf349e33c532fc0841c9aa3627f71fd9bb1fb97e"
        ],
        "id": "id4341219865864755629",
        "abstract": "Nowadays, the small-medium enterprises security against cyber-attacks is a matter of great importance and a challenging area, as it affects them financially and functionally. Novel and sophisticated attacks are emerging daily, targeting and threatening a large number of businesses around the world. For this reason, the implementation and optimization of the performance of Intrusion Detection Systems have attracted the interest of the scientific community. The malicious behavior detection in terms of DDoS and malware cyber-threats using deep learning methods constitutes an extended and the most important part of this paper. The experimental results for the real-time intrusion detection system showed that the proposed model can achieve high accuracy, and low false positive rate, while distinguishing between malicious and normal network traffic.",
        "versions": [],
        "rank": 392
    },
    {
        "authors": [
            "H. Ullah",
            "Z. Onik",
            "Riashat Islam",
            "Dip Nandi"
        ],
        "title": "Alzheimer's Disease and Dementia Detection from 3D Brain MRI Data Using Deep Convolutional Neural Networks",
        "publication_date": "2018-04-06 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/I2CT.2018.8529808",
        "urls": [
            "https://www.semanticscholar.org/paper/a495044baa81a646271923440b1d95b8251e5041"
        ],
        "id": "id-1125747798347985554",
        "abstract": "As reported by the the Alzheimer's Association, there are more than 5 million Americans living with Alzheimer's today, with an anticipated 16 million by 2050. The neurodegenerative disease is currently the 6th leading source of death in the US. In 2017 this disease would cost the nation $1.1 trillion. 1 in 3 seniors die in Alzheimer's disease or another dementia. It kills more than breast cancer and prostate cancer combined. [14] As of the this papers writing, detecting Alzheimer's is a difficult and time consuming task, but requires brain imaging report and human expertise. Needless to say, this conventional approach to detect Alzheimer's is costly and often error prone. In this paper an alternative approach has been discussed, that is fast, costs less and more reliable. Deep Learning represents the true bleeding edge of Machine Intelligence. Convolutional Neural Networks are biologically inspired Multilayer perceptron specially capable of image processing. In this paper we present a state of the art Deep Convolutional Neural Network to detect Alzheimer's Disease and Dementia from 3D MRI image.",
        "versions": [],
        "rank": 393
    },
    {
        "authors": [
            "Denman, Simon",
            "Fernando, Tharindu",
            "Fookes, Clinton",
            "Sridharan, Sridha"
        ],
        "title": "Tracking by Prediction: A Deep Generative Model for Mutli-Person  localisation and Tracking",
        "publication_date": "2018-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/wacv.2018.00128",
        "urls": [
            "http://arxiv.org/abs/1803.03347"
        ],
        "id": "id-7173715525953821482",
        "abstract": "Current multi-person localisation and tracking systems have an over reliance\non the use of appearance models for target re-identification and almost no\napproaches employ a complete deep learning solution for both objectives. We\npresent a novel, complete deep learning framework for multi-person localisation\nand tracking. In this context we first introduce a light weight sequential\nGenerative Adversarial Network architecture for person localisation, which\novercomes issues related to occlusions and noisy detections, typically found in\na multi person environment. In the proposed tracking framework we build upon\nrecent advances in pedestrian trajectory prediction approaches and propose a\nnovel data association scheme based on predicted trajectories. This removes the\nneed for computationally expensive person re-identification systems based on\nappearance features and generates human like trajectories with minimal\nfragmentation. The proposed method is evaluated on multiple public benchmarks\nincluding both static and dynamic cameras and is capable of generating\noutstanding performance, especially among other recently proposed deep neural\nnetwork based approaches.Comment: To appear in IEEE Winter Conference on Applications of Computer\n  Vision (WACV), 201",
        "versions": [],
        "rank": 394
    },
    {
        "authors": [
            "Wenhu Chen",
            "Yilin Shen",
            "Hongxia Jin",
            "William Wang"
        ],
        "title": "A Variational Dirichlet Framework for Out-of-Distribution Detection",
        "publication_date": "2019-04-20 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20200914011139/https://arxiv.org/pdf/1811.07308v4.pdf"
        ],
        "id": "id-2122869033302956793",
        "abstract": "With the recently rapid development in deep learning, deep neural networks have been widely adopted in many real-life applications. However, deep neural networks are also known to have very little control over its uncertainty for unseen examples, which potentially causes very harmful and annoying consequences in practical scenarios. In this paper, we are particularly interested in designing a higher-order uncertainty metric for deep neural networks and investigate its effectiveness under the out-of-distribution detection task proposed by hendrycks2016baseline. Our method first assumes there exists an underlying higher-order distribution P(z), which controls label-wise categorical distribution P(y) over classes on the K-dimension simplex, and then approximate such higher-order distribution via parameterized posterior function p_\u03b8(z|x) under variational inference framework, finally we use the entropy of learned posterior distribution p_\u03b8(z|x) as uncertainty measure to detect out-of-distribution examples. Further, we propose an auxiliary objective function to discriminate against synthesized adversarial examples to further increase the robustness of the proposed uncertainty measure. Through comprehensive experiments on various datasets, our proposed framework is demonstrated to consistently outperform competing algorithms.",
        "versions": [
            {
                "year": 2018,
                "source": "SupportedSources.OPENALEX",
                "title": "A Variational Dirichlet Framework for Out-of-Distribution Detection",
                "journal": "arXiv (Cornell University)",
                "urls": [
                    "https://openalex.org/W2905813690"
                ],
                "doi": null,
                "publication_date": "2018-09-27 00:00:00"
            }
        ],
        "rank": 395
    },
    {
        "authors": [
            "Menhaj, Mohammad Bagher",
            "Parhizkari, Siamak"
        ],
        "title": "A cognitive based Intrusion detection system",
        "publication_date": "2020-05-19 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "http://arxiv.org/abs/2005.09436"
        ],
        "id": "id6210932347384382277",
        "abstract": "Intrusion detection is one of the primary mechanisms to provide computer\nnetworks with security. With an increase in attacks and growing dependence on\nvarious fields such as medicine, commercial, and engineering to give services\nover a network, securing networks have become a significant issue. The purpose\nof Intrusion Detection Systems (IDS) is to make models which can recognize\nregular communications from abnormal ones and take necessary actions. Among\ndifferent methods in this field, Artificial Neural Networks (ANNs) have been\nwidely used. However, ANN-based IDS, has two main disadvantages: 1- Low\ndetection precision. 2- Weak detection stability. To overcome these issues,\nthis paper proposes a new approach based on Deep Neural Network (DNN. The\ngeneral mechanism of our model is as follows: first, some of the data in\ndataset is properly ranked, afterwards, dataset is normalized with Min-Max\nnormalizer to fit in the limited domain. Then dimensionality reduction is\napplied to decrease the amount of both useless dimensions and computational\ncost. After the preprocessing part, Mean-Shift clustering algorithm is the used\nto create different subsets and reduce the complexity of dataset. Based on each\nsubset, two models are trained by Support Vector Machine (SVM) and deep\nlearning method. Between two models for each subset, the model with a higher\naccuracy is chosen. This idea is inspired from philosophy of divide and\nconquer. Hence, the DNN can learn each subset quickly and robustly. Finally, to\nreduce the error from the previous step, an ANN model is trained to gain and\nuse the results in order to be able to predict the attacks. We can reach to\n95.4 percent of accuracy. Possessing a simple structure and less number of\ntunable parameters, the proposed model still has a grand generalization with a\nhigh level of accuracy in compared to other methods such as SVM, Bayes network,\nand STL.Comment: 18 pages, 6 figure",
        "versions": [],
        "rank": 396
    },
    {
        "authors": [
            "Ning Lu",
            "Dan Li",
            "Wenbo Shi",
            "P. Vijayakumar",
            "F. Piccialli",
            "Victor I. Chang"
        ],
        "title": "An efficient combined deep neural network based malware detection framework in 5G environment",
        "publication_date": "2021-04-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Comput. Networks",
        "volume": "189",
        "doi": "10.1016/j.comnet.2021.107932",
        "urls": [
            "https://www.semanticscholar.org/paper/4ae376c00673d4007d3db37c47f43b5255206b78"
        ],
        "id": "id-7821030241709723391",
        "abstract": null,
        "versions": [],
        "rank": 397
    },
    {
        "authors": [
            "Deepak Pathak",
            "Philipp Kr\u00e4henb\u00fchl",
            "Jeff Donahue",
            "Trevor Darrell",
            "Alexei A. Efros"
        ],
        "title": "Context Encoders: Feature Learning by Inpainting",
        "publication_date": "2016-06-27 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Computer Vision and Pattern Recognition",
        "volume": "",
        "doi": "10.1109/cvpr.2016.278",
        "urls": [
            "https://openalex.org/W2963420272",
            "https://doi.org/10.1109/cvpr.2016.278",
            "http://arxiv.org/pdf/1604.07379"
        ],
        "id": "id5221795639509592149",
        "abstract": "",
        "versions": [],
        "rank": 398
    },
    {
        "authors": [
            "Sijin Li",
            "Zhi-Qiang Liu",
            "Antoni B. Chan"
        ],
        "title": "Heterogeneous Multi-task Learning for Human Pose Estimation with Deep Convolutional Neural Network",
        "publication_date": "2014-06-13 10:11:18+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1406.3474v1",
            "http://arxiv.org/abs/1406.3474v1",
            "http://arxiv.org/pdf/1406.3474v1"
        ],
        "id": "id-6781792184209309026",
        "abstract": "We propose an heterogeneous multi-task learning framework for human pose\nestimation from monocular image with deep convolutional neural network. In\nparticular, we simultaneously learn a pose-joint regressor and a sliding-window\nbody-part detector in a deep network architecture. We show that including the\nbody-part detection task helps to regularize the network, directing it to\nconverge to a good solution. We report competitive and state-of-art results on\nseveral data sets. We also empirically show that the learned neurons in the\nmiddle layer of our network are tuned to localized body parts.",
        "versions": [],
        "rank": 399
    },
    {
        "authors": [
            "Crist\u00f3bal Romero",
            "Sebasti\u00e1n Ventura"
        ],
        "title": "Educational Data Mining: A Review of the State of the Art",
        "publication_date": "2010-11-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "IEEE transactions on systems, man and cybernetics",
        "volume": "40",
        "doi": "10.1109/tsmcc.2010.2053532",
        "urls": [
            "https://openalex.org/W2006444123",
            "https://doi.org/10.1109/tsmcc.2010.2053532",
            "https://repository.unab.edu.co/bitstream/20.500.12749/11937/1/2020_Tesis_Andrea_Paola_Sanchez.pdf"
        ],
        "id": "id-7410618744839438437",
        "abstract": "",
        "versions": [],
        "rank": 400
    },
    {
        "authors": [
            "Vijeta Sharma",
            "Manjari Gupta",
            "Ajai Kumar",
            "Deepti Mishra"
        ],
        "title": "Video Processing using Deep learning Techniques: A Systematic Literature Review",
        "publication_date": "2021-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Institute of Electrical and Electronics Engineers (IEEE)",
        "volume": "",
        "doi": "10.1109/access.2021.3118541",
        "urls": [
            "https://web.archive.org/web/20220522093726/https://ieeexplore.ieee.org/ielx7/6287639/6514899/09563948.pdf"
        ],
        "id": "id-5973962642563017096",
        "abstract": "Studies show lots of advanced research on various data types such as image, speech, and text using deep learning techniques, but nowadays, research on video processing is also an emerging field of computer vision. Several surveys are present on video processing using computer vision deep learning techniques, targeting specific functionality such as anomaly detection, crowd analysis, activity monitoring, etc. However, a combined study is still unexplored. This paper aims to present a Systematic Literature Review (SLR) on video processing using deep learning to investigate the applications, functionalities, techniques, datasets, issues, and challenges by formulating the relevant research questions (RQs). This systematic mapping includes 93 research articles from reputed databases published between 2011 and 2020. We categorize the deep learning technique for video processing as CNN, DNN, and RNN based. We observe the significant advancements in video processing between 2017 and 2020, primarily due to the advent of AlexNet, ResNet, and LSTM based deep learning techniques. The prominent fields of video processing research are observed as human action recognition, crowd anomaly detection, and behavior analysis. This SLR is a helpful guide for the researchers to explore the recent literature, available datasets, and existing deep learning techniques for video processing.",
        "versions": [],
        "rank": 401
    },
    {
        "authors": [
            "D. J. Jobson",
            "Zia Ur Rahman",
            "G.A. Woodell"
        ],
        "title": "A multiscale retinex for bridging the gap between color images and the human observation of scenes",
        "publication_date": "1997-07-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "IEEE transactions on image processing",
        "volume": "6",
        "doi": "10.1109/83.597272",
        "urls": [
            "https://openalex.org/W2150721269",
            "https://doi.org/10.1109/83.597272"
        ],
        "id": "id-7057750042607690071",
        "abstract": "",
        "versions": [],
        "rank": 402
    },
    {
        "authors": [
            "Henriksson, Jens"
        ],
        "title": "On Improving Validity of Deep Neural Networks in Safety Critical Applications",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "https://core.ac.uk/download/326728497.pdf"
        ],
        "id": "id2819133016203854144",
        "abstract": "Context: Deep learning has proven to be a valuable component in object detection and classification, as the technique has shown an increased performance throughput compared to traditional software algorithms. Deep learning refers to the process, in which an optimisation process learns an algorithm through a set of labeled data, where the researcher defines an architecture rather than the algorithm itself. As the resulting model contains abstract features retrieved through the optimisation process, new unsolved challenges emerge that need to be resolved before deploying these models in safety critical applications. Aim: The aim of this Licentiate thesis has been to study what extensions are necessary to verify deep neural networks. Furthermore, the thesis studies one challenge in detail: how out-of-distribution samples can be detected and excluded. Method:A comparative framework has been constructed to evaluate performance of out-of-distribution detection methods on common ground. To achieve this, the top performing candidates from recent publications were used as a reference snowballing baseline, from which a set of candidates were studied. From the study, common features were studied and included in the comparative framework. Furthermore, the thesis conducted semi-structured interviews to understand the challenges of deploying deep neural networks in industrial safety critical applications. Results: The thesis found that the main issue with deployment is traceability and quality quantification, in the form that deep learning lacks proper descriptions of how to design test cases, training datasets and robustness of the model itself. While deep learning performance is commendable, error tracing is challenging as the abstract features in the do not have any direct connection to the training samples. In addition, the training phase lacks proper measures to quantify diversity within the dataset, especially for the vastly different scenarios that exist in the real world. One safety method studied in this thesis is to utilize an out-of-distribution detector as a safety measure. The benefit of this measure is that it can both identify and mitigate potential hazards. From our literature review it became apparent that each detector was compared with different techniques, hence a framework was constructed that allowed for extensive and fair comparison. In addition, when utilizing the framework, robustness issues of the detector were found, where performance could drastically change depending on small variations in the deep neural network. Future work: Future works recommend testing the outlier detectors on real world scenarios, and show how the detector can be part of a safety strategy argumentation",
        "versions": [],
        "rank": 403
    },
    {
        "authors": [
            "Lerina Aversano",
            "M. Bernardi",
            "Marta Cimitile",
            "R. Pecori"
        ],
        "title": "Early Detection of Parkinson Disease using Deep Neural Networks on Gait Dynamics",
        "publication_date": "2020-07-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/IJCNN48605.2020.9207380",
        "urls": [
            "https://www.semanticscholar.org/paper/b0d9c43cf19840cffb29792bbe45da4fe96c2d3a"
        ],
        "id": "id-4928536096850440176",
        "abstract": "Parkinson\u2019s disease is a degenerative movement disorder causing considerable disability. However, the early detection of this syndrome and of its progression rates may be decisive for the identification of appropriate therapies. For this reason, the adoption of Neural Networks to detect this disease on the base of walking information is gaining more and more interest. In this paper, we defined a Deep Neural Network based approach allowing one to exploit the information coming from various sensors located under the feet of a person. The proposed approach allows one to discriminate people affected by the Parkinson syndrome and detect the progression rates of the disease itself. To evaluate the proposed architecture we used a known dataset with the aim to compare its performance with other similar approaches. Moreover, we performed an in-depth hyper-parameter optimization to find out the best neural network configuration for the specific task. The comparison shows that the proposed classifier, trained with the best parameters, outperforms the results proviously obtained in other studies on the same dataset.",
        "versions": [],
        "rank": 404
    },
    {
        "authors": [
            "Mike Wu",
            "Noah Goodman",
            "Stefano Ermon"
        ],
        "title": "Improving Compositionality of Neural Networks by Decoding Representations to Inputs",
        "publication_date": "2021-06-01 20:07:16+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2106.00769v2",
            "http://arxiv.org/abs/2106.00769v2",
            "http://arxiv.org/pdf/2106.00769v2"
        ],
        "id": "id-8727424779966383584",
        "abstract": "In traditional software programs, it is easy to trace program logic from\nvariables back to input, apply assertion statements to block erroneous\nbehavior, and compose programs together. Although deep learning programs have\ndemonstrated strong performance on novel applications, they sacrifice many of\nthe functionalities of traditional software programs. With this as motivation,\nwe take a modest first step towards improving deep learning programs by jointly\ntraining a generative model to constrain neural network activations to \"decode\"\nback to inputs. We call this design a Decodable Neural Network, or DecNN. Doing\nso enables a form of compositionality in neural networks, where one can\nrecursively compose DecNN with itself to create an ensemble-like model with\nuncertainty. In our experiments, we demonstrate applications of this\nuncertainty to out-of-distribution detection, adversarial example detection,\nand calibration -- while matching standard neural networks in accuracy. We\nfurther explore this compositionality by combining DecNN with pretrained\nmodels, where we show promising results that neural networks can be regularized\nfrom using protected features.",
        "versions": [],
        "rank": 405
    },
    {
        "authors": [
            "Li, Guanbin",
            "Yu, Yizhou"
        ],
        "title": "Visual Saliency Based on Multiscale Deep Features",
        "publication_date": "2015-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/cvpr.2015.7299184",
        "urls": [
            "https://core.ac.uk/download/38075660.pdf"
        ],
        "id": "id3499970952759686422",
        "abstract": "Visual saliency is a fundamental problem in both cognitive and computational\nsciences, including computer vision. In this CVPR 2015 paper, we discover that\na high-quality visual saliency model can be trained with multiscale features\nextracted using a popular deep learning architecture, convolutional neural\nnetworks (CNNs), which have had many successes in visual recognition tasks. For\nlearning such saliency models, we introduce a neural network architecture,\nwhich has fully connected layers on top of CNNs responsible for extracting\nfeatures at three different scales. We then propose a refinement method to\nenhance the spatial coherence of our saliency results. Finally, aggregating\nmultiple saliency maps computed for different levels of image segmentation can\nfurther boost the performance, yielding saliency maps better than those\ngenerated from a single segmentation. To promote further research and\nevaluation of visual saliency models, we also construct a new large database of\n4447 challenging images and their pixelwise saliency annotation. Experimental\nresults demonstrate that our proposed method is capable of achieving\nstate-of-the-art performance on all public benchmarks, improving the F-Measure\nby 5.0% and 13.2% respectively on the MSRA-B dataset and our new dataset\n(HKU-IS), and lowering the mean absolute error by 5.7% and 35.1% respectively\non these two datasets.Comment: To appear in CVPR 201",
        "versions": [],
        "rank": 406
    },
    {
        "authors": [
            "Rupal A. Kapdi",
            "Deep R. Shah",
            "Jigna S. Patel",
            "Jitali Patel"
        ],
        "title": "Three Class Classification Of Alzheimer's Disease Using Deep NEURAL Networks.",
        "publication_date": "2022-09-29 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.2174/1573405618666220929092341",
        "urls": [
            "https://www.semanticscholar.org/paper/fdd3a37011fafc13ac20c8119bbd5615833f071e"
        ],
        "id": "id5287715078636448635",
        "abstract": "Alzheimer's disease (AD) is prevalent dementia that can cause neurological brain disorders, poor decision making, impaired memory, mood swings, unstable emotions, and personality change. Deep neural networks are proficient in classifying Alzheimer's disease based on MRI images. This classification assists human experts in diagnosing AD and predicts its future progression. The paper proposes various Deep Neural Networks (DNN) for early AD detection to save cost and time for doctors, radiologists, and caregivers. A 3330-image-based Kaggle dataset is used to train the DNN, including 52 images of AD, 717 images of Mild Cognitive Impairment (MCI), and the remaining images of Cognitive Normal (CN). Stratified partitioning splits the dataset into 80% and 20% proportions for training and validation datasets. Proposed models include DenseNet169, DenseNet201, and ResNet152 DNNs with additional three fully-connected layers and softmax and Kullback Leibler Divergence (KLD) loss function. These models are trained considering pre-trained, partially pre-trained, and fully re-trained extended base models. The KLD loss function reduces the error and increases accuracy for all models. The partially pre-trained DenseNet201 model outperformed all the other models. DenseNet201 gives the highest accuracy of 99.98% for training, 99.07% for validation, and 95.66% for test datasets. The DenseNet201 model has the highest accuracy in comparison to other state-of-art-methods.",
        "versions": [],
        "rank": 407
    },
    {
        "authors": [
            "Tonin, F.",
            "Pandey, A.",
            "Patrinos, P.",
            "Suykens, J."
        ],
        "title": "Unsupervised Energy-based Out-of-distribution Detection using Stiefel-Restricted Kernel Machine",
        "publication_date": "2021-07-18 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ijcnn52387.2021.9533706",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/9533266/9533267/09533706.pdf?arnumber=9533706",
            "http://dx.doi.org/10.1109/ijcnn52387.2021.9533706"
        ],
        "id": "id7522705493744586813",
        "abstract": "",
        "versions": [],
        "rank": 408
    },
    {
        "authors": [
            ",",
            "Albanie, S",
            "Hu, J",
            "Shen, L",
            "Sun, G",
            "Vedaldi, A"
        ],
        "title": "Gather-Excite: Exploiting Feature Context in Convolutional Neural  Networks",
        "publication_date": "2018-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "http://arxiv.org/abs/1810.12348"
        ],
        "id": "id3570096320764748754",
        "abstract": "While the use of bottom-up local operators in convolutional neural networks\n(CNNs) matches well some of the statistics of natural images, it may also\nprevent such models from capturing contextual long-range feature interactions.\nIn this work, we propose a simple, lightweight approach for better context\nexploitation in CNNs. We do so by introducing a pair of operators: gather,\nwhich efficiently aggregates feature responses from a large spatial extent, and\nexcite, which redistributes the pooled information to local features. The\noperators are cheap, both in terms of number of added parameters and\ncomputational complexity, and can be integrated directly in existing\narchitectures to improve their performance. Experiments on several datasets\nshow that gather-excite can bring benefits comparable to increasing the depth\nof a CNN at a fraction of the cost. For example, we find ResNet-50 with\ngather-excite operators is able to outperform its 101-layer counterpart on\nImageNet with no additional learnable parameters. We also propose a parametric\ngather-excite operator pair which yields further performance gains, relate it\nto the recently-introduced Squeeze-and-Excitation Networks, and analyse the\neffects of these changes to the CNN feature activation statistics.Comment: NeurIPS 201",
        "versions": [],
        "rank": 409
    },
    {
        "authors": [
            "Bakar, B.",
            "Hanilci, C."
        ],
        "title": "Replay spoofing attack detection using deep neural networks",
        "publication_date": "2018-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/siu.2018.8404584",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/8394765/8404147/08404584.pdf?arnumber=8404584",
            "http://dx.doi.org/10.1109/siu.2018.8404584"
        ],
        "id": "id-3665608536080374621",
        "abstract": "",
        "versions": [],
        "rank": 410
    },
    {
        "authors": [
            "German Ros",
            "Laura Sellart",
            "Joanna Materzynska",
            "David Vazquez",
            "Antonio M. L\u00f3pez"
        ],
        "title": "The SYNTHIA Dataset: A Large Collection of Synthetic Images for Semantic Segmentation of Urban Scenes",
        "publication_date": "2016-06-27 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Computer Vision and Pattern Recognition",
        "volume": "",
        "doi": "10.1109/cvpr.2016.352",
        "urls": [
            "https://openalex.org/W2431874326",
            "https://doi.org/10.1109/cvpr.2016.352"
        ],
        "id": "id3091261424239209957",
        "abstract": "",
        "versions": [],
        "rank": 411
    },
    {
        "authors": [
            "Glorot Xavier",
            "Gulcehre Caglar",
            "Muandet Krikamol",
            "Zhang Zhou"
        ],
        "title": "Discriminative models for multi-instance problems with tree-structure",
        "publication_date": "2017-03-07 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1145/2996758.2996761",
        "urls": [
            "http://arxiv.org/abs/1703.02868"
        ],
        "id": "id-1195822662908628340",
        "abstract": "Modeling network traffic is gaining importance in order to counter modern\nthreats of ever increasing sophistication. It is though surprisingly difficult\nand costly to construct reliable classifiers on top of telemetry data due to\nthe variety and complexity of signals that no human can manage to interpret in\nfull. Obtaining training data with sufficiently large and variable body of\nlabels can thus be seen as prohibitive problem. The goal of this work is to\ndetect infected computers by observing their HTTP(S) traffic collected from\nnetwork sensors, which are typically proxy servers or network firewalls, while\nrelying on only minimal human input in model training phase. We propose a\ndiscriminative model that makes decisions based on all computer's traffic\nobserved during predefined time window (5 minutes in our case). The model is\ntrained on collected traffic samples over equally sized time window per large\nnumber of computers, where the only labels needed are human verdicts about the\ncomputer as a whole (presumed infected vs. presumed clean). As part of training\nthe model itself recognizes discriminative patterns in traffic targeted to\nindividual servers and constructs the final high-level classifier on top of\nthem. We show the classifier to perform with very high precision, while the\nlearned traffic patterns can be interpreted as Indicators of Compromise. In the\nfollowing we implement the discriminative model as a neural network with\nspecial structure reflecting two stacked multi-instance problems. The main\nadvantages of the proposed configuration include not only improved accuracy and\nability to learn from gross labels, but also automatic learning of server types\n(together with their detectors) which are typically visited by infected\ncomputers",
        "versions": [],
        "rank": 412
    },
    {
        "authors": [
            "Jianguo Chen",
            "Ahmad Salah"
        ],
        "title": "Editorial introduction: special issue on advances in parallel and distributed computing for neural computing",
        "publication_date": "2020-04-02 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Springer Science and Business Media LLC",
        "volume": "",
        "doi": "10.1007/s00521-020-04887-7",
        "urls": [
            "https://web.archive.org/web/20200510095712/https://link.springer.com/content/pdf/10.1007/s00521-020-04887-7.pdf"
        ],
        "id": "id3143966522901489086",
        "abstract": "In recent years, the popularity of neural computing (NC), machine learning (ML), and artificial intelligence (AI) has grown substantially. A lot of research was carried out in both academia and industry, and it was applied in many fields. For example, deep learning achieved superhuman performance in image classification. NC/ML/AI technologies were used very successfully to play games such as Chess, Go, Atari, and Jeopardy. In addition, many companies used AI and ML technology in areas such as health care, natural resource management, and advertisement. Most NC/ML/AI technologies and applications require heavy use of high-performance computers and accelerators for efficient processing. Consequently, parallel computing, distributed computing, cloud computing, and high-performance computing (HPC) are key components of these systems. In scientific research and practical applications, clusters of computers and accelerators (e.g., GPUs) are routinely used to train and run various neural network models. In addition, due to time-consuming iterative training processes and massive training datasets, NC/ML/ AI technologies also become a \"killer application\" for parallel computing, distributed computing, and HPC. The above challenges have driven much of the research in distributed and parallel computing. For example, tailored computer architectures were devised and new parallel programming frameworks were developed to accelerate NC/ML/AI models. The objective of this special issue is to bring together the parallel and distributed computing and NC/ML/AI communities to present their applications and solutions to performance issues and also to present how NC/ML/AI can be used to solve performance problems. The range of topics covered by this special issue is broad. The papers in the special issue represent a broad spectrum of parallel and distributed computing, machine learning models, and neural network models. Papers by Zheng Xiao, Zhao Tong, and Yikun Hu et al. focused on computing task scheduling in distributed and parallel computing environments. The paper by Yuedan Chen et al. focused on the partitioning and parallelization of the general sparse matrix-sparse matrix (SpGEMM) on HPC systems, which is used as the basic kernel in many NC/ML/AI algorithms. Papers by Shuang Yang and Hao Wang focused on parallelization of ML algorithms in distributed computing environments, including mobile social networks (MSNs) and of multi-view clustering (MvC) algorithms. Papers by Xiaofeng Zou, Titinunt Kitrungrotsakul, and Keyang Cheng focused on the parallelization and performance optimization of different neural network models in distributed and parallel computing environments, including cloud computing platforms, GPU-based parallel computing systems, and HPC systems. In addition, papers by Ao Liu, Minrong Lu, Jin Zhang, and Fan Wu focused on structural optimization of neural network models. Moreover, papers by Xiaofeng Zou, Minrong Lu, Xiaoyong Tang, Titinunt Kitrungrotsakul, and Fan Wu focused on performance optimization of neural network models and their applications in various fields, such as monetary policy prediction, bioinformatics, image classification, pedestrian re-identification, fingerprint pattern recognition, and human personality classification. The paper by Zheng Xiao et al. focused on task scheduling and virtual machine (VM) allocation in distributed computing environments and described a workload-driven coordination mechanism between virtual machine allocation and task scheduling. The datasets acquired from machine learning and deep learning applications have Markov poverty and are modeled as Markov chains to extract workload characteristic operators of & Jianguo Chen",
        "versions": [],
        "rank": 413
    },
    {
        "authors": [
            "Eric Nalisnick",
            "Balaji Lakshminarayanan",
            "Dilan Gorur",
            "Yee Whye Teh",
            "Akihiro Matsukawa"
        ],
        "title": "Do Deep Generative Models Know What They Don't Know?",
        "publication_date": "2018-10-22 00:00:00",
        "source": "SupportedSources.PAPERS_WITH_CODE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1810.09136v3.pdf",
            "https://github.com/glouppe/info8010-deep-learning",
            "https://openreview.net/pdf?id=H1xwNhCcYm"
        ],
        "id": "id-3288758070578580248",
        "abstract": "A neural network deployed in the wild may be asked to make predictions for\ninputs that were drawn from a different distribution than that of the training\ndata. A plethora of work has demonstrated that it is easy to find or synthesize\ninputs for which a neural network is highly confident yet wrong. Generative\nmodels are widely viewed to be robust to such mistaken confidence as modeling\nthe density of the input features can be used to detect novel,\nout-of-distribution inputs. In this paper we challenge this assumption. We find\nthat the density learned by flow-based models, VAEs, and PixelCNNs cannot\ndistinguish images of common objects such as dogs, trucks, and horses (i.e.\nCIFAR-10) from those of house numbers (i.e. SVHN), assigning a higher\nlikelihood to the latter when the model is trained on the former. Moreover, we\nfind evidence of this phenomenon when pairing several popular image data sets:\nFashionMNIST vs MNIST, CelebA vs SVHN, ImageNet vs CIFAR-10 / CIFAR-100 / SVHN.\nTo investigate this curious behavior, we focus analysis on flow-based\ngenerative models in particular since they are trained and evaluated via the\nexact marginal likelihood. We find such behavior persists even when we restrict\nthe flows to constant-volume transformations. These transformations admit some\ntheoretical analysis, and we show that the difference in likelihoods can be\nexplained by the location and variances of the data and the model curvature.\nOur results caution against using the density estimates from deep generative\nmodels to identify inputs similar to the training distribution until their\nbehavior for out-of-distribution inputs is better understood.",
        "versions": [
            {
                "year": 2019,
                "source": "SupportedSources.CORE",
                "title": "Do Deep Generative Models Know What They Don't Know?",
                "journal": "",
                "urls": [
                    "http://arxiv.org/abs/1810.09136"
                ],
                "doi": null,
                "publication_date": "2019-01-01 00:00:00"
            }
        ],
        "rank": 414
    },
    {
        "authors": [
            "Rozi, M.",
            "Kim, S.",
            "Ozawa, S."
        ],
        "title": "Deep Neural Networks for Malicious JavaScript Detection Using Bytecode Sequences",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ijcnn48605.2020.9207134",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/9200848/9206590/09207134.pdf?arnumber=9207134",
            "http://dx.doi.org/10.1109/ijcnn48605.2020.9207134"
        ],
        "id": "id-6233749068920854726",
        "abstract": "",
        "versions": [],
        "rank": 415
    },
    {
        "authors": [
            "Yansong Gao",
            "Chang Xu",
            "Derui Wang",
            "Shiping Chen",
            "D. Ranasinghe",
            "S. Nepal"
        ],
        "title": "STRIP: a defence against trojan attacks on deep neural networks",
        "publication_date": "2019-02-18 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1145/3359789.3359790",
        "urls": [
            "https://www.semanticscholar.org/paper/63aa6b35e392e26c94ae252623863b4934c0a958"
        ],
        "id": "id2218428712717005392",
        "abstract": "A recent trojan attack on deep neural network (DNN) models is one insidious variant of data poisoning attacks. Trojan attacks exploit an effective backdoor created in a DNN model by leveraging the difficulty in interpretability of the learned model to misclassify any inputs signed with the attacker's chosen trojan trigger. Since the trojan trigger is a secret guarded and exploited by the attacker, detecting such trojan inputs is a challenge, especially at run-time when models are in active operation. This work builds STRong Intentional Perturbation (STRIP) based run-time trojan attack detection system and focuses on vision system. We intentionally perturb the incoming input, for instance by superimposing various image patterns, and observe the randomness of predicted classes for perturbed inputs from a given deployed model---malicious or benign. A low entropy in predicted classes violates the input-dependence property of a benign model and implies the presence of a malicious input---a characteristic of a trojaned input. The high efficacy of our method is validated through case studies on three popular and contrasting datasets: MNIST, CIFAR10 and GTSRB. We achieve an overall false acceptance rate (FAR) of less than 1%, given a preset false rejection rate (FRR) of 1%, for different types of triggers. Using CIFAR10 and GTSRB, we have empirically achieved result of 0% for both FRR and FAR. We have also evaluated STRIP robustness against a number of trojan attack variants and adaptive attacks.",
        "versions": [],
        "rank": 416
    },
    {
        "authors": [
            "Alahi, Alexandre",
            "Bagautdinov, Timur",
            "Fleuret, Fran\u00e7ois",
            "Fua, Pascal",
            "Savarese, Silvio"
        ],
        "title": "Social Scene Understanding: End-to-End Multi-Person Action Localization  and Collective Activity Recognition",
        "publication_date": "2016-11-28 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/cvpr.2017.365",
        "urls": [
            "https://core.ac.uk/download/148032235.pdf"
        ],
        "id": "id-2316771999162934913",
        "abstract": "We present a unified framework for understanding human social behaviors in\nraw image sequences. Our model jointly detects multiple individuals, infers\ntheir social actions, and estimates the collective actions with a single\nfeed-forward pass through a neural network. We propose a single architecture\nthat does not rely on external detection algorithms but rather is trained\nend-to-end to generate dense proposal maps that are refined via a novel\ninference scheme. The temporal consistency is handled via a person-level\nmatching Recurrent Neural Network. The complete model takes as input a sequence\nof frames and outputs detections along with the estimates of individual actions\nand collective activities. We demonstrate state-of-the-art performance of our\nalgorithm on multiple publicly available benchmarks",
        "versions": [],
        "rank": 417
    },
    {
        "authors": [
            "Muller, R.",
            "Illium, S.",
            "Linnhoff-Popien, C."
        ],
        "title": "Deep Recurrent Interpolation Networks for Anomalous Sound Detection",
        "publication_date": "2021-07-18 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ijcnn52387.2021.9533560",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/9533266/9533267/09533560.pdf?arnumber=9533560",
            "http://dx.doi.org/10.1109/ijcnn52387.2021.9533560"
        ],
        "id": "id2046077755245349599",
        "abstract": "",
        "versions": [],
        "rank": 418
    },
    {
        "authors": [
            "Doermann, David",
            "Eum, Sungmin",
            "Kwon, Heesung",
            "Lee, Hyungtae"
        ],
        "title": "IOD-CNN: Integrating Object Detection Networks for Event Recognition",
        "publication_date": "2017-03-21 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/icip.2017.8296406",
        "urls": [
            "http://arxiv.org/abs/1703.07431"
        ],
        "id": "id-3957135608428064852",
        "abstract": "Many previous methods have showed the importance of considering semantically\nrelevant objects for performing event recognition, yet none of the methods have\nexploited the power of deep convolutional neural networks to directly integrate\nrelevant object information into a unified network. We present a novel unified\ndeep CNN architecture which integrates architecturally different, yet\nsemantically-related object detection networks to enhance the performance of\nthe event recognition task. Our architecture allows the sharing of the\nconvolutional layers and a fully connected layer which effectively integrates\nevent recognition, rigid object detection and non-rigid object detection.Comment: submitted to IEEE International Conference on Image Processing 201",
        "versions": [],
        "rank": 419
    },
    {
        "authors": [
            "Marius Cordts",
            "Mohamed M. Omran",
            "Sebastian Ramos",
            "Timo Rehfeld",
            "Markus Enzweiler",
            "Rodrigo Benenson",
            "Uwe Franke",
            "Stefan Roth",
            "Bernt Schiele"
        ],
        "title": "The Cityscapes Dataset for Semantic Urban Scene Understanding",
        "publication_date": "2016-06-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Computer Vision and Pattern Recognition",
        "volume": "",
        "doi": "10.1109/cvpr.2016.350",
        "urls": [
            "https://openalex.org/W2340897893",
            "https://doi.org/10.1109/cvpr.2016.350",
            "http://arxiv.org/pdf/1604.01685"
        ],
        "id": "id-6508716727706723275",
        "abstract": "",
        "versions": [],
        "rank": 420
    },
    {
        "authors": [
            "M. Wo\u017aniak",
            "J. Si\u0142ka",
            "M. Wieczorek"
        ],
        "title": "Deep neural network correlation learning mechanism for CT brain tumor detection",
        "publication_date": "2021-03-16 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1007/S00521-021-05841-X",
        "urls": [
            "https://www.semanticscholar.org/paper/c29cf2a252f3a2444a9846e70208fda3ca6e42bb"
        ],
        "id": "id338917198529239588",
        "abstract": null,
        "versions": [],
        "rank": 421
    },
    {
        "authors": [
            "Fahim Tajwar",
            "Ananya Kumar",
            "Sang Michael Xie",
            "Percy Liang"
        ],
        "title": "No True State-of-the-Art? OOD Detection Methods are Inconsistent across Datasets",
        "publication_date": "2021-09-12 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20210920031515/https://arxiv.org/pdf/2109.05554v1.pdf"
        ],
        "id": "id7131175393554872507",
        "abstract": "Out-of-distribution detection is an important component of reliable ML systems. Prior literature has proposed various methods (e.g., MSP (Hendrycks & Gimpel, 2017), ODIN (Liang et al., 2018), Mahalanobis (Lee et al., 2018)), claiming they are state-of-the-art by showing they outperform previous methods on a selected set of in-distribution (ID) and out-of-distribution (OOD) datasets. In this work, we show that none of these methods are inherently better at OOD detection than others on a standardized set of 16 (ID, OOD) pairs. We give possible explanations for these inconsistencies with simple toy datasets where whether one method outperforms another depends on the structure of the ID and OOD datasets in question. Finally, we show that a method outperforming another on a certain (ID, OOD) pair may not do so in a low-data regime. In the low-data regime, we propose a distance-based method, Pairwise OOD detection (POD), which is based on Siamese networks and improves over Mahalanobis by sidestepping the expensive covariance estimation step. Our results suggest that the OOD detection problem may be too broad, and we should consider more specific structures for leverage.",
        "versions": [],
        "rank": 422
    },
    {
        "authors": [
            "Raza Ali",
            "Joon Huang Chuah",
            "M. S. A. Talip",
            "N. Mokhtar",
            "M. Shoaib"
        ],
        "title": "Structural crack detection using deep convolutional neural networks",
        "publication_date": "2022-01-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1016/j.autcon.2021.103989",
        "urls": [
            "https://www.semanticscholar.org/paper/34091ecf8799cb0705c2de00dfb96a4a5e947ee7"
        ],
        "id": "id7964506323128021142",
        "abstract": null,
        "versions": [],
        "rank": 423
    },
    {
        "authors": [
            "Postels, Janis",
            "Segu, Mattia",
            "Sieber, Luca",
            "Sun, Tao",
            "Tombari, Federico",
            "Van Gool, Luc",
            "Yu, Fisher"
        ],
        "title": "On the Practicality of Deterministic Epistemic Uncertainty",
        "publication_date": "2022-07-05 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "http://arxiv.org/abs/2107.00649"
        ],
        "id": "id-145555488369232068",
        "abstract": "A set of novel approaches for estimating epistemic uncertainty in deep neural\nnetworks with a single forward pass has recently emerged as a valid alternative\nto Bayesian Neural Networks. On the premise of informative representations,\nthese deterministic uncertainty methods (DUMs) achieve strong performance on\ndetecting out-of-distribution (OOD) data while adding negligible computational\ncosts at inference time. However, it remains unclear whether DUMs are well\ncalibrated and can seamlessly scale to real-world applications - both\nprerequisites for their practical deployment. To this end, we first provide a\ntaxonomy of DUMs, and evaluate their calibration under continuous\ndistributional shifts. Then, we extend them to semantic segmentation. We find\nthat, while DUMs scale to realistic vision tasks and perform well on OOD\ndetection, the practicality of current methods is undermined by poor\ncalibration under distributional shifts.Comment: International Conference on Machine Learning 202",
        "versions": [
            {
                "year": 2021,
                "source": "SupportedSources.PAPERS_WITH_CODE",
                "title": "On the Practicality of Deterministic Epistemic Uncertainty",
                "journal": "",
                "urls": [
                    "https://arxiv.org/pdf/2107.00649v3.pdf",
                    "https://github.com/google/uncertainty-baselines",
                    "https://openreview.net/pdf?id=W3-hiLnUYl"
                ],
                "doi": "",
                "publication_date": "2021-07-01 00:00:00"
            }
        ],
        "rank": 424
    },
    {
        "authors": [
            "Bruzzone, Lorenzo",
            "Mou, Lichao",
            "Zhu, Xiao Xiang"
        ],
        "title": "Learning Spectral-Spatial-Temporal Features via a Recurrent  Convolutional Neural Network for Change Detection in Multispectral Imagery",
        "publication_date": "2018-03-07 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/tgrs.2018.2863224",
        "urls": [
            "http://arxiv.org/abs/1803.02642"
        ],
        "id": "id-1687084346597931601",
        "abstract": "Change detection is one of the central problems in earth observation and was\nextensively investigated over recent decades. In this paper, we propose a novel\nrecurrent convolutional neural network (ReCNN) architecture, which is trained\nto learn a joint spectral-spatial-temporal feature representation in a unified\nframework for change detection in multispectral images. To this end, we bring\ntogether a convolutional neural network (CNN) and a recurrent neural network\n(RNN) into one end-to-end network. The former is able to generate rich\nspectral-spatial feature representations, while the latter effectively analyzes\ntemporal dependency in bi-temporal images. In comparison with previous\napproaches to change detection, the proposed network architecture possesses\nthree distinctive properties: 1) It is end-to-end trainable, in contrast to\nmost existing methods whose components are separately trained or computed; 2)\nit naturally harnesses spatial information that has been proven to be\nbeneficial to change detection task; 3) it is capable of adaptively learning\nthe temporal dependency between multitemporal images, unlike most of algorithms\nthat use fairly simple operation like image differencing or stacking. As far as\nwe know, this is the first time that a recurrent convolutional network\narchitecture has been proposed for multitemporal remote sensing image analysis.\nThe proposed network is validated on real multispectral data sets. Both visual\nand quantitative analysis of experimental results demonstrates competitive\nperformance in the proposed mode",
        "versions": [],
        "rank": 425
    },
    {
        "authors": [
            "Jiun-In Guo",
            "Chia-Chi Tsai",
            "Jian-Lin Zeng",
            "Shao-Wei Peng",
            "En-Chih Chang"
        ],
        "title": "Hybrid Fixed-Point/Binary Deep Neural Network Design Methodology for Low-Power Object Detection",
        "publication_date": "2020-08-12 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "IEEE Journal on Emerging and Selected Topics in Circuits and Systems",
        "volume": "10",
        "doi": "10.1109/JETCAS.2020.3015753",
        "urls": [
            "https://www.semanticscholar.org/paper/3e2f76a9f366cafa74f4a1328941b77ef1ef5872"
        ],
        "id": "id6728802735715965619",
        "abstract": "Suffering from both high computational complexity and high memory bandwidth is the major challenge in realizing the deep neural network in low-power for real-time applications. Binarizing the feature maps as well as the filter coefficients in deep neural network is an efficient way to reduce the high power consumption in deep learning object detection, however, it greatly scarifies the detection accuracy when reducing the bit-width of a 32-bit word to a binary bit in a floating-point deep neural network. This paper proposes a hybrid fixed point/binary deep neural network design methodology for object detection to achieve low-power consumption by taking advantage of both the fixed-point and binary deep neural networks, which allocates enough bit-width to design the hardware datapath in different layers of deep neural network. The proposed methodology combines dynamic fixed-point quantization and binarization techniques together to extremely compress the object detection model to result in a compact hybrid fixed-point/binary detection neural network, which achieves lower bandwidth and lower computational complexity. An automation tool based on the proposed methodology is also developed to train a hybrid deep neural network under a specified quality loss range. Taking MobileNet-SSD as an example, using the proposed methodology, the resulted model achieves 91% model size reduction and 75.8% memory bandwidth reduction at the cost of less than 1% mAP quality degradation. The proposed design methodology for hybrid fixed-point/binary deep neural networks achieves a good balance on detection accuracy, model size compression ratio and feature map reduction for low-power deep learning object detection applications.",
        "versions": [],
        "rank": 426
    },
    {
        "authors": [
            "Ryant, N.",
            "Liberman, M.",
            "Yuan, J."
        ],
        "title": "Speech activity detection on youtube using deep neural networks",
        "publication_date": "2013-08-25 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.21437/interspeech.2013-203",
        "urls": [
            "http://dx.doi.org/10.21437/interspeech.2013-203"
        ],
        "id": "id3462627503960158825",
        "abstract": "",
        "versions": [
            {
                "year": 0,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Speech activity detection on youtube using deep neural networks",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/e651c1ec20460ae0f0fcd95f705370090a3bb335"
                ],
                "doi": "",
                "publication_date": "None"
            }
        ],
        "rank": 427
    },
    {
        "authors": [
            "Bello, Juan Pablo",
            "Farnsworth, Andrew",
            "Kelling, Steve",
            "Lostanlen, Vincent",
            "Salamon, Justin"
        ],
        "title": "Robust sound event detection in bioacoustic sensor networks",
        "publication_date": "2019-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "PLoS ONE",
        "volume": "",
        "doi": "10.1371/journal.pone.0214168",
        "urls": [
            "http://arxiv.org/abs/1905.08352"
        ],
        "id": "id-2452018609643926511",
        "abstract": "Bioacoustic sensors, sometimes known as autonomous recording units (ARUs),\ncan record sounds of wildlife over long periods of time in scalable and\nminimally invasive ways. Deriving per-species abundance estimates from these\nsensors requires detection, classification, and quantification of animal\nvocalizations as individual acoustic events. Yet, variability in ambient noise,\nboth over time and across sensors, hinders the reliability of current automated\nsystems for sound event detection (SED), such as convolutional neural networks\n(CNN) in the time-frequency domain. In this article, we develop, benchmark, and\ncombine several machine listening techniques to improve the generalizability of\nSED models across heterogeneous acoustic environments. As a case study, we\nconsider the problem of detecting avian flight calls from a ten-hour recording\nof nocturnal bird migration, recorded by a network of six ARUs in the presence\nof heterogeneous background noise. Starting from a CNN yielding\nstate-of-the-art accuracy on this task, we introduce two noise adaptation\ntechniques, respectively integrating short-term (60 milliseconds) and long-term\n(30 minutes) context. First, we apply per-channel energy normalization (PCEN)\nin the time-frequency domain, which applies short-term automatic gain control\nto every subband in the mel-frequency spectrogram. Secondly, we replace the\nlast dense layer in the network by a context-adaptive neural network (CA-NN)\nlayer. Combining them yields state-of-the-art results that are unmatched by\nartificial data augmentation alone. We release a pre-trained version of our\nbest performing system under the name of BirdVoxDetect, a ready-to-use detector\nof avian flight calls in field recordings.Comment: 32 pages, in English. Submitted to PLOS ONE journal in February 2019;\n  revised August 2019; published October 201",
        "versions": [],
        "rank": 428
    },
    {
        "authors": [
            "Klaus Greff",
            "Rupesh K. Srivastava",
            "Jan Koutn\u00edk",
            "Bas R. Steunebrink",
            "J\u00fcrgen Schmidhuber"
        ],
        "title": "LSTM: A Search Space Odyssey",
        "publication_date": "2017-10-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "IEEE transactions on neural networks and learning systems",
        "volume": "28",
        "doi": "10.1109/tnnls.2016.2582924",
        "urls": [
            "https://openalex.org/W1689711448",
            "https://doi.org/10.1109/tnnls.2016.2582924",
            "http://arxiv.org/pdf/1503.04069"
        ],
        "id": "id4079639384196475833",
        "abstract": "",
        "versions": [],
        "rank": 429
    },
    {
        "authors": [
            "Zou, J.",
            "Ding, N."
        ],
        "title": "Deep Neural Networks Evolve Human-like Attention Distribution during Goal-directed Reading Comprehension",
        "publication_date": "2021-08-26 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.21203/rs.3.rs-813994/v1",
        "urls": [
            "https://www.researchsquare.com/article/rs-813994/v1",
            "https://www.researchsquare.com/article/rs-813994/v1.html",
            "http://dx.doi.org/10.21203/rs.3.rs-813994/v1"
        ],
        "id": "id-7079893154491647604",
        "abstract": "",
        "versions": [],
        "rank": 430
    },
    {
        "authors": [
            "Fabio Vesperini",
            "Paolo Vecchiotti",
            "E. Principi",
            "S. Squartini",
            "F. Piazza"
        ],
        "title": "Deep neural networks for Multi-Room Voice Activity Detection: Advancements and comparative evaluation",
        "publication_date": "2016-07-24 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/IJCNN.2016.7727633",
        "urls": [
            "https://www.semanticscholar.org/paper/634fed3e552c4b8a110ff4518765ee47d32f3131"
        ],
        "id": "id2215816850369863770",
        "abstract": "This paper focuses on Voice Activity Detectors (VAD) for multi-room domestic scenarios based on deep neural network architectures. Interesting advancements are observed with respect to a previous work. A comparative and extensive analysis is lead among four different neural networks (NN). In particular, we exploit Deep Belief Network (DBN), Multi-Layer Perceptron (MLP), Bidirectional Long Short-Term Memory recurrent neural network (BLSTM) and Convolutional Neural Network (CNN). The latter has recently encountered a large success in the computational audio processing field and it has been successfully employed in our task. Two home recorded datasets are used in order to approximate real-life scenarios. They contain audio files from several microphones arranged in various rooms, from whom six features are extracted and used as input for the deep neural classifiers. The output stage has been redesigned compared to the previous author's contribution, in order to take advantage of the networks discriminative ability. Our study is composed by a multi-stage analysis focusing on the selection of the features, the network size and the input microphones. Results are evaluated in terms of Speech Activity Detection error rate (SAD). As result, a best SAD equal to 5.8% and 2.6% is reached respectively in the two considered datasets. In addiction, a significant solidity in terms of microphone positioning is observed in the case of CNN.",
        "versions": [
            {
                "year": 2016,
                "source": "SupportedSources.CROSSREF",
                "title": "Deep neural networks for Multi-Room Voice Activity Detection: Advancements and comparative evaluation",
                "journal": "",
                "urls": [
                    "http://xplorestaging.ieee.org/ielx7/7593175/7726591/07727633.pdf?arnumber=7727633",
                    "http://dx.doi.org/10.1109/ijcnn.2016.7727633"
                ],
                "doi": "10.1109/ijcnn.2016.7727633",
                "publication_date": "2016-01-01 00:00:00"
            }
        ],
        "rank": 431
    },
    {
        "authors": [
            "Jeong, Seong-Gyun",
            "Perona, Pietro",
            "Ryou, Serim"
        ],
        "title": "Anchor Loss: Modulating Loss Scale Based on Prediction Difficulty",
        "publication_date": "2019-11-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/iccv.2019.00609",
        "urls": [
            "https://core.ac.uk/download/287633884.pdf"
        ],
        "id": "id7120288635622920444",
        "abstract": "We propose a novel loss function that dynamically re-scales the cross entropy based on prediction difficulty regarding a sample. Deep neural network architectures in image classification tasks struggle to disambiguate visually similar objects. Likewise, in human pose estimation symmetric body parts often confuse the network with assigning indiscriminative scores to them. This is due to the output prediction, in which only the highest confidence label is selected without taking into consideration a measure of uncertainty. In this work, we define the prediction difficulty as a relative property coming from the confidence score gap between positive and negative labels. More precisely, the proposed loss function penalizes the network to avoid the score of a false prediction being significant. To demonstrate the efficacy of our loss function, we evaluate it on two different domains: image classification and human pose estimation. We find improvements in both applications by achieving higher accuracy compared to the baseline methods",
        "versions": [],
        "rank": 432
    },
    {
        "authors": [
            "Daniel L. K. Yamins",
            "James J. DiCarlo"
        ],
        "title": "Using goal-driven deep learning models to understand sensory cortex",
        "publication_date": "2016-03-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Nature Neuroscience",
        "volume": "19",
        "doi": "10.1038/nn.4244",
        "urls": [
            "https://openalex.org/W2274405424",
            "https://doi.org/10.1038/nn.4244"
        ],
        "id": "id-3947896125331235752",
        "abstract": "",
        "versions": [],
        "rank": 433
    },
    {
        "authors": [
            "Sami Barchid",
            "Jos\u00e9 Mennesson",
            "Chaabane Dj\u00e9raba"
        ],
        "title": "Deep Spiking Convolutional Neural Network for Single Object Localization Based On Deep Continuous Local Learning",
        "publication_date": "2021-05-12 12:02:05+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2105.05609v1",
            "http://arxiv.org/abs/2105.05609v1",
            "http://arxiv.org/pdf/2105.05609v1"
        ],
        "id": "id3213265036909653852",
        "abstract": "With the advent of neuromorphic hardware, spiking neural networks can be a\ngood energy-efficient alternative to artificial neural networks. However, the\nuse of spiking neural networks to perform computer vision tasks remains\nlimited, mainly focusing on simple tasks such as digit recognition. It remains\nhard to deal with more complex tasks (e.g. segmentation, object detection) due\nto the small number of works on deep spiking neural networks for these tasks.\nThe objective of this paper is to make the first step towards modern computer\nvision with supervised spiking neural networks. We propose a deep convolutional\nspiking neural network for the localization of a single object in a grayscale\nimage. We propose a network based on DECOLLE, a spiking model that enables\nlocal surrogate gradient-based learning. The encouraging results reported on\nOxford-IIIT-Pet validates the exploitation of spiking neural networks with a\nsupervised learning approach for more elaborate vision tasks in the future.",
        "versions": [],
        "rank": 434
    },
    {
        "authors": [
            "Anouar Kherchouche",
            "S. Fezza",
            "W. Hamidouche",
            "O. D\u00e9forges"
        ],
        "title": "Detection of Adversarial Examples in Deep Neural Networks with Natural Scene Statistics",
        "publication_date": "2020-07-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/IJCNN48605.2020.9206959",
        "urls": [
            "https://www.semanticscholar.org/paper/92f1be13949eb6855fc4d32de8468d8812f75b97"
        ],
        "id": "id-7235766661565969761",
        "abstract": "Recent studies have demonstrated that the deep neural networks (DNNs) are vulnerable to carefully-crafted perturbations added to a legitimate input image. Such perturbed images are called adversarial examples (AEs) and can cause DNNs to misclassify. Consequently, it is of paramount importance to develop detection methods of AEs, thus allowing to reject them. In this paper, we propose to characterize the AEs through the use of natural scene statistics (NSS). We demonstrate that these statistical properties are altered by the presence of adversarial perturbations. Based on this finding, we propose three different methods that exploit these scene statistics to determine if an input is adversarial or not. The proposed detection methods have been evaluated against four prominent adversarial attacks and on three standards datasets. The experimental results have shown that the proposed methods achieve a high detection accuracy while providing a low false positive rate.",
        "versions": [
            {
                "year": 2020,
                "source": "SupportedSources.CROSSREF",
                "title": "Detection of Adversarial Examples in Deep Neural Networks with Natural Scene Statistics",
                "journal": "",
                "urls": [
                    "http://xplorestaging.ieee.org/ielx7/9200848/9206590/09206959.pdf?arnumber=9206959",
                    "http://dx.doi.org/10.1109/ijcnn48605.2020.9206959"
                ],
                "doi": "10.1109/ijcnn48605.2020.9206959",
                "publication_date": "2020-01-01 00:00:00"
            }
        ],
        "rank": 435
    },
    {
        "authors": [
            "Ding, Yifan",
            "Fan, Deliang",
            "Gong, Boqing",
            "Wang, Liqiang"
        ],
        "title": "A Semi-Supervised Two-Stage Approach to Learning from Noisy Labels",
        "publication_date": "2018-03-21 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/wacv.2018.00138",
        "urls": [
            "http://arxiv.org/abs/1802.02679"
        ],
        "id": "id6822004879131633379",
        "abstract": "The recent success of deep neural networks is powered in part by large-scale\nwell-labeled training data. However, it is a daunting task to laboriously\nannotate an ImageNet-like dateset. On the contrary, it is fairly convenient,\nfast, and cheap to collect training images from the Web along with their noisy\nlabels. This signifies the need of alternative approaches to training deep\nneural networks using such noisy labels. Existing methods tackling this problem\neither try to identify and correct the wrong labels or reweigh the data terms\nin the loss function according to the inferred noisy rates. Both strategies\ninevitably incur errors for some of the data points. In this paper, we contend\nthat it is actually better to ignore the labels of some of the data points than\nto keep them if the labels are incorrect, especially when the noisy rate is\nhigh. After all, the wrong labels could mislead a neural network to a bad local\noptimum. We suggest a two-stage framework for the learning from noisy labels.\nIn the first stage, we identify a small portion of images from the noisy\ntraining set of which the labels are correct with a high probability. The noisy\nlabels of the other images are ignored. In the second stage, we train a deep\nneural network in a semi-supervised manner. This framework effectively takes\nadvantage of the whole training set and yet only a portion of its labels that\nare most likely correct. Experiments on three datasets verify the effectiveness\nof our approach especially when the noisy rate is high",
        "versions": [],
        "rank": 436
    },
    {
        "authors": [
            "Mugdim Bublin"
        ],
        "title": "Machine Learning For Distributed Acoustic Sensors, Classic versus Image and Deep Neural Networks Approach",
        "publication_date": "2019-04-25 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20191014104109/https://arxiv.org/pdf/1904.11546v1.pdf"
        ],
        "id": "id4649041658003821328",
        "abstract": "Distributed Acoustic Sensing (DAS) using fiber optic cables is a promising new technology for pipeline monitoring and protection. In this work, we applied and compared two approaches for event detection using DAS: Classic machine learning approach and the approach based on image processing and deep learning. Although with both approaches acceptable performance can be achieved, the preliminary results show that image based deep learning is more promising approach, offering six times lower event detection delay and twelve times lower execution time.",
        "versions": [],
        "rank": 437
    },
    {
        "authors": [
            "Kun-Hsing Yu",
            "Andrew L. Beam",
            "Isaac S. Kohane"
        ],
        "title": "Artificial intelligence in healthcare",
        "publication_date": "2018-10-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Nature Biomedical Engineering",
        "volume": "2",
        "doi": "10.1038/s41551-018-0305-z",
        "urls": [
            "https://openalex.org/W2895763047",
            "https://doi.org/10.1038/s41551-018-0305-z"
        ],
        "id": "id-3318737960984575392",
        "abstract": "",
        "versions": [],
        "rank": 438
    },
    {
        "authors": [
            "Gehler, Peter",
            "Nowozin, Sebastian",
            "Prokudin, Sergey"
        ],
        "title": "Deep Directional Statistics: Pose Estimation with Uncertainty  Quantification",
        "publication_date": "2018-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-3-030-01240-3_33",
        "urls": [
            "http://arxiv.org/abs/1805.03430"
        ],
        "id": "id-2225389384836798429",
        "abstract": "Modern deep learning systems successfully solve many perception tasks such as\nobject pose estimation when the input image is of high quality. However, in\nchallenging imaging conditions such as on low-resolution images or when the\nimage is corrupted by imaging artifacts, current systems degrade considerably\nin accuracy. While a loss in performance is unavoidable, we would like our\nmodels to quantify their uncertainty in order to achieve robustness against\nimages of varying quality. Probabilistic deep learning models combine the\nexpressive power of deep learning with uncertainty quantification. In this\npaper, we propose a novel probabilistic deep learning model for the task of\nangular regression. Our model uses von Mises distributions to predict a\ndistribution over object pose angle. Whereas a single von Mises distribution is\nmaking strong assumptions about the shape of the distribution, we extend the\nbasic model to predict a mixture of von Mises distributions. We show how to\nlearn a mixture model using a finite and infinite number of mixture components.\nOur model allows for likelihood-based training and efficient inference at test\ntime. We demonstrate on a number of challenging pose estimation datasets that\nour model produces calibrated probability predictions and competitive or\nsuperior point estimates compared to the current state-of-the-art",
        "versions": [],
        "rank": 439
    },
    {
        "authors": [
            "Anandkumar, Anima",
            "Nimmagadda, Tejaswi"
        ],
        "title": "Multi-Object Classification and Unsupervised Scene Understanding Using  Deep Learning Features and Latent Tree Probabilistic Models",
        "publication_date": "2015-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "https://core.ac.uk/download/211391310.pdf"
        ],
        "id": "id2546088223469862965",
        "abstract": "Deep learning has shown state-of-art classification performance on datasets\nsuch as ImageNet, which contain a single object in each image. However,\nmulti-object classification is far more challenging. We present a unified\nframework which leverages the strengths of multiple machine learning methods,\nviz deep learning, probabilistic models and kernel methods to obtain\nstate-of-art performance on Microsoft COCO, consisting of non-iconic images. We\nincorporate contextual information in natural images through a conditional\nlatent tree probabilistic model (CLTM), where the object co-occurrences are\nconditioned on the extracted fc7 features from pre-trained Imagenet CNN as\ninput. We learn the CLTM tree structure using conditional pairwise\nprobabilities for object co-occurrences, estimated through kernel methods, and\nwe learn its node and edge potentials by training a new 3-layer neural network,\nwhich takes fc7 features as input. Object classification is carried out via\ninference on the learnt conditional tree model, and we obtain significant gain\nin precision-recall and F-measures on MS-COCO, especially for difficult object\ncategories. Moreover, the latent variables in the CLTM capture scene\ninformation: the images with top activations for a latent node have common\nthemes such as being a grasslands or a food scene, and on on. In addition, we\nshow that a simple k-means clustering of the inferred latent nodes alone\nsignificantly improves scene classification performance on the MIT-Indoor\ndataset, without the need for any retraining, and without using scene labels\nduring training. Thus, we present a unified framework for multi-object\nclassification and unsupervised scene understanding",
        "versions": [],
        "rank": 440
    },
    {
        "authors": [
            "Han, Jing",
            "Liu, Ding",
            "Qian, Kun",
            "Schuller, Bj\u00f6rn W.",
            "Zhang, Zixing"
        ],
        "title": "Learning Audio Sequence Representations for Acoustic Event  Classification",
        "publication_date": "2017-07-27 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1016/j.eswa.2021.115007",
        "urls": [
            "http://arxiv.org/abs/1707.08729"
        ],
        "id": "id489822321176468897",
        "abstract": "Acoustic Event Classification (AEC) has become a significant task for\nmachines to perceive the surrounding auditory scene. However, extracting\neffective representations that capture the underlying characteristics of the\nacoustic events is still challenging. Previous methods mainly focused on\ndesigning the audio features in a 'hand-crafted' manner. Interestingly,\ndata-learnt features have been recently reported to show better performance. Up\nto now, these were only considered on the frame-level. In this paper, we\npropose an unsupervised learning framework to learn a vector representation of\nan audio sequence for AEC. This framework consists of a Recurrent Neural\nNetwork (RNN) encoder and a RNN decoder, which respectively transforms the\nvariable-length audio sequence into a fixed-length vector and reconstructs the\ninput sequence on the generated vector. After training the encoder-decoder, we\nfeed the audio sequences to the encoder and then take the learnt vectors as the\naudio sequence representations. Compared with previous methods, the proposed\nmethod can not only deal with the problem of arbitrary-lengths of audio\nstreams, but also learn the salient information of the sequence. Extensive\nevaluation on a large-size acoustic event database is performed, and the\nempirical results demonstrate that the learnt audio sequence representation\nyields a significant performance improvement by a large margin compared with\nother state-of-the-art hand-crafted sequence features for AEC",
        "versions": [],
        "rank": 441
    },
    {
        "authors": [
            "Sasanka Potluri",
            "C. Diedrich"
        ],
        "title": "Accelerated deep neural networks for enhanced Intrusion Detection System",
        "publication_date": "2016-09-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ETFA.2016.7733515",
        "urls": [
            "https://www.semanticscholar.org/paper/31ab42350cb0513de6dd30db02e9052f0ce9866c"
        ],
        "id": "id7376108939012707325",
        "abstract": "Network based communication is more vulnerable to outsider and insider attacks in recent days due to its wide spread applications in many fields. Intrusion Detection System (IDS) a software application or a hardware is a security mechanism that is able to monitor network traffic and find abnormal activities in the network. Machine learning techniques which have an important role in detecting the attacks were mostly used in the development of IDS. Due to huge increase in network traffic and different types of attacks, monitoring each and every packet in the network traffic is time consuming and computational intensive. Deep learning acts as a powerful tool by which thorough packet inspection and attack identification is possible. The parallel computing capabilities of the neural network make the Deep Neural Network (DNN) to effectively look through the network traffic with an accelerated performance. In this paper an accelerated DNN architecture is developed to identify the abnormalities in the network data. NSL-KDD dataset is used to compute the training time and to analyze the effectiveness of the detection mechanism.",
        "versions": [],
        "rank": 442
    },
    {
        "authors": [
            "Awni Y. Hannun",
            "Pranav Rajpurkar",
            "Masoumeh Haghpanahi",
            "G. Tison",
            "Codie Bourn",
            "M. Turakhia",
            "A. Ng"
        ],
        "title": "Cardiologist-level arrhythmia detection and classification in ambulatory electrocardiograms using a deep neural network",
        "publication_date": "2019-01-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Nature Medicine",
        "volume": "25",
        "doi": "10.1038/s41591-018-0268-3",
        "urls": [
            "https://www.semanticscholar.org/paper/0f37b083cfd3d113f5c26dbb3620d246b9a40292"
        ],
        "id": "id7631459522141541278",
        "abstract": null,
        "versions": [
            {
                "year": 2019,
                "source": "SupportedSources.OPENALEX",
                "title": "Cardiologist-level arrhythmia detection and classification in ambulatory electrocardiograms using a deep neural network",
                "journal": "Nature Medicine",
                "urls": [
                    "https://openalex.org/W2902644322",
                    "https://doi.org/10.1038/s41591-018-0268-3",
                    "https://europepmc.org/articles/pmc6784839?pdf=render"
                ],
                "doi": "10.1038/s41591-018-0268-3",
                "publication_date": "2019-01-07 00:00:00"
            }
        ],
        "rank": 443
    },
    {
        "authors": [
            "Dongcui Diao",
            "Hengshuai Yao",
            "Bei Jiang"
        ],
        "title": "Class Interference of Deep Neural Networks",
        "publication_date": "2022-10-31 22:29:30+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2211.01370v1",
            "http://arxiv.org/abs/2211.01370v1",
            "http://arxiv.org/pdf/2211.01370v1"
        ],
        "id": "id4479490689796696639",
        "abstract": "Recognizing and telling similar objects apart is even hard for human beings.\nIn this paper, we show that there is a phenomenon of class interference with\nall deep neural networks. Class interference represents the learning difficulty\nin data, and it constitutes the largest percentage of generalization errors by\ndeep networks. To understand class interference, we propose cross-class tests,\nclass ego directions and interference models. We show how to use these\ndefinitions to study minima flatness and class interference of a trained model.\nWe also show how to detect class interference during training through label\ndancing pattern and class dancing notes.",
        "versions": [],
        "rank": 444
    },
    {
        "authors": [
            "Strom, A."
        ],
        "title": "Enhancing face mask detection using deep neural networks and transfer learning for COVID-19 transmission prevention",
        "publication_date": "None",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.17077/etd.005925",
        "urls": [
            "http://dx.doi.org/10.17077/etd.005925"
        ],
        "id": "id-81273157647293473",
        "abstract": "",
        "versions": [],
        "rank": 445
    },
    {
        "authors": [
            "Hakan Gunduz"
        ],
        "title": "Deep Learning-Based Parkinson\u2019s Disease Classification Using Vocal Feature Sets",
        "publication_date": "2019-08-20 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "IEEE Access",
        "volume": "7",
        "doi": "10.1109/access.2019.2936564",
        "urls": [
            "https://openalex.org/W2969944904",
            "https://doi.org/10.1109/access.2019.2936564",
            "https://ieeexplore.ieee.org/ielx7/6287639/8600701/08807125.pdf"
        ],
        "id": "id-498934506889332231",
        "abstract": "",
        "versions": [],
        "rank": 446
    },
    {
        "authors": [
            "Ashish Shrivastava",
            "Tomas Pfister",
            "Oncel Tuzel",
            "Joshua M. Susskind",
            "Wenda Wang",
            "Russell Y. Webb"
        ],
        "title": "Learning from Simulated and Unsupervised Images through Adversarial Training",
        "publication_date": "2017-07-21 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Computer Vision and Pattern Recognition",
        "volume": "",
        "doi": "10.1109/cvpr.2017.241",
        "urls": [
            "https://openalex.org/W2963709863",
            "https://doi.org/10.1109/cvpr.2017.241",
            "http://arxiv.org/pdf/1612.07828"
        ],
        "id": "id8651075244685997956",
        "abstract": "",
        "versions": [],
        "rank": 447
    },
    {
        "authors": [
            "Duanshun Li",
            "Anran Cong",
            "Shuai Guo"
        ],
        "title": "Sewer damage detection from imbalanced CCTV inspection data using deep convolutional neural networks with hierarchical classification",
        "publication_date": "2019-05-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1016/J.AUTCON.2019.01.017",
        "urls": [
            "https://www.semanticscholar.org/paper/2621f385e02f682f522eb2886033e2482c71de37"
        ],
        "id": "id-4691920029873980867",
        "abstract": null,
        "versions": [],
        "rank": 448
    },
    {
        "authors": [
            "Hasib Zunair",
            "A. Ben Hamza"
        ],
        "title": "Melanoma detection using adversarial training and deep transfer learning",
        "publication_date": "2020-07-06 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Physics in Medicine and Biology",
        "volume": "65",
        "doi": "10.1088/1361-6560/ab86d3",
        "urls": [
            "https://openalex.org/W3103031651",
            "https://doi.org/10.1088/1361-6560/ab86d3",
            "http://arxiv.org/pdf/2004.06824"
        ],
        "id": "id1709284155181384550",
        "abstract": "",
        "versions": [
            {
                "year": 2020,
                "source": "SupportedSources.PAPERS_WITH_CODE",
                "title": "Melanoma Detection using Adversarial Training and Deep Transfer Learning",
                "journal": "",
                "urls": [
                    "https://arxiv.org/pdf/2004.06824v2.pdf",
                    "https://github.com/hasibzunair/adversarial-lesions"
                ],
                "doi": "",
                "publication_date": "2020-04-14 00:00:00"
            },
            {
                "year": 2020,
                "source": "SupportedSources.PAPERS_WITH_CODE",
                "title": "Melanoma Detection using Adversarial Training and Deep Transfer Learning",
                "journal": "",
                "urls": [
                    "https://arxiv.org/pdf/2004.06824.pdf",
                    "https://github.com/hasibzunair/adversarial-lesions"
                ],
                "doi": "",
                "publication_date": "2020-04-14 00:00:00"
            }
        ],
        "rank": 449
    },
    {
        "authors": [
            "Young-Sun Yun",
            "Jinmang Jung",
            "Seongbae Eun",
            "S. So",
            "Junyoung Heo"
        ],
        "title": "Detection of GUI Elements on Sketch Images Using Object Detector Based on Deep Neural Networks",
        "publication_date": "2018-01-31 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-981-13-0311-1_16",
        "urls": [
            "https://www.semanticscholar.org/paper/cbec2077707809848ccec3d1dfdd16d66ace3232"
        ],
        "id": "id6375211682906868998",
        "abstract": null,
        "versions": [],
        "rank": 450
    },
    {
        "authors": [
            "Garcia C.",
            "Girshick R. B.",
            "Kaiming He S. R.",
            "Krizhevsky A.",
            "Martin Koestinger P. M. R.",
            "Osadchy M.",
            "Osadchy R.",
            "Ramanan D.",
            "Saberian M.",
            "Sermanet P.",
            "Sun Y.",
            "Szegedy C.",
            "Szegedy C.",
            "Szegedy C.",
            "Tompson Y. L.",
            "Vaillant R.",
            "Viola M.",
            "Wu B."
        ],
        "title": "Multi-view Face Detection Using Deep Convolutional Neural Networks",
        "publication_date": "2015-04-20 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1145/2671188.2749408",
        "urls": [
            "http://arxiv.org/abs/1502.02766"
        ],
        "id": "id-2043849230573896325",
        "abstract": "In this paper we consider the problem of multi-view face detection. While\nthere has been significant research on this problem, current state-of-the-art\napproaches for this task require annotation of facial landmarks, e.g. TSM [25],\nor annotation of face poses [28, 22]. They also require training dozens of\nmodels to fully capture faces in all orientations, e.g. 22 models in HeadHunter\nmethod [22]. In this paper we propose Deep Dense Face Detector (DDFD), a method\nthat does not require pose/landmark annotation and is able to detect faces in a\nwide range of orientations using a single model based on deep convolutional\nneural networks. The proposed method has minimal complexity; unlike other\nrecent deep learning object detection methods [9], it does not require\nadditional components such as segmentation, bounding-box regression, or SVM\nclassifiers. Furthermore, we analyzed scores of the proposed face detector for\nfaces in different orientations and found that 1) the proposed method is able\nto detect faces from different angles and can handle occlusion to some extent,\n2) there seems to be a correlation between dis- tribution of positive examples\nin the training set and scores of the proposed face detector. The latter\nsuggests that the proposed methods performance can be further improved by using\nbetter sampling strategies and more sophisticated data augmentation techniques.\nEvaluations on popular face detection benchmark datasets show that our\nsingle-model face detector algorithm has similar or better performance compared\nto the previous methods, which are more complex and require annotations of\neither different poses or facial landmarks.Comment: in International Conference on Multimedia Retrieval 2015 (ICMR",
        "versions": [],
        "rank": 451
    },
    {
        "authors": [
            "Bolei Zhou",
            "Hang Zhao",
            "Xavier Puig",
            "Sanja Fidler",
            "Adela Barriuso",
            "Antonio Torralba"
        ],
        "title": "Scene Parsing through ADE20K Dataset",
        "publication_date": "2017-07-21 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Computer Vision and Pattern Recognition",
        "volume": "",
        "doi": "10.1109/cvpr.2017.544",
        "urls": [
            "https://openalex.org/W2737258237",
            "https://doi.org/10.1109/cvpr.2017.544",
            "https://dspace.mit.edu/bitstream/1721.1/124982/2/scene-parse-camera-ready.pdf"
        ],
        "id": "id2062702213230810124",
        "abstract": "",
        "versions": [],
        "rank": 452
    },
    {
        "authors": [
            "Angelov, Aleksandar",
            "Fioranelli, Francesco",
            "Murray-Smith, Roderick",
            "Robertson, Andrew"
        ],
        "title": "Practical classification of different moving targets using automotive radar and deep neural networks",
        "publication_date": "2018-10-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1049/iet-rsn.2018.0103",
        "urls": [
            "https://core.ac.uk/download/154430451.pdf"
        ],
        "id": "id-6244322050215550071",
        "abstract": "In this work, the authors present results for classification of different classes of targets (car, single and multiple people, bicycle) using automotive radar data and different neural networks. A fast implementation of radar algorithms for detection, tracking, and micro-Doppler extraction is proposed in conjunction with the automotive radar transceiver TEF810X and microcontroller unit SR32R274 manufactured by NXP Semiconductors. Three different types of neural networks are considered, namely a classic convolutional network, a residual network, and a combination of convolutional and recurrent network, for different classification problems across the four classes of targets recorded. Considerable accuracy (close to 100% in some cases) and low latency of the radar pre-processing prior to classification (\u223c0.55\u2005s to produce a 0.5\u2005s long spectrogram) are demonstrated in this study, and possible shortcomings and outstanding issues are discussed",
        "versions": [],
        "rank": 453
    },
    {
        "authors": [
            "R. D. J. Samuel",
            "B. R. Kanna"
        ],
        "title": "Tuberculosis (TB) detection system using deep neural networks",
        "publication_date": "2019-05-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Neural Computing and Applications",
        "volume": "31",
        "doi": "10.1007/s00521-018-3564-4",
        "urls": [
            "https://www.semanticscholar.org/paper/a73618f0ea764ebb5839a763af1d784a57629e90"
        ],
        "id": "id8203853645727266546",
        "abstract": null,
        "versions": [
            {
                "year": 2018,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Tuberculosis (TB) detection system using deep neural networks",
                "journal": "Neural Computing and Applications",
                "urls": [
                    "https://www.semanticscholar.org/paper/fcf7937ba3c6d91fb4a900af51382abc738f791a"
                ],
                "doi": "10.1007/s00521-018-3564-4",
                "publication_date": "2018-06-05 00:00:00"
            }
        ],
        "rank": 454
    },
    {
        "authors": [
            "M. Saqib",
            "Sultan Daud Khan",
            "N. Sharma",
            "M. Blumenstein"
        ],
        "title": "Person Head Detection in Multiple Scales Using Deep Convolutional Neural Networks",
        "publication_date": "2018-07-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/IJCNN.2018.8489367",
        "urls": [
            "https://www.semanticscholar.org/paper/b1d8d693e34c8cd80cf2e361f0910d5454393c11"
        ],
        "id": "id-8899216890296976771",
        "abstract": "Person detection is an important problem in computer vision with many real-world applications. The detection of a person is still a challenging task due to variations in pose, occlusions and lighting conditions. The purpose of this study is to detect human heads in natural scenes acquired from a publicly available dataset of Hollywood movies. In this work, we have used state-of-the-art object detectors based on deep convolutional neural networks. These object detectors include region-based convolutional neural networks using region proposals for detections. Also, object detectors that detect objects in the single-shot by looking at the image only once for detections. We have used transfer learning for fine-tuning the network already trained on a massive amount of data. During the fine-tuning process, the models having high mean Average Precision (mAP) are used for evaluation of the test dataset. Experimental results show that Faster R-CNN [18] and SSD MultiBox [13] with VGG16 [21] perform better than YOLO [17] and also demonstrate significant improvements against several baseline approaches.",
        "versions": [
            {
                "year": 2018,
                "source": "SupportedSources.CROSSREF",
                "title": "Person Head Detection in Multiple Scales Using Deep Convolutional Neural Networks",
                "journal": "",
                "urls": [
                    "http://xplorestaging.ieee.org/ielx7/8465565/8488986/08489367.pdf?arnumber=8489367",
                    "http://dx.doi.org/10.1109/ijcnn.2018.8489367"
                ],
                "doi": "10.1109/ijcnn.2018.8489367",
                "publication_date": "2018-01-01 00:00:00"
            }
        ],
        "rank": 455
    },
    {
        "authors": [
            "Piyush Agarwal",
            "Jorge Ivan Mireles Gonzalez",
            "Ali Elkamel",
            "Hector Budman"
        ],
        "title": "Hierarchical Deep Recurrent Neural Network based Method for Fault Detection and Diagnosis",
        "publication_date": "2020-12-07 17:11:56+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": "Processes 2022, 10, 2557",
        "volume": "",
        "doi": "10.3390/pr10122557",
        "urls": [
            "http://arxiv.org/pdf/2012.03861v1",
            "http://dx.doi.org/10.3390/pr10122557",
            "http://arxiv.org/abs/2012.03861v1",
            "http://arxiv.org/pdf/2012.03861v1"
        ],
        "id": "id156910913369727463",
        "abstract": "A Deep Neural Network (DNN) based algorithm is proposed for the detection and\nclassification of faults in industrial plants. The proposed algorithm has the\nability to classify faults, especially incipient faults that are difficult to\ndetect and diagnose with traditional threshold based statistical methods or by\nconventional Artificial Neural Networks (ANNs). The algorithm is based on a\nSupervised Deep Recurrent Autoencoder Neural Network (Supervised DRAE-NN) that\nuses dynamic information of the process along the time horizon. Based on this\nnetwork a hierarchical structure is formulated by grouping faults based on\ntheir similarity into subsets of faults for detection and diagnosis. Further,\nan external pseudo-random binary signal (PRBS) is designed and injected into\nthe system to identify incipient faults. The hierarchical structure based\nstrategy improves the detection and classification accuracy significantly for\nboth incipient and non-incipient faults. The proposed approach is tested on the\nbenchmark Tennessee Eastman Process resulting in significant improvements in\nclassification as compared to both multivariate linear model-based strategies\nand non-hierarchical nonlinear model-based strategies.",
        "versions": [],
        "rank": 456
    },
    {
        "authors": [
            "Luo, Tie",
            "Nagarajan, Sai G."
        ],
        "title": "Distributed Anomaly Detection using Autoencoder Neural Networks in WSN  for IoT",
        "publication_date": "2018-05-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/icc.2018.8422402",
        "urls": [
            "http://arxiv.org/abs/1812.04872"
        ],
        "id": "id-1474090158445463926",
        "abstract": "Wireless sensor networks (WSN) are fundamental to the Internet of Things\n(IoT) by bridging the gap between the physical and the cyber worlds. Anomaly\ndetection is a critical task in this context as it is responsible for\nidentifying various events of interests such as equipment faults and\nundiscovered phenomena. However, this task is challenging because of the\nelusive nature of anomalies and the volatility of the ambient environments. In\na resource-scarce setting like WSN, this challenge is further elevated and\nweakens the suitability of many existing solutions. In this paper, for the\nfirst time, we introduce autoencoder neural networks into WSN to solve the\nanomaly detection problem. We design a two-part algorithm that resides on\nsensors and the IoT cloud respectively, such that (i) anomalies can be detected\nat sensors in a fully distributed manner without the need for communicating\nwith any other sensors or the cloud, and (ii) the relatively more\ncomputation-intensive learning task can be handled by the cloud with a much\nlower (and configurable) frequency. In addition to the minimal communication\noverhead, the computational load on sensors is also very low (of polynomial\ncomplexity) and readily affordable by most COTS sensors. Using a real WSN\nindoor testbed and sensor data collected over 4 consecutive months, we\ndemonstrate via experiments that our proposed autoencoder-based anomaly\ndetection mechanism achieves high detection accuracy and low false alarm rate.\nIt is also able to adapt to unforeseeable and new changes in a non-stationary\nenvironment, thanks to the unsupervised learning feature of our chosen\nautoencoder neural networks.Comment: 6 pages, 7 figures, IEEE ICC 201",
        "versions": [],
        "rank": 457
    },
    {
        "authors": [
            "Aichuan Li",
            "Shujuan Yi",
            "Irshad Azeem"
        ],
        "title": "Intelligent Intrusion Detection Method of Industrial Internet of Things Based on CNN-BiLSTM",
        "publication_date": "2022-04-04 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Hindawi Limited",
        "volume": "",
        "doi": "10.1155/2022/5448647",
        "urls": [
            "https://web.archive.org/web/20220406225651/https://downloads.hindawi.com/journals/scn/2022/5448647.pdf"
        ],
        "id": "id6491517971356385605",
        "abstract": "Aiming at the problems of fuzzy detection characteristics, high false positive rate and low accuracy of traditional network intrusion detection technology, an improved intelligent intrusion detection method of industrial Internet of Things based on deep learning is proposed. Firstly, the data set is preprocessed and transformed into 122 dimensional intrusion data set after one-hot coding; Secondly, aiming at the problem that convolution network cannot deal with data with long-distance attributes, Bidirectional long short-term memory (BiLSTM) is used to mine the relationship between data features; At the same time, the Batch Normalization mechanism is introduced to speed up the training of deep neural network. After the activation function performs nonlinear transformation on the input data of the previous layer, it is normalized to ensure the trainability of the network. The experimental results on NSL-KDD data set show that the accuracy of the proposed CNN-BiLSTM model is 96.3%, the detection rate is 97.1%, and the performance is the best.",
        "versions": [],
        "rank": 458
    },
    {
        "authors": [
            "Wu, Ji",
            "Zhang, Xiao-Lei"
        ],
        "title": "Denoising Deep Neural Networks Based Voice Activity Detection",
        "publication_date": "2013-03-04 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/icassp.2013.6637769",
        "urls": [
            "http://arxiv.org/abs/1303.0663"
        ],
        "id": "id-8994752219861516735",
        "abstract": "Recently, the deep-belief-networks (DBN) based voice activity detection (VAD)\nhas been proposed. It is powerful in fusing the advantages of multiple\nfeatures, and achieves the state-of-the-art performance. However, the deep\nlayers of the DBN-based VAD do not show an apparent superiority to the\nshallower layers. In this paper, we propose a denoising-deep-neural-network\n(DDNN) based VAD to address the aforementioned problem. Specifically, we\npre-train a deep neural network in a special unsupervised denoising greedy\nlayer-wise mode, and then fine-tune the whole network in a supervised way by\nthe common back-propagation algorithm. In the pre-training phase, we take the\nnoisy speech signals as the visible layer and try to extract a new feature that\nminimizes the reconstruction cross-entropy loss between the noisy speech\nsignals and its corresponding clean speech signals. Experimental results show\nthat the proposed DDNN-based VAD not only outperforms the DBN-based VAD but\nalso shows an apparent performance improvement of the deep layers over\nshallower layers.Comment: This paper has been accepted by IEEE ICASSP-2013, and will be\n  published online after May, 201",
        "versions": [
            {
                "year": 2013,
                "source": "SupportedSources.ARXIV",
                "title": "Denoising Deep Neural Networks Based Voice Activity Detection",
                "journal": null,
                "urls": [
                    "http://arxiv.org/pdf/1303.0663v1",
                    "http://dx.doi.org/10.1109/ICASSP.2013.6637769",
                    "http://arxiv.org/abs/1303.0663v1",
                    "http://arxiv.org/pdf/1303.0663v1"
                ],
                "doi": "10.1109/ICASSP.2013.6637769",
                "publication_date": "2013-03-04 10:17:49+00:00"
            }
        ],
        "rank": 459
    },
    {
        "authors": [
            "Mohamad Alipour",
            "D. Harris",
            "G. Miller"
        ],
        "title": "Robust Pixel-Level Crack Detection Using Deep Fully Convolutional Neural Networks",
        "publication_date": "2019-11-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1061/(asce)cp.1943-5487.0000854",
        "urls": [
            "https://www.semanticscholar.org/paper/309efec8dee7fe8230fc33983a1ed1a5fefbf408"
        ],
        "id": "id-1426444106087809021",
        "abstract": "AbstractThis paper introduces the idea of using deep fully convolutional neural networks for pixel-level defect detection in concrete infrastructure systems. Although coarse patch-level deep learni...",
        "versions": [],
        "rank": 460
    },
    {
        "authors": [
            "Mostafa Parchami",
            "Saif Iftekar Sayed"
        ],
        "title": "Deep Feature Tracker: A Novel Application for Deep Convolutional Neural Networks",
        "publication_date": "2021-07-30 23:24:29+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2108.00105v1",
            "http://arxiv.org/abs/2108.00105v1",
            "http://arxiv.org/pdf/2108.00105v1"
        ],
        "id": "id3891013823341406522",
        "abstract": "Feature tracking is the building block of many applications such as visual\nodometry, augmented reality, and target tracking. Unfortunately, the\nstate-of-the-art vision-based tracking algorithms fail in surgical images due\nto the challenges imposed by the nature of such environments. In this paper, we\nproposed a novel and unified deep learning-based approach that can learn how to\ntrack features reliably as well as learn how to detect such reliable features\nfor tracking purposes. The proposed network dubbed as Deep-PT, consists of a\ntracker network which is a convolutional neural network simulating\ncross-correlation in terms of deep learning and two fully connected networks\nthat operate on the output of intermediate layers of the tracker to detect\nfeatures and predict trackability of the detected points. The ability to detect\nfeatures based on the capabilities of the tracker distinguishes the proposed\nmethod from previous algorithms used in this area and improves the robustness\nof the algorithms against dynamics of the scene. The network is trained using\nmultiple datasets due to the lack of specialized dataset for feature tracking\ndatasets and extensive comparisons are conducted to compare the accuracy of\nDeep-PT against recent pixel tracking algorithms. As the experiments suggest,\nthe proposed deep architecture deliberately learns what to track and how to\ntrack and outperforms the state-of-the-art methods.",
        "versions": [],
        "rank": 461
    },
    {
        "authors": [
            "Chengyin Hu",
            "Weiwen Shi"
        ],
        "title": "Impact of Scaled Image on Robustness of Deep Neural Networks",
        "publication_date": "2022-09-02 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20220909155507/https://arxiv.org/ftp/arxiv/papers/2209/2209.02132.pdf"
        ],
        "id": "id6814520069399176453",
        "abstract": "Deep neural networks (DNNs) have been widely used in computer vision tasks like image classification, object detection and segmentation. Whereas recent studies have shown their vulnerability to manual digital perturbations or distortion in the input images. The accuracy of the networks is remarkably influenced by the data distribution of their training dataset. Scaling the raw images creates out-of-distribution data, which makes it a possible adversarial attack to fool the networks. In this work, we propose a Scaling-distortion dataset ImageNet-CS by Scaling a subset of the ImageNet Challenge dataset by different multiples. The aim of our work is to study the impact of scaled images on the performance of advanced DNNs. We perform experiments on several state-of-the-art deep neural network architectures on the proposed ImageNet-CS, and the results show a significant positive correlation between scaling size and accuracy decline. Moreover, based on ResNet50 architecture, we demonstrate some tests on the performance of recent proposed robust training techniques and strategies like Augmix, Revisiting and Normalizer Free on our proposed ImageNet-CS. Experiment results have shown that these robust training techniques can improve networks' robustness to scaling transformation.",
        "versions": [],
        "rank": 462
    },
    {
        "authors": [
            "Kai Zhang",
            "Wangmeng Zuo",
            "Yunjin Chen",
            "Deyu Meng",
            "Lei Zhang"
        ],
        "title": "Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising",
        "publication_date": "2017-07-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "IEEE transactions on image processing",
        "volume": "26",
        "doi": "10.1109/tip.2017.2662206",
        "urls": [
            "https://openalex.org/W2508457857",
            "https://doi.org/10.1109/tip.2017.2662206",
            "http://arxiv.org/pdf/1608.03981"
        ],
        "id": "id-1736340791548622587",
        "abstract": "",
        "versions": [],
        "rank": 463
    },
    {
        "authors": [
            "De Cock, Martine",
            "Grumer, Charles",
            "Nascimento, Anderson",
            "Nie, Claire",
            "Olumofin, Femi",
            "Peck, Jonathan",
            "Sivaguru, Raaghavi",
            "Yu, Bin"
        ],
        "title": "CharBot: A Simple and Effective Method for Evading DGA Classifiers",
        "publication_date": "2019-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/access.2019.2927075",
        "urls": [
            "http://arxiv.org/abs/1905.01078"
        ],
        "id": "id861483120796976926",
        "abstract": "Domain generation algorithms (DGAs) are commonly leveraged by malware to\ncreate lists of domain names which can be used for command and control (C&C)\npurposes. Approaches based on machine learning have recently been developed to\nautomatically detect generated domain names in real-time. In this work, we\npresent a novel DGA called CharBot which is capable of producing large numbers\nof unregistered domain names that are not detected by state-of-the-art\nclassifiers for real-time detection of DGAs, including the recently published\nmethods FANCI (a random forest based on human-engineered features) and LSTM.MI\n(a deep learning approach). CharBot is very simple, effective and requires no\nknowledge of the targeted DGA classifiers. We show that retraining the\nclassifiers on CharBot samples is not a viable defense strategy. We believe\nthese findings show that DGA classifiers are inherently vulnerable to\nadversarial attacks if they rely only on the domain name string to make a\ndecision. Designing a robust DGA classifier may, therefore, necessitate the use\nof additional information besides the domain name alone. To the best of our\nknowledge, CharBot is the simplest and most efficient black-box adversarial\nattack against DGA classifiers proposed to date",
        "versions": [],
        "rank": 464
    },
    {
        "authors": [
            "Sungho Jeon",
            "Jongkyun Shin",
            "Young-Jun Lee",
            "Woong-Hee Kim",
            "YoungHyoun Kwon",
            "Hae-Yong Yang"
        ],
        "title": "Empirical study of drone sound detection in real-life environment with deep neural networks",
        "publication_date": "2017-01-20 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.23919/eusipco.2017.8081531",
        "urls": [
            "https://www.semanticscholar.org/paper/977d5f44c9a9073e6f998bd026683603edd100a3"
        ],
        "id": "id7742270656234935689",
        "abstract": "This work aims to investigate the use of deep neural network to detect commercial hobby drones in real-life environments by analyzing their sound data. The purpose of work is to contribute to a system for detecting drones used for malicious purposes, such as for terrorism. Specifically, we present a method capable of detecting the presence of commercial hobby drones as a binary classification problem based on sound event detection. We recorded the sound produced by a few popular commercial hobby drones, and then augmented this data with diverse environmental sound data to remedy the scarcity of drone sound data in diverse environments. We investigated the effectiveness of state-of-the-art event sound classification methods, i.e., a Gaussian Mixture Model (GMM), Convolutional Neural Network (CNN), and Recurrent Neural Network (RNN), for drone sound detection. Our empirical results, which were obtained with a testing dataset collected on an urban street, confirmed the effectiveness of these models for operating in a real environment. In summary, our RNN models showed the best detection performance with an F-Score of 0.8009 with 240 ms of input audio with a short processing time, indicating their applicability to real-time detection systems.",
        "versions": [],
        "rank": 465
    },
    {
        "authors": [
            "Charles Corbi\u00e8re"
        ],
        "title": "Robust Deep Learning for Autonomous Driving",
        "publication_date": "2022-11-14 00:00:00",
        "source": "SupportedSources.PAPERS_WITH_CODE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://arxiv.org/pdf/2211.07772v1.pdf",
            "https://github.com/valeoai/ConfidNet"
        ],
        "id": "id-8808065957822920176",
        "abstract": "The last decade's research in artificial intelligence had a significant impact on the advance of autonomous driving. Yet, safety remains a major concern when it comes to deploying such systems in high-risk environments. The objective of this thesis is to develop methodological tools which provide reliable uncertainty estimates for deep neural networks. First, we introduce a new criterion to reliably estimate model confidence: the true class probability (TCP). We show that TCP offers better properties for failure prediction than current uncertainty measures. Since the true class is by essence unknown at test time, we propose to learn TCP criterion from data with an auxiliary model, introducing a specific learning scheme adapted to this context. The relevance of the proposed approach is validated on image classification and semantic segmentation datasets. Then, we extend our learned confidence approach to the task of domain adaptation where it improves the selection of pseudo-labels in self-training methods. Finally, we tackle the challenge of jointly detecting misclassification and out-of-distributions samples by introducing a new uncertainty measure based on evidential models and defined on the simplex.",
        "versions": [],
        "rank": 466
    },
    {
        "authors": [
            "Diaba, S.",
            "Elmusrati, M."
        ],
        "title": "Proposed algorithm for smart grid DDoS detection based on deep learning",
        "publication_date": "2023-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1016/j.neunet.2022.12.011",
        "urls": [
            "https://api.elsevier.com/content/article/PII:S0893608022005032?httpAccept=text/xml",
            "https://api.elsevier.com/content/article/PII:S0893608022005032?httpAccept=text/plain",
            "http://dx.doi.org/10.1016/j.neunet.2022.12.011"
        ],
        "id": "id-1545175016478740797",
        "abstract": "",
        "versions": [],
        "rank": 467
    },
    {
        "authors": [
            "Matthew Burruss",
            "Shreyas Ramakrishna",
            "Abhishek Dubey"
        ],
        "title": "Deep-RBF Networks for Anomaly Detection in Automotive Cyber-Physical Systems",
        "publication_date": "2021-03-25 23:10:32+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2103.14172v2",
            "http://arxiv.org/abs/2103.14172v2",
            "http://arxiv.org/pdf/2103.14172v2"
        ],
        "id": "id-6514593978307461979",
        "abstract": "Deep Neural Networks (DNNs) are popularly used for implementing autonomy\nrelated tasks in automotive Cyber-Physical Systems (CPSs). However, these\nnetworks have been shown to make erroneous predictions to anomalous inputs,\nwhich manifests either due to Out-of-Distribution (OOD) data or adversarial\nattacks. To detect these anomalies, a separate DNN called assurance monitor is\noften trained and used in parallel to the controller DNN, increasing the\nresource burden and latency. We hypothesize that a single network that can\nperform controller predictions and anomaly detection is necessary to reduce the\nresource requirements. Deep-Radial Basis Function (RBF) networks provide a\nrejection class alongside the class predictions, which can be utilized for\ndetecting anomalies at runtime. However, the use of RBF activation functions\nlimits the applicability of these networks to only classification tasks. In\nthis paper, we show how the deep-RBF network can be used for detecting\nanomalies in CPS regression tasks such as continuous steering predictions.\nFurther, we design deep-RBF networks using popular DNNs such as NVIDIA DAVE-II,\nand ResNet20, and then use the resulting rejection class for detecting\nadversarial attacks such as a physical attack and data poison attack. Finally,\nwe evaluate these attacks and the trained deep-RBF networks using a hardware\nCPS testbed called DeepNNCar and a real-world German Traffic Sign Benchmark\n(GTSB) dataset. Our results show that the deep-RBF networks can robustly detect\nthese attacks in a short time without additional resource requirements.",
        "versions": [],
        "rank": 468
    },
    {
        "authors": [
            "Maurizio Corbetta"
        ],
        "title": "Frontoparietal cortical networks for directing attention and the eye to visual locations: Identical, independent, or overlapping neural systems?",
        "publication_date": "1998-02-03 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Proceedings of the National Academy of Sciences of the United States of America",
        "volume": "95",
        "doi": "10.1073/pnas.95.3.831",
        "urls": [
            "https://openalex.org/W2038894208",
            "https://doi.org/10.1073/pnas.95.3.831",
            "https://europepmc.org/articles/pmc33805?pdf=render"
        ],
        "id": "id-4163909616385129738",
        "abstract": "",
        "versions": [],
        "rank": 469
    },
    {
        "authors": [
            "Swarnendu Ghosh",
            "Nibaran Das",
            "Ishita Das",
            "Ujjwal Maulik"
        ],
        "title": "Understanding Deep Learning Techniques for Image Segmentation",
        "publication_date": "2019-07-13 19:23:42+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1907.06119v1",
            "http://arxiv.org/abs/1907.06119v1",
            "http://arxiv.org/pdf/1907.06119v1"
        ],
        "id": "id6811859316090328817",
        "abstract": "The machine learning community has been overwhelmed by a plethora of deep\nlearning based approaches. Many challenging computer vision tasks such as\ndetection, localization, recognition and segmentation of objects in\nunconstrained environment are being efficiently addressed by various types of\ndeep neural networks like convolutional neural networks, recurrent networks,\nadversarial networks, autoencoders and so on. While there have been plenty of\nanalytical studies regarding the object detection or recognition domain, many\nnew deep learning techniques have surfaced with respect to image segmentation\ntechniques. This paper approaches these various deep learning techniques of\nimage segmentation from an analytical perspective. The main goal of this work\nis to provide an intuitive understanding of the major techniques that has made\nsignificant contribution to the image segmentation domain. Starting from some\nof the traditional image segmentation approaches, the paper progresses\ndescribing the effect deep learning had on the image segmentation domain.\nThereafter, most of the major segmentation algorithms have been logically\ncategorized with paragraphs dedicated to their unique contribution. With an\nample amount of intuitive explanations, the reader is expected to have an\nimproved ability to visualize the internal dynamics of these processes.",
        "versions": [],
        "rank": 470
    },
    {
        "authors": [
            "Ranganath Krishnan",
            "Mahesh Subedar",
            "Omesh Tickoo"
        ],
        "title": "Specifying Weight Priors in Bayesian Deep Neural Networks with Empirical Bayes",
        "publication_date": "2020-04-03 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Association for the Advancement of Artificial Intelligence (AAAI)",
        "volume": "",
        "doi": "10.1609/aaai.v34i04.5875",
        "urls": [
            "https://web.archive.org/web/20201103201549/https://aaai.org/ojs/index.php/AAAI/article/download/5875/5731"
        ],
        "id": "id-497874152999232497",
        "abstract": "Stochastic variational inference for Bayesian deep neural network (DNN) requires specifying priors and approximate posterior distributions over neural network weights. Specifying meaningful weight priors is a challenging problem, particularly for scaling variational inference to deeper architectures involving high dimensional weight space. We propose MOdel Priors with Empirical Bayes using DNN (MOPED) method to choose informed weight priors in Bayesian neural networks. We formulate a two-stage hierarchical modeling, first find the maximum likelihood estimates of weights with DNN, and then set the weight priors using empirical Bayes approach to infer the posterior with variational inference. We empirically evaluate the proposed approach on real-world tasks including image classification, video activity recognition and audio classification with varying complex neural network architectures. We also evaluate our proposed approach on diabetic retinopathy diagnosis task and benchmark with the state-of-the-art Bayesian deep learning techniques. We demonstrate MOPED method enables scalable variational inference and provides reliable uncertainty quantification.",
        "versions": [
            {
                "year": 2019,
                "source": "SupportedSources.INTERNET_ARCHIVE",
                "title": "Specifying Weight Priors in Bayesian Deep Neural Networks with Empirical Bayes",
                "journal": "",
                "urls": [
                    "https://web.archive.org/web/20200321003532/https://arxiv.org/pdf/1906.05323v3.pdf"
                ],
                "doi": "",
                "publication_date": "2019-12-28 00:00:00"
            }
        ],
        "rank": 471
    },
    {
        "authors": [
            "Xianzhi Du",
            "Mostafa El-Khamy",
            "Vlad I. Morariu",
            "Jungwon Lee",
            "Larry Davis"
        ],
        "title": "Fused Deep Neural Networks for Efficient Pedestrian Detection",
        "publication_date": "2018-05-02 00:13:28+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1805.08688v1",
            "http://arxiv.org/abs/1805.08688v1",
            "http://arxiv.org/pdf/1805.08688v1"
        ],
        "id": "id-7041363991672474223",
        "abstract": "In this paper, we present an efficient pedestrian detection system, designed\nby fusion of multiple deep neural network (DNN) systems. Pedestrian candidates\nare first generated by a single shot convolutional multi-box detector at\ndifferent locations with various scales and aspect ratios. The candidate\ngenerator is designed to provide the majority of ground truth pedestrian\nannotations at the cost of a large number of false positives. Then, a\nclassification system using the idea of ensemble learning is deployed to\nimprove the detection accuracy. The classification system further classifies\nthe generated candidates based on opinions of multiple deep verification\nnetworks and a fusion network which utilizes a novel soft-rejection fusion\nmethod to adjust the confidence in the detection results. To improve the\ntraining of the deep verification networks, a novel soft-label method is\ndevised to assign floating point labels to the generated pedestrian candidates.\nA deep context aggregation semantic segmentation network also provides\npixel-level classification of the scene and its results are softly fused with\nthe detection results by the single shot detector. Our pedestrian detector\ncompared favorably to state-of-art methods on all popular pedestrian detection\ndatasets. For example, our fused DNN has better detection accuracy on the\nCaltech Pedestrian dataset than all previous state of art methods, while also\nbeing the fastest. We significantly improved the log-average miss rate on the\nCaltech pedestrian dataset to 7.67% and achieved the new state-of-the-art.",
        "versions": [],
        "rank": 472
    },
    {
        "authors": [
            "Athalye Anish",
            "Baluja Shumeet",
            "Buckman Jacob",
            "Diederik",
            "Eykholt Kevin",
            "Goodfellow Ian J",
            "He Kaiming",
            "Kurakin Alexey",
            "Lin Min",
            "Liu Yanpei",
            "Lu Jiajun",
            "Madry Aleksander",
            "Metzen Jan Hendrik",
            "Papernot Nicolas",
            "Papernot Nicolas",
            "Samangouei Pouya",
            "Schulman John",
            "Simonyan Karen",
            "Tram\u00e8r Florian"
        ],
        "title": "Stochastic Substitute Training: A Gray-box Approach to Craft Adversarial  Examples Against Gradient Obfuscation Defenses",
        "publication_date": "2018-10-23 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1145/3270101.3270111",
        "urls": [
            "http://arxiv.org/abs/1810.10031"
        ],
        "id": "id-7002670357531102782",
        "abstract": "It has been shown that adversaries can craft example inputs to neural\nnetworks which are similar to legitimate inputs but have been created to\npurposely cause the neural network to misclassify the input. These adversarial\nexamples are crafted, for example, by calculating gradients of a carefully\ndefined loss function with respect to the input. As a countermeasure, some\nresearchers have tried to design robust models by blocking or obfuscating\ngradients, even in white-box settings. Another line of research proposes\nintroducing a separate detector to attempt to detect adversarial examples. This\napproach also makes use of gradient obfuscation techniques, for example, to\nprevent the adversary from trying to fool the detector. In this paper, we\nintroduce stochastic substitute training, a gray-box approach that can craft\nadversarial examples for defenses which obfuscate gradients. For those defenses\nthat have tried to make models more robust, with our technique, an adversary\ncan craft adversarial examples with no knowledge of the defense. For defenses\nthat attempt to detect the adversarial examples, with our technique, an\nadversary only needs very limited information about the defense to craft\nadversarial examples. We demonstrate our technique by applying it against two\ndefenses which make models more robust and two defenses which detect\nadversarial examples.Comment: Accepted by AISec '18: 11th ACM Workshop on Artificial Intelligence\n  and Security. Source code at https://github.com/S-Mohammad-Hashemi/SS",
        "versions": [],
        "rank": 473
    },
    {
        "authors": [
            "Moshe Kravchik",
            "Asaf Shabtai"
        ],
        "title": "Detecting Cyberattacks in Industrial Control Systems Using Convolutional Neural Networks",
        "publication_date": "2018-06-21 08:38:31+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1806.08110v2",
            "http://arxiv.org/abs/1806.08110v2",
            "http://arxiv.org/pdf/1806.08110v2"
        ],
        "id": "id996527443444775219",
        "abstract": "This paper presents a study on detecting cyberattacks on industrial control\nsystems (ICS) using unsupervised deep neural networks, specifically,\nconvolutional neural networks. The study was performed on a SecureWater\nTreatment testbed (SWaT) dataset, which represents a scaled-down version of a\nreal-world industrial water treatment plant. e suggest a method for anomaly\ndetection based on measuring the statistical deviation of the predicted value\nfrom the observed value.We applied the proposed method by using a variety of\ndeep neural networks architectures including different variants of\nconvolutional and recurrent networks. The test dataset from SWaT included 36\ndifferent cyberattacks. The proposed method successfully detects the vast\nmajority of the attacks with a low false positive rate thus improving on\nprevious works based on this data set. The results of the study show that 1D\nconvolutional networks can be successfully applied to anomaly detection in\nindustrial control systems and outperform more complex recurrent networks while\nbeing much smaller and faster to train.",
        "versions": [],
        "rank": 474
    },
    {
        "authors": [
            "Babu, R. Venkatesh",
            "Mopuri, Konda Reddy"
        ],
        "title": "Object Level Deep Feature Pooling for Compact Image Representation",
        "publication_date": "2015-04-24 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/cvprw.2015.7301273",
        "urls": [
            "http://arxiv.org/abs/1504.06591"
        ],
        "id": "id3007883714226744476",
        "abstract": "Convolutional Neural Network (CNN) features have been successfully employed\nin recent works as an image descriptor for various vision tasks. But the\ninability of the deep CNN features to exhibit invariance to geometric\ntransformations and object compositions poses a great challenge for image\nsearch. In this work, we demonstrate the effectiveness of the objectness prior\nover the deep CNN features of image regions for obtaining an invariant image\nrepresentation. The proposed approach represents the image as a vector of\npooled CNN features describing the underlying objects. This representation\nprovides robustness to spatial layout of the objects in the scene and achieves\ninvariance to general geometric transformations, such as translation, rotation\nand scaling. The proposed approach also leads to a compact representation of\nthe scene, making each image occupy a smaller memory footprint. Experiments\nshow that the proposed representation achieves state of the art retrieval\nresults on a set of challenging benchmark image datasets, while maintaining a\ncompact representation.Comment: Deep Vision 201",
        "versions": [],
        "rank": 475
    },
    {
        "authors": [
            "B Biggio",
            "DG Lowe",
            "G Katz",
            "GMJB Chaslot",
            "L Kocsis",
            "L Pulina",
            "R Szeliski",
            "X Huang",
            "Y LeCun"
        ],
        "title": "Feature-Guided Black-Box Safety Testing of Deep Neural Networks",
        "publication_date": "2018-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-3-319-89960-2_22",
        "urls": [
            "http://arxiv.org/abs/1710.07859"
        ],
        "id": "id-160145981043621761",
        "abstract": "Despite the improved accuracy of deep neural networks, the discovery of\nadversarial examples has raised serious safety concerns. Most existing\napproaches for crafting adversarial examples necessitate some knowledge\n(architecture, parameters, etc.) of the network at hand. In this paper, we\nfocus on image classifiers and propose a feature-guided black-box approach to\ntest the safety of deep neural networks that requires no such knowledge. Our\nalgorithm employs object detection techniques such as SIFT (Scale Invariant\nFeature Transform) to extract features from an image. These features are\nconverted into a mutable saliency distribution, where high probability is\nassigned to pixels that affect the composition of the image with respect to the\nhuman visual system. We formulate the crafting of adversarial examples as a\ntwo-player turn-based stochastic game, where the first player's objective is to\nminimise the distance to an adversarial example by manipulating the features,\nand the second player can be cooperative, adversarial, or random. We show that,\ntheoretically, the two-player game can con- verge to the optimal strategy, and\nthat the optimal strategy represents a globally minimal adversarial image. For\nLipschitz networks, we also identify conditions that provide safety guarantees\nthat no adversarial examples exist. Using Monte Carlo tree search we gradually\nexplore the game state space to search for adversarial examples. Our\nexperiments show that, despite the black-box setting, manipulations guided by a\nperception-based saliency distribution are competitive with state-of-the-art\nmethods that rely on white-box saliency matrices or sophisticated optimization\nprocedures. Finally, we show how our method can be used to evaluate robustness\nof neural networks in safety-critical applications such as traffic sign\nrecognition in self-driving cars.Comment: 35 pages, 5 tables, 23 figure",
        "versions": [],
        "rank": 476
    },
    {
        "authors": [
            "Connor, Liam",
            "van Leeuwen, Joeri"
        ],
        "title": "Applying Deep Learning to Fast Radio Burst Classification",
        "publication_date": "2018-03-08 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.3847/1538-3881/aae649",
        "urls": [
            "https://core.ac.uk/download/376267175.pdf"
        ],
        "id": "id-8819029522425429216",
        "abstract": "Upcoming Fast Radio Burst (FRB) surveys will search $\\sim$10\\,$^3$ beams on\nsky with very high duty cycle, generating large numbers of single-pulse\ncandidates. The abundance of false positives presents an intractable problem if\ncandidates are to be inspected by eye, making it a good application for\nartificial intelligence (AI). We apply deep learning to single pulse\nclassification and develop a hierarchical framework for ranking events by their\nprobability of being true astrophysical transients. We construct a tree-like\ndeep neural network (DNN) that takes multiple or individual data products as\ninput (e.g. dynamic spectra and multi-beam detection information) and trains on\nthem simultaneously. We have built training and test sets using false-positive\ntriggers from real telescopes, along with simulated FRBs, and single pulses\nfrom pulsars. Training of the DNN was independently done for two radio\ntelescopes: the CHIME Pathfinder, and Apertif on Westerbork. High accuracy and\nrecall can be achieved with a labelled training set of a few thousand events.\nEven with high triggering rates, classification can be done very quickly on\nGraphical Processing Units (GPUs). That speed is essential for selective\nvoltage dumps or issuing real-time VOEvents. Next, we investigate whether\ndedispersion back-ends could be completely replaced by a real-time DNN\nclassifier. It is shown that a single forward propagation through a moderate\nconvolutional network could be faster than brute-force dedispersion; but the\nlow signal-to-noise per pixel makes such a classifier sub-optimal for this\nproblem. Real-time automated classification may prove useful for bright,\nunexpected signals, both now and in the era of radio astronomy when data\nvolumes and the searchable parameter spaces further outgrow our ability to\nmanually inspect the data, such as for SKA and ngVLA",
        "versions": [],
        "rank": 477
    },
    {
        "authors": [
            "Shivangi",
            "Johri, A.",
            "Tripathi, A."
        ],
        "title": "Parkinson Disease Detection Using Deep Neural Networks",
        "publication_date": "2019-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ic3.2019.8844941",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/8830728/8844868/08844941.pdf?arnumber=8844941",
            "http://dx.doi.org/10.1109/ic3.2019.8844941"
        ],
        "id": "id-8139054727338857726",
        "abstract": "",
        "versions": [],
        "rank": 478
    },
    {
        "authors": [
            "Samay Pashine",
            "Sagar Mandiya",
            "Praveen Gupta",
            "Rashid Sheikh"
        ],
        "title": "Deep Fake Detection: Survey of Facial Manipulation Detection Solutions",
        "publication_date": "2021-06-23 18:08:07+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": "International Research Journal of Engineering and Technology\n  Volume 8, Issue 5, May 2021",
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2106.12605v1",
            "http://arxiv.org/abs/2106.12605v1",
            "http://arxiv.org/pdf/2106.12605v1"
        ],
        "id": "id-8554072512521613099",
        "abstract": "Deep Learning as a field has been successfully used to solve a plethora of\ncomplex problems, the likes of which we could not have imagined a few decades\nback. But as many benefits as it brings, there are still ways in which it can\nbe used to bring harm to our society. Deep fakes have been proven to be one\nsuch problem, and now more than ever, when any individual can create a fake\nimage or video simply using an application on the smartphone, there need to be\nsome countermeasures, with which we can detect if the image or video is a fake\nor real and dispose of the problem threatening the trustworthiness of online\ninformation. Although the Deep fakes created by neural networks, may seem to be\nas real as a real image or video, it still leaves behind spatial and temporal\ntraces or signatures after moderation, these signatures while being invisible\nto a human eye can be detected with the help of a neural network trained to\nspecialize in Deep fake detection. In this paper, we analyze several such\nstates of the art neural networks (MesoNet, ResNet-50, VGG-19, and Xception\nNet) and compare them against each other, to find an optimal solution for\nvarious scenarios like real-time deep fake detection to be deployed in online\nsocial media platforms where the classification should be made as fast as\npossible or for a small news agency where the classification need not be in\nreal-time but requires utmost accuracy.",
        "versions": [],
        "rank": 479
    },
    {
        "authors": [
            "Zhenyu Shu",
            "Shiqing Xin",
            "Xin Xu",
            "Ligang Liu",
            "Ladislav Kavan"
        ],
        "title": "Detecting 3D Points of Interest Using Multiple Features and Stacked Auto-encoder",
        "publication_date": "2018-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Institute of Electrical and Electronics Engineers (IEEE)",
        "volume": "",
        "doi": "10.1109/tvcg.2018.2848628",
        "urls": [
            "https://web.archive.org/web/20190225092217/http://pdfs.semanticscholar.org/5db3/51b7b434b72d6a2c0efa5142fdba2b63e3c4.pdf"
        ],
        "id": "id-6527247857606014782",
        "abstract": "Considering the fact that points of interest on 3D shapes can be discriminated from a geometric perspective, it is reasonable to map the geometric signature of a point p to a probability value encoding to what degree p is a point of interest, especially for a specific class of 3D shapes. Based on the observation, we propose a three-phase algorithm for learning and predicting points of interest on 3D shapes by using multiple feature descriptors. Our algorithm requires two separate deep neural networks (stacked auto-encoders) to accomplish the task. During the first phase, we predict the membership of the given 3D shape according to a set of geometric descriptors using a deep neural network. After that, we train the other deep neural network to predict a probability distribution defined on the surface representing the possibility of a point being a point of interest. Finally, we use a manifold clustering technique to extract a set of points of interest as the output. Experimental results show superior detection performance of the proposed method over the previous state-of-the-art approaches.",
        "versions": [],
        "rank": 480
    },
    {
        "authors": [
            "Nikhil R. Pal",
            "Sankar K. Pal"
        ],
        "title": "A review on image segmentation techniques",
        "publication_date": "1993-09-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Pattern Recognition",
        "volume": "26",
        "doi": "10.1016/0031-3203(93)90135-j",
        "urls": [
            "https://openalex.org/W1972544340",
            "https://doi.org/10.1016/0031-3203(93)90135-j"
        ],
        "id": "id1014567330928005442",
        "abstract": "",
        "versions": [],
        "rank": 481
    },
    {
        "authors": [
            "Christian Bartz",
            "Haojin Yang",
            "Christoph Meinel"
        ],
        "title": "SEE: Towards Semi-Supervised End-to-End Scene Text Recognition",
        "publication_date": "2017-12-14 12:59:26+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1712.05404v1",
            "http://arxiv.org/abs/1712.05404v1",
            "http://arxiv.org/pdf/1712.05404v1"
        ],
        "id": "id3684389864836299079",
        "abstract": "Detecting and recognizing text in natural scene images is a challenging, yet\nnot completely solved task. In recent years several new systems that try to\nsolve at least one of the two sub-tasks (text detection and text recognition)\nhave been proposed. In this paper we present SEE, a step towards\nsemi-supervised neural networks for scene text detection and recognition, that\ncan be optimized end-to-end. Most existing works consist of multiple deep\nneural networks and several pre-processing steps. In contrast to this, we\npropose to use a single deep neural network, that learns to detect and\nrecognize text from natural images, in a semi-supervised way. SEE is a network\nthat integrates and jointly learns a spatial transformer network, which can\nlearn to detect text regions in an image, and a text recognition network that\ntakes the identified text regions and recognizes their textual content. We\nintroduce the idea behind our novel approach and show its feasibility, by\nperforming a range of experiments on standard benchmark datasets, where we\nachieve competitive results.",
        "versions": [],
        "rank": 482
    },
    {
        "authors": [
            "Nacereddine Sitouah",
            "Fatiha Merazka",
            "Abdenour Hedjazi"
        ],
        "title": "Deep learning approach for interruption attacks detection in LEO satellite networks",
        "publication_date": "2022-12-10 21:21:14+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2301.03998v1",
            "http://arxiv.org/abs/2301.03998v1",
            "http://arxiv.org/pdf/2301.03998v1"
        ],
        "id": "id-4274309465350340054",
        "abstract": "The developments of satellite communication in network systems require strong\nand effective security plans. Attacks such as denial of service (DoS) can be\ndetected through the use of machine learning techniques, especially under\nnormal operational conditions. This work aims to provide an interruption\ndetection strategy for Low Earth Orbit (\\textsf{LEO}) satellite networks using\ndeep learning algorithms. Both the training, and the testing of the proposed\nmodels are carried out with our own communication datasets, created by\nutilizing a satellite traffic (benign and malicious) that was generated using\nsatellite networks simulation platforms, Omnet++ and Inet. We test different\ndeep learning algorithms including Multi Layer Perceptron (MLP), Convolutional\nNeural Network (CNN), Recurrent Neural Network (RNN), Gated Recurrent Units\n(GRU), and Long Short-term Memory (LSTM). Followed by a full analysis and\ninvestigation of detection rate in both binary classification, and\nmulti-classes classification that includes different interruption categories\nsuch as Distributed DoS (DDoS), Network Jamming, and meteorological\ndisturbances. Simulation results for both classification types surpassed 99.33%\nin terms of detection rate in scenarios of full network surveillance. However,\nin more realistic scenarios, the best-recorded performance was 96.12% for the\ndetection of binary traffic and 94.35% for the detection of multi-class traffic\nwith a false positive rate of 3.72%, using a hybrid model that combines MLP and\nGRU. This Deep Learning approach efficiency calls for the necessity of using\nmachine learning methods to improve security and to give more awareness to\nsearch for solutions that facilitate data collection in LEO satellite networks.",
        "versions": [],
        "rank": 483
    },
    {
        "authors": [
            "O. S. Amosov",
            "S. G. Amosova",
            "Y. S. Ivanov",
            "S. V. Zhiganov"
        ],
        "title": "Using the deep neural networks for normal and abnormal situation recognition in the automatic access monitoring and control system of vehicles",
        "publication_date": "2020-07-08 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Neural Computing and Applications",
        "volume": "",
        "doi": "10.1007/s00521-020-05170-5",
        "urls": [
            "https://www.semanticscholar.org/paper/4f1275678a169a6e4b6d9fb9336a34be9163055a"
        ],
        "id": "id-7644511589494306167",
        "abstract": null,
        "versions": [],
        "rank": 484
    },
    {
        "authors": [
            "A Abeshu",
            "A Adeel",
            "C Yin",
            "CF Morabito",
            "CF Tsai",
            "K Dashtipour",
            "MM Najafabadi",
            "N Shone",
            "PT Boer De",
            "S Gasparini",
            "Y LeCun",
            "Y Yan",
            "Z Wang"
        ],
        "title": "Statistical analysis driven optimized deep learning system for intrusion detection",
        "publication_date": "2018-08-16 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-3-030-00563-4_74",
        "urls": [
            "https://core.ac.uk/download/293885720.pdf"
        ],
        "id": "id4439386328925666165",
        "abstract": "Attackers have developed ever more sophisticated and intelligent ways to hack\ninformation and communication technology systems. The extent of damage an\nindividual hacker can carry out upon infiltrating a system is well understood.\nA potentially catastrophic scenario can be envisaged where a nation-state\nintercepting encrypted financial data gets hacked. Thus, intelligent\ncybersecurity systems have become inevitably important for improved protection\nagainst malicious threats. However, as malware attacks continue to dramatically\nincrease in volume and complexity, it has become ever more challenging for\ntraditional analytic tools to detect and mitigate threat. Furthermore, a huge\namount of data produced by large networks has made the recognition task even\nmore complicated and challenging. In this work, we propose an innovative\nstatistical analysis driven optimized deep learning system for intrusion\ndetection. The proposed intrusion detection system (IDS) extracts optimized and\nmore correlated features using big data visualization and statistical analysis\nmethods (human-in-the-loop), followed by a deep autoencoder for potential\nthreat detection. Specifically, a pre-processing module eliminates the outliers\nand converts categorical variables into one-hot-encoded vectors. The feature\nextraction module discard features with null values and selects the most\nsignificant features as input to the deep autoencoder model (trained in a\ngreedy-wise manner). The NSL-KDD dataset from the Canadian Institute for\nCybersecurity is used as a benchmark to evaluate the feasibility and\neffectiveness of the proposed architecture. Simulation results demonstrate the\npotential of our proposed system and its outperformance as compared to existing\nstate-of-the-art methods and recently published novel approaches. Ongoing work\nincludes further optimization and real-time evaluation of our proposed IDS.Comment: To appear in the 9th International Conference on Brain Inspired\n  Cognitive Systems (BICS 2018",
        "versions": [],
        "rank": 485
    },
    {
        "authors": [
            "Charlie Kirkwood",
            "Theo Economou",
            "Henry Odbert",
            "Nicolas Pugeault"
        ],
        "title": "A deep mixture density network for outlier-corrected interpolation of crowd-sourced weather data",
        "publication_date": "2022-01-25 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20220202094516/https://arxiv.org/pdf/2201.10544v1.pdf"
        ],
        "id": "id-305432427360197610",
        "abstract": "As the costs of sensors and associated IT infrastructure decreases - as exemplified by the Internet of Things - increasing volumes of observational data are becoming available for use by environmental scientists. However, as the number of available observation sites increases, so too does the opportunity for data quality issues to emerge, particularly given that many of these sensors do not have the benefit of official maintenance teams. To realise the value of crowd sourced 'Internet of Things' type observations for environmental modelling, we require approaches that can automate the detection of outliers during the data modelling process so that they do not contaminate the true distribution of the phenomena of interest. To this end, here we present a Bayesian deep learning approach for spatio-temporal modelling of environmental variables with automatic outlier detection. Our approach implements a Gaussian-uniform mixture density network whose dual purposes - modelling the phenomenon of interest, and learning to classify and ignore outliers - are achieved simultaneously, each by specifically designed branches of our neural network. For our example application, we use the Met Office's Weather Observation Website data, an archive of observations from around 1900 privately run and unofficial weather stations across the British Isles. Using data on surface air temperature, we demonstrate how our deep mixture model approach enables the modelling of a highly skilled spatio-temporal temperature distribution without contamination from spurious observations. We hope that adoption of our approach will help unlock the potential of incorporating a wider range of observation sources, including from crowd sourcing, into future environmental models.",
        "versions": [],
        "rank": 486
    },
    {
        "authors": [
            "Griffith, Caitlin A.",
            "Palafox, Leon",
            "Pearson, Kyle A."
        ],
        "title": "Searching for Exoplanets Using Artificial Intelligence",
        "publication_date": "2017-10-20 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": null,
        "volume": "",
        "doi": "10.1093/mnras/stx2761",
        "urls": [
            "http://arxiv.org/abs/1706.04319"
        ],
        "id": "id-7356578151504852571",
        "abstract": "In the last decade, over a million stars were monitored to detect transiting\nplanets. Manual interpretation of potential exoplanet candidates is labor\nintensive and subject to human error, the results of which are difficult to\nquantify. Here we present a new method of detecting exoplanet candidates in\nlarge planetary search projects which, unlike current methods uses a neural\nnetwork. Neural networks, also called \"deep learning\" or \"deep nets\" are\ndesigned to give a computer perception into a specific problem by training it\nto recognize patterns. Unlike past transit detection algorithms deep nets learn\nto recognize planet features instead of relying on hand-coded metrics that\nhumans perceive as the most representative. Our convolutional neural network is\ncapable of detecting Earth-like exoplanets in noisy time-series data with a\ngreater accuracy than a least-squares method. Deep nets are highly\ngeneralizable allowing data to be evaluated from different time series after\ninterpolation without compromising performance. As validated by our deep net\nanalysis of Kepler light curves, we detect periodic transits consistent with\nthe true period without any model fitting. Our study indicates that machine\nlearning will facilitate the characterization of exoplanets in future analysis\nof large astronomy data sets.Comment: Accepted, 16 Pages, 14 Figures,\n  https://github.com/pearsonkyle/Exoplanet-Artificial-Intelligenc",
        "versions": [],
        "rank": 487
    },
    {
        "authors": [
            "Fanzhen Liu",
            "Shan Xue",
            "Jia Wu",
            "Chuan Zhou",
            "Wenbin Hu",
            "Cecile Paris",
            "Surya Nepal",
            "Jian Yang",
            "Philip S. Yu"
        ],
        "title": "Deep Learning for Community Detection: Progress, Challenges and Opportunities",
        "publication_date": "2020-05-17 11:22:11+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": "IJCAI 2020: 4981-4987",
        "volume": "",
        "doi": "10.24963/ijcai.2020/693",
        "urls": [
            "http://arxiv.org/pdf/2005.08225v2",
            "http://dx.doi.org/10.24963/ijcai.2020/693",
            "http://arxiv.org/abs/2005.08225v2",
            "http://arxiv.org/pdf/2005.08225v2"
        ],
        "id": "id-4211272395517457107",
        "abstract": "As communities represent similar opinions, similar functions, similar\npurposes, etc., community detection is an important and extremely useful tool\nin both scientific inquiry and data analytics. However, the classic methods of\ncommunity detection, such as spectral clustering and statistical inference, are\nfalling by the wayside as deep learning techniques demonstrate an increasing\ncapacity to handle high-dimensional graph data with impressive performance.\nThus, a survey of current progress in community detection through deep learning\nis timely. Structured into three broad research streams in this domain - deep\nneural networks, deep graph embedding, and graph neural networks, this article\nsummarizes the contributions of the various frameworks, models, and algorithms\nin each stream along with the current challenges that remain unsolved and the\nfuture research opportunities yet to be explored.",
        "versions": [],
        "rank": 488
    },
    {
        "authors": [
            "Caltagirone, Luca",
            "Scheidegger, Samuel",
            "Svensson, Lennart",
            "Wahde, Mattias"
        ],
        "title": "Fast LIDAR-based Road Detection Using Fully Convolutional Neural  Networks",
        "publication_date": "2017-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ivs.2017.7995848",
        "urls": [
            "http://arxiv.org/abs/1703.03613"
        ],
        "id": "id214269704429204688",
        "abstract": "In this work, a deep learning approach has been developed to carry out road\ndetection using only LIDAR data. Starting from an unstructured point cloud,\ntop-view images encoding several basic statistics such as mean elevation and\ndensity are generated. By considering a top-view representation, road detection\nis reduced to a single-scale problem that can be addressed with a simple and\nfast fully convolutional neural network (FCN). The FCN is specifically designed\nfor the task of pixel-wise semantic segmentation by combining a large receptive\nfield with high-resolution feature maps. The proposed system achieved excellent\nperformance and it is among the top-performing algorithms on the KITTI road\nbenchmark. Its fast inference makes it particularly suitable for real-time\napplications",
        "versions": [],
        "rank": 489
    },
    {
        "authors": [
            "Emre \u00c7akir",
            "T. Heittola",
            "H. Huttunen",
            "T. Virtanen"
        ],
        "title": "Polyphonic sound event detection using multi label deep neural networks",
        "publication_date": "2015-07-12 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/IJCNN.2015.7280624",
        "urls": [
            "https://www.semanticscholar.org/paper/c216388d56aac895d6ff86adbb7f21aaf1eed07d"
        ],
        "id": "id-4381552791959310829",
        "abstract": "In this paper, the use of multi label neural networks are proposed for detection of temporally overlapping sound events in realistic environments. Real-life sound recordings typically have many overlapping sound events, making it hard to recognize each event with the standard sound event detection methods. Frame-wise spectral-domain features are used as inputs to train a deep neural network for multi label classification in this work. The model is evaluated with recordings from realistic everyday environments and the obtained overall accuracy is 63.8%. The method is compared against a state-of-the-art method using non-negative matrix factorization as a pre-processing stage and hidden Markov models as a classifier. The proposed method improves the accuracy by 19% percentage points overall.",
        "versions": [
            {
                "year": 2015,
                "source": "SupportedSources.CROSSREF",
                "title": "Polyphonic sound event detection using multi label deep neural networks",
                "journal": "",
                "urls": [
                    "http://xplorestaging.ieee.org/ielx7/7256526/7280295/07280624.pdf?arnumber=7280624",
                    "http://dx.doi.org/10.1109/ijcnn.2015.7280624"
                ],
                "doi": "10.1109/ijcnn.2015.7280624",
                "publication_date": "2015-01-01 00:00:00"
            }
        ],
        "rank": 490
    },
    {
        "authors": [
            "Cai, D."
        ],
        "title": "Physics-Informed Distribution Transformers Via Molecular Dynamics and Deep Neural Networks",
        "publication_date": "2022-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.2139/ssrn.4028725",
        "urls": [
            "http://dx.doi.org/10.2139/ssrn.4028725"
        ],
        "id": "id-5732747235400079215",
        "abstract": "",
        "versions": [],
        "rank": 491
    },
    {
        "authors": [
            "S. Dorafshan",
            "R. Thomas",
            "Marc Maguire"
        ],
        "title": "SDNET2018: An annotated image dataset for non-contact concrete crack detection using deep convolutional neural networks",
        "publication_date": "2018-11-06 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Data in Brief",
        "volume": "21",
        "doi": "10.1016/j.dib.2018.11.015",
        "urls": [
            "https://www.semanticscholar.org/paper/b595b1f5f740f4b51d550f3a111b3ff865da030a"
        ],
        "id": "id4517020640790051228",
        "abstract": null,
        "versions": [],
        "rank": 492
    },
    {
        "authors": [
            "Cuoco, Elena",
            "Razzano, Massimiliano"
        ],
        "title": "Image-based deep learning for classification of noise transients in  gravitational wave detectors",
        "publication_date": "2018-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": null,
        "volume": "",
        "doi": "10.1088/1361-6382/aab793",
        "urls": [
            "http://arxiv.org/abs/1803.09933"
        ],
        "id": "id-7605538278934265266",
        "abstract": "The detection of gravitational waves has inaugurated the era of gravitational\nastronomy and opened new avenues for the multimessenger study of cosmic\nsources. Thanks to their sensitivity, the Advanced LIGO and Advanced Virgo\ninterferometers will probe a much larger volume of space and expand the\ncapability of discovering new gravitational wave emitters. The characterization\nof these detectors is a primary task in order to recognize the main sources of\nnoise and optimize the sensitivity of interferometers. Glitches are transient\nnoise events that can impact the data quality of the interferometers and their\nclassification is an important task for detector characterization. Deep\nlearning techniques are a promising tool for the recognition and classification\nof glitches. We present a classification pipeline that exploits convolutional\nneural networks to classify glitches starting from their time-frequency\nevolution represented as images. We evaluated the classification accuracy on\nsimulated glitches, showing that the proposed algorithm can automatically\nclassify glitches on very fast timescales and with high accuracy, thus\nproviding a promising tool for online detector characterization.Comment: 25 pages, 8 figures, accepted for publication in Classical and\n  Quantum Gravit",
        "versions": [],
        "rank": 493
    },
    {
        "authors": [
            "Robert Logan",
            "Brian Williams",
            "M. G. Ferreira da silva",
            "Akash Indani",
            "Nicol\u00e1s Schcolnicov",
            "Anjali Ganguly",
            "Sean J. Miller"
        ],
        "title": "Deep Convolutional Neural Networks With Ensemble Learning and Generative Adversarial Networks for Alzheimer\u2019s Disease Image Data Classification",
        "publication_date": "2021-08-17 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Frontiers in Aging Neuroscience",
        "volume": "13",
        "doi": "10.3389/fnagi.2021.720226",
        "urls": [
            "https://www.semanticscholar.org/paper/0892851a2e12a87e15002405dc55e4de658c8fe7"
        ],
        "id": "id5806760751669415178",
        "abstract": "Recent advancements in deep learning (DL) have made possible new methodologies for analyzing massive datasets with intriguing implications in healthcare. Convolutional neural networks (CNN), which have proven to be successful supervised algorithms for classifying imaging data, are of particular interest in the neuroscience community for their utility in the classification of Alzheimer\u2019s disease (AD). AD is the leading cause of dementia in the aging population. There remains a critical unmet need for early detection of AD pathogenesis based on non-invasive neuroimaging techniques, such as magnetic resonance imaging (MRI) and positron emission tomography (PET). In this comprehensive review, we explore potential interdisciplinary approaches for early detection and provide insight into recent advances on AD classification using 3D CNN architectures for multi-modal PET/MRI data. We also consider the application of generative adversarial networks (GANs) to overcome pitfalls associated with limited data. Finally, we discuss increasing the robustness of CNNs by combining them with ensemble learning (EL).",
        "versions": [],
        "rank": 494
    },
    {
        "authors": [
            "Ross Girshick",
            "Jeff Donahue",
            "Trevor Darrell",
            "Jitendra Malik"
        ],
        "title": "Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation",
        "publication_date": "2014-06-23 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Computer Vision and Pattern Recognition",
        "volume": "",
        "doi": "10.1109/cvpr.2014.81",
        "urls": [
            "https://openalex.org/W2102605133",
            "https://doi.org/10.1109/cvpr.2014.81",
            "http://arxiv.org/pdf/1311.2524"
        ],
        "id": "id7177329210519317370",
        "abstract": "",
        "versions": [],
        "rank": 495
    },
    {
        "authors": [
            "Zhizhong Li",
            "Derek Hoiem"
        ],
        "title": "Learning without Forgetting",
        "publication_date": "2018-12-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
        "volume": "40",
        "doi": "10.1109/tpami.2017.2773081",
        "urls": [
            "https://openalex.org/W2473930607",
            "https://doi.org/10.1109/tpami.2017.2773081",
            "https://doi.org/10.1109/tpami.2017.2773081"
        ],
        "id": "id5215085352256294994",
        "abstract": "",
        "versions": [],
        "rank": 496
    },
    {
        "authors": [
            "D. Yudin",
            "A. Skrynnik",
            "A. Krishtopik",
            "I. Belkin",
            "A. Panov"
        ],
        "title": "Object Detection with Deep Neural Networks for Reinforcement Learning in the Task of Autonomous Vehicles Path Planning at the Intersection",
        "publication_date": "2019-10-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Optical Memory and Neural Networks",
        "volume": "28",
        "doi": "10.3103/S1060992X19040118",
        "urls": [
            "https://www.semanticscholar.org/paper/4417daf1c4e0d3edc7ccd66f7402ba7d4a922ca9"
        ],
        "id": "id3603486859660265656",
        "abstract": null,
        "versions": [],
        "rank": 497
    },
    {
        "authors": [
            "Naomie Salim"
        ],
        "title": "Deep Learning Approaches for Big Data Analysis",
        "publication_date": "2019-10-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Institute of Advanced Engineering and Science",
        "volume": "",
        "doi": "10.11591/eecsi.v6.2008",
        "urls": [
            "https://web.archive.org/web/20200507052005/http://journal.portalgaruda.org/index.php/EECSI/article/download/2008/1453"
        ],
        "id": "id4093887733042144752",
        "abstract": "Good representations of data eliminate irrelevant variability of the input data, while preserving the information that is useful for the ultimate task. Among the various ways for learning representation is using deep learning methods. Deep feature hierarchies are formed by stacking unsupervised modules on top of each other, forming multiple nonlinear transformations to produce better representations. In this talk, we will first show how deep learning is used for bioactivity prediction of chemical compounds. Molecules are represented as several convolutional neural networks to predict their bioactivity. In addition, a new concept of merging multiple convolutional neural networks and an automatic learning features representation for the chemical compounds was proposed using the values within neurons of the last layer of the CNN architecture. We will also show how the concepts of deep learning is adapted into a deep belief network (DBN) to enhance the molecular similarity searching. The DBN achieves feature abstraction by reconstruction weight for each feature and minimizing the reconstruction error over the whole feature set. The DBN is later enhanced using data fusion to obtain a lower detection error probability and a higher reliability by using data from multiple distributed descriptors. Secondly, we will show how we used deep learning for stock market prediction. Here, we developed a Deep Long Short Term Memory Network model that is able to forecast the crude palm oil price movement with combined factors such as other commodities prices, weather and news sentiments and price movement of crude palm oil. We also show how we combined stock markets price and financial news and deployed the Long Short Term Memory (LSTM), Recurrent Neural Network (RNN), and Word 2 Vector (Word2Vec) to project the stock prices for the following seven days. Finally, we will show how we exploited deep learning method for the opinion mining and later used it to extract the product's aspects from the user textual review for recommendation systems. Specifically, we employ a multichannel convolutional neural network (MCNN) for two different input layers, namely, word embedding layer and Part-of-speech (POS) tag embedding layer. We show effectiveness of the proposed model in terms of both aspect extraction and rating prediction performance. Biography Professor Naomie Salim's main research goal is to design of new algorithms to improve the effectiveness of searching and mining new knowledge from various kinds of datasets, including unstructured, semi-structured and structured databases. The current focus of her research is on chemical databases and text databases to support the process of computer-aided drug design, text summarisation, plagiarism detection, automatic information extraction, sentiment analysis and recommendation systems. Professor Naomie Salim has been involved in 51 research projects out of which she heads 20 of the projects. The projects are in collaboration with colleagues within UTM or with external organisations and communities, to a total value of RM 6.18 million.",
        "versions": [],
        "rank": 498
    },
    {
        "authors": [
            "Connor Schenck",
            "Dieter Fox"
        ],
        "title": "Detection and Tracking of Liquids with Fully Convolutional Networks",
        "publication_date": "2016-06-20 19:40:29+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1606.06266v1",
            "http://arxiv.org/abs/1606.06266v1",
            "http://arxiv.org/pdf/1606.06266v1"
        ],
        "id": "id-8036094465097438248",
        "abstract": "Recent advances in AI and robotics have claimed many incredible results with\ndeep learning, yet no work to date has applied deep learning to the problem of\nliquid perception and reasoning. In this paper, we apply fully-convolutional\ndeep neural networks to the tasks of detecting and tracking liquids. We\nevaluate three models: a single-frame network, multi-frame network, and a LSTM\nrecurrent network. Our results show that the best liquid detection results are\nachieved when aggregating data over multiple frames, in contrast to standard\nimage segmentation. They also show that the LSTM network outperforms the other\ntwo in both tasks. This suggests that LSTM-based neural networks have the\npotential to be a key component for enabling robots to handle liquids using\nrobust, closed-loop controllers.",
        "versions": [],
        "rank": 499
    },
    {
        "authors": [
            "Lan Liu",
            "Jun Lin",
            "Pengcheng Wang",
            "Langzhou Liu",
            "Rongfu Zhou"
        ],
        "title": "Deep Learning-Based Network Security Data Sampling and Anomaly Prediction in Future Network",
        "publication_date": "2020-05-17 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Hindawi Limited",
        "volume": "",
        "doi": "10.1155/2020/4163825",
        "urls": [
            "https://web.archive.org/web/20200518013755/http://downloads.hindawi.com/journals/ddns/2020/4163825.pdf"
        ],
        "id": "id-6126599545761372964",
        "abstract": "Based on the design idea of future network, this paper analyzes the network security data sampling and anomaly prediction in future network. Through game theory, it is determined that data sampling is performed on some important nodes in the future network. Deep learning methods are used on the selected nodes to collect data and analyze the characteristics of the network data. Then, through offline and real-time analyses, network security abnormal events are predicted in the future network. With the comparison of various algorithms and the adjustment of hyperparameters, the data characteristics and classification algorithms corresponding to different network security attacks are found. We have carried out experiments on the public dataset, and the experiment proves the effectiveness of the method. It can provide reference for the management strategy of the switch node or the host node by the future network controller.",
        "versions": [],
        "rank": 500
    },
    {
        "authors": [
            "Niclas St\u00e5hl",
            "G\u00f6ran Falkman",
            "Alexander Karlsson",
            "Gunnar Mathiason"
        ],
        "title": "Evaluation of Uncertainty Quantification in Deep Learning",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Springer International Publishing",
        "volume": "",
        "doi": "10.1007/978-3-030-50146-4_41",
        "urls": [
            "https://web.archive.org/web/20200815052225/https://link.springer.com/content/pdf/10.1007%2F978-3-030-50146-4_41.pdf"
        ],
        "id": "id-1589076787704133984",
        "abstract": "Artificial intelligence (AI) is nowadays included into an increasing number of critical systems. Inclusion of AI in such systems may, however, pose a risk, since it is, still, infeasible to build AI systems that know how to function well in situations that differ greatly from what the AI has seen before. Therefore, it is crucial that future AI systems have the ability to not only function well in known domains, but also understand and show when they are uncertain when facing something unknown. In this paper, we evaluate four different methods that have been proposed to correctly quantifying uncertainty when the AI model is faced with new samples. We investigate the behaviour of these models when they are applied to samples far from what these models have seen before, and if they correctly attribute those samples with high uncertainty. We also examine if incorrectly classified samples are attributed with an higher uncertainty than correctly classified samples. The major finding from this simple experiment is, surprisingly, that the evaluated methods capture the uncertainty differently and the correlation between the quantified uncertainty of the models is low. This inconsistency is something that needs to be further understood and solved before AI can be used in critical applications in a trustworthy and safe manner.",
        "versions": [],
        "rank": 501
    },
    {
        "authors": [
            "S. Sabut",
            "O. Pandey",
            "B. P. Mishra",
            "M. Mohanty"
        ],
        "title": "Detection of ventricular arrhythmia using hybrid time\u2013frequency-based features and deep neural network",
        "publication_date": "2021-01-08 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Physical and Engineering Sciences in Medicine",
        "volume": "44",
        "doi": "10.1007/s13246-020-00964-2",
        "urls": [
            "https://www.semanticscholar.org/paper/19d56871bfe939ac99ee70d0e18435e8977be116"
        ],
        "id": "id-6125481965968491621",
        "abstract": null,
        "versions": [],
        "rank": 502
    },
    {
        "authors": [
            "P. Kaur",
            "R. Sobti"
        ],
        "title": "Pedestrian and Vehicle detection in automotive embedded systems using deep neural networks",
        "publication_date": "2018-07-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ICRIEECE44171.2018.9008972",
        "urls": [
            "https://www.semanticscholar.org/paper/1493b2e1be610dac7248043cb1e9602cfe80b6fd"
        ],
        "id": "id-5155681409073126594",
        "abstract": "Pedestrian and vehicle detection by autonomous cars is an emerging area of research in the automotive community. The perception system of intelligent vehicles gathers data from sensing devices to understand and analyze traffic situations. This cognitive intelligence is required to make efficacious real-time decisions to avert imminent collisions with vulnerable traffic users such as humans, stranded or moving vehicles, cyclists or other static obstacles. This paper addresses the problem of people and vehicle detection using deep learning models such as convolutional neural networks. The results provided an incredible evidence that Deep neural networks have a significant potential for solving problems related to intelligent transportation systems. Higher rates of accuracy have been achieved by adding multiple hidden layers. The Keras based architecture along with tensorflow libraries have been used to implement the algorithm.",
        "versions": [],
        "rank": 503
    },
    {
        "authors": [
            "Gales, Mark",
            "Malinin, Andrey"
        ],
        "title": "Predictive Uncertainty Estimation via Prior Networks",
        "publication_date": "2018-11-29 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.17863/cam.35237",
        "urls": [
            "https://core.ac.uk/download/162917072.pdf"
        ],
        "id": "id-6221395547287781102",
        "abstract": "Estimating how uncertain an AI system is in its predictions is important to\nimprove the safety of such systems. Uncertainty in predictive can result from\nuncertainty in model parameters, irreducible data uncertainty and uncertainty\ndue to distributional mismatch between the test and training data\ndistributions. Different actions might be taken depending on the source of the\nuncertainty so it is important to be able to distinguish between them.\nRecently, baseline tasks and metrics have been defined and several practical\nmethods to estimate uncertainty developed. These methods, however, attempt to\nmodel uncertainty due to distributional mismatch either implicitly through\nmodel uncertainty or as data uncertainty. This work proposes a new framework\nfor modeling predictive uncertainty called Prior Networks (PNs) which\nexplicitly models distributional uncertainty. PNs do this by parameterizing a\nprior distribution over predictive distributions. This work focuses on\nuncertainty for classification and evaluates PNs on the tasks of identifying\nout-of-distribution (OOD) samples and detecting misclassification on the MNIST\ndataset, where they are found to outperform previous methods. Experiments on\nsynthetic and MNIST and CIFAR-10 data show that unlike previous non-Bayesian\nmethods PNs are able to distinguish between data and distributional\nuncertainty",
        "versions": [],
        "rank": 504
    },
    {
        "authors": [
            "Wei-Long Zheng",
            "Bao-Liang Lu"
        ],
        "title": "Investigating Critical Frequency Bands and Channels for EEG-Based Emotion Recognition with Deep Neural Networks",
        "publication_date": "2015-05-08 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "IEEE Transactions on Autonomous Mental Development",
        "volume": "7",
        "doi": "10.1109/tamd.2015.2431497",
        "urls": [
            "https://openalex.org/W1947251450",
            "https://doi.org/10.1109/tamd.2015.2431497"
        ],
        "id": "id9116194782259010184",
        "abstract": "",
        "versions": [],
        "rank": 505
    },
    {
        "authors": [
            "Erdmann, M.",
            "Schlueter, F.",
            "Smida, R."
        ],
        "title": "Classification and Recovery of Radio Signals from Cosmic Ray Induced Air  Showers with Deep Learning",
        "publication_date": "2019-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1088/1748-0221/14/04/p04005",
        "urls": [
            "http://arxiv.org/abs/1901.04079"
        ],
        "id": "id573970443649560855",
        "abstract": "Radio emission from air showers enables measurements of cosmic particle\nkinematics and identity. The radio signals are detected in broadband Megahertz\nantennas among continuous background noise. We present two deep learning\nconcepts and their performance when applied to simulated data. The first\nnetwork classifies time traces as signal or background. We achieve a true\npositive rate of about 90% for signal-to-noise ratios larger than three with a\nfalse positive rate below 0.2%. The other network is used to clean the time\ntrace from background and to recover the radio time trace originating from an\nair shower. Here we achieve a resolution in the energy contained in the trace\nof about 20% without a bias for $80\\%$ of the traces with a signal. The\nobtained frequency spectrum is cleaned from signals of radio frequency\ninterference and shows the expected shape.Comment: 20 pages, 13 figures, resubmitted to JINS",
        "versions": [],
        "rank": 506
    },
    {
        "authors": [
            "David Burns",
            "Philip Boyer",
            "Colin Arrowsmith",
            "Cari Whyne"
        ],
        "title": "Personalized Activity Recognition with Deep Triplet Embeddings",
        "publication_date": "2022-07-13 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "MDPI AG",
        "volume": "",
        "doi": "10.3390/s22145222",
        "urls": [
            "https://web.archive.org/web/20220715044219/https://mdpi-res.com/d_attachment/sensors/sensors-22-05222/article_deploy/sensors-22-05222.pdf?version=1657690773"
        ],
        "id": "id1124730508067547986",
        "abstract": "A significant challenge for a supervised learning approach to inertial human activity recognition is the heterogeneity of data generated by individual users, resulting in very poor performance for some subjects. We present an approach to personalized activity recognition based on deep feature representation derived from a convolutional neural network (CNN). We experiment with both categorical cross-entropy loss and triplet loss for training, and describe a novel loss function based on subject triplets. We evaluate these methods on three publicly available inertial human activity recognition datasets (MHEALTH, WISDM, and SPAR) comparing classification accuracy, out-of-distribution activity detection, and generalization to new activity classes. The proposed triplet algorithm achieved an average 96.7% classification accuracy across tested datasets versus the 87.5% achieved by the baseline CNN algorithm. We demonstrate that personalized algorithms, and, in particular, the proposed novel triplet loss algorithms, are more robust to inter-subject variability and thus exhibit better performance on classification and out-of-distribution detection tasks.",
        "versions": [
            {
                "year": 2020,
                "source": "SupportedSources.INTERNET_ARCHIVE",
                "title": "Personalized Activity Recognition with Deep Triplet Embeddings",
                "journal": "",
                "urls": [
                    "https://web.archive.org/web/20200321164314/https://arxiv.org/pdf/2001.05517v1.pdf"
                ],
                "doi": "",
                "publication_date": "2020-01-15 00:00:00"
            }
        ],
        "rank": 507
    },
    {
        "authors": [
            "Xianzhi Du",
            "Mostafa El-Khamy",
            "Jungwon Lee",
            "Larry S. Davis"
        ],
        "title": "Fused DNN: A deep neural network fusion approach to fast and robust pedestrian detection",
        "publication_date": "2016-10-11 18:59:12+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1610.03466v2",
            "http://arxiv.org/abs/1610.03466v2",
            "http://arxiv.org/pdf/1610.03466v2"
        ],
        "id": "id6184470998203517155",
        "abstract": "We propose a deep neural network fusion architecture for fast and robust\npedestrian detection. The proposed network fusion architecture allows for\nparallel processing of multiple networks for speed. A single shot deep\nconvolutional network is trained as a object detector to generate all possible\npedestrian candidates of different sizes and occlusions. This network outputs a\nlarge variety of pedestrian candidates to cover the majority of ground-truth\npedestrians while also introducing a large number of false positives. Next,\nmultiple deep neural networks are used in parallel for further refinement of\nthese pedestrian candidates. We introduce a soft-rejection based network fusion\nmethod to fuse the soft metrics from all networks together to generate the\nfinal confidence scores. Our method performs better than existing\nstate-of-the-arts, especially when detecting small-size and occluded\npedestrians. Furthermore, we propose a method for integrating pixel-wise\nsemantic segmentation network into the network fusion architecture as a\nreinforcement to the pedestrian detector. The approach outperforms\nstate-of-the-art methods on most protocols on Caltech Pedestrian dataset, with\nsignificant boosts on several protocols. It is also faster than all other\nmethods.",
        "versions": [],
        "rank": 508
    },
    {
        "authors": [
            "Ilker Bozcan",
            "Erdal Kayacan"
        ],
        "title": "UAV-AdNet: Unsupervised Anomaly Detection using Deep Neural Networks for Aerial Surveillance",
        "publication_date": "2020-11-05 14:26:29+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2011.02853v1",
            "http://arxiv.org/abs/2011.02853v1",
            "http://arxiv.org/pdf/2011.02853v1"
        ],
        "id": "id-2107521375470377646",
        "abstract": "Anomaly detection is a key goal of autonomous surveillance systems that\nshould be able to alert unusual observations. In this paper, we propose a\nholistic anomaly detection system using deep neural networks for surveillance\nof critical infrastructures (e.g., airports, harbors, warehouses) using an\nunmanned aerial vehicle (UAV). First, we present a heuristic method for the\nexplicit representation of spatial layouts of objects in bird-view images.\nThen, we propose a deep neural network architecture for unsupervised anomaly\ndetection (UAV-AdNet), which is trained on environment representations and GPS\nlabels of bird-view images jointly. Unlike studies in the literature, we\ncombine GPS and image data to predict abnormal observations. We evaluate our\nmodel against several baselines on our aerial surveillance dataset and show\nthat it performs better in scene reconstruction and several anomaly detection\ntasks. The codes, trained models, dataset, and video will be available at\nhttps://bozcani.github.io/uavadnet.",
        "versions": [],
        "rank": 509
    },
    {
        "authors": [
            "Matthias Rottmann",
            "Philipp Oberdiek",
            "Gernot A. Fink"
        ],
        "title": "Detection and Retrieval of Out-of-Distribution Objects in Semantic Segmentation",
        "publication_date": "2020-05-14 00:00:00",
        "source": "SupportedSources.PAPERS_WITH_CODE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://arxiv.org/pdf/2005.06831v1.pdf",
            "https://github.com/RonMcKay/OODRetrieval"
        ],
        "id": "id8469399121691646749",
        "abstract": "When deploying deep learning technology in self-driving cars, deep neural networks are constantly exposed to domain shifts. These include, e.g., changes in weather conditions, time of day, and long-term temporal shift. In this work we utilize a deep neural network trained on the Cityscapes dataset containing urban street scenes and infer images from a different dataset, the A2D2 dataset, containing also countryside and highway images. We present a novel pipeline for semantic segmenation that detects out-of-distribution (OOD) segments by means of the deep neural network's prediction and performs image retrieval after feature extraction and dimensionality reduction on image patches. In our experiments we demonstrate that the deployed OOD approach is suitable for detecting out-of-distribution concepts. Furthermore, we evaluate the image patch retrieval qualitatively as well as quantitatively by means of the semi-compatible A2D2 ground truth and obtain mAP values of up to 52.2%.",
        "versions": [],
        "rank": 510
    },
    {
        "authors": [
            "Jiaoyang Huang",
            "Horng-Tzer Yau"
        ],
        "title": "Dynamics of Deep Neural Networks and Neural Tangent Hierarchy",
        "publication_date": "2019-09-18 00:51:05+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1909.08156v1",
            "http://arxiv.org/abs/1909.08156v1",
            "http://arxiv.org/pdf/1909.08156v1"
        ],
        "id": "id-827998862518374733",
        "abstract": "The evolution of a deep neural network trained by the gradient descent can be\ndescribed by its neural tangent kernel (NTK) as introduced in [20], where it\nwas proven that in the infinite width limit the NTK converges to an explicit\nlimiting kernel and it stays constant during training. The NTK was also\nimplicit in some other recent papers [6,13,14]. In the overparametrization\nregime, a fully-trained deep neural network is indeed equivalent to the kernel\nregression predictor using the limiting NTK. And the gradient descent achieves\nzero training loss for a deep overparameterized neural network. However, it was\nobserved in [5] that there is a performance gap between the kernel regression\nusing the limiting NTK and the deep neural networks. This performance gap is\nlikely to originate from the change of the NTK along training due to the finite\nwidth effect. The change of the NTK along the training is central to describe\nthe generalization features of deep neural networks.\n  In the current paper, we study the dynamic of the NTK for finite width deep\nfully-connected neural networks. We derive an infinite hierarchy of ordinary\ndifferential equations, the neural tangent hierarchy (NTH) which captures the\ngradient descent dynamic of the deep neural network. Moreover, under certain\nconditions on the neural network width and the data set dimension, we prove\nthat the truncated hierarchy of NTH approximates the dynamic of the NTK up to\narbitrary precision. This description makes it possible to directly study the\nchange of the NTK for deep neural networks, and sheds light on the observation\nthat deep neural networks outperform kernel regressions using the corresponding\nlimiting NTK.",
        "versions": [],
        "rank": 511
    },
    {
        "authors": [
            "Joshi, A.",
            "Chalasani, S.",
            "Iyer, K."
        ],
        "title": "Semantic Driven Energy based Out-of-Distribution Detection",
        "publication_date": "2022-07-18 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ijcnn55064.2022.9892318",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/9891857/9889787/09892318.pdf?arnumber=9892318",
            "http://dx.doi.org/10.1109/ijcnn55064.2022.9892318"
        ],
        "id": "id-4714998184813272424",
        "abstract": "",
        "versions": [],
        "rank": 512
    },
    {
        "authors": [
            "Ankit Pal",
            "Kar, S.",
            "Bharti, M."
        ],
        "title": "Algorithm for Distracted Driver Detection and Alert Using Deep Learning",
        "publication_date": "2021-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.3103/s1060992x21030103",
        "urls": [
            "https://link.springer.com/content/pdf/10.3103/S1060992X21030103.pdf",
            "https://link.springer.com/article/10.3103/S1060992X21030103/fulltext.html",
            "https://link.springer.com/content/pdf/10.3103/S1060992X21030103.pdf",
            "http://dx.doi.org/10.3103/s1060992x21030103"
        ],
        "id": "id3421644721735092740",
        "abstract": "",
        "versions": [],
        "rank": 513
    },
    {
        "authors": [
            "Dabiri, Sina",
            "Heaslip, Kevin"
        ],
        "title": "Inferring transportation modes from GPS trajectories using a  convolutional neural network",
        "publication_date": "2018-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": null,
        "volume": "",
        "doi": "10.1016/j.trc.2017.11.021",
        "urls": [
            "http://arxiv.org/abs/1804.02386"
        ],
        "id": "id1016036593329410094",
        "abstract": "Identifying the distribution of users' transportation modes is an essential\npart of travel demand analysis and transportation planning. With the advent of\nubiquitous GPS-enabled devices (e.g., a smartphone), a cost-effective approach\nfor inferring commuters' mobility mode(s) is to leverage their GPS\ntrajectories. A majority of studies have proposed mode inference models based\non hand-crafted features and traditional machine learning algorithms. However,\nmanual features engender some major drawbacks including vulnerability to\ntraffic and environmental conditions as well as possessing human's bias in\ncreating efficient features. One way to overcome these issues is by utilizing\nConvolutional Neural Network (CNN) schemes that are capable of automatically\ndriving high-level features from the raw input. Accordingly, in this paper, we\ntake advantage of CNN architectures so as to predict travel modes based on only\nraw GPS trajectories, where the modes are labeled as walk, bike, bus, driving,\nand train. Our key contribution is designing the layout of the CNN's input\nlayer in such a way that not only is adaptable with the CNN schemes but\nrepresents fundamental motion characteristics of a moving object including\nspeed, acceleration, jerk, and bearing rate. Furthermore, we ameliorate the\nquality of GPS logs through several data preprocessing steps. Using the clean\ninput layer, a variety of CNN configurations are evaluated to achieve the best\nCNN architecture. The highest accuracy of 84.8% has been achieved through the\nensemble of the best CNN configuration. In this research, we contrast our\nmethodology with traditional machine learning algorithms as well as the seminal\nand most related studies to demonstrate the superiority of our framework.Comment: 12 pages, 3 figures, 7 tables, Transportation Research Part C:\n  Emerging Technologie",
        "versions": [],
        "rank": 514
    },
    {
        "authors": [
            "Jared Mathews",
            "Prosenjit Chatterjee",
            "Shankar Banik",
            "Cory Nance"
        ],
        "title": "A Deep Learning Approach to Create DNS Amplification Attacks",
        "publication_date": "2022-06-29 01:11:48+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "10.1145/3535782.3535838",
        "urls": [
            "http://arxiv.org/pdf/2206.14346v1",
            "http://dx.doi.org/10.1145/3535782.3535838",
            "http://arxiv.org/abs/2206.14346v1",
            "http://arxiv.org/pdf/2206.14346v1"
        ],
        "id": "id-2966797537783135724",
        "abstract": "In recent years, deep learning has shown itself to be an incredibly valuable\ntool in cybersecurity as it helps network intrusion detection systems to\nclassify attacks and detect new ones. Adversarial learning is the process of\nutilizing machine learning to generate a perturbed set of inputs to then feed\nto the neural network to misclassify it. Much of the current work in the field\nof adversarial learning has been conducted in image processing and natural\nlanguage processing with a wide variety of algorithms. Two algorithms of\ninterest are the Elastic-Net Attack on Deep Neural Networks and TextAttack. In\nour experiment the EAD and TextAttack algorithms are applied to a Domain Name\nSystem amplification classifier. The algorithms are used to generate malicious\nDistributed Denial of Service adversarial examples to then feed as inputs to\nthe network intrusion detection systems neural network to classify as valid\ntraffic. We show in this work that both image processing and natural language\nprocessing adversarial learning algorithms can be applied against a network\nintrusion detection neural network.",
        "versions": [],
        "rank": 515
    },
    {
        "authors": [
            "Justice Amoh",
            "Kofi Odame"
        ],
        "title": "DeepCough: A Deep Convolutional Neural Network in A Wearable Cough Detection System",
        "publication_date": "2015-09-08 19:59:19+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1509.02512v1",
            "http://arxiv.org/abs/1509.02512v1",
            "http://arxiv.org/pdf/1509.02512v1"
        ],
        "id": "id-5769034009540496581",
        "abstract": "In this paper, we present a system that employs a wearable acoustic sensor\nand a deep convolutional neural network for detecting coughs. We evaluate the\nperformance of our system on 14 healthy volunteers and compare it to that of\nother cough detection systems that have been reported in the literature.\nExperimental results show that our system achieves a classification sensitivity\nof 95.1% and a specificity of 99.5%.",
        "versions": [],
        "rank": 516
    },
    {
        "authors": [
            "Paolo Tonella",
            "Rwiddhi Chakraborty",
            "Michael Weiss"
        ],
        "title": "A Review and Refinement of Surprise Adequacy",
        "publication_date": "2021-03-10 00:00:00",
        "source": "SupportedSources.PAPERS_WITH_CODE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://arxiv.org/pdf/2103.05939v1.pdf",
            "https://github.com/coinse/sadl"
        ],
        "id": "id-506956260408080542",
        "abstract": "Surprise Adequacy (SA) is one of the emerging and most promising adequacy criteria for Deep Learning (DL) testing. As an adequacy criterion, it has been used to assess the strength of DL test suites. In addition, it has also been used to find inputs to a Deep Neural Network (DNN) which were not sufficiently represented in the training data, or to select samples for DNN retraining. However, computation of the SA metric for a test suite can be prohibitively expensive, as it involves a quadratic number of distance calculations. Hence, we developed and released a performance-optimized, but functionally equivalent, implementation of SA, reducing the evaluation time by up to 97\\%. We also propose refined variants of the SA omputation algorithm, aiming to further increase the evaluation speed. We then performed an empirical study on MNIST, focused on the out-of-distribution detection capabilities of SA, which allowed us to reproduce parts of the results presented when SA was first released. The experiments show that our refined variants are substantially faster than plain SA, while producing comparable outcomes. Our experimental results exposed also an overlooked issue of SA: it can be highly sensitive to the non-determinism associated with the DNN training procedure.",
        "versions": [],
        "rank": 517
    },
    {
        "authors": [
            "Kurnia Muludi",
            "Mohammad Surya Akbar",
            "Dewi Asiah Shofiana",
            "Admi Syarif"
        ],
        "title": "Sentiment Analysis Of Energy Independence Tweets Using Simple Recurrent Neural Network",
        "publication_date": "2021-10-31 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Universitas Gadjah Mada",
        "volume": "",
        "doi": "10.22146/ijccs.66016",
        "urls": [
            "https://web.archive.org/web/20220311110530/https://jurnal.ugm.ac.id/ijccs/article/download/66016/32405"
        ],
        "id": "id4942436125451348779",
        "abstract": "Sentiment analysis is part of computational research that extracts textual data to obtain positive, or negative values related to a topic. In recent research, data are commonly acquired from social media, including Twitter, where users often provide their personal opinion about a particular subject. Energy independence was once a trending topic discussed in Indonesia, as the opinions are diverse, pros and cons, making it interesting to be analyzed. Deep learning is a branch of machine learning consisting of hidden layers of neural networks by applying non-linear transformations and high-level model abstractions in large databases. The recurrent neural network (RNN) is a deep learning method that processes data repeatedly, primarily suitable for handwriting, multi-word data, or voice recognition. This study compares three algorithms: Simple Neural Network, Bernoulli Naive Bayes, and Long Short-Term Memory (LSTM) in sentiment analysis using the energy independence data from Twitter. Based on the results, the Simple Recurrent Neural Network shows the best performance with an accuracy value of 78% compared to Bernoulli Naive Bayes value of 67% and LSTM with an accuracy value of 75%. Keywords\u2014 Sentiment Analysis; Simple RNN; LSTM; Bernoulli Naive Bayes; Energy Independence;",
        "versions": [],
        "rank": 518
    },
    {
        "authors": [
            "Fujimura, H."
        ],
        "title": "Simultaneous gender classification and voice activity detection using deep neural networks",
        "publication_date": "2014-09-14 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.21437/interspeech.2014-291",
        "urls": [
            "http://dx.doi.org/10.21437/interspeech.2014-291"
        ],
        "id": "id1484601743315305294",
        "abstract": "",
        "versions": [],
        "rank": 519
    },
    {
        "authors": [
            "Daniel, I.",
            "Cominola, A."
        ],
        "title": "Physics-Informed Neural Networks to enhance leakage detection in drinking water distribution systems",
        "publication_date": "2023-02-26 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.5194/egusphere-egu23-12186",
        "urls": [
            "http://dx.doi.org/10.5194/egusphere-egu23-12186"
        ],
        "id": "id-4001237889956958745",
        "abstract": "",
        "versions": [],
        "rank": 520
    },
    {
        "authors": [
            "Jahanzaib Malik",
            "Adnan Akhunzada",
            "Iram Bibi",
            "Muhammad Imran",
            "Arslan Musaddiq",
            "Sung Won Kim"
        ],
        "title": "Hybrid Deep Learning: An Efficient Reconnaissance and Surveillance Detection Mechanism in SDN",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Institute of Electrical and Electronics Engineers (IEEE)",
        "volume": "",
        "doi": "10.1109/access.2020.3009849",
        "urls": [
            "https://web.archive.org/web/20210718050334/https://ieeexplore.ieee.org/ielx7/6287639/8948470/09142203.pdf"
        ],
        "id": "id-7495324828865495771",
        "abstract": "Software defined network (SDN) centralized control intelligence and network abstraction aims to facilitate applications, service deployment, programmability, innovation and ease in configuration management of the underlying networks. However, the centralized control intelligence and programmability is primarily a potential target for the evolving cyber threats and attacks to throw the entire network into chaos. The authors propose a control plane-based orchestration for varied sophisticated threats and attacks. The proposed mechanism comprises of a hybrid Cuda-enabled DL-driven architecture that utilizes the predictive power of Long short-term memory (LSTM) and Convolutional Neural Network (CNN) for an efficient and timely detection of multi-vector threats and attacks. A current state of the art dataset CICIDS2017 and standard performance evaluation metrics have been employed to thoroughly evaluate the proposed mechanism. We rigorously compared our proposed technique with our constructed hybrid DL-architectures and current benchmark algorithms. Our analysis shows that the proposed approach outperforms in terms of detection accuracy with a trivial trade-off speed efficiency. We also performed a 10-fold cross validation to explicitly show unbiased results. INDEX TERMS Security, hybrid deep learning model, software defined networks, long short-term memory, convolutional neural network.",
        "versions": [],
        "rank": 521
    },
    {
        "authors": [
            "Raqibul Hasan",
            "Tarek Taha"
        ],
        "title": "A Reconfigurable Low Power High Throughput Architecture for Deep Network Training",
        "publication_date": "2016-03-24 00:52:22+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1603.07400v2",
            "http://arxiv.org/abs/1603.07400v2",
            "http://arxiv.org/pdf/1603.07400v2"
        ],
        "id": "id-5487668576825053555",
        "abstract": "General purpose computing systems are used for a large variety of\napplications. Extensive supports for flexibility in these systems limit their\nenergy efficiencies. Neural networks, including deep networks, are widely used\nfor signal processing and pattern recognition applications. In this paper we\npropose a multicore architecture for deep neural network based processing.\nMemristor crossbars are utilized to provide low power high throughput execution\nof neural networks. The system has both training and recognition (evaluation of\nnew input) capabilities. The proposed system could be used for classification,\ndimensionality reduction, feature extraction, and anomaly detection\napplications. The system level area and power benefits of the specialized\narchitecture is compared with the NVIDIA Telsa K20 GPGPU. Our experimental\nevaluations show that the proposed architecture can provide up to five orders\nof magnitude more energy efficiency over GPGPUs for deep neural network\nprocessing.",
        "versions": [],
        "rank": 522
    },
    {
        "authors": [
            "Gao, X.",
            "Zhang, T."
        ],
        "title": "Loop closure detection for visual SLAM systems using deep neural networks",
        "publication_date": "2015-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/chicc.2015.7260555",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/7225914/7259602/07260555.pdf?arnumber=7260555",
            "http://dx.doi.org/10.1109/chicc.2015.7260555"
        ],
        "id": "id1112781620670047201",
        "abstract": "",
        "versions": [],
        "rank": 523
    },
    {
        "authors": [
            "Alan B. Cannaday II",
            "C. Davis",
            "G. Scott",
            "Blake Ruprecht",
            "Derek T. Anderson"
        ],
        "title": "Broad Area Search and Detection of Surface-to-Air Missile Sites Using Spatial Fusion of Component Object Detections From Deep Neural Networks",
        "publication_date": "2020-03-23 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
        "volume": "13",
        "doi": "10.1109/JSTARS.2020.3015662",
        "urls": [
            "https://www.semanticscholar.org/paper/8ee62eb0a7e55fb2ed3d2143cd567669795090fd"
        ],
        "id": "id-7691593248265968507",
        "abstract": "Here, we demonstrate how deep neural network (DNN) detections of multiple constitutive or component objects that are part of a larger, more complex, and encompassing feature can be spatially fused to improve the search, detection, and retrieval (ranking) of the larger complex feature. First, scores computed from a spatial clustering algorithm are normalized to a reference space so that they are independent of image resolution and DNN input chip size. Then, multiscale DNN detections from various component objects are fused to improve the detection and retrieval of DNN detections of a larger complex feature. We demonstrate the utility of this approach for broad area search and detection of surface-to-air missile (SAM) sites that have a very low occurrence rate (only 16 sites) over a <inline-formula><tex-math notation=\"LaTeX\">$\\sim$</tex-math></inline-formula>90\u2009000 km<sup>2</sup> study area in SE China. The results demonstrate that spatial fusion of multiscale component-object DNN detections can reduce the detection error rate of <italic>SAM Sites</italic> by <inline-formula><tex-math notation=\"LaTeX\">$>$</tex-math></inline-formula>85% while still maintaining a 100% recall. The novel spatial fusion approach demonstrated here can be easily extended to a wide variety of other challenging object search and detection problems in large-scale remote sensing image datasets.",
        "versions": [
            {
                "year": 2020,
                "source": "SupportedSources.ARXIV",
                "title": "Broad Area Search and Detection of Surface-to-Air Missile Sites Using Spatial Fusion of Component Object Detections from Deep Neural Networks",
                "journal": null,
                "urls": [
                    "http://arxiv.org/pdf/2003.10566v3",
                    "http://arxiv.org/abs/2003.10566v3",
                    "http://arxiv.org/pdf/2003.10566v3"
                ],
                "doi": "",
                "publication_date": "2020-03-23 22:10:19+00:00"
            }
        ],
        "rank": 524
    },
    {
        "authors": [
            "Chang, C.",
            "Lin, H."
        ],
        "title": "A Vision-based Lane Detection Technique using Deep Neural Networks and Temporal Information",
        "publication_date": "2022-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.5220/0010973200003191",
        "urls": [
            "http://dx.doi.org/10.5220/0010973200003191"
        ],
        "id": "id4754478628355293838",
        "abstract": "",
        "versions": [],
        "rank": 525
    },
    {
        "authors": [
            "Dr. Fareed Ahmed Jokhio",
            "Dr. Abdul Wahid Memon",
            "Dr. Irfana Memon",
            "Engr. Aisha Jokhio",
            "Prof. Dr. Sulleman Memon"
        ],
        "title": "DDOS Attacks Detection Using Autoencoders",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "University of Sindh",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20210814215952/https://sujo.usindh.edu.pk/index.php/USJICT/article/download/3299/2480"
        ],
        "id": "id8915917176800157564",
        "abstract": "Computer networks have several issues such as insertion attacks, denial of service attacks, traffic jamming, and unauthorized access. Due to these issues network security is most important. In a network, Distributed Denial of Service (DDoS) attacks may cause significant degradation of the performance of any application. It is very challenging to detect such attacks and undetected attacks are considered as a threat. This paper describes comparative analysis of Denial of Service attacks detection using Feed Forward Neural Networks and Autoencoders which are machine learning based approaches and are usually used for feature learning.",
        "versions": [],
        "rank": 526
    },
    {
        "authors": [
            "Sarmad Shafique",
            "Samabia Tehsin"
        ],
        "title": "Acute Lymphoblastic Leukemia Detection and Classification of Its Subtypes Using Pretrained Deep Convolutional Neural Networks",
        "publication_date": "2018-09-27 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Technology in Cancer Research & Treatment",
        "volume": "17",
        "doi": "10.1177/1533033818802789",
        "urls": [
            "https://www.semanticscholar.org/paper/80ae9c9141ab74e512abf863cac14eb23a0b1f9c"
        ],
        "id": "id-278060944479313233",
        "abstract": "Leukemia is a fatal disease of white blood cells which affects the blood and bone marrow in human body. We deployed deep convolutional neural network for automated detection of acute lymphoblastic leukemia and classification of its subtypes into 4 classes, that is, L1, L2, L3, and Normal which were mostly neglected in previous literature. In contrary to the training from scratch, we deployed pretrained AlexNet which was fine-tuned on our data set. Last layers of the pretrained network were replaced with new layers which can classify the input images into 4 classes. To reduce overtraining, data augmentation technique was used. We also compared the data sets with different color models to check the performance over different color images. For acute lymphoblastic leukemia detection, we achieved a sensitivity of 100%, specificity of 98.11%, and accuracy of 99.50%; and for acute lymphoblastic leukemia subtype classification the sensitivity was 96.74%, specificity was 99.03%, and accuracy was 96.06%. Unlike the standard methods, our proposed method was able to achieve high accuracy without any need of microscopic image segmentation.",
        "versions": [],
        "rank": 527
    },
    {
        "authors": [
            "S. Aroyehun",
            "Alexander Gelbukh"
        ],
        "title": "Aggression Detection in Social Media: Using Deep Neural Networks, Data Augmentation, and Pseudo Labeling",
        "publication_date": "2018-08-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://www.semanticscholar.org/paper/1644a97152d18483e64b1bf644841edeebb35f90"
        ],
        "id": "id-7908098897533375148",
        "abstract": "With the advent of the read-write web which facilitates social interactions in online spaces, the rise of anti-social behaviour in online spaces has attracted the attention of researchers. In this paper, we address the challenge of automatically identifying aggression in social media posts. Our team, saroyehun, participated in the English track of the Aggression Detection in Social Media Shared Task. On this task, we investigate the efficacy of deep neural network models of varying complexity. Our results reveal that deep neural network models require more data points to do better than an NBSVM linear baseline based on character n-grams. Our improved deep neural network models were trained on augmented data and pseudo labeled examples. Our LSTM classifier receives a weighted macro-F1 score of 0.6425 to rank first overall on the Facebook subtask of the shared task. On the social media sub-task, our CNN-LSTM model records a weighted macro-F1 score of 0.5920 to place third overall.",
        "versions": [],
        "rank": 528
    },
    {
        "authors": [
            "Tsukada, R.",
            "Zou, L.",
            "Iba, H."
        ],
        "title": "Evolving Deep Neural Networks for X-ray Based Detection of Dangerous Objects",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-981-15-3685-4_12",
        "urls": [
            "http://link.springer.com/content/pdf/10.1007/978-981-15-3685-4_12",
            "http://dx.doi.org/10.1007/978-981-15-3685-4_12"
        ],
        "id": "id-3671319683281813194",
        "abstract": "",
        "versions": [
            {
                "year": 0,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Evolving Deep Neural Networks for X-ray Based Detection of Dangerous Objects",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/466362cd3d4258206cd432c0ae2969a2bc631bc3"
                ],
                "doi": "10.1007/978-981-15-3685-4_12",
                "publication_date": "None"
            }
        ],
        "rank": 529
    },
    {
        "authors": [
            "M. J. Shafiee",
            "P. Siva",
            "C. Scharfenberger",
            "P. Fieguth",
            "A. Wong"
        ],
        "title": "NeRD: a Neural Response Divergence Approach to Visual Salience Detection",
        "publication_date": "2016-02-04 16:20:26+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1602.01728v1",
            "http://arxiv.org/abs/1602.01728v1",
            "http://arxiv.org/pdf/1602.01728v1"
        ],
        "id": "id-5190577537757353555",
        "abstract": "In this paper, a novel approach to visual salience detection via Neural\nResponse Divergence (NeRD) is proposed, where synaptic portions of deep neural\nnetworks, previously trained for complex object recognition, are leveraged to\ncompute low level cues that can be used to compute image region\ndistinctiveness. Based on this concept , an efficient visual salience detection\nframework is proposed using deep convolutional StochasticNets. Experimental\nresults using CSSD and MSRA10k natural image datasets show that the proposed\nNeRD approach can achieve improved performance when compared to\nstate-of-the-art image saliency approaches, while the attaining low\ncomputational complexity necessary for near-real-time computer vision\napplications.",
        "versions": [],
        "rank": 530
    },
    {
        "authors": [
            "Junyoung Park",
            "Dong In Kim",
            "Byoung-Han Choi",
            "Woochul Kang",
            "H. Kwon"
        ],
        "title": "Classification and Morphological Analysis of Vector Mosquitoes using Deep Convolutional Neural Networks",
        "publication_date": "2020-01-23 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Scientific Reports",
        "volume": "10",
        "doi": "10.1038/s41598-020-57875-1",
        "urls": [
            "https://www.semanticscholar.org/paper/449167b2a2d0c2dfd570ef3e4218a8a97aa544ad"
        ],
        "id": "id1185911500722764488",
        "abstract": null,
        "versions": [],
        "rank": 531
    },
    {
        "authors": [
            "Neha Yadav",
            "Sagar Pande",
            "Aditya Khamparia",
            "Deepak Gupta",
            "Carles Gomez"
        ],
        "title": "Intrusion Detection System on IoT with 5G Network Using Deep Learning",
        "publication_date": "2022-03-10 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Hindawi Limited",
        "volume": "",
        "doi": "10.1155/2022/9304689",
        "urls": [
            "https://web.archive.org/web/20220318062801/https://downloads.hindawi.com/journals/wcmc/2022/9304689.pdf"
        ],
        "id": "id-5762421919423874557",
        "abstract": "The Internet of Things (IoT) cyberattacks of fully integrated servers, applications, and communications networks are increasing at exponential speed. As problems caused by the Internet of Things network remain undetected for longer periods, the efficiency of sensitive devices harms end users, increases cyber threats and identity misuses, increases costs, and affects revenue. For productive safety and security, Internet of Things interface assaults must be observed nearly in real time. In this paper, a smart intrusion detection system suited to detect Internet of Things-based attacks is implemented. In particular, to detect malicious Internet of Things network traffic, a deep learning algorithm has been used. The identity solution ensures the security of operation and supports the Internet of Things connectivity protocols to interoperate. An intrusion detection system (IDS) is one of the popular types of network security technology that is used to secure the network. According to our experimental results, the proposed architecture for intrusion detection will easily recognize real global intruders. The use of a neural network to detect attacks works exceptionally well. In addition, there is an increasing focus on providing user-centric cybersecurity solutions, which necessitate the collection, processing, and analysis of massive amounts of data traffic and network connections in 5G networks. After testing, the autoencoder model, which effectively reduces detection time as well as effectively improves detection precision, has outperformed. Using the proposed technique, 99.76% of accuracy was achieved.",
        "versions": [],
        "rank": 532
    },
    {
        "authors": [
            "M. Rahmani",
            "Abdelmalek Amine",
            "Jos\u00e9 Eduardo Fernandes"
        ],
        "title": "Multi-stage Genetic Algorithm and Deep Neural Network for Robot Execution Failure Detection",
        "publication_date": "2021-08-11 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Neural Processing Letters",
        "volume": "53",
        "doi": "10.1007/s11063-021-10610-x",
        "urls": [
            "https://www.semanticscholar.org/paper/12c9c761b25752dad046a905f72457c9e5a9409b"
        ],
        "id": "id-6934764664554323638",
        "abstract": null,
        "versions": [],
        "rank": 533
    },
    {
        "authors": [
            "Lima, Jefferson L. P.",
            "Mac\u00eado, David",
            "Zanchettin, Cleber"
        ],
        "title": "Heartbeat Anomaly Detection using Adversarial Oversampling",
        "publication_date": "2019-01-28 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ijcnn.2019.8852242",
        "urls": [
            "http://arxiv.org/abs/1901.09972"
        ],
        "id": "id-786253064441821987",
        "abstract": "Cardiovascular diseases are one of the most common causes of death in the\nworld. Prevention, knowledge of previous cases in the family, and early\ndetection is the best strategy to reduce this fact. Different machine learning\napproaches to automatic diagnostic are being proposed to this task. As in most\nhealth problems, the imbalance between examples and classes is predominant in\nthis problem and affects the performance of the automated solution. In this\npaper, we address the classification of heartbeats images in different\ncardiovascular diseases. We propose a two-dimensional Convolutional Neural\nNetwork for classification after using a InfoGAN architecture for generating\nsynthetic images to unbalanced classes. We call this proposal Adversarial\nOversampling and compare it with the classical oversampling methods as SMOTE,\nADASYN, and RandomOversampling. The results show that the proposed approach\nimproves the classifier performance for the minority classes without harming\nthe performance in the balanced classes",
        "versions": [],
        "rank": 534
    },
    {
        "authors": [
            "S. U\u011fuz",
            "N. Uysal"
        ],
        "title": "Classification of olive leaf diseases using deep convolutional neural networks",
        "publication_date": "2020-08-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Neural Computing and Applications",
        "volume": "33",
        "doi": "10.1007/s00521-020-05235-5",
        "urls": [
            "https://www.semanticscholar.org/paper/3dc167724a013bd2eaedbcad605dec2c99734b80"
        ],
        "id": "id8963827928564704249",
        "abstract": null,
        "versions": [],
        "rank": 535
    },
    {
        "authors": [
            "Ian Marius Peters",
            "Andreas Maier",
            "Christoph Brabec",
            "Jens Hauch",
            "Tobias Pickel",
            "Claudia Buerhop-Lutz",
            "Mathis Hoffmann",
            "Lukas Bommes"
        ],
        "title": "Anomaly Detection in IR Images of PV Modules using Supervised Contrastive Learning",
        "publication_date": "2021-12-06 00:00:00",
        "source": "SupportedSources.PAPERS_WITH_CODE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://arxiv.org/pdf/2112.02922v1.pdf",
            "https://github.com/LukasBommes/PV-Mapper"
        ],
        "id": "id-8227545467362211143",
        "abstract": "Increasing deployment of photovoltaic (PV) plants requires methods for automatic detection of faulty PV modules in modalities, such as infrared (IR) images. Recently, deep learning has become popular for this. However, related works typically sample train and test data from the same distribution ignoring the presence of domain shift between data of different PV plants. Instead, we frame fault detection as more realistic unsupervised domain adaptation problem where we train on labelled data of one source PV plant and make predictions on another target plant. We train a ResNet-34 convolutional neural network with a supervised contrastive loss, on top of which we employ a k-nearest neighbor classifier to detect anomalies. Our method achieves a satisfactory area under the receiver operating characteristic (AUROC) of 73.3 % to 96.6 % on nine combinations of four source and target datasets with 2.92 million IR images of which 8.5 % are anomalous. It even outperforms a binary cross-entropy classifier in some cases. With a fixed decision threshold this results in 79.4 % and 77.1 % correctly classified normal and anomalous images, respectively. Most misclassified anomalies are of low severity, such as hot diodes and small hot spots. Our method is insensitive to hyperparameter settings, converges quickly and reliably detects unknown types of anomalies making it well suited for practice. Possible uses are in automatic PV plant inspection systems or to streamline manual labelling of IR datasets by filtering out normal images. Furthermore, our work serves the community with a more realistic view on PV module fault detection using unsupervised domain adaptation to develop more performant methods with favorable generalization capabilities.",
        "versions": [],
        "rank": 536
    },
    {
        "authors": [
            "Arisoy Ebru",
            "Fei Geli",
            "Kakhki Arash Molavi",
            "Kim Gyuwan",
            "Lee Kyumin",
            "Lee Kyumin",
            "Li Fangtao",
            "Maas Andrew L.",
            "Maxwell Harper F.",
            "Mukherjee Arjun",
            "Sutskever Ilya"
        ],
        "title": "Automated Crowdturfing Attacks and Defenses in Online Review Systems",
        "publication_date": "2017-09-07 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1145/3133956.3133990",
        "urls": [
            "http://arxiv.org/abs/1708.08151"
        ],
        "id": "id-765406648293695844",
        "abstract": "Malicious crowdsourcing forums are gaining traction as sources of spreading\nmisinformation online, but are limited by the costs of hiring and managing\nhuman workers. In this paper, we identify a new class of attacks that leverage\ndeep learning language models (Recurrent Neural Networks or RNNs) to automate\nthe generation of fake online reviews for products and services. Not only are\nthese attacks cheap and therefore more scalable, but they can control rate of\ncontent output to eliminate the signature burstiness that makes crowdsourced\ncampaigns easy to detect.\n  Using Yelp reviews as an example platform, we show how a two phased review\ngeneration and customization attack can produce reviews that are\nindistinguishable by state-of-the-art statistical detectors. We conduct a\nsurvey-based user study to show these reviews not only evade human detection,\nbut also score high on \"usefulness\" metrics by users. Finally, we develop novel\nautomated defenses against these attacks, by leveraging the lossy\ntransformation introduced by the RNN training and generation cycle. We consider\ncountermeasures against our mechanisms, show that they produce unattractive\ncost-benefit tradeoffs for attackers, and that they can be further curtailed by\nsimple constraints imposed by online service providers",
        "versions": [],
        "rank": 537
    },
    {
        "authors": [
            "Yutong Sun",
            "Mohit Prabhushankar",
            "Ghassan AlRegib"
        ],
        "title": "Implicit Saliency in Deep Neural Networks",
        "publication_date": "2020-08-04 23:14:24+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2008.01874v1",
            "http://arxiv.org/abs/2008.01874v1",
            "http://arxiv.org/pdf/2008.01874v1"
        ],
        "id": "id8985487383580244202",
        "abstract": "In this paper, we show that existing recognition and localization deep\narchitectures, that have not been exposed to eye tracking data or any saliency\ndatasets, are capable of predicting the human visual saliency. We term this as\nimplicit saliency in deep neural networks. We calculate this implicit saliency\nusing expectancy-mismatch hypothesis in an unsupervised fashion. Our\nexperiments show that extracting saliency in this fashion provides comparable\nperformance when measured against the state-of-art supervised algorithms.\nAdditionally, the robustness outperforms those algorithms when we add large\nnoise to the input images. Also, we show that semantic features contribute more\nthan low-level features for human visual saliency detection.",
        "versions": [],
        "rank": 538
    },
    {
        "authors": [
            "Yaser AbdulAali Jasim"
        ],
        "title": "High-Performance Deep learning to Detection and Tracking Tomato Plant Leaf Predict Disease and Expert Systems",
        "publication_date": "2021-02-28 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Ediciones Universidad de Salamanca",
        "volume": "",
        "doi": "10.14201/adcaij202110297122",
        "urls": [
            "https://web.archive.org/web/20210722023658/https://revistas.usal.es/index.php/2255-2863/article/download/ADCAIJ202110297122/26172"
        ],
        "id": "id1100163407318111890",
        "abstract": "Nowadays, technology and computer science are rapidly developing many tools and algorithms, especially in the field of artificial intelligence. Machine learning is involved in the development of new methodologies and models that have become a novel machine learning area of applications for artificial intelligence. In addition to the architectures of conventional neural network methodologies, deep learning refers to the use of artificial neural network architectures which include multiple processing layers. In this paper, models of the Convolutional neural network were designed to detect (diagnose) plant disorders by applying samples of healthy and unhealthy plant images analyzed by means of methods of deep learning. The models were trained using an open data set containing (18,000) images of ten different plants, including healthy plants. Several model architectures have been trained to achieve the best performance of (97 percent) when the respectively [plant, disease] paired are detected. This is a very useful information or early warning technique and a method that can be further improved with the substantially high-performance rate to support an automated plant disease detection system to work in actual farm conditions.",
        "versions": [],
        "rank": 539
    },
    {
        "authors": [
            "Abouelnaga, Yehya",
            "Eraqi, Hesham M.",
            "Moustafa, Mohamed N.",
            "Saad, Mohamed H."
        ],
        "title": "Driver Distraction Identification with an Ensemble of Convolutional  Neural Networks",
        "publication_date": "2019-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "Journal of Advanced Transportation",
        "volume": "",
        "doi": "10.1155/2019/4125865",
        "urls": [
            "http://arxiv.org/abs/1901.09097"
        ],
        "id": "id-5024642779029286567",
        "abstract": "The World Health Organization (WHO) reported 1.25 million deaths yearly due\nto road traffic accidents worldwide and the number has been continuously\nincreasing over the last few years. Nearly fifth of these accidents are caused\nby distracted drivers. Existing work of distracted driver detection is\nconcerned with a small set of distractions (mostly, cell phone usage).\nUnreliable ad-hoc methods are often used.In this paper, we present the first\npublicly available dataset for driver distraction identification with more\ndistraction postures than existing alternatives. In addition, we propose a\nreliable deep learning-based solution that achieves a 90% accuracy. The system\nconsists of a genetically-weighted ensemble of convolutional neural networks,\nwe show that a weighted ensemble of classifiers using a genetic algorithm\nyields in a better classification confidence. We also study the effect of\ndifferent visual elements in distraction detection by means of face and hand\nlocalizations, and skin segmentation. Finally, we present a thinned version of\nour ensemble that could achieve 84.64% classification accuracy and operate in a\nreal-time environment.Comment: arXiv admin note: substantial text overlap with arXiv:1706.0949",
        "versions": [],
        "rank": 540
    },
    {
        "authors": [
            "Hui Li",
            "Peng Wang",
            "Chunhua Shen"
        ],
        "title": "Toward End-to-End Car License Plate Detection and Recognition With Deep Neural Networks",
        "publication_date": "2017-09-26 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "IEEE Transactions on Intelligent Transportation Systems",
        "volume": "20",
        "doi": "10.1109/TITS.2018.2847291",
        "urls": [
            "https://www.semanticscholar.org/paper/2882441c68580a8d24bac61ae03bcfd8847b2fb7"
        ],
        "id": "id3711604826616470074",
        "abstract": "In this paper, we tackle the problem of car license plate detection and recognition in natural scene images. We propose a unified deep neural network, which can localize license plates and recognize the letters simultaneously in a single forward pass. The whole network can be trained end-to-end. In contrast to existing approaches which take license plate detection and recognition as two separate tasks and settle them step by step, our method jointly solves these two tasks by a single network. It not only avoids intermediate error accumulation but also accelerates the processing speed. For performance evaluation, four data sets including images captured from various scenes under different conditions are tested. Extensive experiments show the effectiveness and the efficiency of our proposed approach.",
        "versions": [],
        "rank": 541
    },
    {
        "authors": [
            "Cordes, James",
            "Foster, Griffin",
            "Gajjar, Vishal",
            "Law, Casey",
            "Siemion, Andrew",
            "Wang, Yu",
            "Zhang, Yunfan Gerry"
        ],
        "title": "Fast Radio Burst 121102 Pulse Detection and Periodicity: A Machine  Learning Approach",
        "publication_date": "2018-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.3847/1538-4357/aadf31",
        "urls": [
            "https://core.ac.uk/download/200776671.pdf"
        ],
        "id": "id-3021165995813823410",
        "abstract": "We report the detection of 72 new pulses from the repeating fast radio burst\nFRB 121102 in Breakthrough Listen C-band (4-8 GHz) observations at the Green\nBank Telescope. The new pulses were found with a convolutional neural network\nin data taken on August 26, 2017, where 21 bursts have been previously\ndetected. Our technique combines neural network detection with dedispersion\nverification. For the current application we demonstrate its advantage over a\ntraditional brute-force dedis- persion algorithm in terms of higher\nsensitivity, lower false positive rates, and faster computational speed.\nTogether with the 21 previously reported pulses, this observa- tion marks the\nhighest number of FRB 121102 pulses from a single observation, total- ing 93\npulses in five hours, including 45 pulses within the first 30 minutes. The\nnumber of data points reveal trends in pulse fluence, pulse detection rate, and\npulse frequency structure. We introduce a new periodicity search technique,\nbased on the Rayleigh test, to analyze the time of arrivals, with which we\nexclude with 99% confidence pe- riodicity in time of arrivals with periods\nlarger than 5.1 times the model-dependent time-stamp uncertainty. In\nparticular, we rule out constant periods >10 ms in the barycentric arrival\ntimes, though intrinsic periodicity in the time of emission remains plausible.Comment: 32 pages, 10 figure",
        "versions": [],
        "rank": 542
    },
    {
        "authors": [],
        "title": "Role of Deep Recurrent Neural Networks in Natural Language Processing",
        "publication_date": "2019-11-02 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Blue Eyes Intelligence Engineering and Sciences Engineering and Sciences Publication - BEIESP",
        "volume": "",
        "doi": "10.35940/ijrte.b1597.0982s1119",
        "urls": [
            "https://web.archive.org/web/20200211180219/https://www.ijrte.org/wp-content/uploads/papers/v8i2S11/B15970982S1119.pdf"
        ],
        "id": "id-493537227343632293",
        "abstract": "Deep learning methods are used to study hierarchical representations of data. Natural Language Processing is a group of computing methodologies used for analyzing and illustrating of Natural Language (NL). Natural Language is used to collect and present information in numerous fields. NLP can be to extract and process information in human language automatically. This paper is to highlight vital research contributions in text analysis, classification and extracting useful information using NLP",
        "versions": [],
        "rank": 543
    },
    {
        "authors": [
            "Akbar Telikani",
            "Amir H. Gandomi"
        ],
        "title": "Cost-sensitive stacked auto-encoders for intrusion detection in the Internet of Things",
        "publication_date": "2021-06-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Internet of things",
        "volume": "14",
        "doi": "10.1016/j.iot.2019.100122",
        "urls": [
            "https://openalex.org/W2978153077",
            "https://doi.org/10.1016/j.iot.2019.100122",
            "https://opus.lib.uts.edu.au/bitstream/10453/144062/2/1-s2.0-S2542660519302033-main.pdf"
        ],
        "id": "id6732352146104872469",
        "abstract": "",
        "versions": [],
        "rank": 544
    },
    {
        "authors": [
            "Ding, Y.",
            "Chen, S.",
            "Xu, J."
        ],
        "title": "Application of Deep Belief Networks for opcode based malware detection",
        "publication_date": "2016-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ijcnn.2016.7727705",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/7593175/7726591/07727705.pdf?arnumber=7727705",
            "http://dx.doi.org/10.1109/ijcnn.2016.7727705"
        ],
        "id": "id3481969405813157477",
        "abstract": "",
        "versions": [],
        "rank": 545
    },
    {
        "authors": [
            "Ramachandra, R.",
            "Raja, K.",
            "Venkatesh, S.",
            "Busch, C."
        ],
        "title": "Fingervein Presentation Attack Detection Using Transferable Features from Deep Convolution Neural Networks",
        "publication_date": "2018-03-05 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1201/b22524-12",
        "urls": [
            "http://dx.doi.org/10.1201/b22524-12"
        ],
        "id": "id-6050596406248862093",
        "abstract": "",
        "versions": [],
        "rank": 546
    },
    {
        "authors": [
            "Haonan Guo",
            "Shenghong Li",
            "Kaiyue Qi",
            "Ying Guo",
            "Zhengwu Xu"
        ],
        "title": "Learning Automata Based Competition Scheme to Train Deep Neural Networks",
        "publication_date": "2020-04-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "IEEE Transactions on Emerging Topics in Computational Intelligence",
        "volume": "4",
        "doi": "10.1109/TETCI.2018.2868474",
        "urls": [
            "https://www.semanticscholar.org/paper/93b80dc6b026a2e68e36f28530d829cae4b47b03"
        ],
        "id": "id7660383642091653966",
        "abstract": "Deep neural network has been one of the most powerful models in the field of machine learning, which has acquired state-of-the-art results in many tasks including image classification, object detection, text recognition, and so on. There have been many tricks to improve the training and generalization performance of deep neural network, such as dropout, ReLU, batch normalization, etc. In this paper, we proposed a new basic element to form deep neural networks, called learning automata competition unit (LCU). The LCU includes a group of general neural units and learning automata. The adopted learning automata are reinforcement learning methods, which can learn the optimal action through continuously interacting with a stochastic environment. Since the learning automata has powerful policy-making ability for both stochastic and non-stationary environment, the proposed LCU can facilitate competition in a group of neural units and gradually select the better trained neural units during training. The selected neural units through competition can make the training process more efficient, which can simultaneously get better training and generalization performance. The experiments on MNIST, CIFAR-10, and the Reuters newswire topic classification dataset show the performance of our method for both deep fully connected neural network and convolutional neural network.",
        "versions": [],
        "rank": 547
    },
    {
        "authors": [
            "Dorothy Chang"
        ],
        "title": "CS591 Report: Application of siamesa network in 2D transformation",
        "publication_date": "2017-06-29 07:13:42+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1706.09598v1",
            "http://arxiv.org/abs/1706.09598v1",
            "http://arxiv.org/pdf/1706.09598v1"
        ],
        "id": "id3618558544305767387",
        "abstract": "Deep learning has been extensively used various aspects of computer vision\narea. Deep learning separate itself from traditional neural network by having a\nmuch deeper and complicated network layers in its network structures.\nTraditionally, deep neural network is abundantly used in computer vision tasks\nincluding classification and detection and has achieve remarkable success and\nset up a new state of the art results in these fields. Instead of using neural\nnetwork for vision recognition and detection. I will show the ability of neural\nnetwork to do image registration, synthesis of images and image retrieval in\nthis report.",
        "versions": [],
        "rank": 548
    },
    {
        "authors": [
            "Hajiarbabi, M.",
            "Agah, A."
        ],
        "title": "Human Skin Detection in Color Images Using Deep Learning",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.4018/978-1-7998-0414-7.ch073",
        "urls": [
            "https://www.igi-global.com/viewtitle.aspx?TitleId=237936",
            "http://dx.doi.org/10.4018/978-1-7998-0414-7.ch073"
        ],
        "id": "id5164494120085718518",
        "abstract": "",
        "versions": [],
        "rank": 549
    },
    {
        "authors": [
            "Aminuddeen Abubakar",
            "Ahmed Baita Garko"
        ],
        "title": "A Predictive Model for Network Intrusion Detection System Using Deep Neural Network",
        "publication_date": "2022-01-10 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "African Journals Online (AJOL)",
        "volume": "",
        "doi": "10.4314/dujopas.v7i3a.12",
        "urls": [
            "https://web.archive.org/web/20220120095834/https://www.ajol.info/index.php/dujopas/article/download/219859/207481"
        ],
        "id": "id6148807624340249413",
        "abstract": "Network Intrusion Detection System (NIDS) is an important part of Cyber safety and security. It plays a key role in all networked ICT systems in detecting rampant attacks such as Denial of Service (DoS) and ransom ware attacks. Existing methods are inadequate in terms of accuracy detection of attacks. However, the requirement for high accuracy detection of attacks using Deep Neural Network requires expensive computing resources which in turn make most organisations, and individuals shy away from it. This study therefore aims at designing a predictive model for network intrusion detection using deep neural networks with very limited computing resources. The study adopted Cross Industry Standard Process for Data Mining (CRISP-DM) as one of the formal methodologies and python was used for both testing and training, using crucial parameters such as the learning rate, number of epochs, neurons and hidden layers which greatly determined the accuracy level of the DNN algorithm. These parameters were experimented with values that are lesser compared to previous studies, training and evaluation were also done on the KDD99 data-set. The varying values of accuracy obtained from this study on four models with different numbers of layers of 50-epochs and learning rate of 0.01 achieved competitive results in comparison with the previous research of 100-1000 epochs and learning rate of 0.1. Therefore, the model with two layers attained same accuracy of 0.955 as the model with three layers from the previous study out of the four models tested in this study. Also, the models with three and four layers in this study attained an accuracy of 0.956, which is 0.001greater than the previous study's models. Keywords: Network-Based IDS, Host-Based IDS, Deep Neural Network, Denial of Service, Knowledge Discovery Dataset",
        "versions": [],
        "rank": 550
    },
    {
        "authors": [],
        "title": "Detection of Melanoma Skin Cancer with Deep Neural Networks",
        "publication_date": "2019-04-20 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.33140/mcr.04.04.05",
        "urls": [
            "http://dx.doi.org/10.33140/mcr.04.04.05"
        ],
        "id": "id-8964684554279074403",
        "abstract": "",
        "versions": [],
        "rank": 551
    },
    {
        "authors": [
            "Sajila D. Wickramaratne",
            "Md Shaad Mahmud"
        ],
        "title": "Automatic Detection of Respiratory Effort Related Arousals With Deep Neural Networks From Polysomnographic Recordings",
        "publication_date": "2020-07-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/EMBC44109.2020.9176413",
        "urls": [
            "https://www.semanticscholar.org/paper/67bea5b26a0278e73128bdc95160e692e8081116"
        ],
        "id": "id-5844343208883694738",
        "abstract": "Sleep disorders have become more common due to the modern lifestyle and stress. The most severe case of sleep disorders called apnea is characterized by a complete breaking block, leading to awakening and subsequent sleep disturbances. The automatic detection of sleep arousals is still challenging. In this paper, a novel method is presented to detect non-apnea sources of arousals during sleep using Polysomnography(PSG) recordings. After the preprocessing, a sequence-to-sequence deep neural network (DNNs) consisting of a series of Bidirectional long short-term memory (Bi-LSTM) layer, and fully connected layers were trained to classify samples in the segments. Initially, three different models were prepared for different datasets. Finally, obtaining the classification result through an ensemble model consisting of the three trained models. The result shows that the area under the receiver precision-recall curve (AUPRC) is 0.59 for the test dataset exceeding the performance of the classifiers in the existing literature.Clinical relevance\u2014 Analyzing Polysomnographic recordings is a time consuming a critical process yet to identify sleep disorders. These recordings span several hours and contain different data streams that include EEG, EMG, etc. This paper proposes a system that can automatically detect respiratory effort-related arousals using a deep neural network from Polysomnographic Recordings. By automating this process with a machine learning-based solution that can eliminate the manual process while facilitating further improvements of the system with future data.",
        "versions": [],
        "rank": 552
    },
    {
        "authors": [
            "Zahra Ghodsi",
            "Tianyu Gu",
            "Siddharth Garg"
        ],
        "title": "SafetyNets: Verifiable Execution of Deep Neural Networks on an Untrusted Cloud",
        "publication_date": "2017-06-30 16:47:16+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": "Advances in Neural Information Processing Systems 2017",
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1706.10268v1",
            "http://arxiv.org/abs/1706.10268v1",
            "http://arxiv.org/pdf/1706.10268v1"
        ],
        "id": "id4665534889665064563",
        "abstract": "Inference using deep neural networks is often outsourced to the cloud since\nit is a computationally demanding task. However, this raises a fundamental\nissue of trust. How can a client be sure that the cloud has performed inference\ncorrectly? A lazy cloud provider might use a simpler but less accurate model to\nreduce its own computational load, or worse, maliciously modify the inference\nresults sent to the client. We propose SafetyNets, a framework that enables an\nuntrusted server (the cloud) to provide a client with a short mathematical\nproof of the correctness of inference tasks that they perform on behalf of the\nclient. Specifically, SafetyNets develops and implements a specialized\ninteractive proof (IP) protocol for verifiable execution of a class of deep\nneural networks, i.e., those that can be represented as arithmetic circuits.\nOur empirical results on three- and four-layer deep neural networks demonstrate\nthe run-time costs of SafetyNets for both the client and server are low.\nSafetyNets detects any incorrect computations of the neural network by the\nuntrusted server with high probability, while achieving state-of-the-art\naccuracy on the MNIST digit recognition (99.4%) and TIMIT speech recognition\ntasks (75.22%).",
        "versions": [],
        "rank": 553
    },
    {
        "authors": [
            "Sabeen Ahmed",
            "Dimah Dera",
            "Saud Ul Hassan",
            "N. Bouaynaya",
            "G. Rasool"
        ],
        "title": "Failure Detection in Deep Neural Networks for Medical Imaging",
        "publication_date": "2022-07-22 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Frontiers in Medical Technology",
        "volume": "4",
        "doi": "10.3389/fmedt.2022.919046",
        "urls": [
            "https://www.semanticscholar.org/paper/0b505dac462d6233dacbcc1eda5e873c8c06f2af"
        ],
        "id": "id2341146196303591331",
        "abstract": "Deep neural networks (DNNs) have started to find their role in the modern healthcare system. DNNs are being developed for diagnosis, prognosis, treatment planning, and outcome prediction for various diseases. With the increasing number of applications of DNNs in modern healthcare, their trustworthiness and reliability are becoming increasingly important. An essential aspect of trustworthiness is detecting the performance degradation and failure of deployed DNNs in medical settings. The softmax output values produced by DNNs are not a calibrated measure of model confidence. Softmax probability numbers are generally higher than the actual model confidence. The model confidence-accuracy gap further increases for wrong predictions and noisy inputs. We employ recently proposed Bayesian deep neural networks (BDNNs) to learn uncertainty in the model parameters. These models simultaneously output the predictions and a measure of confidence in the predictions. By testing these models under various noisy conditions, we show that the (learned) predictive confidence is well calibrated. We use these reliable confidence values for monitoring performance degradation and failure detection in DNNs. We propose two different failure detection methods. In the first method, we define a fixed threshold value based on the behavior of the predictive confidence with changing signal-to-noise ratio (SNR) of the test dataset. The second method learns the threshold value with a neural network. The proposed failure detection mechanisms seamlessly abstain from making decisions when the confidence of the BDNN is below the defined threshold and hold the decision for manual review. Resultantly, the accuracy of the models improves on the unseen test samples. We tested our proposed approach on three medical imaging datasets: PathMNIST, DermaMNIST, and OrganAMNIST, under different levels and types of noise. An increase in the noise of the test images increases the number of abstained samples. BDNNs are inherently robust and show more than 10% accuracy improvement with the proposed failure detection methods. The increased number of abstained samples or an abrupt increase in the predictive variance indicates model performance degradation or possible failure. Our work has the potential to improve the trustworthiness of DNNs and enhance user confidence in the model predictions.",
        "versions": [],
        "rank": 554
    },
    {
        "authors": [
            "Baroffio, Luca",
            "Bondi, Luca",
            "Pau, Danilo",
            "Plebani, Emanuele",
            "Tome', Denis",
            "Tubaro, Stefano"
        ],
        "title": "Reduced Memory Region Based Deep Convolutional Neural Network Detection",
        "publication_date": "2016-09-08 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/icce-berlin.2016.7684706",
        "urls": [
            "http://arxiv.org/abs/1609.02500"
        ],
        "id": "id807181238209124029",
        "abstract": "Accurate pedestrian detection has a primary role in automotive safety: for\nexample, by issuing warnings to the driver or acting actively on car's brakes,\nit helps decreasing the probability of injuries and human fatalities. In order\nto achieve very high accuracy, recent pedestrian detectors have been based on\nConvolutional Neural Networks (CNN). Unfortunately, such approaches require\nvast amounts of computational power and memory, preventing efficient\nimplementations on embedded systems. This work proposes a CNN-based detector,\nadapting a general-purpose convolutional network to the task at hand. By\nthoroughly analyzing and optimizing each step of the detection pipeline, we\ndevelop an architecture that outperforms methods based on traditional image\nfeatures and achieves an accuracy close to the state-of-the-art while having\nlow computational complexity. Furthermore, the model is compressed in order to\nfit the tight constrains of low power devices with a limited amount of embedded\nmemory available. This paper makes two main contributions: (1) it proves that a\nregion based deep neural network can be finely tuned to achieve adequate\naccuracy for pedestrian detection (2) it achieves a very low memory usage\nwithout reducing detection accuracy on the Caltech Pedestrian dataset.Comment: IEEE 2016 ICCE-Berli",
        "versions": [],
        "rank": 555
    },
    {
        "authors": [
            "Chen, Kwang-Cheng",
            "Hanzo, Lajos",
            "Jiang, Chunxiao",
            "Ren, Yong",
            "Wang, Jingjing",
            "Zhang, Haijun"
        ],
        "title": "Thirty Years of Machine Learning: The Road to Pareto-Optimal Wireless  Networks",
        "publication_date": "2019-01-13 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/comst.2020.2965856",
        "urls": [
            "http://arxiv.org/abs/1902.01946"
        ],
        "id": "id-6106926139584334049",
        "abstract": "Future wireless networks have a substantial potential in terms of supporting\na broad range of complex compelling applications both in military and civilian\nfields, where the users are able to enjoy high-rate, low-latency, low-cost and\nreliable information services. Achieving this ambitious goal requires new radio\ntechniques for adaptive learning and intelligent decision making because of the\ncomplex heterogeneous nature of the network structures and wireless services.\nMachine learning (ML) algorithms have great success in supporting big data\nanalytics, efficient parameter estimation and interactive decision making.\nHence, in this article, we review the thirty-year history of ML by elaborating\non supervised learning, unsupervised learning, reinforcement learning and deep\nlearning. Furthermore, we investigate their employment in the compelling\napplications of wireless networks, including heterogeneous networks (HetNets),\ncognitive radios (CR), Internet of things (IoT), machine to machine networks\n(M2M), and so on. This article aims for assisting the readers in clarifying the\nmotivation and methodology of the various ML algorithms, so as to invoke them\nfor hitherto unexplored services as well as scenarios of future wireless\nnetworks.Comment: 46 pages, 22 fig",
        "versions": [],
        "rank": 556
    },
    {
        "authors": [
            "Albani, Dario",
            "Bloisi, Domenico Daniele",
            "Nardi, Daniele",
            "Youssef, Ali"
        ],
        "title": "Fast traffic sign recognition using color segmentation and deep convolutional networks",
        "publication_date": "2016-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": null,
        "volume": "",
        "doi": "10.1007/978-3-319-48680-2_19",
        "urls": [
            "https://core.ac.uk/download/98333366.pdf"
        ],
        "id": "id-5407814195814028570",
        "abstract": "The use of Computer Vision techniques for the automatic\n\nrecognition of road signs is fundamental for the development of intelli-\n\ngent vehicles and advanced driver assistance systems. In this paper, we\n\ndescribe a procedure based on color segmentation, Histogram of Ori-\n\nented Gradients (HOG), and Convolutional Neural Networks (CNN) for\n\ndetecting and classifying road signs. Detection is speeded up by a pre-\n\nprocessing step to reduce the search space, while classication is carried\n\nout by using a Deep Learning technique. A quantitative evaluation of the\n\nproposed approach has been conducted on the well-known German Traf-\n\nc Sign data set and on the novel Data set of Italian Trac Signs (DITS),\n\nwhich is publicly available and contains challenging sequences captured\n\nin adverse weather conditions and in an urban scenario at night-time.\n\nExperimental results demonstrate the eectiveness of the proposed ap-\n\nproach in terms of both classication accuracy and computational speed",
        "versions": [],
        "rank": 557
    },
    {
        "authors": [],
        "title": "Stability of Deep Neural Networks via Discrete Rough Paths",
        "publication_date": "None",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.37473/dac/10.1137/22m1472358",
        "urls": [
            "http://dx.doi.org/10.37473/dac/10.1137/22m1472358"
        ],
        "id": "id-1018322200417125010",
        "abstract": "",
        "versions": [],
        "rank": 558
    },
    {
        "authors": [],
        "title": "Stability of Deep Neural Networks via Discrete Rough Paths",
        "publication_date": "None",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.37473/fic/10.1137/22m1472358",
        "urls": [
            "http://dx.doi.org/10.37473/fic/10.1137/22m1472358"
        ],
        "id": "id6704338791197126022",
        "abstract": "",
        "versions": [],
        "rank": 559
    },
    {
        "authors": [
            "Akmal, Muhammad",
            "Alquthami, Thamer",
            "Benrabah, Abdeldjabar",
            "Raza, Ali"
        ],
        "title": "A Review of Fault Diagnosing Methods in Power Transmission Systems",
        "publication_date": "2020-02-14 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.3390/app10041312",
        "urls": [
            "https://core.ac.uk/download/287599961.pdf"
        ],
        "id": "id8833452387091811745",
        "abstract": "Transient stability is important in power systems. Disturbances like faults need to be segregated to restore transient stability. A comprehensive review of fault diagnosing methods in the power transmission system is presented in this paper. Typically, voltage and current samples are deployed for analysis. Three tasks/topics; fault detection, classification, and location are presented separately to convey a more logical and comprehensive understanding of the concepts. Feature extractions, transformations with dimensionality reduction methods are discussed. Fault classification and location techniques largely use artificial intelligence (AI) and signal processing methods. After the discussion of overall methods and concepts, advancements and future aspects are discussed. Generalized strengths and weaknesses of different AI and machine learning-based algorithms are assessed. A comparison of different fault detection, classification, and location methods is also presented considering features, inputs, complexity, system used and results. This paper may serve as a guideline for the researchers to understand different methods and techniques in this field",
        "versions": [],
        "rank": 560
    },
    {
        "authors": [
            "Chakrabarti, Ayan",
            "Koppal, Sanjeev J.",
            "Pittaluga, Francesco"
        ],
        "title": "Learning Privacy Preserving Encodings through Adversarial Training",
        "publication_date": "2018-12-04 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/wacv.2019.00089",
        "urls": [
            "http://arxiv.org/abs/1802.05214"
        ],
        "id": "id3335610447976618536",
        "abstract": "We present a framework to learn privacy-preserving encodings of images that\ninhibit inference of chosen private attributes, while allowing recovery of\nother desirable information. Rather than simply inhibiting a given fixed\npre-trained estimator, our goal is that an estimator be unable to learn to\naccurately predict the private attributes even with knowledge of the encoding\nfunction. We use a natural adversarial optimization-based formulation for\nthis---training the encoding function against a classifier for the private\nattribute, with both modeled as deep neural networks. The key contribution of\nour work is a stable and convergent optimization approach that is successful at\nlearning an encoder with our desired properties---maintaining utility while\ninhibiting inference of private attributes, not just within the adversarial\noptimization, but also by classifiers that are trained after the encoder is\nfixed. We adopt a rigorous experimental protocol for verification wherein\nclassifiers are trained exhaustively till saturation on the fixed encoders. We\nevaluate our approach on tasks of real-world complexity---learning\nhigh-dimensional encodings that inhibit detection of different scene\ncategories---and find that it yields encoders that are resilient at maintaining\nprivacy.Comment: To appear in WACV 201",
        "versions": [],
        "rank": 561
    },
    {
        "authors": [
            "Yu Shiu",
            "K. Palmer",
            "M. Roch",
            "Erica Fleishman",
            "Xiaobai Liu",
            "E. Nosal",
            "Tyler A. Helble",
            "Danielle M. Cholewiak",
            "D. Gillespie",
            "H. Klinck"
        ],
        "title": "Deep neural networks for automated detection of marine mammal species",
        "publication_date": "2020-01-17 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Scientific Reports",
        "volume": "10",
        "doi": "10.1038/s41598-020-57549-y",
        "urls": [
            "https://www.semanticscholar.org/paper/1efa2cc689631c59fcd55a575c5611e3f5d92a2e"
        ],
        "id": "id7679895468273569028",
        "abstract": null,
        "versions": [],
        "rank": 562
    },
    {
        "authors": [
            "Rita Levi-Montalcini"
        ],
        "title": "The Nerve Growth Factor 35 Years Later",
        "publication_date": "1987-09-04 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Science",
        "volume": "237",
        "doi": "10.1126/science.3306916",
        "urls": [
            "https://openalex.org/W2063695629",
            "https://doi.org/10.1126/science.3306916"
        ],
        "id": "id-2187134095030800662",
        "abstract": "",
        "versions": [],
        "rank": 563
    },
    {
        "authors": [
            "Jain, G.",
            "Sharma, M.",
            "Agarwal, B."
        ],
        "title": "Spam Detection on Social Media Using Semantic Convolutional Neural Network",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.4018/978-1-7998-0414-7.ch039",
        "urls": [
            "https://www.igi-global.com/viewtitle.aspx?TitleId=237900",
            "http://dx.doi.org/10.4018/978-1-7998-0414-7.ch039"
        ],
        "id": "id5962622181530291496",
        "abstract": "",
        "versions": [],
        "rank": 564
    },
    {
        "authors": [
            "Biradar, M.",
            "Shiparamatti, B.",
            "Patil, P."
        ],
        "title": "Fabric Defect Detection Using Deep Convolutional Neural Network",
        "publication_date": "2021-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.3103/s1060992x21030024",
        "urls": [
            "https://link.springer.com/content/pdf/10.3103/S1060992X21030024.pdf",
            "https://link.springer.com/article/10.3103/S1060992X21030024/fulltext.html",
            "https://link.springer.com/content/pdf/10.3103/S1060992X21030024.pdf",
            "http://dx.doi.org/10.3103/s1060992x21030024"
        ],
        "id": "id2552910077653125953",
        "abstract": "",
        "versions": [],
        "rank": 565
    },
    {
        "authors": [
            "Nicol'as I. Tapia",
            "P. Est'evez"
        ],
        "title": "RED: Deep Recurrent Neural Networks for Sleep EEG Event Detection",
        "publication_date": "2020-05-15 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/IJCNN48605.2020.9207719",
        "urls": [
            "https://www.semanticscholar.org/paper/6261b425753d3d4c32bf51da87b7432d3cccc1d4"
        ],
        "id": "id-4247706225576652538",
        "abstract": "The brain electrical activity presents several short events during sleep that can be observed as distinctive microstructures in the electroencephalogram (EEG), such as sleep spindles and K-complexes. These events have been associated with biological processes and neurological disorders, making them a research topic in sleep medicine. However, manual detection limits their study because it is time-consuming and affected by significant inter-expert variability, motivating automatic approaches. We propose a deep learning approach based on convolutional and recurrent neural networks for sleep EEG event detection called Recurrent Event Detector (RED). RED uses one of two input representations: a) the time-domain EEG signal, or b) a complex spectrogram of the signal obtained with the Continuous Wavelet Transform (CWT). Unlike previous approaches, a fixed time window is avoided and temporal context is integrated to better emulate the visual criteria of experts. When evaluated on the MASS dataset, our detectors outperform the state of the art in both sleep spindle and K-complex detection with a mean F1-score of at least 80.9% and 82.6%, respectively. Although the CWT-domain model obtained a similar performance than its time-domain counterpart, the former allows in principle a more interpretable input representation due to the use of a spectrogram. The proposed approach is event-agnostic and can be used directly to detect other types of sleep events.",
        "versions": [],
        "rank": 566
    },
    {
        "authors": [
            "Te Sun Han",
            "Yan-Fu Li"
        ],
        "title": "Out-of-distribution detection-assisted trustworthy machinery fault diagnosis approach with uncertainty-aware deep ensembles",
        "publication_date": "2022-10-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Reliability Engineering & System Safety",
        "volume": "226",
        "doi": "10.1016/j.ress.2022.108648",
        "urls": [
            "https://openalex.org/W4285900042",
            "https://doi.org/10.1016/j.ress.2022.108648"
        ],
        "id": "id3141444874675516266",
        "abstract": "",
        "versions": [],
        "rank": 567
    },
    {
        "authors": [
            "Weiwei Fang",
            "Xin Li",
            "Ping Zhou",
            "Jingwen Yan",
            "Dazhi Jiang",
            "Teng Zhoua"
        ],
        "title": "Deep Learning Anti-fraud Model for Internet Loan: Where We are Going",
        "publication_date": "2021-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Institute of Electrical and Electronics Engineers (IEEE)",
        "volume": "",
        "doi": "10.1109/access.2021.3051079",
        "urls": [
            "https://web.archive.org/web/20210429041727/https://ieeexplore.ieee.org/ielx7/6287639/9312710/09320567.pdf"
        ],
        "id": "id-4405638551949143916",
        "abstract": "Recently, Internet finance is increasingly popular. However, bad debt has become a serious threat to Internet financial companies. The fraud detection models commonly used in conventional financial companies is logistic regression. Although it is interpretable, the accuracy of the logistic regression still remains to be improved. This paper takes a large public loan dataset, e.g. Lending club, for example, to explore the potential of applying deep neural network for fraud detection. We first fill the missing values by a random forest. Then, an XGBoost algorithm is employed to select the most discriminate features. After that, we propose to use a synthetic minority oversampling technique to deal with the sample imbalance. With the preprocessed data, we design a deep neural network for Internet loan fraud detection. Extensive experiments have been conducted to demonstrate the outperformance of the deep neural network compared with the commonly-used models. Such a simple yet effective model may brighten the application of deep learning in anti-fraud for Internet loans, which would benefit the financial engineers in small and medium Internet financial companies. INDEX TERMS Internet finance, loan fraud detection, deep learning, financial model.",
        "versions": [],
        "rank": 568
    },
    {
        "authors": [
            "Tao Chen",
            "Damian Borth",
            "Trevor Darrell",
            "Shih-Fu Chang"
        ],
        "title": "DeepSentiBank: Visual Sentiment Concept Classification with Deep Convolutional Neural Networks",
        "publication_date": "2014-10-30 22:57:12+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1410.8586v1",
            "http://arxiv.org/abs/1410.8586v1",
            "http://arxiv.org/pdf/1410.8586v1"
        ],
        "id": "id-1855865505043013396",
        "abstract": "This paper introduces a visual sentiment concept classification method based\non deep convolutional neural networks (CNNs). The visual sentiment concepts are\nadjective noun pairs (ANPs) automatically discovered from the tags of web\nphotos, and can be utilized as effective statistical cues for detecting\nemotions depicted in the images. Nearly one million Flickr images tagged with\nthese ANPs are downloaded to train the classifiers of the concepts. We adopt\nthe popular model of deep convolutional neural networks which recently shows\ngreat performance improvement on classifying large-scale web-based image\ndataset such as ImageNet. Our deep CNNs model is trained based on Caffe, a\nnewly developed deep learning framework. To deal with the biased training data\nwhich only contains images with strong sentiment and to prevent overfitting, we\ninitialize the model with the model weights trained from ImageNet. Performance\nevaluation shows the newly trained deep CNNs model SentiBank 2.0 (or called\nDeepSentiBank) is significantly improved in both annotation accuracy and\nretrieval performance, compared to its predecessors which mainly use binary SVM\nclassification models.",
        "versions": [],
        "rank": 569
    },
    {
        "authors": [
            "Vincent Corlay",
            "Joseph J. Boutros",
            "Philippe Ciblat",
            "Lo\u00efc Brunel"
        ],
        "title": "Multilevel MIMO Detection with Deep Learning",
        "publication_date": "2018-12-04 18:22:50+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1812.01571v2",
            "http://arxiv.org/abs/1812.01571v2",
            "http://arxiv.org/pdf/1812.01571v2"
        ],
        "id": "id3822292587262930707",
        "abstract": "A quasi-static flat multiple-antenna channel is considered. We show how real\nmultilevel modulation symbols can be detected via deep neural networks. A\nmulti-plateau sigmoid function is introduced. Then, after showing the DNN\narchitecture for detection, we propose a twin-network neural structure. Batch\nsize and training statistics for efficient learning are investigated.\nNear-Maximum-Likelihood performance with a relatively reasonable number of\nparameters is achieved.",
        "versions": [],
        "rank": 570
    },
    {
        "authors": [
            "Jooyoung Moon",
            "Jihyo Kim",
            "Younghak Shin",
            "Sangheum Hwang"
        ],
        "title": "Confidence-Aware Learning for Deep Neural Networks",
        "publication_date": "2020-08-13 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20200815143800/https://arxiv.org/pdf/2007.01458v3.pdf"
        ],
        "id": "id-1194050720679060570",
        "abstract": "Despite the power of deep neural networks for a wide range of tasks, an overconfident prediction issue has limited their practical use in many safety-critical applications. Many recent works have been proposed to mitigate this issue, but most of them require either additional computational costs in training and/or inference phases or customized architectures to output confidence estimates separately. In this paper, we propose a method of training deep neural networks with a novel loss function, named Correctness Ranking Loss, which regularizes class probabilities explicitly to be better confidence estimates in terms of ordinal ranking according to confidence. The proposed method is easy to implement and can be applied to the existing architectures without any modification. Also, it has almost the same computational costs for training as conventional deep classifiers and outputs reliable predictions by a single inference. Extensive experimental results on classification benchmark datasets indicate that the proposed method helps networks to produce well-ranked confidence estimates. We also demonstrate that it is effective for the tasks closely related to confidence estimation, out-of-distribution detection and active learning.",
        "versions": [
            {
                "year": 2020,
                "source": "SupportedSources.PAPERS_WITH_CODE",
                "title": "Confidence-Aware Learning for Deep Neural Networks",
                "journal": "",
                "urls": [
                    "https://arxiv.org/pdf/2007.01458v3.pdf",
                    "https://github.com/daintlab/confidence-aware-learning",
                    "https://proceedings.icml.cc/static/paper_files/icml/2020/5957-Paper.pdf"
                ],
                "doi": "",
                "publication_date": "2020-07-03 00:00:00"
            }
        ],
        "rank": 571
    },
    {
        "authors": [
            "Cheng'an Bai",
            "Chao Zhou"
        ],
        "title": "Pressure Predictions of Turbine Blades with Deep Learning",
        "publication_date": "2018-06-12 03:17:08+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1806.06940v1",
            "http://arxiv.org/abs/1806.06940v1",
            "http://arxiv.org/pdf/1806.06940v1"
        ],
        "id": "id4147297065394120268",
        "abstract": "Deep learning has been used in many areas, such as feature detections in\nimages and the game of go. This paper presents a study that attempts to use the\ndeep learning method to predict turbomachinery performance. Three different\ndeep neural networks are built and trained to predict the pressure\ndistributions of turbine airfoils. The performance of a library of turbine\nairfoils were firstly predicted using methods based on Euler equations, which\nwere then used to train and validate the deep learning neural networks. The\nresults show that network with four layers of convolutional neural network and\ntwo layers of fully connected neural network provides the best predictions. For\nthe best neural network architecture, the pressure prediction on more than 99%\nlocations are better than 3% and 90% locations are better than 1%.",
        "versions": [],
        "rank": 572
    },
    {
        "authors": [
            "Nuno Dion\u00edsio",
            "Fernando Alves",
            "P. M. Ferreira",
            "A. Bessani"
        ],
        "title": "Cyberthreat Detection from Twitter using Deep Neural Networks",
        "publication_date": "2019-04-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/IJCNN.2019.8852475",
        "urls": [
            "https://www.semanticscholar.org/paper/e6075ff4d2518da8eb1a22449dba6430004f000a"
        ],
        "id": "id-4713840480075507510",
        "abstract": "To be prepared against cyberattacks, most organizations resort to security information and event management systems to monitor their infrastructures. These systems depend on the timeliness and relevance of the latest updates, patches and threats provided by cyberthreat intelligence feeds. Open source intelligence platforms, namely social media networks such as Twitter, are capable of aggregating a vast amount of cybersecurity-related sources. To process such information streams, we require scalable and efficient tools capable of identifying and summarizing relevant information for specified assets. This paper presents the processing pipeline of a novel tool that uses deep neural networks to process cybersecurity information received from Twitter. A convolutional neural network identifies tweets containing security-related information relevant to assets in an IT infrastructure. Then, a bidirectional long short-term memory network extracts named entities from these tweets to form a security alert or to fill an indicator of compromise. The proposed pipeline achieves an average 94% true positive rate and 91% true negative rate for the classification task and an average F1-score of 92% for the named entity recognition task, across three case study infrastructures.",
        "versions": [
            {
                "year": 2019,
                "source": "SupportedSources.CROSSREF",
                "title": "Cyberthreat Detection from Twitter using Deep Neural Networks",
                "journal": "",
                "urls": [
                    "http://xplorestaging.ieee.org/ielx7/8840768/8851681/08852475.pdf?arnumber=8852475",
                    "http://dx.doi.org/10.1109/ijcnn.2019.8852475"
                ],
                "doi": "10.1109/ijcnn.2019.8852475",
                "publication_date": "2019-01-01 00:00:00"
            }
        ],
        "rank": 573
    },
    {
        "authors": [
            "Alexander Wong",
            "Mohammad Javad Shafiee",
            "Brendan Chwyl",
            "Francis Li"
        ],
        "title": "FermiNets: Learning generative machines to generate efficient neural networks via generative synthesis",
        "publication_date": "2018-09-17 01:26:57+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1809.05989v2",
            "http://arxiv.org/abs/1809.05989v2",
            "http://arxiv.org/pdf/1809.05989v2"
        ],
        "id": "id4597326449351224100",
        "abstract": "The tremendous potential exhibited by deep learning is often offset by\narchitectural and computational complexity, making widespread deployment a\nchallenge for edge scenarios such as mobile and other consumer devices. To\ntackle this challenge, we explore the following idea: Can we learn generative\nmachines to automatically generate deep neural networks with efficient network\narchitectures? In this study, we introduce the idea of generative synthesis,\nwhich is premised on the intricate interplay between a generator-inquisitor\npair that work in tandem to garner insights and learn to generate highly\nefficient deep neural networks that best satisfies operational requirements.\nWhat is most interesting is that, once a generator has been learned through\ngenerative synthesis, it can be used to generate not just one but a large\nvariety of different, unique highly efficient deep neural networks that satisfy\noperational requirements. Experimental results for image classification,\nsemantic segmentation, and object detection tasks illustrate the efficacy of\ngenerative synthesis in producing generators that automatically generate highly\nefficient deep neural networks (which we nickname FermiNets) with higher model\nefficiency and lower computational costs (reaching >10x more efficient and\nfewer multiply-accumulate operations than several tested state-of-the-art\nnetworks), as well as higher energy efficiency (reaching >4x improvements in\nimage inferences per joule consumed on a Nvidia Tegra X2 mobile processor). As\nsuch, generative synthesis can be a powerful, generalized approach for\naccelerating and improving the building of deep neural networks for on-device\nedge scenarios.",
        "versions": [],
        "rank": 574
    },
    {
        "authors": [
            "Rikiya Yamashita",
            "Mizuho Nishio",
            "Richard K. G. Do",
            "Kaori Togashi"
        ],
        "title": "Convolutional neural networks: an overview and application in radiology",
        "publication_date": "2018-06-22 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Insights Into Imaging",
        "volume": "9",
        "doi": "10.1007/s13244-018-0639-9",
        "urls": [
            "https://openalex.org/W2809254203",
            "https://doi.org/10.1007/s13244-018-0639-9",
            "https://doi.org/10.1007/s13244-018-0639-9"
        ],
        "id": "id7948572217661465846",
        "abstract": "",
        "versions": [],
        "rank": 575
    },
    {
        "authors": [
            "Kumari Deepshikha",
            "Sai Harsha Yelleni",
            "P.K. Srijith",
            "C Krishna Mohan"
        ],
        "title": "Monte Carlo DropBlock for Modelling Uncertainty in Object Detection",
        "publication_date": "2021-08-08 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20210815113627/https://arxiv.org/pdf/2108.03614v1.pdf"
        ],
        "id": "id-2663098976181617961",
        "abstract": "With the advancements made in deep learning, computer vision problems like object detection and segmentation have seen a great improvement in performance. However, in many real-world applications such as autonomous driving vehicles, the risk associated with incorrect predictions of objects is very high. Standard deep learning models for object detection such as YOLO models are often overconfident in their predictions and do not take into account the uncertainty in predictions on out-of-distribution data. In this work, we propose an efficient and effective approach to model uncertainty in object detection and segmentation tasks using Monte-Carlo DropBlock (MC-DropBlock) based inference. The proposed approach applies drop-block during training time and test time on the convolutional layer of the deep learning models such as YOLO. We show that this leads to a Bayesian convolutional neural network capable of capturing the epistemic uncertainty in the model. Additionally, we capture the aleatoric uncertainty using a Gaussian likelihood. We demonstrate the effectiveness of the proposed approach on modeling uncertainty in object detection and segmentation tasks using out-of-distribution experiments. Experimental results show that MC-DropBlock improves the generalization, calibration, and uncertainty modeling capabilities of YOLO models in object detection and segmentation.",
        "versions": [],
        "rank": 576
    },
    {
        "authors": [
            "Chatelain, Cl\u00e9ment",
            "Deguerre, Benjamin",
            "Gasso, Gilles"
        ],
        "title": "Fast object detection in compressed JPEG Images",
        "publication_date": "2019-04-16 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/itsc.2019.8916937",
        "urls": [
            "http://arxiv.org/abs/1904.08408"
        ],
        "id": "id3831991181922616353",
        "abstract": "Object detection in still images has drawn a lot of attention over past few\nyears, and with the advent of Deep Learning impressive performances have been\nachieved with numerous industrial applications. Most of these deep learning\nmodels rely on RGB images to localize and identify objects in the image.\nHowever in some application scenarii, images are compressed either for storage\nsavings or fast transmission. Therefore a time consuming image decompression\nstep is compulsory in order to apply the aforementioned deep models. To\nalleviate this drawback, we propose a fast deep architecture for object\ndetection in JPEG images, one of the most widespread compression format. We\ntrain a neural network to detect objects based on the blockwise DCT (discrete\ncosine transform) coefficients {issued from} the JPEG compression algorithm. We\nmodify the well-known Single Shot multibox Detector (SSD) by replacing its\nfirst layers with one convolutional layer dedicated to process the DCT inputs.\nExperimental evaluations on PASCAL VOC and industrial dataset comprising images\nof road traffic surveillance show that the model is about $2\\times$ faster than\nregular SSD with promising detection performances. To the best of our\nknowledge, this paper is the first to address detection in compressed JPEG\nimages",
        "versions": [],
        "rank": 577
    },
    {
        "authors": [
            "Tinwala, W.",
            "Rauniyar, S."
        ],
        "title": "Big Five Personality Detection Using Deep Convolutional Neural Networks",
        "publication_date": "2021-09-13 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.20944/preprints202109.0199.v1",
        "urls": [
            "http://dx.doi.org/10.20944/preprints202109.0199.v1"
        ],
        "id": "id3487471915023963498",
        "abstract": "",
        "versions": [],
        "rank": 578
    },
    {
        "authors": [
            "Dayoub, Feras",
            "Milford, Michael",
            "Miller, Dimity",
            "S\u00fcnderhauf, Niko"
        ],
        "title": "Evaluating Merging Strategies for Sampling-based Uncertainty Techniques  in Object Detection",
        "publication_date": "2019-03-06 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/icra.2019.8793821",
        "urls": [
            "http://arxiv.org/abs/1809.06006"
        ],
        "id": "id-5626600047172084814",
        "abstract": "There has been a recent emergence of sampling-based techniques for estimating\nepistemic uncertainty in deep neural networks. While these methods can be\napplied to classification or semantic segmentation tasks by simply averaging\nsamples, this is not the case for object detection, where detection sample\nbounding boxes must be accurately associated and merged. A weak merging\nstrategy can significantly degrade the performance of the detector and yield an\nunreliable uncertainty measure. This paper provides the first in-depth\ninvestigation of the effect of different association and merging strategies. We\ncompare different combinations of three spatial and two semantic affinity\nmeasures with four clustering methods for MC Dropout with a Single Shot\nMulti-Box Detector. Our results show that the correct choice of\naffinity-clustering combination can greatly improve the effectiveness of the\nclassification and spatial uncertainty estimation and the resulting object\ndetection performance. We base our evaluation on a new mix of datasets that\nemulate near open-set conditions (semantically similar unknown classes),\ndistant open-set conditions (semantically dissimilar unknown classes) and the\ncommon closed-set conditions (only known classes).Comment: to appear in IEEE International Conference on Robotics and Automation\n  2019 (ICRA 2019",
        "versions": [],
        "rank": 579
    },
    {
        "authors": [
            "Bouwmans, Thierry",
            "Javed, Sajid",
            "Jung, Soon Ki",
            "Sultana, Maryam"
        ],
        "title": "Deep Neural Network Concepts for Background Subtraction: A Systematic  Review and Comparative Evaluation",
        "publication_date": "2018-11-13 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1016/j.neunet.2019.04.024",
        "urls": [
            "http://arxiv.org/abs/1811.05255"
        ],
        "id": "id-5492338934151920819",
        "abstract": "Conventional neural networks show a powerful framework for background\nsubtraction in video acquired by static cameras. Indeed, the well-known SOBS\nmethod and its variants based on neural networks were the leader methods on the\nlargescale CDnet 2012 dataset during a long time. Recently, convolutional\nneural networks which belong to deep learning methods were employed with\nsuccess for background initialization, foreground detection and deep learned\nfeatures. Currently, the top current background subtraction methods in CDnet\n2014 are based on deep neural networks with a large gap of performance in\ncomparison on the conventional unsupervised approaches based on multi-features\nor multi-cues strategies. Furthermore, a huge amount of papers was published\nsince 2016 when Braham and Van Droogenbroeck published their first work on CNN\napplied to background subtraction providing a regular gain of performance. In\nthis context, we provide the first review of deep neural network concepts in\nbackground subtraction for novices and experts in order to analyze this success\nand to provide further directions. For this, we first surveyed the methods used\nbackground initialization, background subtraction and deep learned features.\nThen, we discuss the adequacy of deep neural networks for background\nsubtraction. Finally, experimental results are presented on the CDnet 2014\ndataset.Comment: 46 pages, 4 figures, submitted to neural network",
        "versions": [],
        "rank": 580
    },
    {
        "authors": [
            "Rowan McAllister",
            "Gregory Kahn",
            "Jeff Clune",
            "Sergey Levine"
        ],
        "title": "Robustness to Out-of-Distribution Inputs via Task-Aware Generative Uncertainty",
        "publication_date": "2018-12-27 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20191024234849/https://arxiv.org/pdf/1812.10687v1.pdf"
        ],
        "id": "id-5118523305480328978",
        "abstract": "Deep learning provides a powerful tool for machine perception when the observations resemble the training data. However, real-world robotic systems must react intelligently to their observations even in unexpected circumstances. This requires a system to reason about its own uncertainty given unfamiliar, out-of-distribution observations. Approximate Bayesian approaches are commonly used to estimate uncertainty for neural network predictions, but can struggle with out-of-distribution observations. Generative models can in principle detect out-of-distribution observations as those with a low estimated density. However, the mere presence of an out-of-distribution input does not by itself indicate an unsafe situation. In this paper, we present a method for uncertainty-aware robotic perception that combines generative modeling and model uncertainty to cope with uncertainty stemming from out-of-distribution states. Our method estimates an uncertainty measure about the model's prediction, taking into account an explicit (generative) model of the observation distribution to handle out-of-distribution inputs. This is accomplished by probabilistically projecting observations onto the training distribution, such that out-of-distribution inputs map to uncertain in-distribution observations, which in turn produce uncertain task-related predictions, but only if task-relevant parts of the image change. We evaluate our method on an action-conditioned collision prediction task with both simulated and real data, and demonstrate that our method of projecting out-of-distribution observations improves the performance of four standard Bayesian and non-Bayesian neural network approaches, offering more favorable trade-offs between the proportion of time a robot can remain autonomous and the proportion of impending crashes successfully avoided.",
        "versions": [],
        "rank": 581
    },
    {
        "authors": [
            "Kriszti\u00e1n Vida",
            "Attila B\u00f3di",
            "Tam\u00e1s Szklen\u00e1r",
            "B\u00e1lint Seli"
        ],
        "title": "Finding flares in Kepler and TESS data with recurrent deep neural networks",
        "publication_date": "2021-05-24 18:15:37+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": "A&A 652, A107 (2021)",
        "volume": "",
        "doi": "10.1051/0004-6361/202141068",
        "urls": [
            "http://arxiv.org/pdf/2105.11485v2",
            "http://dx.doi.org/10.1051/0004-6361/202141068",
            "http://arxiv.org/abs/2105.11485v2",
            "http://arxiv.org/pdf/2105.11485v2"
        ],
        "id": "id-5961480639844920669",
        "abstract": "Stellar flares are an important aspect of magnetic activity -- both for\nstellar evolution and circumstellar habitability viewpoints - but automatically\nand accurately finding them is still a challenge to researchers in the Big Data\nera of astronomy. We present an experiment to detect flares in space-borne\nphotometric data using deep neural networks. Using a set of artificial data and\nreal photometric data we trained a set of neural networks, and found that the\nbest performing architectures were the recurrent neural networks (RNNs) using\nLong Short-Term Memory (LSTM) layers. The best trained network detected flares\nover {$5\\sigma$ with $\\gtrsim80$\\% recall and precision} and was also capable\nto distinguish typical false signals (e.g. maxima of RR Lyr stars) from real\nflares. Testing the network trained on Kepler data on TESS light curves showed\nthat the neural net is able to generalize and find flares - with similar\neffectiveness - in completely new data having previously unseen sampling and\ncharacteristics.",
        "versions": [],
        "rank": 582
    },
    {
        "authors": [
            "K. Prabhakar",
            "A. Ramaswamy",
            "Suvaansh Bhambri",
            "J. Gubbi",
            "R. Venkatesh Babu",
            "B. Purushothaman"
        ],
        "title": "CDNet++: Improved Change Detection with Deep Neural Network Feature Correlation",
        "publication_date": "2020-07-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/IJCNN48605.2020.9207306",
        "urls": [
            "https://www.semanticscholar.org/paper/4f39bf1cfca2fe40aa58d5ae141b0a8eee10b3d6"
        ],
        "id": "id-777629134062310594",
        "abstract": "In this paper, we present a deep convolutional neural network (CNN) architecture for segmenting semantic changes between two images. The main objective is to segment changes at the semantic level than detecting background changes, which are irrelevant to the application. The difficulties include seasonal changes, lighting differences, artifacts due to alignment and occlusion. The existing approaches fail to address all the problems together; thus, none of them achieve state-of-the-art performance in three publicly available change detection datasets: VL-CMU-CD [1], TSUNAMI [2] and GSV [2]. Our proposed approach is a simple yet effective method that can handle even adverse challenges. In our approach, we leverage the correlation between high-level abstract CNN features to segment the changes. Compared with several traditional and other deep learning-based change detection methods, our proposed method achieves state-of-the-art performance in all three datasets.",
        "versions": [],
        "rank": 583
    },
    {
        "authors": [
            "C. Chatzichristos",
            "J. Dan",
            "A. Narayanan",
            "N. Seeuws",
            "K. Vandecasteele",
            "M. de Vos",
            "A. Bertrand",
            "S. Van Huffel"
        ],
        "title": "Epileptic Seizure Detection in EEG via Fusion of Multi-View Attention-Gated U-Net Deep Neural Networks",
        "publication_date": "2020-12-05 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/SPMB50085.2020.9353630",
        "urls": [
            "https://www.semanticscholar.org/paper/d7d26e6e50a2f4cdc118a6e7613aa6a97c6f6a6c"
        ],
        "id": "id-8811079982802429642",
        "abstract": "Electroencephalography (EEG) is an essential tool in clinical practice for the diagnosis and monitoring of people with epilepsy. Manual annotation of epileptic seizures is a time consuming process performed by expert neurologists. Hence, a procedure which automatically detects seizures would be hugely beneficial for a fast and cost-effective diagnosis. Recent progress in machine learning techniques, especially deep learning methods, coupled with the availability of large public EEG seizure databases provide new opportunities towards the design of automatic EEG-based seizure detection algorithms. We propose an epileptic seizure detection pipeline based on the fusion of multiple attention-gated U-nets, each operating on a different view of the EEG data. These different views correspond to distinct signal processing techniques applied on the raw EEG. The proposed model uses a long short term memory (LSTM) network for fusion of the individual attention-gated U-net outputs to detect seizures in EEG. The model outperforms the state-of-the-art models on the TUH EEG seizure dataset and was awarded the first place in the Neureka\u2122 2020 Epilepsy Challenge.",
        "versions": [],
        "rank": 584
    },
    {
        "authors": [
            "Laurent Itti",
            "Christof Koch"
        ],
        "title": "Computational modelling of visual attention",
        "publication_date": "2001-03-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Nature Reviews Neuroscience",
        "volume": "2",
        "doi": "10.1038/35058500",
        "urls": [
            "https://openalex.org/W2144764737",
            "https://doi.org/10.1038/35058500",
            "https://authors.library.caltech.edu/40408/1/391.pdf"
        ],
        "id": "id6157078092030790634",
        "abstract": "",
        "versions": [],
        "rank": 585
    },
    {
        "authors": [
            "Qisheng Huang",
            "Chunming Zhao",
            "Ming Jiang",
            "Xiaoming Li",
            "Jing Liang"
        ],
        "title": "Cascade-Net: a New Deep Learning Architecture for OFDM Detection",
        "publication_date": "2018-11-30 19:07:57+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1812.00023v1",
            "http://arxiv.org/abs/1812.00023v1",
            "http://arxiv.org/pdf/1812.00023v1"
        ],
        "id": "id6079163113637693693",
        "abstract": "In this paper, we consider using deep neural network for OFDM symbol\ndetection and demonstrate its performance advantages in combating large Doppler\nShift. In particular, a new architecture named Cascade-Net is proposed for\ndetection, where deep neural network is cascading with a zero-forcing\npreprocessor to prevent the network stucking in a saddle point or a local\nminimum point. In addition, we propose a sliding detection approach in order to\ndetect OFDM symbols with large number of subcarriers. We evaluate this new\narchitecture, as well as the sliding algorithm, using the Rayleigh channel with\nlarge Doppler spread, which could degrade detection performance in an OFDM\nsystem and is especially severe for high frequency band and mmWave\ncommunications. The numerical results of OFDM detection in SISO scenario show\nthat cascade-net can achieve better performance than zero-forcing method while\nproviding robustness against ill conditioned channels. We also show the better\nperformance of the sliding cascade network (SCN) compared to sliding\nzero-forcing detector through numerical simulation.",
        "versions": [],
        "rank": 586
    },
    {
        "authors": [
            "Aqsa Saeed Qureshi",
            "T. Roos"
        ],
        "title": "Transfer Learning with Ensembles of Deep Neural Networks for Skin Cancer Detection in Imbalanced Data Sets",
        "publication_date": "2021-03-22 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1007/s11063-022-11049-4",
        "urls": [
            "https://www.semanticscholar.org/paper/1cbfcc1a0d4fcec1a3e329b80461f6088dc08172"
        ],
        "id": "id1782336725780166399",
        "abstract": null,
        "versions": [],
        "rank": 587
    },
    {
        "authors": [
            "Huili Chen",
            "Cheng Fu",
            "Jishen Zhao",
            "F. Koushanfar"
        ],
        "title": "DeepInspect: A Black-box Trojan Detection and Mitigation Framework for Deep Neural Networks",
        "publication_date": "2019-08-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.24963/ijcai.2019/647",
        "urls": [
            "https://www.semanticscholar.org/paper/a94eb8f40c02fa7e30e3c92b331aadc1cd3dd944"
        ],
        "id": "id6753937024624614024",
        "abstract": "Deep Neural Networks (DNNs) are vulnerable to Neural Trojan (NT) attacks where the adversary injects malicious behaviors during DNN training. This type of \u2018backdoor\u2019 attack is activated when the input is stamped with the trigger pattern specified by the attacker, resulting in an incorrect prediction of the model. Due to the wide application of DNNs in various critical fields, it is indispensable to inspect whether the pre-trained DNN has been trojaned before employing a model. Our goal in this paper is to address the security concern on unknown DNN to NT attacks and ensure safe model deployment. We propose DeepInspect, the first black-box Trojan detection solution with minimal prior knowledge of the model. DeepInspect learns the probability distribution of potential triggers from the queried model using a conditional generative model, thus retrieves the footprint of backdoor insertion. In addition to NT detection, we show that DeepInspect\u2019s trigger generator enables effective Trojan mitigation by model patching. We corroborate the effectiveness, efficiency, and scalability of DeepInspect against the state-of-the-art NT attacks across various benchmarks. Extensive experiments show that DeepInspect offers superior detection performance and lower runtime overhead than the prior work.",
        "versions": [],
        "rank": 588
    },
    {
        "authors": [
            "Bharat B. Biswal",
            "Maarten Mennes",
            "Xi-Nian Zuo",
            "Suril Gohel",
            "Clare Kelly",
            "Steve Smith",
            "Christian F. Beckmann",
            "Jonathan S. Adelstein",
            "Randy L. Buckner",
            "Stan Colcombe",
            "Anne-Marie Dogonowski",
            "Monique Ernst",
            "Damien A. Fair",
            "Michelle Hampson",
            "Matthew J. Hoptman",
            "James S. Hyde",
            "Vesa Kiviniemi",
            "Rolf K\u00f6tter",
            "Shi-Jiang Li",
            "Ching Po Lin",
            "Mark E. Lowe",
            "Clare E. Mackay",
            "David J. Madden",
            "Kristoffer Hougaard Madsen",
            "Daniel S. Margulies",
            "Helen S. Mayberg",
            "Katie L. McMahon",
            "Christopher S. Monk",
            "Stewart H. Mostofsky",
            "Bonnie J. Nagel",
            "James J. Pekar",
            "Scott Peltier",
            "Steven E. Petersen",
            "Valentin Riedl",
            "Serge A.R.B. Rombouts",
            "Bart Rypma",
            "Bradley L. Schlaggar",
            "Sein Schmidt",
            "Rachael D. Seidler",
            "Greg J. Siegle",
            "Christian Sorg",
            "Gao Jun Teng",
            "Juha Veijola",
            "Arno Villringer",
            "Martin Walter",
            "Lihong V. Wang",
            "Xuchu Weng",
            "Susan Whitfield-Gabrieli",
            "Peter R. Williamson",
            "Christian Windischberger",
            "Yu-Feng Zang",
            "Hongying Zhang",
            "F. Xavier Castellanos",
            "Michael P. Milham"
        ],
        "title": "Toward discovery science of human brain function",
        "publication_date": "2010-03-09 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Proceedings of the National Academy of Sciences of the United States of America",
        "volume": "107",
        "doi": "10.1073/pnas.0911855107",
        "urls": [
            "https://openalex.org/W2008607322",
            "https://doi.org/10.1073/pnas.0911855107",
            "https://europepmc.org/articles/pmc2842060?pdf=render"
        ],
        "id": "id5413686533572633256",
        "abstract": "",
        "versions": [],
        "rank": 589
    },
    {
        "authors": [
            "Kevin Faust",
            "Quin Xie",
            "Dominick Han",
            "Kartikay Goyle",
            "Zoya Volynskaya",
            "Ugljesa Djuric",
            "Phedias Diamandis"
        ],
        "title": "Visualizing histopathologic deep learning classification and anomaly detection using nonlinear feature space dimensionality reduction",
        "publication_date": "2018-05-16 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "BMC Bioinformatics",
        "volume": "19",
        "doi": "10.1186/s12859-018-2184-4",
        "urls": [
            "https://openalex.org/W2803405718",
            "https://doi.org/10.1186/s12859-018-2184-4",
            "https://bmcbioinformatics.biomedcentral.com/track/pdf/10.1186/s12859-018-2184-4"
        ],
        "id": "id-7764533300606827375",
        "abstract": "",
        "versions": [],
        "rank": 590
    },
    {
        "authors": [
            "Li, Jerry",
            "Madry, Aleksander",
            "Tran, Brandon"
        ],
        "title": "Spectral Signatures in Backdoor Attacks",
        "publication_date": "2018-11-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "http://arxiv.org/abs/1811.00636"
        ],
        "id": "id1526246001250726764",
        "abstract": "A recent line of work has uncovered a new form of data poisoning: so-called\n\\emph{backdoor} attacks. These attacks are particularly dangerous because they\ndo not affect a network's behavior on typical, benign data. Rather, the network\nonly deviates from its expected output when triggered by a perturbation planted\nby an adversary.\n  In this paper, we identify a new property of all known backdoor attacks,\nwhich we call \\emph{spectral signatures}. This property allows us to utilize\ntools from robust statistics to thwart the attacks. We demonstrate the efficacy\nof these signatures in detecting and removing poisoned examples on real image\nsets and state of the art neural network architectures. We believe that\nunderstanding spectral signatures is a crucial first step towards designing ML\nsystems secure against such backdoor attacksComment: 16 pages, accepted to NIPS 201",
        "versions": [],
        "rank": 591
    },
    {
        "authors": [
            "Afshar Shamsi",
            "Hamzeh Asgharnezhad",
            "Shirin Shamsi Jokandan",
            "Abbas Khosravi",
            "Parham M. Kebria",
            "Darius Nahavandi",
            "Saeid Nahavandi",
            "Dipti Srinivasan"
        ],
        "title": "An Uncertainty-Aware Transfer Learning-Based Framework for COVID-19 Diagnosis",
        "publication_date": "2021-02-11 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "IEEE transactions on neural networks and learning systems",
        "volume": "32",
        "doi": "10.1109/tnnls.2021.3054306",
        "urls": [
            "https://openalex.org/W3128511643",
            "https://doi.org/10.1109/tnnls.2021.3054306",
            "https://ieeexplore.ieee.org/ielx7/5962385/9394817/09353390.pdf"
        ],
        "id": "id5142382270928115081",
        "abstract": "",
        "versions": [],
        "rank": 592
    },
    {
        "authors": [
            "T. Ozturk",
            "Muhammed Talo",
            "Eylul Azra Yildirim",
            "U. Baloglu",
            "\u00d6zal Y\u0131ld\u0131r\u0131m",
            "U. Acharya"
        ],
        "title": "Automated detection of COVID-19 cases using deep neural networks with X-ray images",
        "publication_date": "2020-04-28 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Computers in Biology and Medicine",
        "volume": "121",
        "doi": "10.1016/j.compbiomed.2020.103792",
        "urls": [
            "https://www.semanticscholar.org/paper/ebe3f062c05b57cb1f0f0f1e73ad23d8af6aef33"
        ],
        "id": "id2853340035113429909",
        "abstract": null,
        "versions": [],
        "rank": 593
    },
    {
        "authors": [
            "Chen, Yingke",
            "Opara, Chidimma",
            "Wei, Bo"
        ],
        "title": "HTMLPhish: Enabling Phishing Web Page Detection by Applying Deep Learning Techniques on HTML Analysis",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ijcnn48605.2020.9207707",
        "urls": [
            "https://core.ac.uk/download/323307033.pdf"
        ],
        "id": "id2415663401999889342",
        "abstract": "Recently, the development and implementation of phishing attacks require little technical skills and costs. This uprising has led to an ever-growing number of phishing attacks on the World Wide Web. Consequently, proactive techniques to fight phishing attacks have become extremely necessary. In this paper, we propose HTMLPhish, a deep learning based datadriven end-to-end automatic phishing web page classification approach. Specifically, HTMLPhish receives the content of the HTML document of a web page and employs Convolutional Neural Networks (CNNs) to learn the semantic dependencies in the textual contents of the HTML. The CNNs learn appropriate feature representations from the HTML document embeddings without extensive manual feature engineering. Furthermore, our proposed approach of the concatenation of the word and character embeddings allows our model to manage new features and ensure easy extrapolation to test data. We conduct comprehensive experiments on a dataset of more than 50,000 HTML documents that provides a distribution of phishing to benign web pages obtainable in the real-world that yields over 93% Accuracy and True Positive Rate. Also, HTMLPhish is a completely language-independent and client-side strategy which can, therefore, conduct web page phishing detection regardless of the textual language",
        "versions": [],
        "rank": 594
    },
    {
        "authors": [
            "Rawat, Bhanu Pratap Singh",
            "Shamsi, Saqib",
            "Wadhwa, Manya"
        ],
        "title": "Group Affect Prediction Using Multimodal Distributions",
        "publication_date": "2018-03-12 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/wacvw.2018.00015",
        "urls": [
            "http://arxiv.org/abs/1710.01216"
        ],
        "id": "id-1267145674103202249",
        "abstract": "We describe our approach towards building an efficient predictive model to\ndetect emotions for a group of people in an image. We have proposed that\ntraining a Convolutional Neural Network (CNN) model on the emotion heatmaps\nextracted from the image, outperforms a CNN model trained entirely on the raw\nimages. The comparison of the models have been done on a recently published\ndataset of Emotion Recognition in the Wild (EmotiW) challenge, 2017. The\nproposed method achieved validation accuracy of 55.23% which is 2.44% above the\nbaseline accuracy, provided by the EmotiW organizers.Comment: This research paper has been accepted at Workshop on Computer Vision\n  for Active and Assisted Living, WACV 201",
        "versions": [],
        "rank": 595
    },
    {
        "authors": [
            "Junchi Yan",
            "Chenxiao Yang",
            "Yiting Chen",
            "Qitian Wu"
        ],
        "title": "Energy-based Out-of-Distribution Detection for Graph Neural Networks",
        "publication_date": "2023-02-06 00:00:00",
        "source": "SupportedSources.PAPERS_WITH_CODE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://arxiv.org/pdf/2302.02914v2.pdf",
            "https://github.com/qitianwu/graphood-gnnsafe"
        ],
        "id": "id-674808873859672192",
        "abstract": "Learning on graphs, where instance nodes are inter-connected, has become one of the central problems for deep learning, as relational structures are pervasive and induce data inter-dependence which hinders trivial adaptation of existing approaches that assume inputs to be i.i.d.~sampled. However, current models mostly focus on improving testing performance of in-distribution data and largely ignore the potential risk w.r.t. out-of-distribution (OOD) testing samples that may cause negative outcome if the prediction is overconfident on them. In this paper, we investigate the under-explored problem, OOD detection on graph-structured data, and identify a provably effective OOD discriminator based on an energy function directly extracted from graph neural networks trained with standard classification loss. This paves a way for a simple, powerful and efficient OOD detection model for GNN-based learning on graphs, which we call GNNSafe. It also has nice theoretical properties that guarantee an overall distinguishable margin between the detection scores for in-distribution and OOD samples, which, more critically, can be further strengthened by a learning-free energy belief propagation scheme. For comprehensive evaluation, we introduce new benchmark settings that evaluate the model for detecting OOD data from both synthetic and real distribution shifts (cross-domain graph shifts and temporal graph shifts). The results show that GNNSafe achieves up to $17.0\\%$ AUROC improvement over state-of-the-arts and it could serve as simple yet strong baselines in such an under-developed area.",
        "versions": [],
        "rank": 596
    },
    {
        "authors": [
            "P. H\u00e1jek",
            "Aliaksandr Barushka",
            "Michal Munk"
        ],
        "title": "Fake consumer review detection using deep neural networks integrating word embeddings and emotion mining",
        "publication_date": "2020-02-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Neural Computing and Applications",
        "volume": "",
        "doi": "10.1007/s00521-020-04757-2",
        "urls": [
            "https://www.semanticscholar.org/paper/fb0aaa854f882a9a72eb5c0600cc08b781aa422c"
        ],
        "id": "id-8078377037684232890",
        "abstract": null,
        "versions": [],
        "rank": 597
    },
    {
        "authors": [
            "Cakir, E.",
            "Ozan, E.",
            "Virtanen, T."
        ],
        "title": "Filterbank learning for deep neural network based polyphonic sound event detection",
        "publication_date": "2016-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ijcnn.2016.7727634",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/7593175/7726591/07727634.pdf?arnumber=7727634",
            "http://dx.doi.org/10.1109/ijcnn.2016.7727634"
        ],
        "id": "id-8508870524256582833",
        "abstract": "",
        "versions": [],
        "rank": 598
    },
    {
        "authors": [
            "J\u00f6rg K\u00f6nig",
            "Minqian Chen",
            "Wiebke R\u00f6sing",
            "David Boho",
            "Patrick M\u00e4der",
            "Christian Cierpka"
        ],
        "title": "On the use of a cascaded convolutional neural network for three-dimensional flow measurements using astigmatic PTV",
        "publication_date": "2020-05-04 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Measurement Science and Technology",
        "volume": "31",
        "doi": "10.1088/1361-6501/ab7bfd",
        "urls": [
            "https://openalex.org/W3010407922",
            "https://doi.org/10.1088/1361-6501/ab7bfd",
            "https://doi.org/10.1088/1361-6501/ab7bfd"
        ],
        "id": "id8418165742356035477",
        "abstract": "",
        "versions": [
            {
                "year": 2020,
                "source": "SupportedSources.INTERNET_ARCHIVE",
                "title": "On the use of a cascaded convolutional neural network for three-dimensional flow measurements using astigmatic PTV",
                "journal": "IOP Publishing",
                "urls": [
                    "https://web.archive.org/web/20201106073355/https://www.db-thueringen.de/servlets/MCRFileNodeServlet/dbt_derivate_00049719/1361-6501_31_2020_7_074015.pdf"
                ],
                "doi": "10.1088/1361-6501/ab7bfd",
                "publication_date": "2020-03-03 00:00:00"
            }
        ],
        "rank": 599
    },
    {
        "authors": [
            "Mohammad Javad Shafiee",
            "Elnaz Barshan",
            "Alexander Wong"
        ],
        "title": "Evolution in Groups: A deeper look at synaptic cluster driven evolution of deep neural networks",
        "publication_date": "2017-04-07 03:28:02+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1704.02081v1",
            "http://arxiv.org/abs/1704.02081v1",
            "http://arxiv.org/pdf/1704.02081v1"
        ],
        "id": "id3452131491261967588",
        "abstract": "A promising paradigm for achieving highly efficient deep neural networks is\nthe idea of evolutionary deep intelligence, which mimics biological evolution\nprocesses to progressively synthesize more efficient networks. A crucial design\nfactor in evolutionary deep intelligence is the genetic encoding scheme used to\nsimulate heredity and determine the architectures of offspring networks. In\nthis study, we take a deeper look at the notion of synaptic cluster-driven\nevolution of deep neural networks which guides the evolution process towards\nthe formation of a highly sparse set of synaptic clusters in offspring\nnetworks. Utilizing a synaptic cluster-driven genetic encoding, the\nprobabilistic encoding of synaptic traits considers not only individual\nsynaptic properties but also inter-synaptic relationships within a deep neural\nnetwork. This process results in highly sparse offspring networks which are\nparticularly tailored for parallel computational devices such as GPUs and deep\nneural network accelerator chips. Comprehensive experimental results using four\nwell-known deep neural network architectures (LeNet-5, AlexNet, ResNet-56, and\nDetectNet) on two different tasks (object categorization and object detection)\ndemonstrate the efficiency of the proposed method. Cluster-driven genetic\nencoding scheme synthesizes networks that can achieve state-of-the-art\nperformance with significantly smaller number of synapses than that of the\noriginal ancestor network. ($\\sim$125-fold decrease in synapses for MNIST).\nFurthermore, the improved cluster efficiency in the generated offspring\nnetworks ($\\sim$9.71-fold decrease in clusters for MNIST and a $\\sim$8.16-fold\ndecrease in clusters for KITTI) is particularly useful for accelerated\nperformance on parallel computing hardware architectures such as those in GPUs\nand deep neural network accelerator chips.",
        "versions": [],
        "rank": 600
    },
    {
        "authors": [
            "Burgard, Wolfram",
            "Eitel, Andreas",
            "Riedmiller, Martin",
            "Spinello, Luciano",
            "Springenberg, Jost Tobias"
        ],
        "title": "Multimodal Deep Learning for Robust RGB-D Object Recognition",
        "publication_date": "2015-08-18 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/iros.2015.7353446",
        "urls": [
            "http://arxiv.org/abs/1507.06821"
        ],
        "id": "id-8824812574020854050",
        "abstract": "Robust object recognition is a crucial ingredient of many, if not all,\nreal-world robotics applications. This paper leverages recent progress on\nConvolutional Neural Networks (CNNs) and proposes a novel RGB-D architecture\nfor object recognition. Our architecture is composed of two separate CNN\nprocessing streams - one for each modality - which are consecutively combined\nwith a late fusion network. We focus on learning with imperfect sensor data, a\ntypical problem in real-world robotics tasks. For accurate learning, we\nintroduce a multi-stage training methodology and two crucial ingredients for\nhandling depth data with CNNs. The first, an effective encoding of depth\ninformation for CNNs that enables learning without the need for large depth\ndatasets. The second, a data augmentation scheme for robust learning with depth\nimages by corrupting them with realistic noise patterns. We present\nstate-of-the-art results on the RGB-D object dataset and show recognition in\nchallenging RGB-D real-world noisy settings.Comment: Final version submitted to IROS'2015, results unchanged,\n  reformulation of some text passages in abstract and introductio",
        "versions": [],
        "rank": 601
    },
    {
        "authors": [
            "Mohammad Javad Shafiee",
            "Francis Li",
            "Alexander Wong"
        ],
        "title": "Exploring the Imposition of Synaptic Precision Restrictions For Evolutionary Synthesis of Deep Neural Networks",
        "publication_date": "2017-07-01 04:56:08+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1707.00095v1",
            "http://arxiv.org/abs/1707.00095v1",
            "http://arxiv.org/pdf/1707.00095v1"
        ],
        "id": "id-5449105348072769731",
        "abstract": "A key contributing factor to incredible success of deep neural networks has\nbeen the significant rise on massively parallel computing devices allowing\nresearchers to greatly increase the size and depth of deep neural networks,\nleading to significant improvements in modeling accuracy. Although deeper,\nlarger, or complex deep neural networks have shown considerable promise, the\ncomputational complexity of such networks is a major barrier to utilization in\nresource-starved scenarios. We explore the synaptogenesis of deep neural\nnetworks in the formation of efficient deep neural network architectures within\nan evolutionary deep intelligence framework, where a probabilistic generative\nmodeling strategy is introduced to stochastically synthesize increasingly\nefficient yet effective offspring deep neural networks over generations,\nmimicking evolutionary processes such as heredity, random mutation, and natural\nselection in a probabilistic manner. In this study, we primarily explore the\nimposition of synaptic precision restrictions and its impact on the\nevolutionary synthesis of deep neural networks to synthesize more efficient\nnetwork architectures tailored for resource-starved scenarios. Experimental\nresults show significant improvements in synaptic efficiency (~10X decrease for\nGoogLeNet-based DetectNet) and inference speed (>5X increase for\nGoogLeNet-based DetectNet) while preserving modeling accuracy.",
        "versions": [],
        "rank": 602
    },
    {
        "authors": [
            "Dan Pan",
            "An Zeng",
            "L. Jia",
            "Yin Huang",
            "Tory O. Frizzell",
            "Xiaowei Song"
        ],
        "title": "Early Detection of Alzheimer\u2019s Disease Using Magnetic Resonance Imaging: A Novel Approach Combining Convolutional Neural Networks and Ensemble Learning",
        "publication_date": "2020-05-13 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Frontiers in Neuroscience",
        "volume": "14",
        "doi": "10.3389/fnins.2020.00259",
        "urls": [
            "https://www.semanticscholar.org/paper/809903d837638f092a7dab0c88d6f0816a1b317f"
        ],
        "id": "id-8032620152615141605",
        "abstract": "Early detection is critical for effective management of Alzheimer\u2019s disease (AD) and screening for mild cognitive impairment (MCI) is common practice. Among several deep-learning techniques that have been applied to assessing structural brain changes on magnetic resonance imaging (MRI), convolutional neural network (CNN) has gained popularity due to its superb efficiency in automated feature learning with the use of a variety of multilayer perceptrons. Meanwhile, ensemble learning (EL) has shown to be beneficial in the robustness of learning-system performance via integrating multiple models. Here, we proposed a classifier ensemble developed by combining CNN and EL, i.e., the CNN-EL approach, to identify subjects with MCI or AD using MRI: i.e., classification between (1) AD and healthy cognition (HC), (2) MCIc (MCI patients who will convert to AD) and HC, and (3) MCIc and MCInc (MCI patients who will not convert to AD). For each binary classification task, a large number of CNN models were trained applying a set of sagittal, coronal, or transverse MRI slices; these CNN models were then integrated into a single ensemble. Performance of the ensemble was evaluated using stratified fivefold cross-validation method for 10 times. The number of the intersection points determined by the most discriminable slices separating two classes in a binary classification task among the sagittal, coronal, and transverse slice sets, transformed into the standard Montreal Neurological Institute (MNI) space, acted as an indicator to assess the ability of a brain region in which the points were located to classify AD. Thus, the brain regions with most intersection points were considered as those mostly contributing to the early diagnosis of AD. The result revealed an accuracy rate of 0.84 \u00b1 0.05, 0.79 \u00b1 0.04, and 0.62 \u00b1 0.06, respectively, for classifying AD vs. HC, MCIc vs. HC, and MCIc vs. MCInc, comparable to previous reports and a 3D deep learning approach (3D-SENet) based on a more state-of-the-art and popular Squeeze-and-Excitation Networks model using channel attention mechanism. Notably, the intersection points accurately located the medial temporal lobe and several other structures of the limbic system, i.e., brain regions known to be struck early in AD. More interestingly, the classifiers disclosed multiple patterned MRI changes in the brain in AD and MCIc, involving these key regions. These results suggest that as a data-driven method, the combined CNN and EL approach can locate the most discriminable brain regions indicated by the trained ensemble model while the generalization ability of the ensemble model was maximized to successfully capture AD-related brain variations early in the disease process; it can also provide new insights into understanding the complex heterogeneity of whole-brain MRI changes in AD. Further research is needed to examine the clinical implication of the finding, capability of the advocated CNN-EL approach to help understand and evaluate an individual subject\u2019s disease status, symptom burden and progress, and the generalizability of the advocated CNN-EL approach to locate the most discriminable brain regions in the detection of other brain disorders such as schizophrenia, autism, and severe depression, in a data-driven way.",
        "versions": [],
        "rank": 603
    },
    {
        "authors": [
            "Nikos K. Logothetis",
            "J Pauls",
            "Mark Augath",
            "T Trinath",
            "Axel Oeltermann"
        ],
        "title": "Neurophysiological investigation of the basis of the fMRI signal",
        "publication_date": "2001-07-12 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Nature",
        "volume": "412",
        "doi": "10.1038/35084005",
        "urls": [
            "https://openalex.org/W2114104729",
            "https://doi.org/10.1038/35084005"
        ],
        "id": "id4788678357248417342",
        "abstract": "",
        "versions": [],
        "rank": 604
    },
    {
        "authors": [
            "Weixin Liang",
            "James Zou"
        ],
        "title": "Neural Group Testing to Accelerate Deep Learning",
        "publication_date": "2021-05-09 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20210512112254/https://arxiv.org/pdf/2011.10704v2.pdf"
        ],
        "id": "id5241669816257629806",
        "abstract": "Recent advances in deep learning have made the use of large, deep neural networks with tens of millions of parameters. The sheer size of these networks imposes a challenging computational burden during inference. Existing work focuses primarily on accelerating each forward pass of a neural network. Inspired by the group testing strategy for efficient disease testing, we propose neural group testing, which accelerates by testing a group of samples in one forward pass. Groups of samples that test negative are ruled out. If a group tests positive, samples in that group are then retested adaptively. A key challenge of neural group testing is to modify a deep neural network so that it could test multiple samples in one forward pass. We propose three designs to achieve this without introducing any new parameters and evaluate their performances. We applied neural group testing in an image moderation task to detect rare but inappropriate images. We found that neural group testing can group up to 16 images in one forward pass and reduce the overall computation cost by over 73% while improving detection performance.",
        "versions": [
            {
                "year": 2020,
                "source": "SupportedSources.ARXIV",
                "title": "Neural Group Testing to Accelerate Deep Learning",
                "journal": null,
                "urls": [
                    "http://arxiv.org/pdf/2011.10704v2",
                    "http://arxiv.org/abs/2011.10704v2",
                    "http://arxiv.org/pdf/2011.10704v2"
                ],
                "doi": "",
                "publication_date": "2020-11-21 02:23:54+00:00"
            }
        ],
        "rank": 605
    },
    {
        "authors": [
            "Laurent Itti",
            "Christof Koch"
        ],
        "title": "A saliency-based search mechanism for overt and covert shifts of visual attention",
        "publication_date": "2000-06-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Vision Research",
        "volume": "40",
        "doi": "10.1016/s0042-6989(99)00163-7",
        "urls": [
            "https://openalex.org/W2054802006",
            "https://doi.org/10.1016/s0042-6989(99)00163-7",
            "https://doi.org/10.1016/s0042-6989(99)00163-7"
        ],
        "id": "id1277860852223547511",
        "abstract": "",
        "versions": [],
        "rank": 606
    },
    {
        "authors": [
            "Abel L. Peirson"
        ],
        "title": "Neural network analysis of X-ray polarimeter data",
        "publication_date": "2022-06-21 17:10:56+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2206.10537v1",
            "http://arxiv.org/abs/2206.10537v1",
            "http://arxiv.org/pdf/2206.10537v1"
        ],
        "id": "id-2122838181006402451",
        "abstract": "This chapter presents deep neural network based methods for enhancing the\nsensitivity of X-ray telescopic observations with imaging polarimeters. Deep\nneural networks can be used to determine photoelectron emission directions,\nphoton absorptions points, and photon energies from 2D photoelectron track\nimages, with estimates for both the statistical and model uncertainties. Deep\nneural network predictive uncertainties can be incorporated into a weighted\nmaximum likelihood to estimate source polarization parameters. Events\nconverting outside of the fiducial gas volume, whose tracks have little\npolarization sensitivity, complicate polarization estimation. Deep neural\nnetwork based classifiers can be used to select against these events to improve\nenergy resolution and polarization sensitivity. The performance of deep neural\nnetwork methods is compared against standard data analysis methods, revealing a\n< 0.75x improvement in minimum detectable polarization for IXPE-specific\nsimulations. Potential future developments and improvements to these methods\nare discussed.",
        "versions": [],
        "rank": 607
    },
    {
        "authors": [
            "Akbar Satya Nugraha",
            "Yudistira Novanto",
            "Bayu Rahayudi"
        ],
        "title": "Supervised Virtual-to-Real Domain Adaptation for Object Detection Task using YOLO",
        "publication_date": "2023-02-27 15:36:14+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2302.13891v1",
            "http://arxiv.org/abs/2302.13891v1",
            "http://arxiv.org/pdf/2302.13891v1"
        ],
        "id": "id1997339303333638191",
        "abstract": "Deep neural network shows excellent use in a lot of real-world tasks. One of\nthe deep learning tasks is object detection. Well-annotated datasets will\naffect deep neural network accuracy. More data learned by deep neural networks\nwill make the model more accurate. However, a well-annotated dataset is hard to\nfind, especially in a specific domain. To overcome this, computer-generated\ndata or virtual datasets are used. Researchers could generate many images with\nspecific use cases also with its annotation. Research studies showed that\nvirtual datasets could be used for object detection tasks. Nevertheless, with\nthe usage of the virtual dataset, the model must adapt to real datasets, or the\nmodel must have domain adaptability features. We explored the domain adaptation\ninside the object detection model using a virtual dataset to overcome a few\nwell-annotated datasets. We use VW-PPE dataset, using 5000 and 10000 virtual\ndata and 220 real data. For model architecture, we used YOLOv4 using\nCSPDarknet53 as the backbone and PAN as the neck. The domain adaptation\ntechnique with fine-tuning only on backbone weight achieved a mean average\nprecision of 74.457%.",
        "versions": [],
        "rank": 608
    },
    {
        "authors": [
            "Pecchia, Leandro",
            "Pescap\u00e8, Antonio",
            "Porumb, Mihaela",
            "Stranges, Saverio"
        ],
        "title": "Precision medicine and artificial intelligence : a pilot study on deep learning for hypoglycemic events detection based on ECG",
        "publication_date": "2020-01-13 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1038/s41598-019-56927-5",
        "urls": [
            "https://core.ac.uk/download/287605709.pdf"
        ],
        "id": "id-5456057741733619164",
        "abstract": "Tracking the fluctuations in blood glucose levels is important for healthy subjects and crucial diabetic patients. Tight glucose monitoring reduces the risk of hypoglycemia, which can result in a series of complications, especially in diabetic patients, such as confusion, irritability, seizure and can even be fatal in specific conditions. Hypoglycemia affects the electrophysiology of the heart. However, due to strong inter-subject heterogeneity, previous studies based on a cohort of subjects failed to deploy electrocardiogram (ECG)-based hypoglycemic detection systems reliably. The current study used personalised medicine approach and Artificial Intelligence (AI) to automatically detect nocturnal hypoglycemia using a few heartbeats of raw ECG signal recorded with non-invasive, wearable devices, in healthy individuals, monitored 24\u2009hours for 14 consecutive days. Additionally, we present a visualisation method enabling clinicians to visualise which part of the ECG signal (e.g., T-wave, ST-interval) is significantly associated with the hypoglycemic event in each subject, overcoming the intelligibility problem of deep-learning methods. These results advance the feasibility of a real-time, non-invasive hypoglycemia alarming system using short excerpts of ECG signal",
        "versions": [
            {
                "year": 2020,
                "source": "SupportedSources.CORE",
                "title": "Precision medicine and artificial intelligence : a pilot study on deep learning for hypoglycemic events detection based on ECG",
                "journal": "",
                "urls": [
                    "https://core.ac.uk/download/287605709.pdf"
                ],
                "doi": "10.1038/s41598-019-56927-5",
                "publication_date": "2020-01-13 00:00:00"
            }
        ],
        "rank": 609
    },
    {
        "authors": [
            "Thierry Bouwmans",
            "Sajid Javed",
            "Maryam Sultana",
            "Soon Ki Jung"
        ],
        "title": "Deep Neural Network Concepts for Background Subtraction: A Systematic Review and Comparative Evaluation",
        "publication_date": "2018-11-13 12:35:19+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1811.05255v1",
            "http://arxiv.org/abs/1811.05255v1",
            "http://arxiv.org/pdf/1811.05255v1"
        ],
        "id": "id5414164429343411007",
        "abstract": "Conventional neural networks show a powerful framework for background\nsubtraction in video acquired by static cameras. Indeed, the well-known SOBS\nmethod and its variants based on neural networks were the leader methods on the\nlargescale CDnet 2012 dataset during a long time. Recently, convolutional\nneural networks which belong to deep learning methods were employed with\nsuccess for background initialization, foreground detection and deep learned\nfeatures. Currently, the top current background subtraction methods in CDnet\n2014 are based on deep neural networks with a large gap of performance in\ncomparison on the conventional unsupervised approaches based on multi-features\nor multi-cues strategies. Furthermore, a huge amount of papers was published\nsince 2016 when Braham and Van Droogenbroeck published their first work on CNN\napplied to background subtraction providing a regular gain of performance. In\nthis context, we provide the first review of deep neural network concepts in\nbackground subtraction for novices and experts in order to analyze this success\nand to provide further directions. For this, we first surveyed the methods used\nbackground initialization, background subtraction and deep learned features.\nThen, we discuss the adequacy of deep neural networks for background\nsubtraction. Finally, experimental results are presented on the CDnet 2014\ndataset.",
        "versions": [],
        "rank": 610
    },
    {
        "authors": [
            "Balaji Dharamsoth"
        ],
        "title": "Speech Emotion Recognition using Deep Neural Networks",
        "publication_date": "2020-06-30 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.22214/ijraset.2020.6395",
        "urls": [
            "https://www.semanticscholar.org/paper/376912bf315042008e487bef4ac85182ca86d076"
        ],
        "id": "id-6192312660633266366",
        "abstract": ": The aim of this project work is to propose a speech emotion recognition method based on speech features and speech transcriptions (text). Modelling emotional behaviours is a challenging task due to the variability in perceiving and describing emotions. We try to perform emotion analysis on the speech by collecting speech and textual features and applying a deep neural network model which can classify the sentiments of the speech. Ideally, we would like to experiment with several deep neural network models which take in different combinations of speech features and text as inputs. Speech features such as Mel-Frequency Cepstral Coefficients (MFCC) help retain emotion related low-level characteristics in speech whereas text helps capture the semantic meaning, both of which help in different aspects of emotion detection.",
        "versions": [],
        "rank": 611
    },
    {
        "authors": [
            "Byun, Taejoon",
            "Cofer, Darren",
            "Rayadurgam, Sanjai",
            "Sharma, Vaibhav",
            "Vijayakumar, Abhishek"
        ],
        "title": "Input Prioritization for Testing Neural Networks",
        "publication_date": "2019-01-11 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/aitest.2019.000-6",
        "urls": [
            "http://arxiv.org/abs/1901.03768"
        ],
        "id": "id232562067657075003",
        "abstract": "Deep neural networks (DNNs) are increasingly being adopted for sensing and\ncontrol functions in a variety of safety and mission-critical systems such as\nself-driving cars, autonomous air vehicles, medical diagnostics, and industrial\nrobotics. Failures of such systems can lead to loss of life or property, which\nnecessitates stringent verification and validation for providing high\nassurance. Though formal verification approaches are being investigated,\ntesting remains the primary technique for assessing the dependability of such\nsystems. Due to the nature of the tasks handled by DNNs, the cost of obtaining\ntest oracle data---the expected output, a.k.a. label, for a given input---is\nhigh, which significantly impacts the amount and quality of testing that can be\nperformed. Thus, prioritizing input data for testing DNNs in meaningful ways to\nreduce the cost of labeling can go a long way in increasing testing efficacy.\nThis paper proposes using gauges of the DNN's sentiment derived from the\ncomputation performed by the model, as a means to identify inputs that are\nlikely to reveal weaknesses. We empirically assessed the efficacy of three such\nsentiment measures for prioritization---confidence, uncertainty, and\nsurprise---and compare their effectiveness in terms of their fault-revealing\ncapability and retraining effectiveness. The results indicate that sentiment\nmeasures can effectively flag inputs that expose unacceptable DNN behavior. For\nMNIST models, the average percentage of inputs correctly flagged ranged from\n88% to 94.8%",
        "versions": [],
        "rank": 612
    },
    {
        "authors": [
            "Alessandro Fatica",
            "Irene Bozzoni"
        ],
        "title": "Long non-coding RNAs: new players in cell differentiation and development",
        "publication_date": "2014-01-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Nature Reviews Genetics",
        "volume": "15",
        "doi": "10.1038/nrg3606",
        "urls": [
            "https://openalex.org/W2032183472",
            "https://doi.org/10.1038/nrg3606"
        ],
        "id": "id640142239605557515",
        "abstract": "",
        "versions": [],
        "rank": 613
    },
    {
        "authors": [
            "Ahmad Hijazi",
            "Abed El Safadi",
            "Jean-Marie Flaus"
        ],
        "title": "A Deep Learning Approach for Intrusion Detection System in Industry Network",
        "publication_date": "2018-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20220419153923/http://ceur-ws.org/Vol-2343/paper12.pdf"
        ],
        "id": "id3307552855375342597",
        "abstract": "Network has brought convenience to the world by allowing flexible transformation of data, but it also exposes a high number of vulnerabilities. A Network Intrusion Detection System (NIDS) helps system and network administrators to detect network security breaches in their organizations. Identifying anonymous and new attacks is one of the main challenges in IDSs researches. Deep learning (2010's), which is a subfield of machine learning (1980's), is concerned with algorithms that are based on the structure and function of brain called artificial neural networks. The progression on such learning algorithms may improve the functionality of IDS especially in Industrial Control Systems to increase its detection rate on unknown attacks. In this work, we propose a deep learning approach to implement an effective and enhanced IDS for securing industrial network.",
        "versions": [],
        "rank": 614
    },
    {
        "authors": [
            "Xuegong Du",
            "Xiaojun Cao",
            "Rui Zhang",
            "Akshi Kumar"
        ],
        "title": "Big Data Analysis and Prediction System Based on Improved Convolutional Neural Network",
        "publication_date": "2022-03-10 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Hindawi Limited",
        "volume": "",
        "doi": "10.1155/2022/4564247",
        "urls": [
            "https://web.archive.org/web/20220323114103/https://downloads.hindawi.com/journals/cin/2022/4564247.pdf"
        ],
        "id": "id2330753917236532958",
        "abstract": "This paper presents a big data analysis and prediction system based on convolutional neural networks. Continuous template matching technology is used to analyze the distributed data structure of big data, and the information fusion processing of cloud service combination big data is combined with matching related detection methods, frequent item detection, and association rule feature extraction of high-dimensional fusion data. A clustering method is adopted to realize the classification and mining of cloud service portfolio big data. The hardware equipment of the car to detect the surrounding environment is complicated, and the combination of the convolutional neural network and the camera to detect the surrounding environment has become a research hotspot. However, simply using the convolutional neural network to process the camera data to control the turning angle of the car has the problems of long training time and low accuracy. An improved convolutional neural network is proposed. The experimental results show that the accuracy of data mining by this method is 12.43% and 21.76% higher than that of traditional methods, and the number of iteration steps is shorter, indicating that the timeliness of mining is higher. This network structure can effectively improve the training speed of the network and improve the accuracy of the network. It is proven that the convolutional neural network has faster training speed and higher accuracy.",
        "versions": [],
        "rank": 615
    },
    {
        "authors": [
            "Soha Abd Mohamed El-Moamen",
            "Marghany Hassan Mohamed",
            "Mohammed F. Farghally"
        ],
        "title": "Constructive Learning of Deep Neural Networks for Bigdata Analysis",
        "publication_date": "2020-12-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Association of Technology and Science",
        "volume": "",
        "doi": "10.7753/ijcatr0912.1001",
        "urls": [
            "https://web.archive.org/web/20201211180754/https://ijcat.com/archieve/volume9/issue12/ijcatr09121001.pdf"
        ],
        "id": "id8707802907505197023",
        "abstract": "The need for tracking and evaluation of patients in real-time has contributed to an increase in knowing people's actions to enhance care facilities. Deep learning is good at both a rapid pace in collecting frameworks of big data healthcare and good predictions for detection the lung cancer early. In this paper, we proposed a constructive deep neural network with Apache Spark to classify images and levels of lung cancer. We developed a binary classification model using threshold technique classifying nodules to benign or malignant. At the proposed framework, the neural network models training, defined using the Keras API, is performed using BigDL in a distributed Spark clusters. The proposed algorithm has metrics AUC-0.9810, a misclassifying rate from which it has been shown that our suggested classifiers perform better than other classifiers.",
        "versions": [],
        "rank": 616
    },
    {
        "authors": [
            "Aldea, Emanuel",
            "Bursuc, Andrei",
            "Dubuisson, S\u00e9verine",
            "Filliat, David",
            "Franchi, Gianni",
            "Kazmierczak, R\u00e9mi",
            "Tena, Angel",
            "Yu, Xuanlong"
        ],
        "title": "MUAD: Multiple Uncertainties for Autonomous Driving, a benchmark for  multiple uncertainty types and tasks",
        "publication_date": "2022-10-07 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "http://arxiv.org/abs/2203.01437"
        ],
        "id": "id-4514723057016776432",
        "abstract": "Predictive uncertainty estimation is essential for safe deployment of Deep\nNeural Networks in real-world autonomous systems. However, disentangling the\ndifferent types and sources of uncertainty is non trivial for most datasets,\nespecially since there is no ground truth for uncertainty. In addition, while\nadverse weather conditions of varying intensities can disrupt neural network\npredictions, they are usually under-represented in both training and test sets\nin public datasets.We attempt to mitigate these setbacks and introduce the MUAD\ndataset (Multiple Uncertainties for Autonomous Driving), consisting of 10,413\nrealistic synthetic images with diverse adverse weather conditions (night, fog,\nrain, snow), out-of-distribution objects, and annotations for semantic\nsegmentation, depth estimation, object, and instance detection. MUAD allows to\nbetter assess the impact of different sources of uncertainty on model\nperformance. We conduct a thorough experimental study of this impact on several\nbaseline Deep Neural Networks across multiple tasks, and release our dataset to\nallow researchers to benchmark their algorithm methodically in adverse\nconditions. More visualizations and the download link for MUAD are available at\nhttps://muad-dataset.github.io/.Comment: Accepted at BMVC 202",
        "versions": [],
        "rank": 617
    },
    {
        "authors": [
            "Bargal, Sarah Adel",
            "Kim, Donghyun",
            "Murino, Vittorio",
            "Sclaroff, Stan",
            "Zhang, Jianming",
            "Zunino, Andrea"
        ],
        "title": "Excitation Backprop for RNNs",
        "publication_date": "2018-03-08 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/cvpr.2018.00156",
        "urls": [
            "http://arxiv.org/abs/1711.06778"
        ],
        "id": "id-7777754545663565837",
        "abstract": "Deep models are state-of-the-art for many vision tasks including video action\nrecognition and video captioning. Models are trained to caption or classify\nactivity in videos, but little is known about the evidence used to make such\ndecisions. Grounding decisions made by deep networks has been studied in\nspatial visual content, giving more insight into model predictions for images.\nHowever, such studies are relatively lacking for models of spatiotemporal\nvisual content - videos. In this work, we devise a formulation that\nsimultaneously grounds evidence in space and time, in a single pass, using\ntop-down saliency. We visualize the spatiotemporal cues that contribute to a\ndeep model's classification/captioning output using the model's internal\nrepresentation. Based on these spatiotemporal cues, we are able to localize\nsegments within a video that correspond with a specific action, or phrase from\na caption, without explicitly optimizing/training for these tasks.Comment: CVPR 2018 Camera Ready Versio",
        "versions": [],
        "rank": 618
    },
    {
        "authors": [
            "Andreas Sedlmeier",
            "Thomas Gabor",
            "Thomy Phan",
            "Lenz Belzner",
            "Claudia Linnhoff-Popien"
        ],
        "title": "Uncertainty-Based Out-of-Distribution Detection in Deep Reinforcement Learning",
        "publication_date": "2019-01-08 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20191025111127/https://arxiv.org/pdf/1901.02219v1.pdf"
        ],
        "id": "id-4133346532962390388",
        "abstract": "We consider the problem of detecting out-of-distribution (OOD) samples in deep reinforcement learning. In a value based reinforcement learning setting, we propose to use uncertainty estimation techniques directly on the agent's value estimating neural network to detect OOD samples. The focus of our work lies in analyzing the suitability of approximate Bayesian inference methods and related ensembling techniques that generate uncertainty estimates. Although prior work has shown that dropout-based variational inference techniques and bootstrap-based approaches can be used to model epistemic uncertainty, the suitability for detecting OOD samples in deep reinforcement learning remains an open question. Our results show that uncertainty estimation can be used to differentiate in- from out-of-distribution samples. Over the complete training process of the reinforcement learning agents, bootstrap-based approaches tend to produce more reliable epistemic uncertainty estimates, when compared to dropout-based approaches.",
        "versions": [],
        "rank": 619
    },
    {
        "authors": [
            "Zhang Qianhao",
            "Alexander Mai",
            "Joseph Menke",
            "Allen Yang"
        ],
        "title": "Loop Closure Detection with RGB-D Feature Pyramid Siamese Networks",
        "publication_date": "2018-11-25 03:39:48+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1811.09938v1",
            "http://arxiv.org/abs/1811.09938v1",
            "http://arxiv.org/pdf/1811.09938v1"
        ],
        "id": "id-6964903983188811191",
        "abstract": "In visual Simultaneous Localization And Mapping (SLAM), detecting loop\nclosures has been an important but difficult task. Currently, most solutions\nare based on the bag-of-words approach. Yet the possibility of deep neural\nnetwork application to this task has not been fully explored due to the lack of\nappropriate architecture design and of sufficient training data. In this paper\nwe demonstrate the applicability of deep neural networks by addressing both\nissues. Specifically we show that a feature pyramid Siamese neural network can\nachieve state-of-the-art performance on pairwise loop closure detection. The\nnetwork is trained and tested on large-scale RGB-D datasets with a novel\nautomatic loop closure labeling algorithm. Each image pair is labelled by how\nmuch the images overlap, allowing loop closure to be computed directly rather\nthan by labor intensive manual labeling. We present an algorithm to adopt any\nlarge-scale generic RGB-D dataset for use in training deep loop-closure\nnetworks. We show for the first time that deep neural networks are capable of\ndetecting loop closures, and we provide a method for generating large-scale\ndatasets for use in evaluating and training loop closure detectors.",
        "versions": [],
        "rank": 620
    },
    {
        "authors": [
            "Yi Shi",
            "Kemal Davaslioglu",
            "Yalin E. Sagduyu",
            "William C. Headley, Michael Fowler",
            "Gilbert Green"
        ],
        "title": "Deep Learning for RF Signal Classification in Unknown and Dynamic Spectrum Environments",
        "publication_date": "2019-09-25 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20200930014159/https://arxiv.org/pdf/1909.11800v1.pdf"
        ],
        "id": "id1907455288962783973",
        "abstract": "Dynamic spectrum access (DSA) benefits from detection and classification of interference sources including in-network users, out-network users, and jammers that may all coexist in a wireless network. We present a deep learning based signal (modulation) classification solution in a realistic wireless network setting, where 1) signal types may change over time; 2) some signal types may be unknown for which there is no training data; 3) signals may be spoofed such as the smart jammers replaying other signal types; and 4) different signal types may be superimposed due to the interference from concurrent transmissions. For case 1, we apply continual learning and train a Convolutional Neural Network (CNN) using an Elastic Weight Consolidation (EWC) based loss. For case 2, we detect unknown signals via outlier detection applied to the outputs of convolutional layers using Minimum Covariance Determinant (MCD) and k-means clustering methods. For case 3, we extend the CNN structure to capture phase shifts due to radio hardware effects to identify the spoofing signal sources. For case 4, we apply blind source separation using Independent Component Analysis (ICA) to separate interfering signals. We utilize the signal classification results in a distributed scheduling protocol, where in-network (secondary) users employ signal classification scores to make channel access decisions and share the spectrum with each other while avoiding interference with out-network (primary) users and jammers. Compared with benchmark TDMA-based schemes, we show that distributed scheduling constructed upon signal classification results provides major improvements to in-network user throughput and out-network user success ratio.",
        "versions": [],
        "rank": 621
    },
    {
        "authors": [
            "Ladicky, Lubor",
            "Pollefeys, Marc",
            "Savinov, Nikolay"
        ],
        "title": "Matching neural paths: transfer from recognition to correspondence  search",
        "publication_date": "2017-11-05 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "http://arxiv.org/abs/1705.08272"
        ],
        "id": "id68597935286438187",
        "abstract": "Many machine learning tasks require finding per-part correspondences between\nobjects. In this work we focus on low-level correspondences - a highly\nambiguous matching problem. We propose to use a hierarchical semantic\nrepresentation of the objects, coming from a convolutional neural network, to\nsolve this ambiguity. Training it for low-level correspondence prediction\ndirectly might not be an option in some domains where the ground-truth\ncorrespondences are hard to obtain. We show how transfer from recognition can\nbe used to avoid such training. Our idea is to mark parts as \"matching\" if\ntheir features are close to each other at all the levels of convolutional\nfeature hierarchy (neural paths). Although the overall number of such paths is\nexponential in the number of layers, we propose a polynomial algorithm for\naggregating all of them in a single backward pass. The empirical validation is\ndone on the task of stereo correspondence and demonstrates that we achieve\ncompetitive results among the methods which do not use labeled target domain\ndata.Comment: Accepted at NIPS 201",
        "versions": [],
        "rank": 622
    },
    {
        "authors": [
            "Diaa Badawi",
            "Tuba Ayhan",
            "Sule Ozev",
            "Chengmo Yang",
            "Alex Orailoglu",
            "A. Enis \u00c7etin"
        ],
        "title": "Detecting Gas Vapor Leaks Using Uncalibrated Sensors",
        "publication_date": "2019-08-20 21:38:48+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1908.07619v1",
            "http://arxiv.org/abs/1908.07619v1",
            "http://arxiv.org/pdf/1908.07619v1"
        ],
        "id": "id3371861457297244001",
        "abstract": "Chemical and infra-red sensors generate distinct responses under similar\nconditions because of sensor drift, noise or resolution errors. In this work,\nwe use different time-series data sets obtained by infra-red and E-nose sensors\nin order to detect Volatile Organic Compounds (VOCs) and Ammonia vapor leaks.\nWe process time-series sensor signals using deep neural networks (DNN). Three\nneural network algorithms are utilized for this purpose. Additive neural\nnetworks (termed AddNet) are based on a multiplication-devoid operator and\nconsequently exhibit energy-efficiency compared to regular neural networks. The\nsecond algorithm uses generative adversarial neural networks so as to expose\nthe classifying neural network to more realistic data points in order to help\nthe classifier network to deliver improved generalization. Finally, we use\nconventional convolutional neural networks as a baseline method and compare\ntheir performance with the two aforementioned deep neural network algorithms in\norder to evaluate their effectiveness empirically.",
        "versions": [],
        "rank": 623
    },
    {
        "authors": [
            "Wang, Baoyuan",
            "Wang, Wenping",
            "Wu, Ruobing",
            "Yu, Yizhou"
        ],
        "title": "Harvesting Discriminative Meta Objects with Deep CNN Features for Scene  Classification",
        "publication_date": "2015-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": null,
        "volume": "",
        "doi": "10.1109/iccv.2015.152",
        "urls": [
            "https://core.ac.uk/download/45603302.pdf"
        ],
        "id": "id3982203470851865471",
        "abstract": "Recent work on scene classification still makes use of generic CNN features\nin a rudimentary manner. In this ICCV 2015 paper, we present a novel pipeline\nbuilt upon deep CNN features to harvest discriminative visual objects and parts\nfor scene classification. We first use a region proposal technique to generate\na set of high-quality patches potentially containing objects, and apply a\npre-trained CNN to extract generic deep features from these patches. Then we\nperform both unsupervised and weakly supervised learning to screen these\npatches and discover discriminative ones representing category-specific objects\nand parts. We further apply discriminative clustering enhanced with local CNN\nfine-tuning to aggregate similar objects and parts into groups, called meta\nobjects. A scene image representation is constructed by pooling the feature\nresponse maps of all the learned meta objects at multiple spatial scales. We\nhave confirmed that the scene image representation obtained using this new\npipeline is capable of delivering state-of-the-art performance on two popular\nscene benchmark datasets, MIT Indoor 67~\\cite{MITIndoor67} and\nSun397~\\cite{Sun397}Comment: To Appear in ICCV 201",
        "versions": [],
        "rank": 624
    },
    {
        "authors": [
            "David J. C. MacKay"
        ],
        "title": "Bayesian Interpolation",
        "publication_date": "1992-05-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Neural Computation",
        "volume": "4",
        "doi": "10.1162/neco.1992.4.3.415",
        "urls": [
            "https://openalex.org/W2911546748",
            "https://doi.org/10.1162/neco.1992.4.3.415",
            "https://authors.library.caltech.edu/13792/1/MACnc92a.pdf"
        ],
        "id": "id7702775583051212255",
        "abstract": "",
        "versions": [],
        "rank": 625
    },
    {
        "authors": [
            "Dietmayer, Klaus",
            "Kraus, Florian"
        ],
        "title": "Uncertainty Estimation in One-Stage Object Detection",
        "publication_date": "2020-07-10 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/itsc.2019.8917494",
        "urls": [
            "http://arxiv.org/abs/1905.10296"
        ],
        "id": "id-755224879764532758",
        "abstract": "Environment perception is the task for intelligent vehicles on which all\nsubsequent steps rely. A key part of perception is to safely detect other road\nusers such as vehicles, pedestrians, and cyclists. With modern deep learning\ntechniques huge progress was made over the last years in this field. However\nsuch deep learning based object detection models cannot predict how certain\nthey are in their predictions, potentially hampering the performance of later\nsteps such as tracking or sensor fusion. We present a viable approaches to\nestimate uncertainty in an one-stage object detector, while improving the\ndetection performance of the baseline approach. The proposed model is evaluated\non a large scale automotive pedestrian dataset. Experimental results show that\nthe uncertainty outputted by our system is coupled with detection accuracy and\nthe occlusion level of pedestrians",
        "versions": [],
        "rank": 626
    },
    {
        "authors": [
            "Jing Chen"
        ],
        "title": "DDoS Attack Target Detection based on AM+BPNN",
        "publication_date": "2022-08-20 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Boya Century Publishing",
        "volume": "",
        "doi": "10.54691/sjt.v4i8.1647",
        "urls": [
            "https://web.archive.org/web/20221115045753/https://bcpublication.org/index.php/SJT/article/download/1647/1645"
        ],
        "id": "id5703225626910190996",
        "abstract": "The computer has developed from a single machine to a multi-machine network. The development of the network has penetrated into people's life, and similarly, the problem of network security has also followed. Distributed Denial of Service (DDoS) attack is one of the most popular network attacks at present. How to effectively detect DDoS attack targets and take urgent protective measures has become one of the difficulties in the research community. In this paper, a method of detecting DDoS attacks by using CNN neural network with attention mechanism (AM) is proposed by using the characteristics of a large amount of data in DDoS attacks. The technology used in this method is relatively mature, the implementation is simple, the cost is low, and it has certain practical significance.",
        "versions": [],
        "rank": 627
    },
    {
        "authors": [
            "Fua, Pascal",
            "Lis, Krzysztof",
            "Nakka, Krishna",
            "Salzmann, Mathieu"
        ],
        "title": "Detecting the Unexpected via Image Resynthesis",
        "publication_date": "2019-04-17 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/iccv.2019.00224",
        "urls": [
            "http://arxiv.org/abs/1904.07595"
        ],
        "id": "id2332629502706078710",
        "abstract": "Classical semantic segmentation methods, including the recent deep learning\nones, assume that all classes observed at test time have been seen during\ntraining. In this paper, we tackle the more realistic scenario where unexpected\nobjects of unknown classes can appear at test time. The main trends in this\narea either leverage the notion of prediction uncertainty to flag the regions\nwith low confidence as unknown, or rely on autoencoders and highlight\npoorly-decoded regions. Having observed that, in both cases, the detected\nregions typically do not correspond to unexpected objects, in this paper, we\nintroduce a drastically different strategy: It relies on the intuition that the\nnetwork will produce spurious labels in regions depicting unexpected objects.\nTherefore, resynthesizing the image from the resulting semantic map will yield\nsignificant appearance differences with respect to the input image. In other\nwords, we translate the problem of detecting unknown classes to one of\nidentifying poorly-resynthesized image regions. We show that this outperforms\nboth uncertainty- and autoencoder-based methods",
        "versions": [],
        "rank": 628
    },
    {
        "authors": [
            "Young-Nam Cha",
            "Wooram Choi",
            "Oral Buyukozturk"
        ],
        "title": "Deep Learning-Based Crack Damage Detection Using Convolutional Neural Networks",
        "publication_date": "2017-05-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Computer-aided Civil and Infrastructure Engineering",
        "volume": "32",
        "doi": "10.1111/mice.12263",
        "urls": [
            "https://openalex.org/W2598457882",
            "https://doi.org/10.1111/mice.12263",
            "https://mspace.lib.umanitoba.ca/xmlui/bitstream/1993/35153/1/choi_wooram.pdf"
        ],
        "id": "id-3207437666594285526",
        "abstract": "",
        "versions": [],
        "rank": 629
    },
    {
        "authors": [
            "Shvets, A.",
            "Iglovikov, V.",
            "Rakhlin, A.",
            "Kalinin, A."
        ],
        "title": "Angiodysplasia Detection and Localization Using Deep Convolutional Neural Networks",
        "publication_date": "2018-04-23 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1101/306159",
        "urls": [
            "https://syndication.highwire.org/content/doi/10.1101/306159",
            "http://dx.doi.org/10.1101/306159"
        ],
        "id": "id56852994322667780",
        "abstract": "",
        "versions": [],
        "rank": 630
    },
    {
        "authors": [
            "Arghandeh, Reza",
            "Hamidi, Reza Jalilzadeh",
            "Livani, Hanif",
            "Niazazari, Iman"
        ],
        "title": "Cause Identification of Electromagnetic Transient Events using  Spatiotemporal Feature Learning",
        "publication_date": "2019-03-09 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "http://arxiv.org/abs/1903.04486"
        ],
        "id": "id4760928657495731680",
        "abstract": "This paper presents a spatiotemporal unsupervised feature learning method for\ncause identification of electromagnetic transient events (EMTE) in power grids.\nThe proposed method is formulated based on the availability of\ntime-synchronized high-frequency measurement, and using the convolutional\nneural network (CNN) as the spatiotemporal feature representation along with\nsoftmax function. Despite the existing threshold-based, or energy-based events\nanalysis methods, such as support vector machine (SVM), autoencoder, and\ntapered multi-layer perception (t-MLP) neural network, the proposed feature\nlearning is carried out with respect to both time and space. The effectiveness\nof the proposed feature learning and the subsequent cause identification is\nvalidated through the EMTP simulation of different events such as line\nenergization, capacitor bank energization, lightning, fault, and high-impedance\nfault in the IEEE 30-bus, and the real-time digital simulation (RTDS) of the\nWSCC 9-bus system.Comment: 9 pages, 7 figure",
        "versions": [],
        "rank": 631
    },
    {
        "authors": [
            "Jan Macdonald",
            "Maximilian M\u00e4rz",
            "Luis Oala",
            "Wojciech Samek"
        ],
        "title": "Interval Neural Networks as Instability Detectors for Image Reconstructions",
        "publication_date": "2020-03-27 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20200408072718/https://arxiv.org/pdf/2003.13471v1.pdf"
        ],
        "id": "id-9093611275972028308",
        "abstract": "This work investigates the detection of instabilities that may occur when utilizing deep learning models for image reconstruction tasks. Although neural networks often empirically outperform traditional reconstruction methods, their usage for sensitive medical applications remains controversial. Indeed, in a recent series of works, it has been demonstrated that deep learning approaches are susceptible to various types of instabilities, caused for instance by adversarial noise or out-of-distribution features. It is argued that this phenomenon can be observed regardless of the underlying architecture and that there is no easy remedy. Based on this insight, the present work demonstrates on two use cases how uncertainty quantification methods can be employed as instability detectors. In particular, it is shown that the recently proposed Interval Neural Networks are highly effective in revealing instabilities of reconstructions. Such an ability is crucial to ensure a safe use of deep learning-based methods for medical image reconstruction.",
        "versions": [],
        "rank": 632
    },
    {
        "authors": [
            "Pierre G. B. Moutounet-Cartan"
        ],
        "title": "Deep Convolutional Neural Networks to Diagnose COVID-19 and other Pneumonia Diseases from Posteroanterior Chest X-Rays",
        "publication_date": "2020-05-02 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20200506085738/https://arxiv.org/pdf/2005.00845v1.pdf"
        ],
        "id": "id-3553203334067923518",
        "abstract": "The article explores different deep convolutional neural network architectures trained and tested on posteroanterior chest X-rays of 327 patients who are healthy (152 patients), diagnosed with COVID-19 (125), and other types of pneumonia (48). In particular, this paper looks at the deep convolutional neural networks VGG16 and VGG19, InceptionResNetV2 and InceptionV3, as well as Xception, all followed by a flat multi-layer perceptron and a final 30 is VGG16 with a final 30 Finding, Other Pneumonia). It has an internal cross-validated accuracy of 93.9(\u00b13.4) sensitivity of 96.8(\u00b10.8) are 84.1(\u00b113.5) was Adam with a 1e-4 learning rate, and categorical cross-entropy loss. It is hoped that, once this research will be put to practice in hospitals, healthcare professionals will be able in the medium to long-term to diagnosing through machine learning tools possible pneumonia, and if detected, whether it is linked to a COVID-19 infection, allowing the detection of new possible COVID-19 foyers after the end of possible \"stop-and-go\" lockdowns as expected by until a vaccine is found and widespread. Furthermore, in the short-term, it is hoped practitioners can compare the diagnosis from the deep convolutional neural networks with possible RT-PCR testing results, and if clashing, a Computed Tomography could be performed as they are more accurate in showing COVID-19 pneumonia.",
        "versions": [],
        "rank": 633
    },
    {
        "authors": [
            "Uma S",
            "Umamaheswari S"
        ],
        "title": "A Review on Video Tracking for Multiple Objects in Neural Network",
        "publication_date": "2020-11-10 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "IOS Press",
        "volume": "",
        "doi": "10.3233/apc200175",
        "urls": [
            "https://web.archive.org/web/20210715184826/https://ebooks.iospress.nl/pdf/doi/10.3233/APC200175"
        ],
        "id": "id7374729243526914818",
        "abstract": "Video Multiple Object Detection and Tracking (VMODT) is the current area of research in computer vision which has increased due to the attention of commercial and academic potential it has offered. Multiple Object Tracking (MOT) shares all challenges to be handled such that long time occluded, fully occluded in small object, frequent occlusion in crowd and severely blurred in fast motion in video etc., In this paper, a review on VMODT with various models,approaches and tracking algorithms is carried out. Neural Networks are developed to provide optimal solution in monitoring the regularity, re-identification, predicting the activity and control action of objects in surveillance application. This review work will be helpful for understanding the start-of-art in VMODT, finding the limitation in current algorithm. However, hybriding the different tracking methods will improve the performance and facilitate new approaches in deep learning.",
        "versions": [],
        "rank": 634
    },
    {
        "authors": [
            "Li Yin",
            "Y. M. Zhou"
        ],
        "title": "Life detection strategy based on infrared vision and ultra-wideband radar data fusion",
        "publication_date": "2019-02-28 03:16:42+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1903.01564v2",
            "http://arxiv.org/abs/1903.01564v2",
            "http://arxiv.org/pdf/1903.01564v2"
        ],
        "id": "id6288588413817073849",
        "abstract": "The life detection method based on a single type of information source cannot\nmeet the requirement of post-earthquake rescue due to its limitations in\ndifferent scenes and bad robustness in life detection. This paper proposes a\nmethod based on deep neural network for multi-sensor decision-level fusion\nwhich concludes Convolutional Neural Network and Long Short Term Memory neural\nnetwork (CNN+LSTM). Firstly, we calculate the value of the life detection\nprobability of each sensor with various methods in the same scene\nsimultaneously, which will be gathered to make samples for inputs of the deep\nneural network. Then we use Convolutional Neural Network (CNN) to extract the\ndistribution characteristics of the spatial domain from inputs which is the\ntwo-channel combination of the probability values and the smoothing probability\nvalues of each life detection sensor respectively. Furthermore, the sequence\ntime relationship of the outputs from the last layers will be analyzed with\nLong Short Term Memory (LSTM) layers, then we concatenate the results from\nthree branches of LSTM layers. Finally, two sets of LSTM neural networks that\nis different from the previous layers are used to integrate the three branches\nof the features, and the results of the two classifications are output using\nthe fully connected network with Binary Cross Entropy (BEC) loss function.\nTherefore, the classification results of the life detection can be concluded\naccurately with the proposed algorithm.",
        "versions": [],
        "rank": 635
    },
    {
        "authors": [
            "Inkyu Sa",
            "ZongYuan Ge",
            "Feras Dayoub",
            "B. Upcroft",
            "Tristan Perez",
            "C. McCool"
        ],
        "title": "DeepFruits: A Fruit Detection System Using Deep Neural Networks",
        "publication_date": "2016-08-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Sensors (Basel, Switzerland)",
        "volume": "16",
        "doi": "10.3390/s16081222",
        "urls": [
            "https://www.semanticscholar.org/paper/9397e7acd062245d37350f5c05faf56e9cfae0d6"
        ],
        "id": "id-511745705190616303",
        "abstract": "This paper presents a novel approach to fruit detection using deep convolutional neural networks. The aim is to build an accurate, fast and reliable fruit detection system, which is a vital element of an autonomous agricultural robotic platform; it is a key element for fruit yield estimation and automated harvesting. Recent work in deep neural networks has led to the development of a state-of-the-art object detector termed Faster Region-based CNN (Faster R-CNN). We adapt this model, through transfer learning, for the task of fruit detection using imagery obtained from two modalities: colour (RGB) and Near-Infrared (NIR). Early and late fusion methods are explored for combining the multi-modal (RGB and NIR) information. This leads to a novel multi-modal Faster R-CNN model, which achieves state-of-the-art results compared to prior work with the F1 score, which takes into account both precision and recall performances improving from 0.807 to 0.838 for the detection of sweet pepper. In addition to improved accuracy, this approach is also much quicker to deploy for new fruits, as it requires bounding box annotation rather than pixel-level annotation (annotating bounding boxes is approximately an order of magnitude quicker to perform). The model is retrained to perform the detection of seven fruits, with the entire process taking four hours to annotate and train the new model per fruit.",
        "versions": [],
        "rank": 636
    },
    {
        "authors": [
            "Weilin Cong",
            "Sanyuan Zhao",
            "Hui Tian",
            "Jianbing Shen"
        ],
        "title": "Improved Face Detection and Alignment using Cascade Deep Convolutional Network",
        "publication_date": "2017-07-28 06:07:38+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1707.09364v1",
            "http://arxiv.org/abs/1707.09364v1",
            "http://arxiv.org/pdf/1707.09364v1"
        ],
        "id": "id-8597746327105612634",
        "abstract": "Real-world face detection and alignment demand an advanced discriminative\nmodel to address challenges by pose, lighting and expression. Illuminated by\nthe deep learning algorithm, some convolutional neural networks based face\ndetection and alignment methods have been proposed. Recent studies have\nutilized the relation between face detection and alignment to make models\ncomputationally efficiency, however they ignore the connection between each\ncascade CNNs. In this paper, we propose an structure to propose higher quality\ntraining data for End-to-End cascade network training, which give computers\nmore space to automatic adjust weight parameter and accelerate convergence.\nExperiments demonstrate considerable improvement over existing detection and\nalignment models.",
        "versions": [],
        "rank": 637
    },
    {
        "authors": [
            "Hongruixuan Chen",
            "Chen Wu",
            "Bo Du",
            "Liangpei Zhang"
        ],
        "title": "DSDANet: Deep Siamese Domain Adaptation Convolutional Neural Network for Cross-domain Change Detection",
        "publication_date": "2020-06-16 15:00:54+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2006.09225v1",
            "http://arxiv.org/abs/2006.09225v1",
            "http://arxiv.org/pdf/2006.09225v1"
        ],
        "id": "id3556259928360261465",
        "abstract": "Change detection (CD) is one of the most vital applications in remote\nsensing. Recently, deep learning has achieved promising performance in the CD\ntask. However, the deep models are task-specific and CD data set bias often\nexists, hence it is inevitable that deep CD models would suffer degraded\nperformance after transferring it from original CD data set to new ones, making\nmanually label numerous samples in the new data set unavoidable, which costs a\nlarge amount of time and human labor. How to learn a transferable CD model in\nthe data set with enough labeled data (original domain) but can well detect\nchanges in another data set without labeled data (target domain)? This is\ndefined as the cross-domain change detection problem. In this paper, we propose\na novel deep siamese domain adaptation convolutional neural network (DSDANet)\narchitecture for cross-domain CD. In DSDANet, a siamese convolutional neural\nnetwork first extracts spatial-spectral features from multi-temporal images.\nThen, through multi-kernel maximum mean discrepancy (MK-MMD), the learned\nfeature representation is embedded into a reproducing kernel Hilbert space\n(RKHS), in which the distribution of two domains can be explicitly matched. By\noptimizing the network parameters and kernel coefficients with the source\nlabeled data and target unlabeled data, DSDANet can learn transferrable feature\nrepresentation that can bridge the discrepancy between two domains. To the best\nof our knowledge, it is the first time that such a domain adaptation-based deep\nnetwork is proposed for CD. The theoretical analysis and experimental results\ndemonstrate the effectiveness and potential of the proposed method.",
        "versions": [],
        "rank": 638
    },
    {
        "authors": [
            "T. Khan",
            "S. Naqvi",
            "Muhammad Arsalan",
            "Muhamamd Aurangzeb Khan",
            "H. A. Khan",
            "M. A. Haider"
        ],
        "title": "Exploiting Residual Edge Information in Deep Fully Convolutional Neural Networks For Retinal Vessel Segmentation",
        "publication_date": "2020-07-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/IJCNN48605.2020.9207411",
        "urls": [
            "https://www.semanticscholar.org/paper/e6913f64d5ce387b95b777c797609ef1e7d64e39"
        ],
        "id": "id1149850153516201959",
        "abstract": "Accurate automatic segmentation of the retinal vessels is crucial for early detection and diagnosis of vision-threatening retinal diseases. A new supervised method using a variant of the fully convolutional neural network is pro-posed with the advantages of reduced hyper-parameters, reduced computational/memory requirements, and robust performance in capturing tiny vessel information. The fully convolutional architectures previously employed for vessel segmentation have multiple tunable hyperparameters and difficulty in end-to-end training due to their decoder structure. We resolve this problem by sharing information from the encoder for upsampling at the decoder stage, resulting in a significantly smaller number of tunable parameters and low computational overhead at the train and test stages. Moreover, the need for pre- and post-processing steps are eradicated. Consequently, the detection accuracy is significantly improved with scores of 0.9620, 0.9623, and 0.9620 on DRIVE, STARE, and CHASE_DB1 datasets respectively.",
        "versions": [],
        "rank": 639
    },
    {
        "authors": [
            "Hongruixuan Chen",
            "Chen Wu",
            "Bo Du",
            "Liangepei Zhang"
        ],
        "title": "Deep Siamese Domain Adaptation Convolutional Neural Network for Cross-domain Change Detection in Multispectral Images",
        "publication_date": "2020-04-13 02:15:04+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2004.05745v1",
            "http://arxiv.org/abs/2004.05745v1",
            "http://arxiv.org/pdf/2004.05745v1"
        ],
        "id": "id-1535996031048278125",
        "abstract": "Recently, deep learning has achieved promising performance in the change\ndetection task. However, the deep models are task-specific and data set bias\noften exists, thus it is difficult to transfer a network trained on one\nmulti-temporal data set (source domain) to another multi-temporal data set with\nvery limited (even no) labeled data (target domain). In this paper, we propose\na novel deep siamese domain adaptation convolutional neural network (DSDANet)\narchitecture for cross-domain change detection. In DSDANet, a siamese\nconvolutional neural network first extracts spatial-spectral features from\nmulti-temporal images. Then, through multiple kernel maximum mean discrepancy\n(MK-MMD), the learned feature representation is embedded into a reproducing\nkernel Hilbert space (RKHS), in which the distribution of two domains can be\nexplicitly matched. By optimizing the network parameters and kernel\ncoefficients with the source labeled data and target unlabeled data, the\nDSDANet can learn transferrable feature representation that can bridge the\ndiscrepancy between two domains. To the best of our knowledge, it is the first\ntime that such a domain adaptation-based deep network is proposed for change\ndetection. The theoretical analysis and experimental results demonstrate the\neffectiveness and potential of the proposed method.",
        "versions": [],
        "rank": 640
    },
    {
        "authors": [
            "Matthew Ng",
            "Fumin Guo",
            "Labonny Biswas",
            "Steffen E. Petersen",
            "Stefan K. Piechnik",
            "Stefan Neubauer",
            "Graham Wright"
        ],
        "title": "Estimating Uncertainty in Neural Networks for Cardiac MRI Segmentation: A Benchmark Study",
        "publication_date": "2020-12-31 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20230105054519/https://arxiv.org/pdf/2012.15772v2.pdf"
        ],
        "id": "id-9051295692548708655",
        "abstract": "Convolutional neural networks (CNNs) have demonstrated promise in automated cardiac magnetic resonance imaging segmentation. However, when using CNNs in a large real world dataset, it is important to quantify segmentation uncertainty in order to know which segmentations could be problematic. In this work, we performed a systematic study of Bayesian and non-Bayesian methods for estimating uncertainty in segmentation neural networks. We evaluated Bayes by Backprop (BBB), Monte Carlo (MC) Dropout, and Deep Ensembles in terms of segmentation accuracy, probability calibration, uncertainty on out-of-distribution images, and segmentation quality control. We tested these algorithms on datasets with various distortions and observed that Deep Ensembles outperformed the other methods except for images with heavy noise distortions. For segmentation quality control, we showed that segmentation uncertainty is correlated with segmentation accuracy. With the incorporation of uncertainty estimates, we were able to reduce the percentage of poor segmentation to 5% by flagging 31% to 48% of the most uncertain images for manual review, substantially lower than random review of the results without using neural network uncertainty.",
        "versions": [],
        "rank": 641
    },
    {
        "authors": [
            "Fei Lu",
            "Zhenjiang Shi",
            "Rijian Su",
            "Wei Wang"
        ],
        "title": "Communication Signal Modulation Mechanism Based on Artificial Feature Engineering Deep Neural Network Modulation Identifier",
        "publication_date": "2021-06-18 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Hindawi Limited",
        "volume": "",
        "doi": "10.1155/2021/9988651",
        "urls": [
            "https://web.archive.org/web/20210620031629/https://downloads.hindawi.com/journals/wcmc/2021/9988651.pdf"
        ],
        "id": "id1173304278554220402",
        "abstract": "Based on the characteristics of time domain and frequency domain recognition theory, a recognition scheme is designed to complete the modulation identification of communication signals including 16 analog and digital modulations, involving 10 different eigenvalues in total. In the in-class recognition of FSK signal, feature extraction in frequency domain is carried out, and a statistical algorithm of spectral peak number is proposed. This paper presents a method to calculate the rotation degree of constellation image. By calculating the rotation degree and modifying the clustering radius, the recognition rate of QAM signal is improved significantly. Another commonly used method for calculating the rotation of constellations is based on Radon transform. Compared with the proposed algorithm, the proposed algorithm has lower computational complexity and higher accuracy under certain SNR conditions. In the modulation discriminator of the deep neural network, the spectral features and cumulative features are extracted as inputs, the modified linear elements are used as neuron activation functions, and the cross-entropy is used as loss functions. In the modulation recognitor of deep neural network, deep neural network and cyclic neural network are constructed for modulation recognition of communication signals. The neural network automatic modulation recognizer is implemented on CPU and GPU, which verifies the recognition accuracy of communication signal modulation recognizer based on neural network. The experimental results show that the communication signal modulation recognizer based on artificial neural network has good classification accuracy in both the training set and the test set.",
        "versions": [],
        "rank": 642
    },
    {
        "authors": [
            "Elad Dvash",
            "Yam Peleg",
            "Shay Zucker",
            "Raja Giryes"
        ],
        "title": "Shallow Transits -- Deep Learning II: Identify Individual Exoplanetary Transits in Red Noise using Deep Learning",
        "publication_date": "2022-03-15 15:53:32+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "10.3847/1538-3881/ac5ea2",
        "urls": [
            "http://arxiv.org/pdf/2203.08017v1",
            "http://dx.doi.org/10.3847/1538-3881/ac5ea2",
            "http://arxiv.org/abs/2203.08017v1",
            "http://arxiv.org/pdf/2203.08017v1"
        ],
        "id": "id-7670249010163812813",
        "abstract": "In a previous paper, we have introduced a deep learning neural network that\nshould be able to detect the existence of very shallow periodic planetary\ntransits in the presence of red noise. The network in that feasibility study\nwould not provide any further details about the detected transits. The current\npaper completes this missing part. We present a neural network that tags\nsamples that were obtained during transits. This is essentially similar to the\ntask of identifying the semantic context of each pixel in an image -- an\nimportant task in computer vision, called `semantic segmentation', which is\noften performed by deep neural networks. The neural network we present makes\nuse of novel deep learning concepts such as U-Nets, Generative Adversarial\nNetworks (GAN), and adversarial loss. The resulting segmentation should allow\nfurther studies of the light curves which are tagged as containing transits.\nThis approach towards the detection and study of very shallow transits is bound\nto play a significant role in future space-based transit surveys such as PLATO,\nwhich are specifically aimed to detect those extremely difficult cases of\nlong-period shallow transits. Our segmentation network also adds to the growing\ntoolbox of deep learning approaches which are being increasingly used in the\nstudy of exoplanets, but so far mainly for vetting transits, rather than their\ninitial detection.",
        "versions": [],
        "rank": 643
    },
    {
        "authors": [
            "Damien A. Fair",
            "Alexander L. Cohen",
            "Jonathan D. Power",
            "Nico U.F. Dosenbach",
            "Jessica A. Church",
            "Francis M. Miezin",
            "Bradley L. Schlaggar",
            "Steven E. Petersen"
        ],
        "title": "Functional Brain Networks Develop from a \u201cLocal to Distributed\u201d Organization",
        "publication_date": "2009-05-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "PLOS Computational Biology",
        "volume": "5",
        "doi": "10.1371/journal.pcbi.1000381",
        "urls": [
            "https://openalex.org/W2159549823",
            "https://doi.org/10.1371/journal.pcbi.1000381",
            "https://journals.plos.org/ploscompbiol/article/file?id=10.1371/journal.pcbi.1000381&type=printable"
        ],
        "id": "id2821175129428533315",
        "abstract": "",
        "versions": [],
        "rank": 644
    },
    {
        "authors": [
            "Marios Anthimopoulos",
            "Stergios Christodoulidis",
            "Lukas Ebner",
            "Andreas Christe",
            "Stavroula Mougiakakou"
        ],
        "title": "Lung Pattern Classification for Interstitial Lung Diseases Using a Deep Convolutional Neural Network",
        "publication_date": "2016-02-29 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "IEEE Transactions on Medical Imaging",
        "volume": "35",
        "doi": "10.1109/tmi.2016.2535865",
        "urls": [
            "https://openalex.org/W2323929895",
            "https://doi.org/10.1109/tmi.2016.2535865",
            "https://boris.unibe.ch/94475/1/RSNAartorg2016b.pdf"
        ],
        "id": "id9161777833646252679",
        "abstract": "",
        "versions": [],
        "rank": 645
    },
    {
        "authors": [
            "Hrithika Dodia",
            "Himanshu Tandel",
            "Lynette D'Mello"
        ],
        "title": "SpecGrav -- Detection of Gravitational Waves using Deep Learning",
        "publication_date": "2021-07-08 05:06:34+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2107.03607v1",
            "http://arxiv.org/abs/2107.03607v1",
            "http://arxiv.org/pdf/2107.03607v1"
        ],
        "id": "id-3664888385428332938",
        "abstract": "Gravitational waves are ripples in the fabric of space-time that travel at\nthe speed of light. The detection of gravitational waves by LIGO is a major\nbreakthrough in the field of astronomy. Deep Learning has revolutionized many\nindustries including health care, finance and education. Deep Learning\ntechniques have also been explored for detection of gravitational waves to\novercome the drawbacks of traditional matched filtering method. However, in\nseveral researches, the training phase of neural network is very time consuming\nand hardware devices with large memory are required for the task. In order to\nreduce the extensive amount of hardware resources and time required in training\na neural network for detecting gravitational waves, we made SpecGrav. We use 2D\nConvolutional Neural Network and spectrograms of gravitational waves embedded\nin noise to detect gravitational waves from binary black hole merger and binary\nneutron star merger. The training phase of our neural network was of about just\n19 minutes on a 2GB GPU.",
        "versions": [],
        "rank": 646
    },
    {
        "authors": [
            "Lo\u00efc Cordone",
            "Beno\u00eet Miramond",
            "Philippe Thi\u00e9rion"
        ],
        "title": "Object Detection with Spiking Neural Networks on Automotive Event Data",
        "publication_date": "2022-05-09 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/IJCNN55064.2022.9892618",
        "urls": [
            "https://www.semanticscholar.org/paper/9a5fe0ac9d16df142fdad4b2f129ecd480b2ea7d"
        ],
        "id": "id664059656541485444",
        "abstract": "Automotive embedded algorithms have very high constraints in terms of latency, accuracy and power consumption. In this work, we propose to train spiking neural networks (SNNs) directly on data coming from event cameras to design fast and efficient automotive embedded applications. Indeed, SNNs are more biologically realistic neural networks where neurons communicate using discrete and asynchronous spikes, a naturally energy-efficient and hardware friendly operating mode. Event data, which are binary and sparse in space and time, are therefore the ideal input for spiking neural networks. But to date, their performance was insufficient for automotive real-world problems, such as detecting complex objects in an uncontrolled environment. To address this issue, we took advantage of the latest advancements in matter of spike backpropagation - surrogate gradient learning, parametric LIF, SpikingJelly framework - and of our new voxel cube event encoding to train 4 different SNNs based on popular deep learning networks: SqueezeNet, VGG, MobileNet, and DenseNet. As a result, we managed to increase the size and the complexity of SNNs usually considered in the literature. In this paper, we conducted experiments on two automotive event datasets, establishing new state-of-the-art classification results for spiking neural networks. Based on these results, we combined our SNNs with SSD to propose the first spiking neural networks capable of performing object detection on the complex GEN1 Automotive Detection event dataset.",
        "versions": [],
        "rank": 647
    },
    {
        "authors": [
            "Acciarri, R.",
            "Adams, C.",
            "An, R.",
            "Asaadi, J.",
            "Auger, M.",
            "Bagby, L.",
            "Baller, B.",
            "Barr, G.",
            "Bass, M.",
            "Bay, F.",
            "Bishai, M.",
            "Blake, A.",
            "Bolton, T.",
            "Bugel, L.",
            "Caicedo, D. A. Martinez",
            "Camilleri, L.",
            "Caratelli, D.",
            "Carls, B.",
            "Cavanna, F.",
            "Chen, H.",
            "Church, E.",
            "Cianci, D.",
            "Collin, G. H.",
            "Conrad, J. M.",
            "Convery, M.",
            "Crespo-Anad\u00f3n, J. I.",
            "de Vries, J. Jan",
            "Del Tutto, M.",
            "Devitt, D.",
            "Dytman, S.",
            "Eberly, B.",
            "Ereditato, A.",
            "Esquivel, J.",
            "Fernandez, R. Castillo",
            "Fleming, B. T.",
            "Foreman, W.",
            "Furmanski, A. P.",
            "Garvey, G. T.",
            "Genty, V.",
            "Goeldi, D.",
            "Gollapinni, S.",
            "Graf, N.",
            "Gramellini, E.",
            "Greenlee, H.",
            "Grosso, R.",
            "Guenette, R.",
            "Hackenburg, A.",
            "Hamilton, P.",
            "Hen, O.",
            "Hewes, J.",
            "Hill, C.",
            "Ho, J.",
            "Horton-Smith, G.",
            "James, C.",
            "Jen, C. -M.",
            "Jiang, L.",
            "John, J. St.",
            "Johnson, R. A.",
            "Jones, B. J. P.",
            "Joshi, J.",
            "Jostlein, H.",
            "Kaleko, D.",
            "Karagiorgi, G.",
            "Ketchum, W.",
            "Kirby, B.",
            "Kirby, M.",
            "Kobilarcik, T.",
            "Kreslo, I.",
            "Laube, A.",
            "Li, Y.",
            "Lister, A.",
            "Littlejohn, B. R.",
            "Lockwitz, S.",
            "Lorca, D.",
            "Louis, W. C.",
            "Luethi, M.",
            "Lundberg, B.",
            "Luo, X.",
            "Marchionni, A.",
            "Mariani, C.",
            "Marshall, J.",
            "Meddage, V.",
            "Miceli, T.",
            "MicroBooNE collaboration",
            "Mills, G. B.",
            "Moon, J.",
            "Mooney, M.",
            "Moore, C. D.",
            "Mousseau, J.",
            "Murrells, R.",
            "Naples, D.",
            "Nienaber, P.",
            "Nowak, J.",
            "Palamara, O.",
            "Paolone, V.",
            "Papavassiliou, V.",
            "Pate, S. F.",
            "Pavlovic, Z.",
            "Porzio, D.",
            "Pulliam, G.",
            "Qian, X.",
            "Raaf, J. L.",
            "Rafique, A.",
            "Rochester, L.",
            "Russell, B.",
            "Sanchez, L. Escudero",
            "Schmitz, D. W.",
            "Schukraft, A.",
            "Seligman, W.",
            "Shaevitz, M. H.",
            "Sinclair, J.",
            "Snider, E. L.",
            "Soderberg, M.",
            "Soleti, S. R.",
            "Spentzouris, P.",
            "Spitz, J.",
            "Strauss, T.",
            "Szelc, A. M.",
            "S\u00f6ldner-Rembold, S.",
            "Tagg, N.",
            "Terao, K.",
            "Thomson, M.",
            "Toups, M.",
            "Tsai, Y. -T.",
            "Tufanli, S.",
            "Usher, T.",
            "Van de Water, R. G.",
            "Viren, B.",
            "von Rohr, C. Rudolf",
            "Weber, M.",
            "Weston, J.",
            "Wickremasinghe, D. A.",
            "Wolbers, S.",
            "Wongjirad, T.",
            "Woodruff, K.",
            "Yang, T.",
            "Zeller, G. P.",
            "Zennamo, J.",
            "Zhang, C."
        ],
        "title": "Convolutional Neural Networks Applied to Neutrino Events in a Liquid  Argon Time Projection Chamber",
        "publication_date": "2016-11-16 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1088/1748-0221/12/03/p03011",
        "urls": [
            "http://arxiv.org/abs/1611.05531"
        ],
        "id": "id-2492386450146952900",
        "abstract": "We present several studies of convolutional neural networks applied to data\ncoming from the MicroBooNE detector, a liquid argon time projection chamber\n(LArTPC). The algorithms studied include the classification of single particle\nimages, the localization of single particle and neutrino interactions in an\nimage, and the detection of a simulated neutrino event overlaid with cosmic ray\nbackgrounds taken from real detector data. These studies demonstrate the\npotential of convolutional neural networks for particle identification or event\ndetection on simulated neutrino interactions. We also address technical issues\nthat arise when applying this technique to data from a large LArTPC at or near\nground level",
        "versions": [],
        "rank": 648
    },
    {
        "authors": [
            "Shay Zucker",
            "Raja Giryes"
        ],
        "title": "Shallow Transits\u2014Deep Learning. I. Feasibility Study of Deep Learning to Detect Periodic Transits of Exoplanets",
        "publication_date": "2018-03-12 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "American Astronomical Society",
        "volume": "",
        "doi": "10.3847/1538-3881/aaae05",
        "urls": [
            "https://web.archive.org/web/20200824183400/https://arxiv.org/pdf/1711.03163v1.pdf"
        ],
        "id": "id-3625399094329034904",
        "abstract": "Transits of habitable planets around solar-like stars are expected to be shallow, and to have long periods, which means low information content. The current bottleneck in the detection of such transits is caused in large part by the presence of red (correlated) noise in the light curves obtained from the dedicated space telescopes. Based on the groundbreaking results deep learning achieves in many signal and image processing applications, we propose to use deep neural networks to solve this problem. We present a feasibility study, in which we applied a convolutional neural network on a simulated training set. The training set comprised light curves received from a hypothetical high-cadence space-based telescope. We simulated the red noise by using Gaussian Processes with a wide variety of hyperparameters. We then tested the network on a completely different test set simulated in the same way. Our study proves that very difficult cases can indeed be detected. Furthermore, we show how detection trends can be studied, and detection biases be quantified. We have also checked the robustness of the neural-network performance against practical artifacts such as outliers and discontinuities, which are known to affect space-based high-cadence light curves. Future work will allow us to use the neural networks to characterize the transit model and identify individual transits. This new approach will certainly be an indispensable tool for the detection of habitable planets in the future planet-detection space missions such as PLATO.",
        "versions": [
            {
                "year": 2017,
                "source": "SupportedSources.ARXIV",
                "title": "Shallow Transits - Deep Learning I: Feasibility Study of Deep Learning to Detect Periodic Transits of Exoplanets",
                "journal": null,
                "urls": [
                    "http://arxiv.org/pdf/1711.03163v2",
                    "http://dx.doi.org/10.3847/1538-3881/aaae05",
                    "http://arxiv.org/abs/1711.03163v2",
                    "http://arxiv.org/pdf/1711.03163v2"
                ],
                "doi": "10.3847/1538-3881/aaae05",
                "publication_date": "2017-11-08 21:00:11+00:00"
            }
        ],
        "rank": 649
    },
    {
        "authors": [
            "Max Frei",
            "Frank Einar Kruis"
        ],
        "title": "Image-based size analysis of agglomerated and partially sintered particles via convolutional neural networks",
        "publication_date": "2020-01-15 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Powder Technology",
        "volume": "360",
        "doi": "10.1016/j.powtec.2019.10.020",
        "urls": [
            "https://openalex.org/W2956776787",
            "https://doi.org/10.1016/j.powtec.2019.10.020",
            "http://arxiv.org/pdf/1907.05112"
        ],
        "id": "id2275248373476261932",
        "abstract": "",
        "versions": [],
        "rank": 650
    },
    {
        "authors": [
            "Li Wang",
            "Jun Tang",
            "Q. Liao"
        ],
        "title": "A Study on Radar Target Detection Based on Deep Neural Networks",
        "publication_date": "2019-01-30 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "IEEE Sensors Letters",
        "volume": "3",
        "doi": "10.1109/LSENS.2019.2896072",
        "urls": [
            "https://www.semanticscholar.org/paper/c7530e014b09484b5bde10a3dc41b6609c8918bf"
        ],
        "id": "id-95440456733820850",
        "abstract": "Target detection is one of the most important radar applications widely used in practice. Target detection can be regarded as a kind of classification, which distinguishes whether the signal undertested consists of an echo from a target (target present) or just corresponds to the noise (target absent). The deep neural network (DNN) is a popular topic for classification and has successfully been applied in different fields of science. Recently, many researchers have proposed DNNs for radar applications. In this article, we analyze a possible application of DNN- for target detection in radar, DNN-based detectors are designed, and the performance of the detector is demonstrated by comparison with traditional target detectors.",
        "versions": [],
        "rank": 651
    },
    {
        "authors": [
            "Rui Hou",
            "Chen Chen",
            "Mubarak Shah"
        ],
        "title": "Tube Convolutional Neural Network (T-CNN) for Action Detection in Videos",
        "publication_date": "2017-03-30 20:28:31+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1703.10664v3",
            "http://arxiv.org/abs/1703.10664v3",
            "http://arxiv.org/pdf/1703.10664v3"
        ],
        "id": "id-5480058837134965346",
        "abstract": "Deep learning has been demonstrated to achieve excellent results for image\nclassification and object detection. However, the impact of deep learning on\nvideo analysis (e.g. action detection and recognition) has been limited due to\ncomplexity of video data and lack of annotations. Previous convolutional neural\nnetworks (CNN) based video action detection approaches usually consist of two\nmajor steps: frame-level action proposal detection and association of proposals\nacross frames. Also, these methods employ two-stream CNN framework to handle\nspatial and temporal feature separately. In this paper, we propose an\nend-to-end deep network called Tube Convolutional Neural Network (T-CNN) for\naction detection in videos. The proposed architecture is a unified network that\nis able to recognize and localize action based on 3D convolution features. A\nvideo is first divided into equal length clips and for each clip a set of tube\nproposals are generated next based on 3D Convolutional Network (ConvNet)\nfeatures. Finally, the tube proposals of different clips are linked together\nemploying network flow and spatio-temporal action detection is performed using\nthese linked video proposals. Extensive experiments on several video datasets\ndemonstrate the superior performance of T-CNN for classifying and localizing\nactions in both trimmed and untrimmed videos compared to state-of-the-arts.",
        "versions": [],
        "rank": 652
    },
    {
        "authors": [
            "Mohamad T Sultan",
            "Hesham El Sayed",
            "Manzoor Ahmed Khan"
        ],
        "title": "An Intrusion Detection Mechanism for MANETs Based on Deep Learning Artificial Neural Networks (ANNs)",
        "publication_date": "2023-03-14 21:45:12+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "10.5121/ijcnc.2023.15101",
        "urls": [
            "http://arxiv.org/pdf/2303.08248v1",
            "http://dx.doi.org/10.5121/ijcnc.2023.15101",
            "http://arxiv.org/abs/2303.08248v1",
            "http://arxiv.org/pdf/2303.08248v1"
        ],
        "id": "id5048843258303965529",
        "abstract": "Mobile Ad-hoc Network (MANET) is a distributed, decentralized network of\nwireless portable nodes connecting directly without any fixed communication\nbase station or centralized administration. Nodes in MANET move continuously in\nrandom directions and follow an arbitrary manner, which presents numerous\nchallenges to these networks and make them more susceptible to different\nsecurity threats. Due to this decentralized nature of their overall\narchitecture, combined with the limitation of hardware resources, those\ninfrastructure-less networks are more susceptible to different security attacks\nsuch as black hole attack, network partition, node selfishness, and Denial of\nService (DoS) attacks. This work aims to present, investigate, and design an\nintrusion detection predictive technique for Mobile Ad hoc networks using deep\nlearning artificial neural networks (ANNs). A simulation-based evaluation and a\ndeep ANNs modelling for detecting and isolating a Denial of Service (DoS)\nattack are presented to improve the overall security level of Mobile ad hoc\nnetworks.",
        "versions": [],
        "rank": 653
    },
    {
        "authors": [
            "Asif Iqbal Khan",
            "Junaid Latief Shah",
            "M. Bhat"
        ],
        "title": "CoroNet: A deep neural network for detection and diagnosis of COVID-19 from chest x-ray images",
        "publication_date": "2020-04-10 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Computer Methods and Programs in Biomedicine",
        "volume": "196",
        "doi": "10.1016/j.cmpb.2020.105581",
        "urls": [
            "https://www.semanticscholar.org/paper/3a9b2a9a8127281b86e27ffd75170b93361fa78f"
        ],
        "id": "id-5309197336837049124",
        "abstract": null,
        "versions": [],
        "rank": 654
    },
    {
        "authors": [
            "Mattia Seg\u00f9",
            "Davide Scaramuzza",
            "Antonio Loquercio"
        ],
        "title": "A General Framework for Uncertainty Estimation in Deep Learning",
        "publication_date": "2019-07-16 00:00:00",
        "source": "SupportedSources.PAPERS_WITH_CODE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://arxiv.org/pdf/1907.06890v4.pdf",
            "https://github.com/mattiasegu/uncertainty_estimation_deep_learning"
        ],
        "id": "id8360534160778618137",
        "abstract": "Neural networks predictions are unreliable when the input sample is out of the training distribution or corrupted by noise. Being able to detect such failures automatically is fundamental to integrate deep learning algorithms into robotics. Current approaches for uncertainty estimation of neural networks require changes to the network and optimization process, typically ignore prior knowledge about the data, and tend to make over-simplifying assumptions which underestimate uncertainty. To address these limitations, we propose a novel framework for uncertainty estimation. Based on Bayesian belief networks and Monte-Carlo sampling, our framework not only fully models the different sources of prediction uncertainty, but also incorporates prior data information, e.g. sensor noise. We show theoretically that this gives us the ability to capture uncertainty better than existing methods. In addition, our framework has several desirable properties: (i) it is agnostic to the network architecture and task; (ii) it does not require changes in the optimization process; (iii) it can be applied to already trained architectures. We thoroughly validate the proposed framework through extensive experiments on both computer vision and control tasks, where we outperform previous methods by up to 23% in accuracy.",
        "versions": [],
        "rank": 655
    },
    {
        "authors": [
            "A. Subeesh",
            "S. Bhole",
            "K. Singh",
            "N. S. Chandel",
            "Y. Rajwade",
            "K. Rao",
            "S.P. Kumar",
            "D. Jat"
        ],
        "title": "Deep convolutional neural network models for weed detection in polyhouse grown bell peppers",
        "publication_date": "2022-02-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1016/j.aiia.2022.01.002",
        "urls": [
            "https://www.semanticscholar.org/paper/e31827047d6ffe6f033d033858b0be529b935353"
        ],
        "id": "id-5408226618339504219",
        "abstract": null,
        "versions": [],
        "rank": 656
    },
    {
        "authors": [
            "Rohit Kumar Kaliyar",
            "Anurag Goswami",
            "Pratik Narang"
        ],
        "title": "EchoFakeD: improving fake news detection in social media with an efficient deep neural network",
        "publication_date": "2021-01-02 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Neural Computing & Applications",
        "volume": "33",
        "doi": "10.1007/s00521-020-05611-1",
        "urls": [
            "https://www.semanticscholar.org/paper/84729df1775316bc38c66f423e53a63a3b81fe5d"
        ],
        "id": "id4296794268092948013",
        "abstract": null,
        "versions": [],
        "rank": 657
    },
    {
        "authors": [
            "Yang YANG",
            "Rong CHEN",
            "Xiao BAI",
            "DeHeng CHEN",
            "Y. Ahn",
            "F. Wu"
        ],
        "title": "Finance Fraud Detection With Neural Network",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "EDP Sciences",
        "volume": "",
        "doi": "10.1051/e3sconf/202021403005",
        "urls": [
            "https://web.archive.org/web/20201208143739/https://www.e3s-conferences.org/articles/e3sconf/pdf/2020/74/e3sconf_ebldm2020_03005.pdf"
        ],
        "id": "id3540545018875976592",
        "abstract": "The payment card industry has grown increasingly with the development of online business. However, payment card fraud has become a serious problem around the world. Companies and banks lost huge amounts of dollars annually due to fraud. It is necessary to investigate a learning algorithm to detect fraud in finance transaction automatically. In this paper, we put forward a fraud detection algorithm by using neural network. The neural network model and final result will be described to show the superiority of this model.",
        "versions": [],
        "rank": 658
    },
    {
        "authors": [
            "Patrick O. Glauner"
        ],
        "title": "Deep Convolutional Neural Networks for Smile Recognition",
        "publication_date": "2015-08-26 15:39:09+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1508.06535v1",
            "http://arxiv.org/abs/1508.06535v1",
            "http://arxiv.org/pdf/1508.06535v1"
        ],
        "id": "id-4326423844632163180",
        "abstract": "This thesis describes the design and implementation of a smile detector based\non deep convolutional neural networks. It starts with a summary of neural\nnetworks, the difficulties of training them and new training methods, such as\nRestricted Boltzmann Machines or autoencoders. It then provides a literature\nreview of convolutional neural networks and recurrent neural networks. In order\nto select databases for smile recognition, comprehensive statistics of\ndatabases popular in the field of facial expression recognition were generated\nand are summarized in this thesis. It then proposes a model for smile\ndetection, of which the main part is implemented. The experimental results are\ndiscussed in this thesis and justified based on a comprehensive model selection\nperformed. All experiments were run on a Tesla K40c GPU benefiting from a\nspeedup of up to factor 10 over the computations on a CPU. A smile detection\ntest accuracy of 99.45% is achieved for the Denver Intensity of Spontaneous\nFacial Action (DISFA) database, significantly outperforming existing approaches\nwith accuracies ranging from 65.55% to 79.67%. This experiment is re-run under\nvarious variations, such as retaining less neutral images or only the low or\nhigh intensities, of which the results are extensively compared.",
        "versions": [],
        "rank": 659
    },
    {
        "authors": [
            "Kamil Ciosek",
            "Vincent Fortuin",
            "Ryota Tomioka",
            "Katja Hofmann",
            "Richard E. Turner"
        ],
        "title": "Conservative Uncertainty Estimation By Fitting Prior Networks",
        "publication_date": "2020-04-30 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "International Conference on Learning Representations",
        "volume": "",
        "doi": null,
        "urls": [
            "https://openalex.org/W2996246027"
        ],
        "id": "id8799145032314800676",
        "abstract": "",
        "versions": [],
        "rank": 660
    },
    {
        "authors": [
            "Jiangyi Wang",
            "Xiaoqiang Hua",
            "Xinwu Zeng"
        ],
        "title": "Spectral-Based SPD Matrix Representation for Signal Detection Using a Deep Neutral Network",
        "publication_date": "2020-05-22 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "MDPI AG",
        "volume": "",
        "doi": "10.3390/e22050585",
        "urls": [
            "https://web.archive.org/web/20200528192805/https://res.mdpi.com/d_attachment/entropy/entropy-22-00585/article_deploy/entropy-22-00585.pdf"
        ],
        "id": "id70412025841101374",
        "abstract": "The symmetric positive definite (SPD) matrix has attracted much attention in classification problems because of its remarkable performance, which is due to the underlying structure of the Riemannian manifold with non-negative curvature as well as the use of non-linear geometric metrics, which have a stronger ability to distinguish SPD matrices and reduce information loss compared to the Euclidean metric. In this paper, we propose a spectral-based SPD matrix signal detection method with deep learning that uses time-frequency spectra to construct SPD matrices and then exploits a deep SPD matrix learning network to detect the target signal. Using this approach, the signal detection problem is transformed into a binary classification problem on a manifold to judge whether the input sample has target signal or not. Two matrix models are applied, namely, an SPD matrix based on spectral covariance and an SPD matrix based on spectral transformation. A simulated-signal dataset and a semi-physical simulated-signal dataset are used to demonstrate that the spectral-based SPD matrix signal detection method with deep learning has a gain of 1.7\u20133.3 dB under appropriate conditions. The results show that our proposed method achieves better detection performances than its state-of-the-art spectral counterparts that use convolutional neural networks.",
        "versions": [],
        "rank": 661
    },
    {
        "authors": [
            "Amoli, E.",
            "Arabalibeik, H.",
            "Soleimani, H.",
            "Mahmoudi, T."
        ],
        "title": "Deep convolutional neural networks for filtering out normal frames in reviewing wireless capsule endoscopy videos",
        "publication_date": "2022-07-22 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.21203/rs.3.rs-1827246/v1",
        "urls": [
            "https://www.researchsquare.com/article/rs-1827246/v1",
            "https://www.researchsquare.com/article/rs-1827246/v1.html",
            "http://dx.doi.org/10.21203/rs.3.rs-1827246/v1"
        ],
        "id": "id1290683486271351136",
        "abstract": "",
        "versions": [],
        "rank": 662
    },
    {
        "authors": [
            "Xiaosong Wang",
            "Yifan Peng",
            "Le Lu",
            "Zhiyong Lu",
            "Mohammadhadi Bagheri",
            "David Zhang"
        ],
        "title": "ChestX-Ray8: Hospital-Scale Chest X-Ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases",
        "publication_date": "2017-07-21 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "arXiv (Cornell University)",
        "volume": "",
        "doi": "10.1109/cvpr.2017.369",
        "urls": [
            "https://openalex.org/W3101156210",
            "https://doi.org/10.1109/cvpr.2017.369",
            "http://arxiv.org/pdf/1705.02315"
        ],
        "id": "id862305010374095524",
        "abstract": "",
        "versions": [],
        "rank": 663
    },
    {
        "authors": [
            "Feiyang Cai",
            "Xenofon Koutsoukos"
        ],
        "title": "Real-time Out-of-distribution Detection in Learning-Enabled Cyber-Physical Systems",
        "publication_date": "2020-04-21 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "International Conference on Cyber-Physical Systems",
        "volume": "",
        "doi": "10.1109/iccps48487.2020.00024",
        "urls": [
            "https://openalex.org/W3027099759",
            "https://doi.org/10.1109/iccps48487.2020.00024",
            "http://arxiv.org/pdf/2001.10494"
        ],
        "id": "id-1189867351752031638",
        "abstract": "",
        "versions": [
            {
                "year": 2020,
                "source": "SupportedSources.INTERNET_ARCHIVE",
                "title": "Real-time Out-of-distribution Detection in Learning-Enabled Cyber-Physical Systems",
                "journal": "",
                "urls": [
                    "https://web.archive.org/web/20200321092833/https://arxiv.org/pdf/2001.10494v1.pdf"
                ],
                "doi": "",
                "publication_date": "2020-01-28 00:00:00"
            }
        ],
        "rank": 664
    },
    {
        "authors": [],
        "title": "Video for Breast Mass Detection and Classification Using Deep Convolutional Neural Networks for Radiologist Diagnosis Assistance",
        "publication_date": "None",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/compsac51774.2021.00291/video",
        "urls": [
            "http://dx.doi.org/10.1109/compsac51774.2021.00291/video"
        ],
        "id": "id3692702393157150826",
        "abstract": "",
        "versions": [],
        "rank": 665
    },
    {
        "authors": [
            "Abdulatif, Sherif",
            "Aziz, Fady",
            "Kleiner, Bernhard",
            "Schneider, Urs",
            "Wei, Qian"
        ],
        "title": "Micro-Doppler Based Human-Robot Classification Using Ensemble and Deep  Learning Approaches",
        "publication_date": "2018-02-26 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/radar.2018.8378705",
        "urls": [
            "http://arxiv.org/abs/1711.09177"
        ],
        "id": "id1817617289730198460",
        "abstract": "Radar sensors can be used for analyzing the induced frequency shifts due to\nmicro-motions in both range and velocity dimensions identified as micro-Doppler\n($\\boldsymbol{\\mu}$-D) and micro-Range ($\\boldsymbol{\\mu}$-R), respectively.\nDifferent moving targets will have unique $\\boldsymbol{\\mu}$-D and\n$\\boldsymbol{\\mu}$-R signatures that can be used for target classification.\nSuch classification can be used in numerous fields, such as gait recognition,\nsafety and surveillance. In this paper, a 25 GHz FMCW Single-Input\nSingle-Output (SISO) radar is used in industrial safety for real-time\nhuman-robot identification. Due to the real-time constraint, joint\nRange-Doppler (R-D) maps are directly analyzed for our classification problem.\nFurthermore, a comparison between the conventional classical learning\napproaches with handcrafted extracted features, ensemble classifiers and deep\nlearning approaches is presented. For ensemble classifiers, restructured range\nand velocity profiles are passed directly to ensemble trees, such as gradient\nboosting and random forest without feature extraction. Finally, a Deep\nConvolutional Neural Network (DCNN) is used and raw R-D images are directly fed\ninto the constructed network. DCNN shows a superior performance of 99\\%\naccuracy in identifying humans from robots on a single R-D map.Comment: 6 pages, accepted in IEEE Radar Conference 201",
        "versions": [],
        "rank": 666
    },
    {
        "authors": [
            "Utkarsh Chandra Srivastava",
            "Anshuman Singh",
            "Dr. K. Sree Kumar"
        ],
        "title": "Intracranial Hemorrhage Detection Using Neural Network Based Methods With Federated Learning",
        "publication_date": "2022-03-17 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20220326172025/https://arxiv.org/pdf/2005.08644v3.pdf"
        ],
        "id": "id-3519387402441983742",
        "abstract": "Intracranial hemorrhage, bleeding that occurs inside the cranium, is a serious health problem requiring rapid and often intensive medical treatment. Such a condition is traditionally diagnosed by highly-trained specialists analyzing computed tomography (CT) scan of the patient and identifying the location and type of hemorrhage if one exists. We propose a neural network approach to find and classify the condition based upon the CT scan. The model architecture implements a time distributed convolutional network. We observed accuracy above 92% from such an architecture, provided enough data. We propose further extensions to our approach involving the deployment of federated learning. This would be helpful in pooling learned parameters without violating the inherent privacy of the data involved.",
        "versions": [],
        "rank": 667
    },
    {
        "authors": [
            "Hooman Alavizadeh",
            "Julian Jang-Jaccard",
            "Hootan Alavizadeh"
        ],
        "title": "Deep Q-Learning based Reinforcement Learning Approach for Network Intrusion Detection",
        "publication_date": "2021-11-27 20:18:00+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2111.13978v1",
            "http://arxiv.org/abs/2111.13978v1",
            "http://arxiv.org/pdf/2111.13978v1"
        ],
        "id": "id380575725114547925",
        "abstract": "The rise of the new generation of cyber threats demands more sophisticated\nand intelligent cyber defense solutions equipped with autonomous agents capable\nof learning to make decisions without the knowledge of human experts. Several\nreinforcement learning methods (e.g., Markov) for automated network intrusion\ntasks have been proposed in recent years. In this paper, we introduce a new\ngeneration of network intrusion detection methods that combines a\nQ-learning-based reinforcement learning with a deep-feed forward neural network\nmethod for network intrusion detection. Our proposed Deep Q-Learning (DQL)\nmodel provides an ongoing auto-learning capability for a network environment\nthat can detect different types of network intrusions using an automated\ntrial-error approach and continuously enhance its detection capabilities. We\nprovide the details of fine-tuning different hyperparameters involved in the\nDQL model for more effective self-learning. According to our extensive\nexperimental results based on the NSL-KDD dataset, we confirm that the lower\ndiscount factor which is set as 0.001 under 250 episodes of training yields the\nbest performance results. Our experimental results also show that our proposed\nDQL is highly effective in detecting different intrusion classes and\noutperforms other similar machine learning approaches.",
        "versions": [],
        "rank": 668
    },
    {
        "authors": [
            "Konstantin Dobratulin",
            "Andrey Gaidel",
            "Irina Aupova",
            "Anna Ivleva",
            "Aleksandr Kapishnikov",
            "Pavel Zelter"
        ],
        "title": "The efficiency of deep learning algorithms for detecting anatomical reference points on radiological images of the head profile",
        "publication_date": "2020-05-25 13:51:03+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2005.12110v2",
            "http://arxiv.org/abs/2005.12110v2",
            "http://arxiv.org/pdf/2005.12110v2"
        ],
        "id": "id-7618693095554508137",
        "abstract": "In this article we investigate the efficiency of deep learning algorithms in\nsolving the task of detecting anatomical reference points on radiological\nimages of the head in lateral projection using a fully convolutional neural\nnetwork and a fully convolutional neural network with an extended architecture\nfor biomedical image segmentation - U-Net. A comparison is made for the results\nof detection anatomical reference points for each of the selected neural\nnetwork architectures and their comparison with the results obtained when\northodontists detected anatomical reference points. Based on the obtained\nresults, it was concluded that a U-Net neural network allows performing the\ndetection of anatomical reference points more accurately than a fully\nconvolutional neural network. The results of the detection of anatomical\nreference points by the U-Net neural network are closer to the average results\nof the detection of reference points by a group of orthodontists.",
        "versions": [],
        "rank": 669
    },
    {
        "authors": [
            "Michelucci, U."
        ],
        "title": "Histology Tissue Classification",
        "publication_date": "2019-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-1-4842-4976-5_8",
        "urls": [
            "http://link.springer.com/content/pdf/10.1007/978-1-4842-4976-5_8",
            "http://dx.doi.org/10.1007/978-1-4842-4976-5_8"
        ],
        "id": "id-2324255529434600074",
        "abstract": "",
        "versions": [],
        "rank": 670
    },
    {
        "authors": [
            "Chungjun Lee",
            "Jibum Hong",
            "DongNyeong Heo",
            "Heeyoul Choi"
        ],
        "title": "Sequential Deep Learning Architectures for Anomaly Detection in Virtual Network Function Chains",
        "publication_date": "2021-09-29 08:47:57+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2109.14276v1",
            "http://arxiv.org/abs/2109.14276v1",
            "http://arxiv.org/pdf/2109.14276v1"
        ],
        "id": "id-5847463278732458113",
        "abstract": "Software-defined networking (SDN) and network function virtualization (NFV)\nhave enabled the efficient provision of network service. However, they also\nraised new tasks to monitor and ensure the status of virtualized service, and\nanomaly detection is one of such tasks. There have been many data-driven\napproaches to implement anomaly detection system (ADS) for virtual network\nfunctions in service function chains (SFCs). In this paper, we aim to develop\nmore advanced deep learning models for ADS. Previous approaches used learning\nalgorithms such as random forest (RF), gradient boosting machine (GBM), or deep\nneural networks (DNNs). However, these models have not utilized sequential\ndependencies in the data. Furthermore, they are limited as they can only apply\nto the SFC setting from which they were trained. Therefore, we propose several\nsequential deep learning models to learn time-series patterns and sequential\npatterns of the virtual network functions (VNFs) in the chain with variable\nlengths. As a result, the suggested models improve detection performance and\napply to SFCs with varying numbers of VNFs.",
        "versions": [],
        "rank": 671
    },
    {
        "authors": [
            "Nathan Inkawhich",
            "Eric L. Davis",
            "Matthew Inkawhich",
            "Uttam Majumder",
            "Yi Chen"
        ],
        "title": "Training SAR-ATR Models for Reliable Operation in Open-World Environments",
        "publication_date": "2021-03-25 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
        "volume": "14",
        "doi": "10.1109/jstars.2021.3068944",
        "urls": [
            "https://openalex.org/W3148297393",
            "https://doi.org/10.1109/jstars.2021.3068944",
            "https://ieeexplore.ieee.org/ielx7/4609443/9314330/09387072.pdf"
        ],
        "id": "id-925138109103671682",
        "abstract": "",
        "versions": [],
        "rank": 672
    },
    {
        "authors": [
            "Yusuke Uchida",
            "Yuki Nagai",
            "Shigeyuki Sakazawa",
            "Shin'ichi Satoh"
        ],
        "title": "Embedding Watermarks into Deep Neural Networks",
        "publication_date": "2017-01-15 17:32:02+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": "ICMR '17 Proceedings of the 2017 ACM on International Conference\n  on Multimedia Retrieval Pages 269-277",
        "volume": "",
        "doi": "10.1145/3078971.3078974",
        "urls": [
            "http://arxiv.org/pdf/1701.04082v2",
            "http://dx.doi.org/10.1145/3078971.3078974",
            "http://arxiv.org/abs/1701.04082v2",
            "http://arxiv.org/pdf/1701.04082v2"
        ],
        "id": "id7329925888071111158",
        "abstract": "Deep neural networks have recently achieved significant progress. Sharing\ntrained models of these deep neural networks is very important in the rapid\nprogress of researching or developing deep neural network systems. At the same\ntime, it is necessary to protect the rights of shared trained models. To this\nend, we propose to use a digital watermarking technology to protect\nintellectual property or detect intellectual property infringement of trained\nmodels. Firstly, we formulate a new problem: embedding watermarks into deep\nneural networks. We also define requirements, embedding situations, and attack\ntypes for watermarking to deep neural networks. Secondly, we propose a general\nframework to embed a watermark into model parameters using a parameter\nregularizer. Our approach does not hurt the performance of networks into which\na watermark is embedded. Finally, we perform comprehensive experiments to\nreveal the potential of watermarking to deep neural networks as a basis of this\nnew problem. We show that our framework can embed a watermark in the situations\nof training a network from scratch, fine-tuning, and distilling without hurting\nthe performance of a deep neural network. The embedded watermark does not\ndisappear even after fine-tuning or parameter pruning; the watermark completely\nremains even after removing 65% of parameters were pruned. The implementation\nof this research is: https://github.com/yu4u/dnn-watermark",
        "versions": [],
        "rank": 673
    },
    {
        "authors": [
            "Mingxuan Li",
            "Yuanxun Shao"
        ],
        "title": "Deep Compression of Neural Networks for Fault Detection on Tennessee Eastman Chemical Processes",
        "publication_date": "2021-01-18 10:53:12+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2101.06993v1",
            "http://arxiv.org/abs/2101.06993v1",
            "http://arxiv.org/pdf/2101.06993v1"
        ],
        "id": "id-1497005428748424236",
        "abstract": "Artificial neural network has achieved the state-of-art performance in fault\ndetection on the Tennessee Eastman process, but it often requires enormous\nmemory to fund its massive parameters. In order to implement online real-time\nfault detection, three deep compression techniques (pruning, clustering, and\nquantization) are applied to reduce the computational burden. We have\nextensively studied 7 different combinations of compression techniques, all\nmethods achieve high model compression rates over 64% while maintain high fault\ndetection accuracy. The best result is applying all three techniques, which\nreduces the model sizes by 91.5% and remains a high accuracy over 94%. This\nresult leads to a smaller storage requirement in production environments, and\nmakes the deployment smoother in real world.",
        "versions": [],
        "rank": 674
    },
    {
        "authors": [
            "Jasmine Sekhon",
            "Cody Fleming"
        ],
        "title": "Towards Improved Testing For Deep Learning",
        "publication_date": "2019-02-17 20:25:02+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1902.06320v1",
            "http://arxiv.org/abs/1902.06320v1",
            "http://arxiv.org/pdf/1902.06320v1"
        ],
        "id": "id-7651537981446065091",
        "abstract": "The growing use of deep neural networks in safety-critical applications makes\nit necessary to carry out adequate testing to detect and correct any incorrect\nbehavior for corner case inputs before they can be actually used. Deep neural\nnetworks lack an explicit control-flow structure, making it impossible to apply\nto them traditional software testing criteria such as code coverage. In this\npaper, we examine existing testing methods for deep neural networks, the\nopportunities for improvement and the need for a fast, scalable, generalizable\nend-to-end testing method. We also propose a coverage criterion for deep neural\nnetworks that tries to capture all possible parts of the deep neural network's\nlogic.",
        "versions": [],
        "rank": 675
    },
    {
        "authors": [
            "Muwei Li",
            "Yurui Gao",
            "Fei Gao",
            "Adam K. Anderson",
            "Zhaohua Ding",
            "John C. Gore"
        ],
        "title": "Functional engagement of white matter in resting-state brain networks",
        "publication_date": "2020-10-15 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "NeuroImage",
        "volume": "220",
        "doi": "10.1016/j.neuroimage.2020.117096",
        "urls": [
            "https://openalex.org/W3037496527",
            "https://doi.org/10.1016/j.neuroimage.2020.117096",
            "https://doi.org/10.1016/j.neuroimage.2020.117096"
        ],
        "id": "id-1971986695723605487",
        "abstract": "",
        "versions": [],
        "rank": 676
    },
    {
        "authors": [
            "Subrato Bharati",
            "Prajoy Podder",
            "M. Rubaiyat Hossain Mondal"
        ],
        "title": "Artificial Neural Network Based Breast Cancer Screening: A Comprehensive Review",
        "publication_date": "2020-05-29 17:13:51+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": "International Journal of Computer Information Systems and\n  Industrial Management Applications (ISSN 2150-7988), Volume 12 (2020), pp.\n  125-137",
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2006.01767v1",
            "http://arxiv.org/abs/2006.01767v1",
            "http://arxiv.org/pdf/2006.01767v1"
        ],
        "id": "id8649408521918449832",
        "abstract": "Breast cancer is a common fatal disease for women. Early diagnosis and\ndetection is necessary in order to improve the prognosis of breast cancer\naffected people. For predicting breast cancer, several automated systems are\nalready developed using different medical imaging modalities. This paper\nprovides a systematic review of the literature on artificial neural network\n(ANN) based models for the diagnosis of breast cancer via mammography. The\nadvantages and limitations of different ANN models including spiking neural\nnetwork (SNN), deep belief network (DBN), convolutional neural network (CNN),\nmultilayer neural network (MLNN), stacked autoencoders (SAE), and stacked\nde-noising autoencoders (SDAE) are described in this review. The review also\nshows that the studies related to breast cancer detection applied different\ndeep learning models to a number of publicly available datasets. For comparing\nthe performance of the models, different metrics such as accuracy, precision,\nrecall, etc. were used in the existing studies. It is found that the best\nperformance was achieved by residual neural network (ResNet)-50 and ResNet-101\nmodels of CNN algorithm.",
        "versions": [],
        "rank": 677
    },
    {
        "authors": [
            "T. Wittenberg",
            "Pascal Zobel",
            "Magnus Rathke",
            "S. M\u00fchldorfer"
        ],
        "title": "Computer Aided Detection of Polyps in Whitelight- Colonoscopy Images using Deep Neural Networks",
        "publication_date": "2019-09-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Current Directions in Biomedical Engineering",
        "volume": "5",
        "doi": "10.1515/cdbme-2019-0059",
        "urls": [
            "https://www.semanticscholar.org/paper/f8abbfc481bb29817d021e856b775879476be7a1"
        ],
        "id": "id-9072142310957829333",
        "abstract": "Abstract Early detection of polyps is one central goal of colonoscopic screening programs. To support gastroenterologists during this examination process, deep convolutional neural network can be applied for computer-assisted detection of neoplastic lesions. In this work, a Mask R-CNN architecture was applied. For training and testing, three independent colonoscopy data sets were used, including 2484 HD labelled images with polyps from our clinic, as well as two public image data sets from the MICCAI 2015 polyp detection challenge, consisting of 612 SD and 194 HD labelled images with polyps. After training the deep neural network, best results for the three test data sets were achieved in the range of recall = 0.92, precision = 0.86, F1 = 0.89 (data set A), rec = 0.86, prec = 0.80, F1 = 0.82 (data set B) and rec = 0.83, prec = 0.74, F1 = 0.79 (data set C).",
        "versions": [],
        "rank": 678
    },
    {
        "authors": [
            "Bakewell, Robert",
            "Goh, Vicky",
            "Montana, Giovanni",
            "Pesce, Emanuele",
            "Withey, Samuel",
            "Ypsilantis, Petros-Pavlos"
        ],
        "title": "Learning to detect chest radiographs containing lung nodules using  visual attention networks",
        "publication_date": "2019-02-07 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1016/j.media.2018.12.007",
        "urls": [
            "https://core.ac.uk/download/195275075.pdf"
        ],
        "id": "id8910232630584092443",
        "abstract": "Machine learning approaches hold great potential for the automated detection\nof lung nodules in chest radiographs, but training the algorithms requires vary\nlarge amounts of manually annotated images, which are difficult to obtain. Weak\nlabels indicating whether a radiograph is likely to contain pulmonary nodules\nare typically easier to obtain at scale by parsing historical free-text\nradiological reports associated to the radiographs. Using a repositotory of\nover 700,000 chest radiographs, in this study we demonstrate that promising\nnodule detection performance can be achieved using weak labels through\nconvolutional neural networks for radiograph classification. We propose two\nnetwork architectures for the classification of images likely to contain\npulmonary nodules using both weak labels and manually-delineated bounding\nboxes, when these are available. Annotated nodules are used at training time to\ndeliver a visual attention mechanism informing the model about its localisation\nperformance. The first architecture extracts saliency maps from high-level\nconvolutional layers and compares the estimated position of a nodule against\nthe ground truth, when this is available. A corresponding localisation error is\nthen back-propagated along with the softmax classification error. The second\napproach consists of a recurrent attention model that learns to observe a short\nsequence of smaller image portions through reinforcement learning. When a\nnodule annotation is available at training time, the reward function is\nmodified accordingly so that exploring portions of the radiographs away from a\nnodule incurs a larger penalty. Our empirical results demonstrate the potential\nadvantages of these architectures in comparison to competing methodologies",
        "versions": [],
        "rank": 679
    },
    {
        "authors": [
            "Mohammed Zakariah",
            "R. B",
            "Yousef Ajmi Alotaibi",
            "Yanhui Guo",
            "Kiet Tran-Trung",
            "M. M. Elahi"
        ],
        "title": "An Analytical Study of Speech Pathology Detection Based on MFCC and Deep Neural Networks",
        "publication_date": "2022-04-04 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Computational and Mathematical Methods in Medicine",
        "volume": "2022",
        "doi": "10.1155/2022/7814952",
        "urls": [
            "https://www.semanticscholar.org/paper/89f27f5e6bb265235af3ad101dd8f88798f6eacc"
        ],
        "id": "id-4923138512735851604",
        "abstract": "Diseases of internal organs other than the vocal folds can also affect a person's voice. As a result, voice problems are on the rise, even though they are frequently overlooked. According to a recent study, voice pathology detection systems can successfully help the assessment of voice abnormalities and enable the early diagnosis of voice pathology. For instance, in the early identification and diagnosis of voice problems, the automatic system for distinguishing healthy and diseased voices has gotten much attention. As a result, artificial intelligence-assisted voice analysis brings up new possibilities in healthcare. The work was aimed at assessing the utility of several automatic speech signal analysis methods for diagnosing voice disorders and suggesting a strategy for classifying healthy and diseased voices. The proposed framework integrates the efficacy of three voice characteristics: chroma, mel spectrogram, and mel frequency cepstral coefficient (MFCC). We also designed a deep neural network (DNN) capable of learning from the retrieved data and producing a highly accurate voice-based disease prediction model. The study describes a series of studies using the Saarbruecken Voice Database (SVD) to detect abnormal voices. The model was developed and tested using the vowels /a/, /i/, and /u/ pronounced in high, low, and average pitches. We also maintained the \u201ccontinuous sentence\u201d audio files collected from SVD to select how well the developed model generalizes to completely new data. The highest accuracy achieved was 77.49%, superior to prior attempts in the same domain. Additionally, the model attains an accuracy of 88.01% by integrating speaker gender information. The designed model trained on selected diseases can also obtain a maximum accuracy of 96.77% (cordectomy \u00d7 healthy). As a result, the suggested framework is the best fit for the healthcare industry.",
        "versions": [],
        "rank": 680
    },
    {
        "authors": [
            "Oriol Vinyals",
            "Alexander Toshev",
            "Samy Bengio",
            "Dumitru Erhan"
        ],
        "title": "Show and tell: A neural image caption generator",
        "publication_date": "2015-06-07 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Computer Vision and Pattern Recognition",
        "volume": "",
        "doi": "10.1109/cvpr.2015.7298935",
        "urls": [
            "https://openalex.org/W1895577753",
            "https://doi.org/10.1109/cvpr.2015.7298935",
            "http://arxiv.org/pdf/1411.4555"
        ],
        "id": "id-7343263524776335873",
        "abstract": "",
        "versions": [],
        "rank": 681
    },
    {
        "authors": [],
        "title": "A Deep Learning Approach for the Detection of COVID-19 from Chest X-Ray images using Convolutional Neural Networks",
        "publication_date": "2022-04-19 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.33140/amlai.03.02.01",
        "urls": [
            "http://dx.doi.org/10.33140/amlai.03.02.01"
        ],
        "id": "id1020278522549864290",
        "abstract": "",
        "versions": [],
        "rank": 682
    },
    {
        "authors": [
            "Michael D. Greicius",
            "Benjamin C. Flores",
            "Vinod Menon",
            "Gary H. Glover",
            "H. Brent Solvason",
            "Heather A. Kenna",
            "Allan L. Reiss",
            "Alan F. Schatzberg"
        ],
        "title": "Resting-State Functional Connectivity in Major Depression: Abnormally Increased Contributions from Subgenual Cingulate Cortex and Thalamus",
        "publication_date": "2007-09-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Biological Psychiatry",
        "volume": "62",
        "doi": "10.1016/j.biopsych.2006.09.020",
        "urls": [
            "https://openalex.org/W2095438393",
            "https://doi.org/10.1016/j.biopsych.2006.09.020",
            "https://europepmc.org/articles/pmc2001244?pdf=render"
        ],
        "id": "id3390950566954970381",
        "abstract": "",
        "versions": [],
        "rank": 683
    },
    {
        "authors": [
            "Jiemin Fang",
            "Yuzhu Sun",
            "Kangjian Peng",
            "Qian Zhang",
            "Yuan Li",
            "Wenyu Liu",
            "Xinggang Wang"
        ],
        "title": "Fast Neural Network Adaptation via Parameter Remapping and Architecture Search",
        "publication_date": "2020-01-08 13:45:15+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2001.02525v2",
            "http://arxiv.org/abs/2001.02525v2",
            "http://arxiv.org/pdf/2001.02525v2"
        ],
        "id": "id-4411775596568209961",
        "abstract": "Deep neural networks achieve remarkable performance in many computer vision\ntasks. Most state-of-the-art (SOTA) semantic segmentation and object detection\napproaches reuse neural network architectures designed for image classification\nas the backbone, commonly pre-trained on ImageNet. However, performance gains\ncan be achieved by designing network architectures specifically for detection\nand segmentation, as shown by recent neural architecture search (NAS) research\nfor detection and segmentation. One major challenge though, is that ImageNet\npre-training of the search space representation (a.k.a. super network) or the\nsearched networks incurs huge computational cost. In this paper, we propose a\nFast Neural Network Adaptation (FNA) method, which can adapt both the\narchitecture and parameters of a seed network (e.g. a high performing manually\ndesigned backbone) to become a network with different depth, width, or kernels\nvia a Parameter Remapping technique, making it possible to utilize NAS for\ndetection/segmentation tasks a lot more efficiently. In our experiments, we\nconduct FNA on MobileNetV2 to obtain new networks for both segmentation and\ndetection that clearly out-perform existing networks designed both manually and\nby NAS. The total computation cost of FNA is significantly less than SOTA\nsegmentation/detection NAS approaches: 1737$\\times$ less than DPC, 6.8$\\times$\nless than Auto-DeepLab and 7.4$\\times$ less than DetNAS. The code is available\nat https://github.com/JaminFong/FNA.",
        "versions": [],
        "rank": 684
    },
    {
        "authors": [
            "Elliott, Andrew",
            "Law, Stephen",
            "Russell, Chris"
        ],
        "title": "Explaining Classifiers using Adversarial Perturbations on the Perceptual  Ball",
        "publication_date": "2021-03-30 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "https://core.ac.uk/download/478783368.pdf"
        ],
        "id": "id7147582263741674112",
        "abstract": "We present a simple regularization of adversarial perturbations based upon\nthe perceptual loss. While the resulting perturbations remain imperceptible to\nthe human eye, they differ from existing adversarial perturbations in that they\nare semi-sparse alterations that highlight objects and regions of interest\nwhile leaving the background unaltered. As a semantically meaningful adverse\nperturbations, it forms a bridge between counterfactual explanations and\nadversarial perturbations in the space of images. We evaluate our approach on\nseveral standard explainability benchmarks, namely, weak localization,\ninsertion deletion, and the pointing game demonstrating that perceptually\nregularized counterfactuals are an effective explanation for image-based\nclassifiers.Comment: CVPR 202",
        "versions": [],
        "rank": 685
    },
    {
        "authors": [
            "Dabetwar, S.",
            "Ekwaro-Osire, S.",
            "Dias, J."
        ],
        "title": "Damage Detection of Composite Materials Using Data Fusion With Deep Neural Networks",
        "publication_date": "2021-07-16 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1115/1.0003274v",
        "urls": [
            "http://dx.doi.org/10.1115/1.0003274v"
        ],
        "id": "id-5382138183832206845",
        "abstract": "",
        "versions": [],
        "rank": 686
    },
    {
        "authors": [
            "Medrouk, L.",
            "Pappa, A."
        ],
        "title": "Do Deep Networks Really Need Complex Modules for Multilingual Sentiment Polarity Detection and Domain Classification?",
        "publication_date": "2018-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ijcnn.2018.8489613",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/8465565/8488986/08489613.pdf?arnumber=8489613",
            "http://dx.doi.org/10.1109/ijcnn.2018.8489613"
        ],
        "id": "id-7463125711403836314",
        "abstract": "",
        "versions": [],
        "rank": 687
    },
    {
        "authors": [
            "Marcin Kopaczka",
            "Justus Schock",
            "Dorit Merhof"
        ],
        "title": "Super-realtime facial landmark detection and shape fitting by deep regression of shape model parameters",
        "publication_date": "2019-02-09 17:59:07+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1902.03459v1",
            "http://arxiv.org/abs/1902.03459v1",
            "http://arxiv.org/pdf/1902.03459v1"
        ],
        "id": "id1289443518439219830",
        "abstract": "We present a method for highly efficient landmark detection that combines\ndeep convolutional neural networks with well established model-based fitting\nalgorithms. Motivated by established model-based fitting methods such as active\nshapes, we use a PCA of the landmark positions to allow generative modeling of\nfacial landmarks. Instead of computing the model parameters using iterative\noptimization, the PCA is included in a deep neural network using a novel layer\ntype. The network predicts model parameters in a single forward pass, thereby\nallowing facial landmark detection at several hundreds of frames per second.\nOur architecture allows direct end-to-end training of a model-based landmark\ndetection method and shows that deep neural networks can be used to reliably\npredict model parameters directly without the need for an iterative\noptimization. The method is evaluated on different datasets for facial landmark\ndetection and medical image segmentation. PyTorch code is freely available at\nhttps://github.com/justusschock/shapenet",
        "versions": [],
        "rank": 688
    },
    {
        "authors": [
            "Ravi Bhandari",
            "A. Nambi",
            "V. Padmanabhan",
            "B. Raman"
        ],
        "title": "Driving Lane Detection on Smartphones using Deep Neural Networks",
        "publication_date": "2020-01-17 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "ACM Transactions on Sensor Networks (TOSN)",
        "volume": "16",
        "doi": "10.1145/3358797",
        "urls": [
            "https://www.semanticscholar.org/paper/664408551ec6bac0eba9eacaf5fd7887b94c2b1c"
        ],
        "id": "id1097337348282987356",
        "abstract": "Current smartphone-based navigation applications fail to provide lane-level information due to poor GPS accuracy. Detecting and tracking a vehicle\u2019s lane position on the road assists in lane-level navigation. For instance, it would be important to know whether a vehicle is in the correct lane for safely making a turn, or whether the vehicle\u2019s speed is compliant with a lane-specific speed limit. Recent efforts have used road network information and inertial sensors to estimate lane position. While inertial sensors can detect lane shifts over short windows, it would suffer from error accumulation over time. In this article, we present DeepLane, a system that leverages the back camera of a windshield-mounted smartphone to provide an accurate estimate of the vehicle\u2019s current lane. We employ a deep learning--based technique to classify the vehicle\u2019s lane position. DeepLane does not depend on any infrastructure support such as lane markings and works even when there are no lane markings, a characteristic of many roads in developing regions. We perform extensive evaluation of DeepLane on real-world datasets collected in developed and developing regions. DeepLane can detect a vehicle\u2019s lane position with an accuracy of over 90%, and we have implemented DeepLane as an Android app.",
        "versions": [],
        "rank": 689
    },
    {
        "authors": [
            "Rajiv Bishwokarma",
            "Binay Paudyal",
            "Hitendra Dev Shakya",
            "Pravesh Chapagain",
            "Shirshak Bajgain"
        ],
        "title": "Deep neural network-based automatic system for electricity meter reading in Nepal",
        "publication_date": "2021-01-03 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "figshare",
        "volume": "",
        "doi": "10.6084/m9.figshare.13515128.v1",
        "urls": [
            "https://web.archive.org/web/20210106011827/https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/25934381/RESSD2020_PaperID13.pdf"
        ],
        "id": "id859285470275894410",
        "abstract": "This work proposes a new system that Nepalese energy/utility companies can implement to obtain better accuracy of energy usage scenarios. The proposed system can also be used to reduce undesired non-technical losses in the electricity market. This reduction is achieved by replacing the middle agents with an intelligent system that can identify energy meter readings and calculate accurate billing information correctly. As part of the system, common smartphones are used for taking pictures of energy meters by the owners, who upload them to the central server. The central server then utilizes a deep neural network \u2013 YOLOv3 \u2013 to detect and identify energy meter counters and digits, from which current energy consumption is extracted. This extracted value is then used for calculating the billing information.",
        "versions": [],
        "rank": 690
    },
    {
        "authors": [
            "Adri\u00e0 Recasens",
            "DY Carson Lam",
            "E Decenci\u00e8re",
            "G Quellec",
            "J Amin",
            "L Seoud",
            "MD Abr\u00e0moff",
            "MU Akram",
            "N Ramachandran",
            "P Costa",
            "R Welikala",
            "V Gulshan",
            "Z Wang",
            "Ze Yang"
        ],
        "title": "Combining Fine- and Coarse-Grained Classifiers for Diabetic Retinopathy  Detection",
        "publication_date": "2020-05-28 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-3-030-39343-4_21",
        "urls": [
            "http://arxiv.org/abs/2005.14308"
        ],
        "id": "id-432099541947273459",
        "abstract": "Visual artefacts of early diabetic retinopathy in retinal fundus images are\nusually small in size, inconspicuous, and scattered all over retina. Detecting\ndiabetic retinopathy requires physicians to look at the whole image and fixate\non some specific regions to locate potential biomarkers of the disease.\nTherefore, getting inspiration from ophthalmologist, we propose to combine\ncoarse-grained classifiers that detect discriminating features from the whole\nimages, with a recent breed of fine-grained classifiers that discover and pay\nparticular attention to pathologically significant regions. To evaluate the\nperformance of this proposed ensemble, we used publicly available EyePACS and\nMessidor datasets. Extensive experimentation for binary, ternary and quaternary\nclassification shows that this ensemble largely outperforms individual image\nclassifiers as well as most of the published works in most training setups for\ndiabetic retinopathy detection. Furthermore, the performance of fine-grained\nclassifiers is found notably superior than coarse-grained image classifiers\nencouraging the development of task-oriented fine-grained classifiers modelled\nafter specialist ophthalmologists.Comment: Pages 12, Figures ",
        "versions": [],
        "rank": 691
    },
    {
        "authors": [
            "Amara Dinesh Kumar"
        ],
        "title": "Novel Deep Learning Model for Traffic Sign Detection Using Capsule Networks",
        "publication_date": "2018-05-11 14:34:15+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": "International Journal of Pure and Applied Mathematics Volume 118\n  No. 20 2018, 4543-4548 ISSN: 1314-3395",
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1805.04424v1",
            "http://arxiv.org/abs/1805.04424v1",
            "http://arxiv.org/pdf/1805.04424v1"
        ],
        "id": "id3851137857347411553",
        "abstract": "Convolutional neural networks are the most widely used deep learning\nalgorithms for traffic signal classification till date but they fail to capture\npose, view, orientation of the images because of the intrinsic inability of max\npooling layer.This paper proposes a novel method for Traffic sign detection\nusing deep learning architecture called capsule networks that achieves\noutstanding performance on the German traffic sign dataset.Capsule network\nconsists of capsules which are a group of neurons representing the\ninstantiating parameters of an object like the pose and orientation by using\nthe dynamic routing and route by agreement algorithms.unlike the previous\napproaches of manual feature extraction,multiple deep neural networks with many\nparameters,our method eliminates the manual effort and provides resistance to\nthe spatial variances.CNNs can be fooled easily using various adversary attacks\nand capsule networks can overcome such attacks from the intruders and can offer\nmore reliability in traffic sign detection for autonomous vehicles.Capsule\nnetwork have achieved the state-of-the-art accuracy of 97.6% on German Traffic\nSign Recognition Benchmark dataset (GTSRB).",
        "versions": [],
        "rank": 692
    },
    {
        "authors": [
            "Sharada P. Mohanty",
            "David L. Hughes",
            "Marcel Salath\u00e9"
        ],
        "title": "Using Deep Learning for Image-Based Plant Disease Detection",
        "publication_date": "2016-09-22 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Frontiers in Plant Science",
        "volume": "7",
        "doi": "10.3389/fpls.2016.01419",
        "urls": [
            "https://openalex.org/W2473156356",
            "https://doi.org/10.3389/fpls.2016.01419",
            "https://www.frontiersin.org/articles/10.3389/fpls.2016.01419/pdf"
        ],
        "id": "id1248352105568128181",
        "abstract": "",
        "versions": [],
        "rank": 693
    },
    {
        "authors": [
            "Shuhan Yuan",
            "Xintao Wu",
            "Jun Li",
            "Aidong Lu"
        ],
        "title": "Spectrum-based deep neural networks for fraud detection",
        "publication_date": "2017-06-03 03:08:34+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1706.00891v1",
            "http://arxiv.org/abs/1706.00891v1",
            "http://arxiv.org/pdf/1706.00891v1"
        ],
        "id": "id-7324842084789520892",
        "abstract": "In this paper, we focus on fraud detection on a signed graph with only a\nsmall set of labeled training data. We propose a novel framework that combines\ndeep neural networks and spectral graph analysis. In particular, we use the\nnode projection (called as spectral coordinate) in the low dimensional spectral\nspace of the graph's adjacency matrix as input of deep neural networks.\nSpectral coordinates in the spectral space capture the most useful topology\ninformation of the network. Due to the small dimension of spectral coordinates\n(compared with the dimension of the adjacency matrix derived from a graph),\ntraining deep neural networks becomes feasible. We develop and evaluate two\nneural networks, deep autoencoder and convolutional neural network, in our\nfraud detection framework. Experimental results on a real signed graph show\nthat our spectrum based deep neural networks are effective in fraud detection.",
        "versions": [],
        "rank": 694
    },
    {
        "authors": [
            "Eberz, Simon",
            "Lovisotto, Giulio",
            "Martinovic, Ivan"
        ],
        "title": "Biometric Backdoors: A Poisoning Attack Against Unsupervised Template  Updating",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/eurosp48549.2020.00020",
        "urls": [
            "http://arxiv.org/abs/1905.09162"
        ],
        "id": "id-1375566642298529350",
        "abstract": "In this work, we investigate the concept of biometric backdoors: a template\npoisoning attack on biometric systems that allows adversaries to stealthily and\neffortlessly impersonate users in the long-term by exploiting the template\nupdate procedure. We show that such attacks can be carried out even by\nattackers with physical limitations (no digital access to the sensor) and zero\nknowledge of training data (they know neither decision boundaries nor user\ntemplate). Based on the adversaries' own templates, they craft several\nintermediate samples that incrementally bridge the distance between their own\ntemplate and the legitimate user's. As these adversarial samples are added to\nthe template, the attacker is eventually accepted alongside the legitimate\nuser. To avoid detection, we design the attack to minimize the number of\nrejected samples.\n  We design our method to cope with the weak assumptions for the attacker and\nwe evaluate the effectiveness of this approach on state-of-the-art face\nrecognition pipelines based on deep neural networks. We find that in scenarios\nwhere the deep network is known, adversaries can successfully carry out the\nattack over 70% of cases with less than ten injection attempts. Even in\nblack-box scenarios, we find that exploiting the transferability of adversarial\nsamples from surrogate models can lead to successful attacks in around 15% of\ncases. Finally, we design a poisoning detection technique that leverages the\nconsistent directionality of template updates in feature space to discriminate\nbetween legitimate and malicious updates. We evaluate such a countermeasure\nwith a set of intra-user variability factors which may present the same\ndirectionality characteristics, obtaining equal error rates for the detection\nbetween 7-14% and leading to over 99% of attacks being detected after only two\nsample injections.Comment: 12 page",
        "versions": [],
        "rank": 695
    },
    {
        "authors": [
            "D. Ciresan",
            "A. Giusti",
            "L. Gambardella",
            "J. Schmidhuber"
        ],
        "title": "Mitosis Detection in Breast Cancer Histology Images with Deep Neural Networks",
        "publication_date": "2013-09-22 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention",
        "volume": "16 Pt 2",
        "doi": "10.1007/978-3-642-40763-5_51",
        "urls": [
            "https://www.semanticscholar.org/paper/485f0c988c7a4f9bc0e976c65a5055837091fd39"
        ],
        "id": "id-425864439969981753",
        "abstract": null,
        "versions": [],
        "rank": 696
    },
    {
        "authors": [
            "Karunanithy, G.",
            "Mackenzie, H.",
            "Hansen, D."
        ],
        "title": "Virtual Homonuclear Decoupling in Direct Detection NMR Experiments using Deep Neural Networks",
        "publication_date": "2021-07-09 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.33774/chemrxiv-2021-zs4pl-v2",
        "urls": [
            "https://chemrxiv.org/engage/api-gateway/chemrxiv/assets/orp/resource/item/60e7051e0387b17547ca5aea/original/virtual-homonuclear-decoupling-in-direct-detection-nmr-experiments-using-deep-neural-networks.pdf",
            "http://dx.doi.org/10.33774/chemrxiv-2021-zs4pl-v2"
        ],
        "id": "id-8479723144679125048",
        "abstract": "",
        "versions": [],
        "rank": 697
    },
    {
        "authors": [
            "Karunanithy, G.",
            "Mackenzie, H.",
            "Hansen, F."
        ],
        "title": "Virtual Homonuclear Decoupling in Direct Detection NMR Experiments using Deep Neural Networks",
        "publication_date": "2021-03-24 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.26434/chemrxiv.14269463.v1",
        "urls": [
            "https://chemrxiv.org/engage/api-gateway/chemrxiv/assets/orp/resource/item/60c75696337d6c029ee28e5a/original/virtual-homonuclear-decoupling-in-direct-detection-nmr-experiments-using-deep-neural-networks.pdf",
            "http://dx.doi.org/10.26434/chemrxiv.14269463.v1"
        ],
        "id": "id2326760485290173110",
        "abstract": "",
        "versions": [],
        "rank": 698
    },
    {
        "authors": [
            "Karunanithy, G.",
            "Mackenzie, H.",
            "Hansen, F."
        ],
        "title": "Virtual Homonuclear Decoupling in Direct Detection NMR Experiments using Deep Neural Networks",
        "publication_date": "2021-03-24 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.26434/chemrxiv.14269463",
        "urls": [
            "https://ndownloader.figshare.com/files/27060236",
            "http://dx.doi.org/10.26434/chemrxiv.14269463"
        ],
        "id": "id-1350376865965979819",
        "abstract": "",
        "versions": [],
        "rank": 699
    },
    {
        "authors": [
            "Aman Priyanshu",
            "Sarthak Shastri",
            "Sai Sravan Medicherla"
        ],
        "title": "ARLIF-IDS \u2013 Attention augmented Real-Time Isolation Forest Intrusion Detection System",
        "publication_date": "2022-04-20 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20220426225928/https://arxiv.org/pdf/2204.09737v1.pdf"
        ],
        "id": "id-1051363837515665423",
        "abstract": "Distributed Denial of Service (DDoS) attack is a malicious attempt to disrupt the normal traffic of a targeted server, service or network by overwhelming the target or its surrounding infrastructure with a flood of Internet traffic. Emerging technologies such as the Internet of Things and Software Defined Networking leverage lightweight strategies for the early detection of DDoS attacks. Previous literature demonstrates the utility of lower number of significant features for intrusion detection. Thus, it is essential to have a fast and effective security identification model based on low number of features. In this work, a novel Attention-based Isolation Forest Intrusion Detection System is proposed. The model considerably reduces training time and memory consumption of the generated model. For performance assessment, the model is assessed over two benchmark datasets, the NSL-KDD dataset & the KDDCUP'99 dataset. Experimental results demonstrate that the proposed attention augmented model achieves a significant reduction in execution time, by 91.78%, and an average detection F1-Score of 0.93 on the NSL-KDD and KDDCUP'99 dataset. The results of performance evaluation show that the proposed methodology has low complexity and requires less processing time and computational resources, outperforming other current IDS based on machine learning algorithms.",
        "versions": [],
        "rank": 700
    },
    {
        "authors": [
            "Lucas R. Hofer",
            "Milan Krstaji\u0107",
            "P\u00e9ter Juh\u00e1sz",
            "Anna L. Marchant",
            "Robert P. Smith"
        ],
        "title": "Atom Cloud Detection Using a Deep Neural Network",
        "publication_date": "2020-11-20 18:07:45+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": "Mach. Learn.: Sci. Technol. 2 045008 (2021)",
        "volume": "",
        "doi": "10.1088/2632-2153/abf5ee",
        "urls": [
            "http://arxiv.org/pdf/2011.10536v1",
            "http://dx.doi.org/10.1088/2632-2153/abf5ee",
            "http://arxiv.org/abs/2011.10536v1",
            "http://arxiv.org/pdf/2011.10536v1"
        ],
        "id": "id-629089776096922433",
        "abstract": "We use a deep neural network to detect and place region-of-interest boxes\naround ultracold atom clouds in absorption and fluorescence images---with the\nability to identify and bound multiple clouds within a single image. The neural\nnetwork also outputs segmentation masks that identify the size, shape and\norientation of each cloud from which we extract the clouds' Gaussian\nparameters. This allows 2D Gaussian fits to be reliably seeded thereby enabling\nfully automatic image processing.",
        "versions": [],
        "rank": 701
    },
    {
        "authors": [
            "W. Nicholas Greene",
            "Matthew Giamou",
            "Valentin Peretroukhin",
            "Nicholas Roy",
            "David M. Rosen",
            "Jonathan Kelly"
        ],
        "title": "A Smooth Representation of Belief over SO(3) for Deep Rotation Learning with Uncertainty",
        "publication_date": "2020-06-01 00:00:00",
        "source": "SupportedSources.PAPERS_WITH_CODE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://arxiv.org/pdf/2006.01031v4.pdf",
            "https://github.com/utiasSTARS/bingham-rotation-learning"
        ],
        "id": "id-6228365061699250546",
        "abstract": "Accurate rotation estimation is at the heart of robot perception tasks such as visual odometry and object pose estimation. Deep neural networks have provided a new way to perform these tasks, and the choice of rotation representation is an important part of network design. In this work, we present a novel symmetric matrix representation of the 3D rotation group, SO(3), with two important properties that make it particularly suitable for learned models: (1) it satisfies a smoothness property that improves convergence and generalization when regressing large rotation targets, and (2) it encodes a symmetric Bingham belief over the space of unit quaternions, permitting the training of uncertainty-aware models. We empirically validate the benefits of our formulation by training deep neural rotation regressors on two data modalities. First, we use synthetic point-cloud data to show that our representation leads to superior predictive accuracy over existing representations for arbitrary rotation targets. Second, we use image data collected onboard ground and aerial vehicles to demonstrate that our representation is amenable to an effective out-of-distribution (OOD) rejection technique that significantly improves the robustness of rotation estimates to unseen environmental effects and corrupted input images, without requiring the use of an explicit likelihood loss, stochastic sampling, or an auxiliary classifier. This capability is key for safety-critical applications where detecting novel inputs can prevent catastrophic failure of learned models.",
        "versions": [],
        "rank": 702
    },
    {
        "authors": [
            "Jingwei Li",
            "Bo Sun"
        ],
        "title": "A Network Attack Detection Method Using SDA and Deep Neural Network Based on Internet of Things",
        "publication_date": "2020-06-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "International Journal of Wireless Information Networks",
        "volume": "27",
        "doi": "10.1007/s10776-019-00462-7",
        "urls": [
            "https://www.semanticscholar.org/paper/de370dc3a8fafd10c4f3f73c51fbc9979370da26"
        ],
        "id": "id6859885332418894404",
        "abstract": null,
        "versions": [],
        "rank": 703
    },
    {
        "authors": [
            "Pengcheng Xi",
            "Chang Shu",
            "Rafik Goubran"
        ],
        "title": "Abnormality Detection in Mammography using Deep Convolutional Neural Networks",
        "publication_date": "2018-03-05 20:04:56+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1803.01906v1",
            "http://arxiv.org/abs/1803.01906v1",
            "http://arxiv.org/pdf/1803.01906v1"
        ],
        "id": "id8164777875576258276",
        "abstract": "Breast cancer is the most common cancer in women worldwide. The most common\nscreening technology is mammography. To reduce the cost and workload of\nradiologists, we propose a computer aided detection approach for classifying\nand localizing calcifications and masses in mammogram images. To improve on\nconventional approaches, we apply deep convolutional neural networks (CNN) for\nautomatic feature learning and classifier building. In computer-aided\nmammography, deep CNN classifiers cannot be trained directly on full mammogram\nimages because of the loss of image details from resizing at input layers.\nInstead, our classifiers are trained on labelled image patches and then adapted\nto work on full mammogram images for localizing the abnormalities.\nState-of-the-art deep convolutional neural networks are compared on their\nperformance of classifying the abnormalities. Experimental results indicate\nthat VGGNet receives the best overall accuracy at 92.53\\% in classifications.\nFor localizing abnormalities, ResNet is selected for computing class activation\nmaps because it is ready to be deployed without structural change or further\ntraining. Our approach demonstrates that deep convolutional neural network\nclassifiers have remarkable localization capabilities despite no supervision on\nthe location of abnormalities is provided.",
        "versions": [],
        "rank": 704
    },
    {
        "authors": [
            "Balazs Harangi"
        ],
        "title": "Skin lesion detection based on an ensemble of deep convolutional neural network",
        "publication_date": "2017-05-09 14:43:52+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "10.1016/j.jbi.2018.08.006",
        "urls": [
            "http://arxiv.org/pdf/1705.03360v1",
            "http://dx.doi.org/10.1016/j.jbi.2018.08.006",
            "http://arxiv.org/abs/1705.03360v1",
            "http://arxiv.org/pdf/1705.03360v1"
        ],
        "id": "id4920064382753582878",
        "abstract": "Skin cancer is a major public health problem, with over 5 million newly\ndiagnosed cases in the United States each year. Melanoma is the deadliest form\nof skin cancer, responsible for over 9,000 deaths each year. In this paper, we\npropose an ensemble of deep convolutional neural networks to classify\ndermoscopy images into three classes. To achieve the highest classification\naccuracy, we fuse the outputs of the softmax layers of four different neural\narchitectures. For aggregation, we consider the individual accuracies of the\nnetworks weighted by the confidence values provided by their final softmax\nlayers. This fusion-based approach outperformed all the individual neural\nnetworks regarding classification accuracy.",
        "versions": [],
        "rank": 705
    },
    {
        "authors": [
            "Soubarna Banik",
            "Mikko Lauri",
            "Simone Frintrop"
        ],
        "title": "Multi-label Object Attribute Classification using a Convolutional Neural Network",
        "publication_date": "2018-11-10 20:27:59+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1811.04309v1",
            "http://arxiv.org/abs/1811.04309v1",
            "http://arxiv.org/pdf/1811.04309v1"
        ],
        "id": "id-3302361604964661907",
        "abstract": "Objects of different classes can be described using a limited number of\nattributes such as color, shape, pattern, and texture. Learning to detect\nobject attributes instead of only detecting objects can be helpful in dealing\nwith a priori unknown objects. With this inspiration, a deep convolutional\nneural network for low-level object attribute classification, called the Deep\nAttribute Network (DAN), is proposed. Since object features are implicitly\nlearned by object recognition networks, one such existing network is modified\nand fine-tuned for developing DAN. The performance of DAN is evaluated on the\nImageNet Attribute and a-Pascal datasets. Experiments show that in comparison\nwith state-of-the-art methods, the proposed model achieves better results.",
        "versions": [],
        "rank": 706
    },
    {
        "authors": [
            "Maoguo Gong",
            "Jiaojiao Zhao",
            "Jia Liu",
            "Q. Miao",
            "L. Jiao"
        ],
        "title": "Change Detection in Synthetic Aperture Radar Images Based on Deep Neural Networks",
        "publication_date": "None",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "IEEE Transactions on Neural Networks and Learning Systems",
        "volume": "27",
        "doi": "10.1109/TNNLS.2015.2435783",
        "urls": [
            "https://www.semanticscholar.org/paper/d1cbceec6bf279ea473dc950e049cb99088711f9"
        ],
        "id": "id-7009059772736591816",
        "abstract": "This paper presents a novel change detection approach for synthetic aperture radar images based on deep learning. The approach accomplishes the detection of the changed and unchanged areas by designing a deep neural network. The main guideline is to produce a change detection map directly from two images with the trained deep neural network. The method can omit the process of generating a difference image (DI) that shows difference degrees between multitemporal synthetic aperture radar images. Thus, it can avoid the effect of the DI on the change detection results. The learning algorithm for deep architectures includes unsupervised feature learning and supervised fine-tuning to complete classification. The unsupervised feature learning aims at learning the representation of the relationships between the two images. In addition, the supervised fine-tuning aims at learning the concepts of the changed and unchanged pixels. Experiments on real data sets and theoretical analysis indicate the advantages, feasibility, and potential of the proposed method. Moreover, based on the results achieved by various traditional algorithms, respectively, deep learning can further improve the detection performance.",
        "versions": [],
        "rank": 707
    },
    {
        "authors": [
            "Salman Hameed Khan",
            "Xuming He",
            "F. Porikli",
            "Bennamoun"
        ],
        "title": "Forest Change Detection in Incomplete Satellite Images With Deep Neural Networks",
        "publication_date": "2017-06-14 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "IEEE Transactions on Geoscience and Remote Sensing",
        "volume": "55",
        "doi": "10.1109/TGRS.2017.2707528",
        "urls": [
            "https://www.semanticscholar.org/paper/46b8911cbc37a09245ae9686b2c2228ffa585ff1"
        ],
        "id": "id2456569270279223071",
        "abstract": "Land cover change monitoring is an important task from the perspective of regional resource monitoring, disaster management, land development, and environmental planning. In this paper, we analyze imagery data from remote sensing satellites to detect forest cover changes over a period of 29 years (1987\u20132015). Since the original data are severely incomplete and contaminated with artifacts, we first devise a spatiotemporal inpainting mechanism to recover the missing surface reflectance information. The spatial filling process makes use of the available data of the nearby temporal instances followed by a sparse encoding-based reconstruction. We formulate the change detection task as a region classification problem. We build a multiresolution profile (MRP) of the target area and generate a candidate set of bounding-box proposals that enclose potential change regions. In contrast to existing methods that use handcrafted features, we automatically learn region representations using a deep neural network in a data-driven fashion. Based on these highly discriminative representations, we determine forest changes and predict their onset and offset timings by labeling the candidate set of proposals. Our approach achieves the state-of-the-art average patch classification rate of 91.6% (an improvement of ~16%) and the mean onset/offset prediction error of 4.9 months (an error reduction of five months) compared with a strong baseline. We also qualitatively analyze the detected changes in the unlabeled image regions, which demonstrate that the proposed forest change detection approach is scalable to new regions.",
        "versions": [],
        "rank": 708
    },
    {
        "authors": [
            "D Cire\u015fan",
            "DC Cire\u015fan",
            "EC Mommers",
            "HR Roth",
            "M Veta",
            "M Veta",
            "P Kronqvist"
        ],
        "title": "Cutting out the middleman: measuring nuclear area in histopathology  slides without segmentation",
        "publication_date": "2016-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": null,
        "volume": "",
        "doi": "10.1007/978-3-319-46723-8_73",
        "urls": [
            "http://arxiv.org/abs/1606.06127"
        ],
        "id": "id-672741285553964644",
        "abstract": "The size of nuclei in histological preparations from excised breast tumors is\npredictive of patient outcome (large nuclei indicate poor outcome).\nPathologists take into account nuclear size when performing breast cancer\ngrading. In addition, the mean nuclear area (MNA) has been shown to have\nindependent prognostic value. The straightforward approach to measuring nuclear\nsize is by performing nuclei segmentation. We hypothesize that given an image\nof a tumor region with known nuclei locations, the area of the individual\nnuclei and region statistics such as the MNA can be reliably computed directly\nfrom the image data by employing a machine learning model, without the\nintermediate step of nuclei segmentation. Towards this goal, we train a deep\nconvolutional neural network model that is applied locally at each nucleus\nlocation, and can reliably measure the area of the individual nuclei and the\nMNA. Furthermore, we show how such an approach can be extended to perform\ncombined nuclei detection and measurement, which is reminiscent of\ngranulometry.Comment: Conditionally accepted for MICCAI 201",
        "versions": [],
        "rank": 709
    },
    {
        "authors": [
            "Mohammad Javad Shafiee",
            "Brendan Chwyl",
            "Francis Li",
            "Rongyan Chen",
            "Michelle Karg",
            "Christian Scharfenberger",
            "Alexander Wong"
        ],
        "title": "StressedNets: Efficient Feature Representations via Stress-induced Evolutionary Synthesis of Deep Neural Networks",
        "publication_date": "2018-01-16 17:47:13+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1801.05387v1",
            "http://arxiv.org/abs/1801.05387v1",
            "http://arxiv.org/pdf/1801.05387v1"
        ],
        "id": "id-1878245848298752407",
        "abstract": "The computational complexity of leveraging deep neural networks for\nextracting deep feature representations is a significant barrier to its\nwidespread adoption, particularly for use in embedded devices. One particularly\npromising strategy to addressing the complexity issue is the notion of\nevolutionary synthesis of deep neural networks, which was demonstrated to\nsuccessfully produce highly efficient deep neural networks while retaining\nmodeling performance. Here, we further extend upon the evolutionary synthesis\nstrategy for achieving efficient feature extraction via the introduction of a\nstress-induced evolutionary synthesis framework, where stress signals are\nimposed upon the synapses of a deep neural network during training to induce\nstress and steer the synthesis process towards the production of more efficient\ndeep neural networks over successive generations and improved model fidelity at\na greater efficiency. The proposed stress-induced evolutionary synthesis\napproach is evaluated on a variety of different deep neural network\narchitectures (LeNet5, AlexNet, and YOLOv2) on different tasks (object\nclassification and object detection) to synthesize efficient StressedNets over\nmultiple generations. Experimental results demonstrate the efficacy of the\nproposed framework to synthesize StressedNets with significant improvement in\nnetwork architecture efficiency (e.g., 40x for AlexNet and 33x for YOLOv2) and\nspeed improvements (e.g., 5.5x inference speed-up for YOLOv2 on an Nvidia Tegra\nX1 mobile processor).",
        "versions": [],
        "rank": 710
    },
    {
        "authors": [
            "Cao Vu Dung",
            "Hidehiko Sekiya",
            "Suichi Hirano",
            "Takayuki Okatani",
            "C. Miki"
        ],
        "title": "A vision-based method for crack detection in gusset plate welded joints of steel bridges using deep convolutional neural networks",
        "publication_date": "2019-06-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1016/J.AUTCON.2019.02.013",
        "urls": [
            "https://www.semanticscholar.org/paper/bb6a35307105f43c6051bd6819f7a97605e3f60e"
        ],
        "id": "id-4746433683093511951",
        "abstract": null,
        "versions": [],
        "rank": 711
    },
    {
        "authors": [
            "Pengkun Liu",
            "H. Chi",
            "Xiao Li",
            "Jingjing Guo"
        ],
        "title": "Effects of dataset characteristics on the performance of fatigue detection for crane operators using hybrid deep neural networks",
        "publication_date": "2021-12-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1016/j.autcon.2021.103901",
        "urls": [
            "https://www.semanticscholar.org/paper/2e76ef17f334053b6ccf7606bda9a14f1364815c"
        ],
        "id": "id-3914557758588795162",
        "abstract": null,
        "versions": [],
        "rank": 712
    },
    {
        "authors": [
            "Shraddha Mane",
            "Dattaraj Rao"
        ],
        "title": "Explaining Network Intrusion Detection System Using Explainable AI Framework",
        "publication_date": "2021-03-12 07:15:09+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2103.07110v1",
            "http://arxiv.org/abs/2103.07110v1",
            "http://arxiv.org/pdf/2103.07110v1"
        ],
        "id": "id7064236963338713811",
        "abstract": "Cybersecurity is a domain where the data distribution is constantly changing\nwith attackers exploring newer patterns to attack cyber infrastructure.\nIntrusion detection system is one of the important layers in cyber safety in\ntoday's world. Machine learning based network intrusion detection systems\nstarted showing effective results in recent years. With deep learning models,\ndetection rates of network intrusion detection system are improved. More\naccurate the model, more the complexity and hence less the interpretability.\nDeep neural networks are complex and hard to interpret which makes difficult to\nuse them in production as reasons behind their decisions are unknown. In this\npaper, we have used deep neural network for network intrusion detection and\nalso proposed explainable AI framework to add transparency at every stage of\nmachine learning pipeline. This is done by leveraging Explainable AI algorithms\nwhich focus on making ML models less of black boxes by providing explanations\nas to why a prediction is made. Explanations give us measurable factors as to\nwhat features influence the prediction of a cyberattack and to what degree.\nThese explanations are generated from SHAP, LIME, Contrastive Explanations\nMethod, ProtoDash and Boolean Decision Rules via Column Generation. We apply\nthese approaches to NSL KDD dataset for intrusion detection system and\ndemonstrate results.",
        "versions": [],
        "rank": 713
    },
    {
        "authors": [
            "J. Yu",
            "Yunhe Hou",
            "V. Li"
        ],
        "title": "Online False Data Injection Attack Detection With Wavelet Transform and Deep Neural Networks",
        "publication_date": "2018-04-10 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "IEEE Transactions on Industrial Informatics",
        "volume": "14",
        "doi": "10.1109/TII.2018.2825243",
        "urls": [
            "https://www.semanticscholar.org/paper/bf599a6863c524dda9a1b6dbc5ecbb2e31e556a4"
        ],
        "id": "id8536992208408925760",
        "abstract": "State estimation is critical to the operation and control of modern power systems. However, many cyber-attacks, such as false data injection attacks, can circumvent conventional detection methods and interfere the normal operation of grids. While there exists research focusing on detecting such attacks in dc state estimation, attack detection in ac systems is also critical, since ac state estimation is more widely employed in power utilities. In this paper, we propose a new false data injection attack detection mechanism for ac state estimation. When malicious data are injected in the state vectors, their spatial and temporal data correlations may deviate from those in normal operating conditions. The proposed mechanism can effectively capture such inconsistency by analyzing temporally consecutive estimated system states using wavelet transform and deep neural network techniques. We assess the performance of the proposed mechanism with comprehensive case studies on IEEE 118- and 300-bus power systems. The results indicate that the mechanism can achieve a satisfactory attack detection accuracy. Furthermore, we conduct a preliminary sensitivity test on the control parameters of the proposed mechanism.",
        "versions": [],
        "rank": 714
    },
    {
        "authors": [
            "Goodfellow Ian",
            "Goodfellow Ian J.",
            "Oord Aaron Van",
            "Simonyan Karen"
        ],
        "title": "SINVAD: Search-based Image Space Navigation for DNN Image Classifier  Test Input Generation",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1145/3387940.3391456",
        "urls": [
            "http://arxiv.org/abs/2005.09296"
        ],
        "id": "id-3650631733107908448",
        "abstract": "The testing of Deep Neural Networks (DNNs) has become increasingly important\nas DNNs are widely adopted by safety critical systems. While many test adequacy\ncriteria have been suggested, automated test input generation for many types of\nDNNs remains a challenge because the raw input space is too large to randomly\nsample or to navigate and search for plausible inputs. Consequently, current\ntesting techniques for DNNs depend on small local perturbations to existing\ninputs, based on the metamorphic testing principle. We propose new ways to\nsearch not over the entire image space, but rather over a plausible input space\nthat resembles the true training distribution. This space is constructed using\nVariational Autoencoders (VAEs), and navigated through their latent vector\nspace. We show that this space helps efficiently produce test inputs that can\nreveal information about the robustness of DNNs when dealing with realistic\ntests, opening the field to meaningful exploration through the space of highly\nstructured images",
        "versions": [],
        "rank": 715
    },
    {
        "authors": [],
        "title": "Virtual Homonuclear Decoupling in Direct Detection Nuclear Magnetic Resonance Experiments Using Deep Neural Networks",
        "publication_date": "None",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1021/jacs.1c04010.s001",
        "urls": [
            "http://dx.doi.org/10.1021/jacs.1c04010.s001"
        ],
        "id": "id4727286261443786482",
        "abstract": "",
        "versions": [],
        "rank": 716
    },
    {
        "authors": [
            "Andre Esteva",
            "Brett Kuprel",
            "Roberto A. Novoa",
            "Justin Sangwook Ko",
            "Susan M. Swetter",
            "Helen M. Blau",
            "Sebastian Thrun"
        ],
        "title": "Dermatologist-level classification of skin cancer with deep neural networks",
        "publication_date": "2017-02-02 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Nature",
        "volume": "542",
        "doi": "10.1038/nature21056",
        "urls": [
            "https://openalex.org/W2581082771",
            "https://doi.org/10.1038/nature21056",
            "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8382232"
        ],
        "id": "id-4103642583874270407",
        "abstract": "",
        "versions": [],
        "rank": 717
    },
    {
        "authors": [
            "Patira, Samkit"
        ],
        "title": "Over speed detection using Artificial Intelligence",
        "publication_date": "2019-05-22 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "https://core.ac.uk/download/215423169.pdf"
        ],
        "id": "id825900129660411289",
        "abstract": "Over speeding is one of the most common traffic violations. Around 41 million people are issued speeding tickets each year in USA i.e one every second. Existing approaches to detect over- speeding are not scalable and require manual efforts. In this project, by the use of computer vision and artificial intelligence, I have tried to detect over speeding and report the violation to the law enforcement officer. It was observed that when predictions are done using YoloV3, we get the best results",
        "versions": [],
        "rank": 718
    },
    {
        "authors": [
            "Dorjan Hitaj",
            "Luigi V. Mancini"
        ],
        "title": "Have You Stolen My Model? Evasion Attacks Against Deep Neural Network Watermarking Techniques",
        "publication_date": "2018-09-03 14:25:46+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1809.00615v1",
            "http://arxiv.org/abs/1809.00615v1",
            "http://arxiv.org/pdf/1809.00615v1"
        ],
        "id": "id3486075379177817710",
        "abstract": "Deep neural networks have had enormous impact on various domains of computer\nscience, considerably outperforming previous state of the art machine learning\ntechniques. To achieve this performance, neural networks need large quantities\nof data and huge computational resources, which heavily increases their\nconstruction costs. The increased cost of building a good deep neural network\nmodel gives rise to a need for protecting this investment from potential\ncopyright infringements. Legitimate owners of a machine learning model want to\nbe able to reliably track and detect a malicious adversary that tries to steal\nthe intellectual property related to the model. Recently, this problem was\ntackled by introducing in deep neural networks the concept of watermarking,\nwhich allows a legitimate owner to embed some secret information(watermark) in\na given model. The watermark allows the legitimate owner to detect copyright\ninfringements of his model. This paper focuses on verifying the robustness and\nreliability of state-of- the-art deep neural network watermarking schemes. We\nshow that, a malicious adversary, even in scenarios where the watermark is\ndifficult to remove, can still evade the verification by the legitimate owners,\nthus avoiding the detection of model theft.",
        "versions": [],
        "rank": 719
    },
    {
        "authors": [
            "A Victor",
            "AF Jerant",
            "BM Devassy",
            "F Nachbar",
            "L Yu",
            "M Ruela",
            "MH Jafari",
            "N Nida",
            "S Bakheet",
            "V Yadav"
        ],
        "title": "Analyzing Digital Image by Deep Learning for Melanoma Diagnosis",
        "publication_date": "2019-06-19 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-3-030-20518-8_23",
        "urls": [
            "https://core.ac.uk/download/214844823.pdf"
        ],
        "id": "id-283820439123531613",
        "abstract": "Image classi cation is an important task in many medical\r\napplications, in order to achieve an adequate diagnostic of di erent le-\r\nsions. Melanoma is a frequent kind of skin cancer, which most of them\r\ncan be detected by visual exploration. Heterogeneity and database size\r\nare the most important di culties to overcome in order to obtain a good\r\nclassi cation performance. In this work, a deep learning based method\r\nfor accurate classi cation of wound regions is proposed. Raw images are\r\nfed into a Convolutional Neural Network (CNN) producing a probability\r\nof being a melanoma or a non-melanoma. Alexnet and GoogLeNet were\r\nused due to their well-known e ectiveness. Moreover, data augmentation\r\nwas used to increase the number of input images. Experiments show that\r\nthe compared models can achieve high performance in terms of mean ac-\r\ncuracy with very few data and without any preprocessing.Universidad de M\u00e1laga. Campus de Excelencia Internacional Andaluc\u00eda Tech",
        "versions": [],
        "rank": 720
    },
    {
        "authors": [
            "Zhe Cao",
            "Gines Hidalgo",
            "Tomas Simon",
            "Shih-En Wei",
            "Yaser Sheikh"
        ],
        "title": "OpenPose: Realtime Multi-Person 2D Pose Estimation Using Part Affinity Fields",
        "publication_date": "2021-01-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
        "volume": "43",
        "doi": "10.1109/tpami.2019.2929257",
        "urls": [
            "https://openalex.org/W2962730651",
            "https://doi.org/10.1109/tpami.2019.2929257",
            "http://arxiv.org/pdf/1812.08008"
        ],
        "id": "id-5057993867963637979",
        "abstract": "",
        "versions": [],
        "rank": 721
    },
    {
        "authors": [
            "Thomas Blaschke"
        ],
        "title": "Object based image analysis for remote sensing",
        "publication_date": "2010-01-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "ISPRS journal of photogrammetry and remote sensing",
        "volume": "65",
        "doi": "10.1016/j.isprsjprs.2009.06.004",
        "urls": [
            "https://openalex.org/W1984792953",
            "https://doi.org/10.1016/j.isprsjprs.2009.06.004",
            "https://doi.org/10.1016/j.isprsjprs.2009.06.004"
        ],
        "id": "id-4427490498561376010",
        "abstract": "",
        "versions": [],
        "rank": 722
    },
    {
        "authors": [
            "Cheng, Cheng",
            "Jiang, Wenqian",
            "Ma, Guijun",
            "Yuan, Ye",
            "Zhou, Beitong"
        ],
        "title": "A Novel GAN-based Fault Diagnosis Approach for Imbalanced Industrial  Time Series",
        "publication_date": "2019-04-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "http://arxiv.org/abs/1904.00575"
        ],
        "id": "id-584735961891079810",
        "abstract": "This paper proposes a novel fault diagnosis approach based on generative\nadversarial networks (GAN) for imbalanced industrial time series where normal\nsamples are much larger than failure cases. We combine a well-designed feature\nextractor with GAN to help train the whole network. Aimed at obtaining data\ndistribution and hidden pattern in both original distinguishing features and\nlatent space, the encoder-decoder-encoder three-sub-network is employed in GAN,\nbased on Deep Convolution Generative Adversarial Networks (DCGAN) but without\nTanh activation layer and only trained on normal samples. In order to verify\nthe validity and feasibility of our approach, we test it on rolling bearing\ndata from Case Western Reserve University and further verify it on data\ncollected from our laboratory. The results show that our proposed approach can\nachieve excellent performance in detecting faulty by outputting much larger\nevaluation scores",
        "versions": [],
        "rank": 723
    },
    {
        "authors": [
            "H He",
            "J Duchi",
            "K He",
            "M Everingham",
            "M Li",
            "N Srivastava",
            "PF Felzenszwalb"
        ],
        "title": "S-OHEM: Stratified Online Hard Example Mining for Object Detection",
        "publication_date": "2017-08-15 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": null,
        "volume": "",
        "doi": "10.1007/978-981-10-7305-2_15",
        "urls": [
            "http://arxiv.org/abs/1705.02233"
        ],
        "id": "id-308875581762456984",
        "abstract": "One of the major challenges in object detection is to propose detectors with\nhighly accurate localization of objects. The online sampling of high-loss\nregion proposals (hard examples) uses the multitask loss with equal weight\nsettings across all loss types (e.g, classification and localization, rigid and\nnon-rigid categories) and ignores the influence of different loss distributions\nthroughout the training process, which we find essential to the training\nefficacy. In this paper, we present the Stratified Online Hard Example Mining\n(S-OHEM) algorithm for training higher efficiency and accuracy detectors.\nS-OHEM exploits OHEM with stratified sampling, a widely-adopted sampling\ntechnique, to choose the training examples according to this influence during\nhard example mining, and thus enhance the performance of object detectors. We\nshow through systematic experiments that S-OHEM yields an average precision\n(AP) improvement of 0.5% on rigid categories of PASCAL VOC 2007 for both the\nIoU threshold of 0.6 and 0.7. For KITTI 2012, both results of the same metric\nare 1.6%. Regarding the mean average precision (mAP), a relative increase of\n0.3% and 0.5% (1% and 0.5%) is observed for VOC07 (KITTI12) using the same set\nof IoU threshold. Also, S-OHEM is easy to integrate with existing region-based\ndetectors and is capable of acting with post-recognition level regressors.Comment: 9 pages, 3 figures, accepted by CCCV 201",
        "versions": [],
        "rank": 724
    },
    {
        "authors": [
            "T. \u017dvirblis",
            "Linas Petkevi\u010dius",
            "P. Vaitkus",
            "E. \u0160abanovi\u010d",
            "Viktor Skrickij",
            "A. Kilikevi\u010dius"
        ],
        "title": "Investigation of Deep Neural Networks for Hypoid Gear Signal Classification to Identify Anomalies",
        "publication_date": "2021-04-22 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/AIEEE51419.2021.9435792",
        "urls": [
            "https://www.semanticscholar.org/paper/4629f532ccef16fd392369c60fd0e95b23aa6105"
        ],
        "id": "id3042047165396901599",
        "abstract": "A breakthrough of deep learning methods as automated feature extraction techniques for fault further evaluation and classification has blossomed in recent years. Multiple novel approaches of pattern recognition for fault diagnostic algorithms were proposed recently for vibration signal processing. In this paper, deep learning algorithms such as one- and two-dimensional convolutional neural networks (CNN-1D and CNN-2D), long short-term memory (LSTM) and Transformer were developed for hypoid gear faults multi-class and binary classification. The best model for seven gear conditions classification was the CNN-2D with 81.1% accuracy, while fault detection in binary classification achieved 100% accuracy. Also, LSTM and Transformer neural network showed extremely high accuracy result for binary classification. Gear condition without any faults was the most easily classifiable and showed the best statistics of model fit for all the models except for CNN-1D. The investigation revealed that experiments with lower torque achieved better classification accuracy, while different rotation speed had no significant effect. This study showed that superior accuracy results for hypoid gear fault classification were reached by using deep neural networks models and with vibration signal as input information.",
        "versions": [],
        "rank": 725
    },
    {
        "authors": [
            "Caron, Sascha",
            "de Austri, Roberto Ruiz",
            "G\u00f3mez-Vargas, Germ\u00e1n A.",
            "Hendriks, Luc"
        ],
        "title": "Analyzing {\\gamma}-rays of the Galactic Center with Deep Learning",
        "publication_date": "2018-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": null,
        "volume": "",
        "doi": "10.1088/1475-7516/2018/05/058",
        "urls": [
            "https://core.ac.uk/download/158611058.pdf"
        ],
        "id": "id-8789418791513381976",
        "abstract": "We present a new method to interpret the $\\gamma$-ray data of our inner\nGalaxy as measured by the Fermi Large Area Telescope (Fermi LAT). We train and\ntest convolutional neural networks with simulated Fermi-LAT images based on\nmodels tuned to real data. We use this method to investigate the origin of an\nexcess emission of GeV $\\gamma$-rays seen in previous studies. Interpretations\nof this excess include $\\gamma$ rays created by the annihilation of dark matter\nparticles and $\\gamma$ rays originating from a collection of unresolved point\nsources, such as millisecond pulsars. Our new method allows precise\nmeasurements of the contribution and properties of an unresolved population of\n$\\gamma$-ray point sources in the interstellar diffuse emission model.Comment: 24 pages, 11 figure",
        "versions": [],
        "rank": 726
    },
    {
        "authors": [
            "Kelin Yang",
            "Yongsheng Xu",
            "Peng Li",
            "Ning Shao"
        ],
        "title": "Research on Transmission Lines Early Warning Technology Based on Deep Learning",
        "publication_date": "2019-11-07 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "IOP Publishing",
        "volume": "",
        "doi": "10.1088/1757-899x/631/4/042040",
        "urls": [
            "https://web.archive.org/web/20220125143513/https://iopscience.iop.org/article/10.1088/1757-899X/631/4/042040/pdf"
        ],
        "id": "id2953548452406313728",
        "abstract": "At the present stage, high-voltage transmission lines are distributed in long distance chains,with large space span, complicated meteorological and geographical environment. The operating environment of the transmission lines is poor. Hence, manual patrol and maintenance are difficult. Various faults are very likely to affect the safe and stable operation of the power grid system. Therefore, this paper proposes a transmission lines early warning method based on Deep Learning. Through object detection technology of Deep Learning, intrusion objects in the monitoring screen are automatically identified, at same time, their positions and types are marked. The experimental results show that this method has high accuracy and is suitable for the current power grid monitoring system.",
        "versions": [],
        "rank": 727
    },
    {
        "authors": [
            "Wenwu Xie",
            "Jian Xiao",
            "Jinxia Yang",
            "Xin Peng",
            "Chao Yu",
            "Peng Zhu"
        ],
        "title": "Deep Learning-based Modulation Detection for NOMA Systems",
        "publication_date": "2020-10-16 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20201024133321/https://arxiv.org/ftp/arxiv/papers/2005/2005.11684.pdf"
        ],
        "id": "id7876309639861998169",
        "abstract": "Since the signal with strong power should be demodulated first for successive interference cancellation (SIC) demodulation in non-orthogonal multiple access (NOMA) systems, the base station (BS) should inform the near user terminal (UT), which has allocated higher power, of modulation mode of the far user terminal. To avoid unnecessary signaling overhead in this process, a blind detection algorithm of NOMA signal modulation mode is designed in this paper. Taking the joint constellation density diagrams of NOMA signal as the detection features, deep residual network is built for classification, so as to detect the modulation mode of NOMA signal. In view of the fact that the joint constellation diagrams are easily polluted by high intensity noise and lose their real distribution pattern, the wavelet denoising method is adopted to improve the quality of constellations. The simulation results represent that the proposed algorithm can achieve satisfactory detection accuracy in NOMA systems. In addition, the factors affecting the recognition performance are also verified and analyzed.",
        "versions": [],
        "rank": 728
    },
    {
        "authors": [
            "Tianxing Hong",
            "Jiguo Yu"
        ],
        "title": "Identification of Contact Relationship of Electrical Engineering Distribution Network with Two-Dimensional Wavelet Threshold Deep Neural Network",
        "publication_date": "2022-08-17 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Hindawi Limited",
        "volume": "",
        "doi": "10.1155/2022/3611623",
        "urls": [
            "https://web.archive.org/web/20220820004350/https://downloads.hindawi.com/journals/misy/2022/3611623.pdf"
        ],
        "id": "id-1461174284099630189",
        "abstract": "With the improvement of electrification in power systems, accurate and rapid fault location helps to repair faults, which is of great significance to the stability of distribution network operation. As an important part of power distribution in the power system, the electrical engineering distribution network is directly connected to the power transmission system and power end users. Its safety and reliability are related not only to the power sales interests of power companies, but also to the power users' rights and interests in power consumption. In this paper, an improved threshold based on the peak-sum ratio (PSR) is proposed, the time-frequency features in the disturbance signal are extracted through the continuous transformation of the two-dimensional wavelet threshold deep neural network to generate the disturbance time-frequency map of the electrical engineering distribution network, and then the deep learning model is used to analyze the model. After the classification performance is continuously optimized, the signal disturbance identification of electrical engineering distribution network is realized. By calculating the PSR of the distribution network, the correction factor can adaptively adjust the general threshold according to the noise distribution characteristics of different disturbance signals. By analyzing the data one by one, it can be seen that the improved threshold function has obvious advantages in the input signal-to-noise ratio of 10\u201312 dB, 16\u201318 dB, and 21\u201326 dB. At 13 dB, 14 dB, 20 dB, 27 dB, and 28 dB, the SNR difference of the distribution network is very small, and at 15 dB, 19 dB, 29 dB, and 30 dB, it is slightly inferior, but its denoising effect is generally better. The example results have shown that the recognition accuracy of the two-dimensional wavelet threshold denoising method in a noise-free environment has been effectively improved, and it has a certain anti-noise performance. The method proposed in this study has few feature extraction steps, is easy to implement, and is suitable for more types of disturbances.",
        "versions": [],
        "rank": 729
    },
    {
        "authors": [
            "Shivkaran Ravidas",
            "M.A. Ansari"
        ],
        "title": "An Efficient Scheme of Deep Convolution Neural Network for Multi View Face Detection",
        "publication_date": "2019-03-08 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "MECS Publisher",
        "volume": "",
        "doi": "10.5815/ijisa.2019.03.06",
        "urls": [
            "https://web.archive.org/web/20190428203020/http://www.mecs-press.org/ijisa/ijisa-v11-n3/IJISA-V11-N3-6.pdf"
        ],
        "id": "id-4419463106191299099",
        "abstract": "The aim of this paper is to detect multi-view faces using deep convolutional neural network (DCNN). Multi-view face detection is a challenging issue due to wide changes in appearance under different pose expression and illumination conditions. To address challenges, we designed a deep learning scheme with different network structures to enhance the multi view faces. More specifically, we design cascade architecture on convolutional neural networks (CNNs) which quickly reject non-face regions. Implementation, detection and retrieval of faces will be obtained with the help of direct visual matching technology. Further, a probabilistic calculation of resemblance among the images of face will be conducted on the basis of the Bayesian analysis for achieving detection of various faces. Experiment detects faces with \u00b190 degree out of plane rotations. Fine-tuned AlexNet is used to detect multi view faces. For this work, we extracted examples of training from AFLW (Annotated Facial Landmarks in the Wild) dataset that involve 21K images with 24K annotations of the face. Index Terms-Face detection, multi view face detection, deep learning, convolutional neural network (CNN) and Computer vision.",
        "versions": [],
        "rank": 730
    },
    {
        "authors": [
            "Lumini, Alessandra",
            "Nanni, Loris"
        ],
        "title": "Fair comparison of skin detection approaches on publicly available  datasets",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1016/j.eswa.2020.113677",
        "urls": [
            "http://arxiv.org/abs/1802.02531"
        ],
        "id": "id-3489708676410595861",
        "abstract": "Skin detection is the process of discriminating skin and non-skin regions in\na digital image and it is widely used in several applications ranging from hand\ngesture analysis to track body parts and face detection. Skin detection is a\nchallenging problem which has drawn extensive attention from the research\ncommunity, nevertheless a fair comparison among approaches is very difficult\ndue to the lack of a common benchmark and a unified testing protocol. In this\nwork, we investigate the most recent researches in this field and we propose a\nfair comparison among approaches using several different datasets. The major\ncontributions of this work are an exhaustive literature review of skin color\ndetection approaches, a framework to evaluate and combine different skin\ndetector approaches, whose source code is made freely available for future\nresearch, and an extensive experimental comparison among several recent methods\nwhich have also been used to define an ensemble that works well in many\ndifferent problems. Experiments are carried out in 10 different datasets\nincluding more than 10000 labelled images: experimental results confirm that\nthe best method here proposed obtains a very good performance with respect to\nother stand-alone approaches, without requiring ad hoc parameter tuning. A\nMATLAB version of the framework for testing and of the methods proposed in this\npaper will be freely available from https://github.com/LorisNann",
        "versions": [],
        "rank": 731
    },
    {
        "authors": [
            "Krstulovic, Sacha",
            "Plumbley, Mark D.",
            "Sigtia, Siddharth",
            "Stark, Adam M."
        ],
        "title": "Automatic Environmental Sound Recognition: Performance versus  Computational Cost",
        "publication_date": "2016-07-15 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": null,
        "volume": "",
        "doi": "10.1109/taslp.2016.2592698",
        "urls": [
            "https://core.ac.uk/download/76987873.pdf"
        ],
        "id": "id5572113352402126675",
        "abstract": "In the context of the Internet of Things (IoT), sound sensing applications\nare required to run on embedded platforms where notions of product pricing and\nform factor impose hard constraints on the available computing power. Whereas\nAutomatic Environmental Sound Recognition (AESR) algorithms are most often\ndeveloped with limited consideration for computational cost, this article seeks\nwhich AESR algorithm can make the most of a limited amount of computing power\nby comparing the sound classification performance em as a function of its\ncomputational cost. Results suggest that Deep Neural Networks yield the best\nratio of sound classification accuracy across a range of computational costs,\nwhile Gaussian Mixture Models offer a reasonable accuracy at a consistently\nsmall cost, and Support Vector Machines stand between both in terms of\ncompromise between accuracy and computational cost",
        "versions": [],
        "rank": 732
    },
    {
        "authors": [
            "Sylvain Baillet",
            "John C. Mosher",
            "Richard M. Leahy"
        ],
        "title": "Electromagnetic brain mapping",
        "publication_date": "2001-11-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "IEEE Signal Processing Magazine",
        "volume": "18",
        "doi": "10.1109/79.962275",
        "urls": [
            "https://openalex.org/W2016980059",
            "https://doi.org/10.1109/79.962275"
        ],
        "id": "id-7911474764586162076",
        "abstract": "",
        "versions": [],
        "rank": 733
    },
    {
        "authors": [
            "Balkenhol, Maschenka",
            "Bejnordi, Babak Ehteshami",
            "Bult, Peter",
            "Hermsen, Meyke",
            "Karssemeijer, Nico",
            "Litjens, Geert",
            "van der Laak, Jeroen",
            "van Ginneken, Bram",
            "Zuidhof, Guido"
        ],
        "title": "Context-aware stacked convolutional neural networks for classification  of breast carcinomas in whole-slide histopathology images",
        "publication_date": "2017-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": null,
        "volume": "",
        "doi": "10.1117/1.jmi.4.4.044504",
        "urls": [
            "http://arxiv.org/abs/1705.03678"
        ],
        "id": "id2047061123914014732",
        "abstract": "Automated classification of histopathological whole-slide images (WSI) of\nbreast tissue requires analysis at very high resolutions with a large\ncontextual area. In this paper, we present context-aware stacked convolutional\nneural networks (CNN) for classification of breast WSIs into normal/benign,\nductal carcinoma in situ (DCIS), and invasive ductal carcinoma (IDC). We first\ntrain a CNN using high pixel resolution patches to capture cellular level\ninformation. The feature responses generated by this model are then fed as\ninput to a second CNN, stacked on top of the first. Training of this stacked\narchitecture with large input patches enables learning of fine-grained\n(cellular) details and global interdependence of tissue structures. Our system\nis trained and evaluated on a dataset containing 221 WSIs of H&E stained breast\ntissue specimens. The system achieves an AUC of 0.962 for the binary\nclassification of non-malignant and malignant slides and obtains a three class\naccuracy of 81.3% for classification of WSIs into normal/benign, DCIS, and IDC,\ndemonstrating its potentials for routine diagnostics",
        "versions": [],
        "rank": 734
    },
    {
        "authors": [
            "Dai, Bo",
            "Lin, Dahua",
            "Zhang, Yuqi"
        ],
        "title": "Detecting Visual Relationships with Deep Relational Networks",
        "publication_date": "2017-04-12 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/cvpr.2017.352",
        "urls": [
            "http://arxiv.org/abs/1704.03114"
        ],
        "id": "id-5529623368788690888",
        "abstract": "Relationships among objects play a crucial role in image understanding.\nDespite the great success of deep learning techniques in recognizing individual\nobjects, reasoning about the relationships among objects remains a challenging\ntask. Previous methods often treat this as a classification problem,\nconsidering each type of relationship (e.g. \"ride\") or each distinct visual\nphrase (e.g. \"person-ride-horse\") as a category. Such approaches are faced with\nsignificant difficulties caused by the high diversity of visual appearance for\neach kind of relationships or the large number of distinct visual phrases. We\npropose an integrated framework to tackle this problem. At the heart of this\nframework is the Deep Relational Network, a novel formulation designed\nspecifically for exploiting the statistical dependencies between objects and\ntheir relationships. On two large datasets, the proposed method achieves\nsubstantial improvement over state-of-the-art.Comment: To be appeared in CVPR 2017 as an oral pape",
        "versions": [],
        "rank": 735
    },
    {
        "authors": [
            "Wei Zhang",
            "Yueqin Li",
            "Xiaofeng Li",
            "Minggang Shao",
            "Yajie Mi",
            "Hongli Zhang",
            "Guoqing Zhi"
        ],
        "title": "Deep Neural Network-Based SQL Injection Detection Method",
        "publication_date": "2022-03-24 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1155/2022/4836289",
        "urls": [
            "https://www.semanticscholar.org/paper/cfd1701886d0135c69c5b49f24978862b0074bb8"
        ],
        "id": "id1506407746073424308",
        "abstract": "Among the network security problems, SQL injection is a common and challenging network attack means, which can cause inestimable loop-breaking and loss to the database, and how to detect SQL injection statements is one of the current research hotspots. Based on the data characteristics of SQL statements, a deep neural network-based SQL injection detection model and algorithm are built. The core method is to convert the data into word vector form by word pause method, then form a sparse matrix and pass it into the model for training, build a multihidden layer deep neural network model containing ReLU function, optimize the traditional loss function, and introduce Dropout method to improve the generalization ability of this model. The accuracy of the final model is maintained at over 96%. By comparing the experimental results with traditional machine learning algorithms and LSTM algorithms, the proposed algorithm effectively solves the problems of overfitting in machine learning and the need for manual screening to extract features, which greatly improves the accuracy of SQL injection detection.",
        "versions": [],
        "rank": 736
    },
    {
        "authors": [
            "Prateek Singh",
            "Ambalika Sharma",
            "Shreesha Maiya"
        ],
        "title": "Automated Atrial Fibrillation Classification Based on Denoising Stacked Autoencoder and Optimized Deep Network",
        "publication_date": "2022-01-26 21:45:48+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2202.05177v1",
            "http://arxiv.org/abs/2202.05177v1",
            "http://arxiv.org/pdf/2202.05177v1"
        ],
        "id": "id-3739178608200295184",
        "abstract": "The incidences of atrial fibrillation (AFib) are increasing at a daunting\nrate worldwide. For the early detection of the risk of AFib, we have developed\nan automatic detection system based on deep neural networks. For achieving\nbetter classification, it is mandatory to have good pre-processing of\nphysiological signals. Keeping this in mind, we have proposed a two-fold study.\nFirst, an end-to-end model is proposed to denoise the electrocardiogram signals\nusing denoising autoencoders (DAE). To achieve denoising, we have used three\nnetworks including, convolutional neural network (CNN), dense neural network\n(DNN), and recurrent neural networks (RNN). Compared the three models and CNN\nbased DAE performance is found to be better than the other two. Therefore, the\nsignals denoised by the CNN based DAE were used to train the deep neural\nnetworks for classification. Three neural networks' performance has been\nevaluated using accuracy, specificity, sensitivity, and signal to noise ratio\n(SNR) as the evaluation criteria.\n  The proposed end-to-end deep learning model for detecting atrial fibrillation\nin this study has achieved an accuracy rate of 99.20%, a specificity of 99.50%,\na sensitivity of 99.50%, and a true positive rate of 99.00%. The average\naccuracy of the algorithms we compared is 96.26%, and our algorithm's accuracy\nis 3.2% higher than this average of the other algorithms. The CNN\nclassification network performed better as compared to the other two.\nAdditionally, the model is computationally efficient for real-time\napplications, and it takes approx 1.3 seconds to process 24 hours ECG signal.\nThe proposed model was also tested on unseen dataset with different proportions\nof arrhythmias to examine the model's robustness, which resulted in 99.10% of\nrecall and 98.50% of precision.",
        "versions": [],
        "rank": 737
    },
    {
        "authors": [
            "Mohammad Shokri",
            "Ahad Harati",
            "Kimya Taba"
        ],
        "title": "Salient Object Detection in Video using Deep Non-Local Neural Networks",
        "publication_date": "2018-10-16 15:55:57+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "10.1016/j.jvcir.2020.102769",
        "urls": [
            "http://arxiv.org/pdf/1810.07097v1",
            "http://dx.doi.org/10.1016/j.jvcir.2020.102769",
            "http://arxiv.org/abs/1810.07097v1",
            "http://arxiv.org/pdf/1810.07097v1"
        ],
        "id": "id-8641190730963373405",
        "abstract": "Detection of salient objects in image and video is of great importance in\nmany computer vision applications. In spite of the fact that the state of the\nart in saliency detection for still images has been changed substantially over\nthe last few years, there have been few improvements in video saliency\ndetection. This paper investigates the use of recently introduced non-local\nneural networks in video salient object detection. Non-local neural networks\nare applied to capture global dependencies and hence determine the salient\nobjects. The effect of non-local operations is studied separately on static and\ndynamic saliency detection in order to exploit both appearance and motion\nfeatures. A novel deep non-local neural network architecture is introduced for\nvideo salient object detection and tested on two well-known datasets DAVIS and\nFBMS. The experimental results show that the proposed algorithm outperforms\nstate-of-the-art video saliency detection methods.",
        "versions": [],
        "rank": 738
    },
    {
        "authors": [
            "Sen Wang",
            "Yuxiang Xing",
            "Li Zhang",
            "Hewei Gao",
            "Haotong Zhang"
        ],
        "title": "A systematic evaluation and optimization of automatic detection of ulcers in wireless capsule endoscopy on a large dataset using deep convolutional neural networks",
        "publication_date": "2019-10-23 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Physics in Medicine & Biology",
        "volume": "64",
        "doi": "10.1088/1361-6560/ab5086",
        "urls": [
            "https://www.semanticscholar.org/paper/9fe7f8bd75869aa1a6cab80ac833ca85136aa073"
        ],
        "id": "id2682778505878905072",
        "abstract": "Compared with conventional gastroscopy which is invasive and painful, wireless capsule endoscopy (WCE) can provide noninvasive examination of gastrointestinal (GI) tract. The WCE video can effectively support physicians to reach a diagnostic decision while a huge number of images need to be analyzed (more than 50\u2009000 frames per patient). In this paper, we propose a computer-aided diagnosis method called second glance (secG) detection framework for automatic detection of ulcers based on deep convolutional neural networks that provides both classification confidence and bounding box of lesion area. We evaluated its performance on a large dataset that consists of 1504 patient cases (the largest WCE ulcer dataset to our best knowledge, 1076 cases with ulcers, 428 normal cases). We use 15\u2009781 ulcer frames from 753 ulcer cases and 17\u2009138 normal frames from 300 normal cases for training. Validation dataset consists of 2040 ulcer frames from 108 cases and 2319 frames from 43 normal cases. For test, we use 4917 ulcer frames from 215 ulcer cases and 5007 frames from 85 normal cases. Test results demonstrate the 0.9469 ROC-AUC of the proposed secG detection framework outperforms state-of-the-art detection frameworks including Faster-RCNN (0.9014) and SSD-300 (0.8355), which implies the effectiveness of our method. From the ulcer size analysis, we find the detection of ulcers is highly related to the size. For ulcers with size larger than 1% of the full image size, the sensitivity exceeds 92.00%. For ulcers that are smaller than 1% of the full image size, the sensitivity is around 85.00%. The overall sensitivity, specificity and accuracy are 89.71%, 90.48% and 90.10%, at a threshold value of 0.6706, which implies the potential of the proposed method to suppress oversights and to reduce the burden of physicians.",
        "versions": [],
        "rank": 739
    },
    {
        "authors": [
            "M. Siddique",
            "S. Sakib",
            "Mohammad Mahmudur Rahman Khan",
            "Abyaz Kader Tanzeem",
            "M. Chowdhury",
            "N. Yasmin"
        ],
        "title": "Deep Convolutional Neural Networks Model-based Brain Tumor Detection in Brain MRI Images",
        "publication_date": "2020-10-03 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/I-SMAC49090.2020.9243461",
        "urls": [
            "https://www.semanticscholar.org/paper/6f0c0986af0ff13aa9487a9352a0fe9312b6e760"
        ],
        "id": "id-2261013672569354011",
        "abstract": "Diagnosing Brain Tumor with the aid of Magnetic Resonance Imaging (MRI) has gained enormous prominence over the years primarily in the field of medical science. Detection and/or partitioning of brain tumors solely with the aid of MR imaging is achieved at the cost of immense time and effort and demands a lot of expertise from engaged personnel. This substantiates the necessity of fabricating an autonomous model brain tumor diagnosis. Our work involves the implementation of a deep convolutional neural network (DCNN) for diagnosing brain tumor from MR images. The dataset, used in this paper, consists of 253 brain MR images where 155 images are reported to have tumors. Our model can single out the MR images with tumors with an overall accuracy of 96%. The model outperformed the existing conventional methods for the diagnosis of brain tumor in the test dataset (Precision = 0.93, Sensitivity = 1.00, and F1-score = 0.97). Moreover, the average precision-recall score of the proposed model is 0.93, Cohen's Kappa 0.91, and AUC 0.95. Therefore, the proposed model can be helpful for clinical experts to verify whether the patient has a brain tumor and, consequently, accelerate the treatment procedure.",
        "versions": [],
        "rank": 740
    },
    {
        "authors": [
            "Xiong Zhang",
            "Miao Zhang",
            "Xiao Tian"
        ],
        "title": "Real-time Earthquake Early Warning with Deep Learning: Application to the 2016 Central Apennines, Italy Earthquake Sequence",
        "publication_date": "2020-06-02 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20200604192249/https://arxiv.org/ftp/arxiv/papers/2006/2006.01332.pdf"
        ],
        "id": "id-7601112776978176252",
        "abstract": "Earthquake early warning systems are required to report earthquake locations and magnitudes as quickly as possible before the damaging S wave arrival to mitigate seismic hazards. Deep learning techniques provide potential for extracting earthquake source information from full seismic waveforms instead of seismic phase picks. We developed a novel deep learning earthquake early warning system that utilizes fully convolutional networks to simultaneously detect earthquakes and estimate their source parameters from continuous seismic waveform streams. The system determines earthquake location and magnitude as soon as one station receives earthquake signals and evolutionarily improves the solutions by receiving continuous data. We apply the system to the 2016 Mw 6.0 earthquake in Central Apennines, Italy and its subsequent sequence. Earthquake locations and magnitudes can be reliably determined as early as four seconds after the earliest P phase, with mean error ranges of 6.8-3.7 km and 0.31-0.23, respectively.",
        "versions": [],
        "rank": 741
    },
    {
        "authors": [
            "Chao Lu",
            "Wei Xu",
            "Hong Shen",
            "Hua Zhang",
            "Xiaohu You"
        ],
        "title": "An Enhanced SCMA Detector Enabled by Deep Neural Network",
        "publication_date": "2018-08-24 06:24:24+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1808.08015v1",
            "http://arxiv.org/abs/1808.08015v1",
            "http://arxiv.org/pdf/1808.08015v1"
        ],
        "id": "id-1657818233595857882",
        "abstract": "In this paper, we propose a learning approach for sparse code multiple access\n(SCMA) signal detection by using a deep neural network via unfolding the\nprocedure of message passing algorithm (MPA). The MPA can be converted to a\nsparsely connected neural network if we treat the weights as the parameters of\na neural network. The neural network can be trained off-line and then deployed\nfor online detection. By further refining the network weights corresponding to\nthe edges of a factor graph, the proposed method achieves a better performance.\nMoreover, the deep neural network based detection is a computationally\nefficient since highly paralleled computations in the network are enabled in\nemerging Artificial Intelligence (AI) chips.",
        "versions": [],
        "rank": 742
    },
    {
        "authors": [
            "Wu Yanchen",
            "Mian Ahmad Jan"
        ],
        "title": "Sonar Image Target Detection and Recognition Based on Convolution Neural Network",
        "publication_date": "2021-03-22 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Hindawi Limited",
        "volume": "",
        "doi": "10.1155/2021/5589154",
        "urls": [
            "https://web.archive.org/web/20210324114729/https://downloads.hindawi.com/journals/misy/2021/5589154.pdf"
        ],
        "id": "id-3351240300973884508",
        "abstract": "Recent advancements in deep learning offer an effective approach for the study in machine vision using optical images. In this paper, a convolution neural network is used to deal with the target task of sonar detection, and the performance of each neural network model in the sonar image detection and recognition task of underwater box and tire is compared. The simulation results show that the neural network method proposed in this paper is better than the traditional machine learning methods and SSD network models. The average accuracy of the proposed method for sonar image target recognition is 93%, and the detection time of a single image is only 0.3 seconds.",
        "versions": [],
        "rank": 743
    },
    {
        "authors": [
            "Y. Mu",
            "Salim Sazzed",
            "Maytha Alshammari",
            "Jiangwen Sun",
            "Jing He"
        ],
        "title": "A Tool for Segmentation of Secondary Structures in 3D Cryo-EM Density Map Components Using Deep Convolutional Neural Networks",
        "publication_date": "2021-11-03 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Frontiers in Bioinformatics",
        "volume": "1",
        "doi": "10.3389/fbinf.2021.710119",
        "urls": [
            "https://www.semanticscholar.org/paper/6a3cbe3cfd00a9848780630458ede5e01b17c7e9"
        ],
        "id": "id-7547129421819592722",
        "abstract": "Although cryo-electron microscopy (cryo-EM) has been successfully used to derive atomic structures for many proteins, it is still challenging to derive atomic structures when the resolution of cryo-EM density maps is in the medium resolution range, such as 5\u201310 \u00c5. Detection of protein secondary structures, such as helices and \u03b2-sheets, from cryo-EM density maps provides constraints for deriving atomic structures from such maps. As more deep learning methodologies are being developed for solving various molecular problems, effective tools are needed for users to access them. We have developed an effective software bundle, DeepSSETracer, for the detection of protein secondary structure from cryo-EM component maps in medium resolution. The bundle contains the network architecture and a U-Net model trained with a curriculum and gradient of episodic memory (GEM). The bundle integrates the deep neural network with the visualization capacity provided in ChimeraX. Using a Linux server that is remotely accessed by Windows users, it takes about 6 s on one CPU and one GPU for the trained deep neural network to detect secondary structures in a cryo-EM component map containing 446 amino acids. A test using 28 chain components of cryo-EM maps shows overall residue-level F1 scores of 0.72 and 0.65 to detect helices and \u03b2-sheets, respectively. Although deep learning applications are built on software frameworks, such as PyTorch and Tensorflow, our pioneer work here shows that integration of deep learning applications with ChimeraX is a promising and effective approach. Our experiments show that the F1 score measured at the residue level is an effective evaluation of secondary structure detection for individual classes. The test using 28 cryo-EM component maps shows that DeepSSETracer detects \u03b2-sheets more accurately than Emap2sec+, with a weighted average residue-level F1 score of 0.65 and 0.42, respectively. It also shows that Emap2sec+ detects helices more accurately than DeepSSETracer with a weighted average residue-level F1 score of 0.77 and 0.72 respectively.",
        "versions": [],
        "rank": 744
    },
    {
        "authors": [
            "S. Kiranyaz",
            "Junaid Malik",
            "M. Zahid",
            "T. Ince",
            "M. Chowdhury",
            "A. Khandakar",
            "A. Tahir",
            "M. Gabbouj"
        ],
        "title": "Robust Peak Detection for Holter ECGs by Self-Organized Operational Neural Networks",
        "publication_date": "2021-09-30 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "IEEE transactions on neural networks and learning systems",
        "volume": "PP",
        "doi": "10.1109/TNNLS.2022.3158867",
        "urls": [
            "https://www.semanticscholar.org/paper/674ff3d0d1de5be4bb89ae4ecaf6039e3d386b9d"
        ],
        "id": "id-501449017838179499",
        "abstract": "Although numerous R-peak detectors have been proposed in the literature, their robustness and performance levels may significantly deteriorate in low-quality and noisy signals acquired from mobile electrocardiogram (ECG) sensors, such as Holter monitors. Recently, this issue has been addressed by deep 1-D convolutional neural networks (CNNs) that have achieved state-of-the-art performance levels in Holter monitors; however, they pose a high complexity level that requires special parallelized hardware setup for real-time processing. On the other hand, their performance deteriorates when a compact network configuration is used instead. This is an expected outcome as recent studies have demonstrated that the learning performance of CNNs is limited due to their strictly homogenous configuration with the sole linear neuron model. This has been addressed by operational neural networks (ONNs) with their heterogenous network configuration encapsulating neurons with various nonlinear operators. In this study, to further boost the peak detection performance along with an elegant computational efficiency, we propose 1-D Self-Organized ONNs (Self-ONNs) with generative neurons. The most crucial advantage of 1-D Self-ONNs over the ONNs is their self-organization capability that voids the need to search for the best operator set per neuron since each generative neuron has the ability to create the optimal operator during training. The experimental results over the China Physiological Signal Challenge-2020 (CPSC) dataset with more than one million ECG beats show that the proposed 1-D Self-ONNs can significantly surpass the state-of-the-art deep CNN with less computational complexity. Results demonstrate that the proposed solution achieves a 99.10% F1-score, 99.79% sensitivity, and 98.42% positive predictivity in the CPSC dataset, which is the best R-peak detection performance ever achieved.",
        "versions": [],
        "rank": 745
    },
    {
        "authors": [
            "R. Golan",
            "C. Jacob",
            "J. Denzinger"
        ],
        "title": "Lung nodule detection in CT images using deep convolutional neural networks",
        "publication_date": "2016-07-24 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/IJCNN.2016.7727205",
        "urls": [
            "https://www.semanticscholar.org/paper/49949855c6440569175bb926bcc6f9162ad55cdb"
        ],
        "id": "id705523900836936181",
        "abstract": "Early detection of lung nodules in thoracic Computed Tomography (CT) scans is of great importance for the successful diagnosis and treatment of lung cancer. Due to improvements in screening technologies, and an increased demand for their use, radiologists are required to analyze an ever increasing amount of image data, which can affect the quality of their diagnoses. Computer-Aided Detection (CADe) systems are designed to assist radiologists in this endeavor. Here, we present a CADe system for the detection of lung nodules in thoracic CT images. Our system is based on (1) the publicly available Lung Image Database Consortium (LIDC) and Image Database Resource Initiative (IDRI) database, which contains 1018 thoracic CT scans with nodules of different shape and size, and (2) a deep Convolutional Neural Network (CNN), which is trained, using the back-propagation algorithm, to extract valuable volumetric features from the input data and detect lung nodules in sub-volumes of CT images. Considering only those test nodules that have been annotated by four radiologists, our CADe system achieves a sensitivity (true positive rate) of 78.9% with 20 false positives (FPs) per scan, or a sensitivity of 71.2% with 10 FPs per scan. This is achieved without using any segmentation or additional FP reduction procedures, both of which are commonly used in other CADe systems. Furthermore, our CADe system is validated on a larger number of lung nodules compared to other studies, which increases the variation in their appearance, and therefore, makes their detection by a CADe system more challenging.",
        "versions": [
            {
                "year": 2016,
                "source": "SupportedSources.CROSSREF",
                "title": "Lung nodule detection in CT images using deep convolutional neural networks",
                "journal": "",
                "urls": [
                    "http://xplorestaging.ieee.org/ielx7/7593175/7726591/07727205.pdf?arnumber=7727205",
                    "http://dx.doi.org/10.1109/ijcnn.2016.7727205"
                ],
                "doi": "10.1109/ijcnn.2016.7727205",
                "publication_date": "2016-01-01 00:00:00"
            }
        ],
        "rank": 746
    },
    {
        "authors": [
            "Alonso, Erik",
            "Aramendi, Elisabete",
            "Elola, Andoni",
            "Idris, Ahamed",
            "Irusta, Unai",
            "Owens, Pamela",
            "Pic\u00f3n, Artzai"
        ],
        "title": "Deep Neural Networks for ECG-Based Pulse Detection during Out-of-Hospital Cardiac Arrest",
        "publication_date": "2019-03-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "Entropy",
        "volume": "",
        "doi": "10.3390/e21030305.",
        "urls": [
            "https://core.ac.uk/download/196553074.pdf"
        ],
        "id": "id-7413483808846258852",
        "abstract": "The automatic detection of pulse during out-of-hospital cardiac arrest (OHCA) is necessary for the early recognition of the arrest and the detection of return of spontaneous circulation (end of the arrest). The only signal available in every single defibrillator and valid for the detection of pulse is the electrocardiogram (ECG). In this study we propose two deep neural network (DNN) architectures to detect pulse using short ECG segments (5 s), i.e., to classify the rhythm into pulseless electrical activity (PEA) or pulse-generating rhythm (PR). A total of 3914 5-s ECG segments, 2372 PR and 1542 PEA, were extracted from 279 OHCA episodes. Data were partitioned patient-wise into training (80%) and test (20%) sets. The first DNN architecture was a fully convolutional neural network, and the second architecture added a recurrent layer to learn temporal dependencies. Both DNN architectures were tuned using Bayesian optimization, and the results for the test set were compared to state-of-the art PR/PEA discrimination algorithms based on machine learning and hand crafted features. The PR/PEA classifiers were evaluated in terms of sensitivity (Se) for PR, specificity (Sp) for PEA, and the balanced accuracy (BAC), the average of Se and Sp. The Se/Sp/BAC of the DNN architectures were 94.1%/92.9%/93.5% for the first one, and 95.5%/91.6%/93.5% for the second one. Both architectures improved the performance of state of the art methods by more than 1.5 points in BAC.This work was supported by: The Spanish Ministerio de Econom\u00eda y Competitividad, TEC2015-64678-R,\n\njointly with the Fondo Europeo de Desarrollo Regional (FEDER), UPV/EHU via GIU17/031 and the Basque\n\nGovernment through the grant PRE_2018_2_0260",
        "versions": [],
        "rank": 747
    },
    {
        "authors": [
            "Ignacio Serna",
            "Alejandro Pe\u00f1a",
            "Aythami Morales",
            "Julian Fierrez"
        ],
        "title": "InsideBias: Measuring Bias in Deep Networks and Application to Face Gender Biometrics",
        "publication_date": "2020-04-14 15:20:50+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2004.06592v3",
            "http://arxiv.org/abs/2004.06592v3",
            "http://arxiv.org/pdf/2004.06592v3"
        ],
        "id": "id68334528345505581",
        "abstract": "This work explores the biases in learning processes based on deep neural\nnetwork architectures. We analyze how bias affects deep learning processes\nthrough a toy example using the MNIST database and a case study in gender\ndetection from face images. We employ two gender detection models based on\npopular deep neural networks. We present a comprehensive analysis of bias\neffects when using an unbalanced training dataset on the features learned by\nthe models. We show how bias impacts in the activations of gender detection\nmodels based on face images. We finally propose InsideBias, a novel method to\ndetect biased models. InsideBias is based on how the models represent the\ninformation instead of how they perform, which is the normal practice in other\nexisting methods for bias detection. Our strategy with InsideBias allows to\ndetect biased models with very few samples (only 15 images in our case study).\nOur experiments include 72K face images from 24K identities and 3 ethnic\ngroups.",
        "versions": [],
        "rank": 748
    },
    {
        "authors": [
            "Calafell, Andrea",
            "Giro-i-Nieto, Xavier",
            "Manchon-Vizuete, Daniel",
            "Salvador, Amaia",
            "Zeppelzauer, Matthias"
        ],
        "title": "Cultural Event Recognition with Visual ConvNets and Temporal Models",
        "publication_date": "2015-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/cvprw.2015.7301334",
        "urls": [
            "https://core.ac.uk/download/41779706.pdf"
        ],
        "id": "id6872620564604840779",
        "abstract": "This paper presents our contribution to the ChaLearn Challenge 2015 on\nCultural Event Classification. The challenge in this task is to automatically\nclassify images from 50 different cultural events. Our solution is based on the\ncombination of visual features extracted from convolutional neural networks\nwith temporal information using a hierarchical classifier scheme. We extract\nvisual features from the last three fully connected layers of both CaffeNet\n(pretrained with ImageNet) and our fine tuned version for the ChaLearn\nchallenge. We propose a late fusion strategy that trains a separate low-level\nSVM on each of the extracted neural codes. The class predictions of the\nlow-level SVMs form the input to a higher level SVM, which gives the final\nevent scores. We achieve our best result by adding a temporal refinement step\ninto our classification scheme, which is applied directly to the output of each\nlow-level SVM. Our approach penalizes high classification scores based on\nvisual features when their time stamp does not match well an event-specific\ntemporal distribution learned from the training and validation data. Our system\nachieved the second best result in the ChaLearn Challenge 2015 on Cultural\nEvent Classification with a mean average precision of 0.767 on the test set.Comment: Initial version of the paper accepted at the CVPR Workshop ChaLearn\n  Looking at People 201",
        "versions": [],
        "rank": 749
    },
    {
        "authors": [
            "Brian Li",
            "Steven Palayew",
            "Francis Li",
            "Saad Abbasi",
            "Saeejith Nair",
            "Alexander Wong"
        ],
        "title": "PCBDet: An Efficient Deep Neural Network Object Detection Architecture for Automatic PCB Component Detection on the Edge",
        "publication_date": "2023-01-23 04:34:25+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2301.09268v1",
            "http://arxiv.org/abs/2301.09268v1",
            "http://arxiv.org/pdf/2301.09268v1"
        ],
        "id": "id1399819210899019815",
        "abstract": "There can be numerous electronic components on a given PCB, making the task\nof visual inspection to detect defects very time-consuming and prone to error,\nespecially at scale. There has thus been significant interest in automatic PCB\ncomponent detection, particularly leveraging deep learning. However, deep\nneural networks typically require high computational resources, possibly\nlimiting their feasibility in real-world use cases in manufacturing, which\noften involve high-volume and high-throughput detection with constrained edge\ncomputing resource availability. As a result of an exploration of efficient\ndeep neural network architectures for this use case, we introduce PCBDet, an\nattention condenser network design that provides state-of-the-art inference\nthroughput while achieving superior PCB component detection performance\ncompared to other state-of-the-art efficient architecture designs. Experimental\nresults show that PCBDet can achieve up to 2$\\times$ inference speed-up on an\nARM Cortex A72 processor when compared to an EfficientNet-based design while\nachieving $\\sim$2-4\\% higher mAP on the FICS-PCB benchmark dataset.",
        "versions": [],
        "rank": 750
    },
    {
        "authors": [
            "Raswitha Bandi, Et. al."
        ],
        "title": "Tensor Flow Model in Medical Image Analysis - Review",
        "publication_date": "2021-04-11 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Auricle Technologies, Pvt., Ltd.",
        "volume": "",
        "doi": "10.17762/turcomat.v12i5.2032",
        "urls": [
            "https://web.archive.org/web/20210421020731/https://turcomat.org/index.php/turkbilmat/article/download/2032/1759"
        ],
        "id": "id-7378967084153779379",
        "abstract": "Support Vector Machines, Reinforcement algorithms, artificial neural networks are some of the Machine Learning Algorithms available in Medical Analysis. By using these algorithms, much of the research has been done in analysis of liver cancer for genome classification and identification of lesions. At present, Deep learning algorithms have quickly turned into a strategy for examine CT images. This article presents one of the major deep learning techniques named tensor flow technique to investigate images in scan for the task of visualization of abnormal condition of liver tumor in the context of shape and color towards disease diagnosis. We surveyed the utilization of tensor flow for classifying images, detection of objects, and detection of lesions. In this paper, we mainly concentrated on the study and working of tensor flow in image classification. Also, a summary of the present and future scope in this area has been presented in detail.",
        "versions": [],
        "rank": 751
    },
    {
        "authors": [
            "Francisco Arellano Espitia",
            "Lucia Ruiz Soto"
        ],
        "title": "Novel Methods Based on Deep Learning Applied to Condition Monitoring in Smart Manufacturing Processes",
        "publication_date": "2020-03-25 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "IntechOpen",
        "volume": "",
        "doi": "10.5772/intechopen.89570",
        "urls": [
            "https://web.archive.org/web/20200401034325/https://api.intechopen.com/chapter/pdf-download/69429.pdf"
        ],
        "id": "id-1698597477925151304",
        "abstract": "The Industry 4.0 is the recent trend of automation and the rotating machinery takes a role of great relevance when it comes to meet the demands and challenges of smart manufacturing. Condition-based monitoring (CBM) schemes are the most prominent tool to cover the task of predictive diagnosis. With the current demand of the industry and the increasing complexity of the systems, it is vital to incorporate CBM methodologies that are capable of facing the variability and complexity of manufacturing processes. In recent years, various deep learning techniques have been applied successfully in different areas of research, such as image recognition, robotics, and the detection of abnormalities in clinical studies; some of these techniques have been approaching to the diagnosis of the condition in rotating machinery, promising great results in the Industry 4.0 era. In this chapter, some of the deep learning techniques that promise to make important advances in the field of intelligent fault diagnosis in industrial electromechanical systems will be addressed.",
        "versions": [],
        "rank": 752
    },
    {
        "authors": [
            "Tianyu Ma",
            "Ajay Gupta",
            "Mert R. Sabuncu"
        ],
        "title": "Volumetric landmark detection with a multi-scale shift equivariant neural network",
        "publication_date": "2020-03-03 17:06:19+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "10.1109/ISBI45749.2020.9098620",
        "urls": [
            "http://arxiv.org/pdf/2003.01639v2",
            "http://dx.doi.org/10.1109/ISBI45749.2020.9098620",
            "http://arxiv.org/abs/2003.01639v2",
            "http://arxiv.org/pdf/2003.01639v2"
        ],
        "id": "id-3557350687162554891",
        "abstract": "Deep neural networks yield promising results in a wide range of computer\nvision applications, including landmark detection. A major challenge for\naccurate anatomical landmark detection in volumetric images such as clinical CT\nscans is that large-scale data often constrain the capacity of the employed\nneural network architecture due to GPU memory limitations, which in turn can\nlimit the precision of the output. We propose a multi-scale, end-to-end deep\nlearning method that achieves fast and memory-efficient landmark detection in\n3D images. Our architecture consists of blocks of shift-equivariant networks,\neach of which performs landmark detection at a different spatial scale. These\nblocks are connected from coarse to fine-scale, with differentiable resampling\nlayers, so that all levels can be trained together. We also present a noise\ninjection strategy that increases the robustness of the model and allows us to\nquantify uncertainty at test time. We evaluate our method for carotid artery\nbifurcations detection on 263 CT volumes and achieve a better than\nstate-of-the-art accuracy with mean Euclidean distance error of 2.81mm.",
        "versions": [],
        "rank": 753
    },
    {
        "authors": [
            "I. Zyout",
            "Abdulrohman Oatawneh"
        ],
        "title": "Detection of PV Solar Panel Surface Defects using Transfer Learning of the Deep Convolutional Neural Networks",
        "publication_date": "2020-02-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ASET48392.2020.9118384",
        "urls": [
            "https://www.semanticscholar.org/paper/7cc7b5e5633afc85dc25ff8b5e26ae9203c23789"
        ],
        "id": "id-4484272358425143245",
        "abstract": "The need for automatic defect inspection of solar panels becomes more vital with higher demands of producing and installing new solar energy systems worldwide. Deep convolutional neural networks (CNN) remarkably perform very well for solving the image classification task from different domains. In this paper, the convolutional neural network is applied to characterize the surface of the PV panel and to detect the presence of the defect. The application of transfer learning with AlexNet CNN provided a very promising performance and reveal the potential of the approach for the detection of various defects in the surface of the solar panel.",
        "versions": [],
        "rank": 754
    },
    {
        "authors": [
            "T. Jun",
            "H. Park",
            "Hoang Minh Nguyen",
            "Daeyoung Kim",
            "Young-Hak Kim"
        ],
        "title": "Premature Ventricular Contraction Beat Detection with Deep Neural Networks",
        "publication_date": "2016-12-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ICMLA.2016.0154",
        "urls": [
            "https://www.semanticscholar.org/paper/1d11b135f37701c6f31bdece0d6965ca3ca44a1d"
        ],
        "id": "id1877821145156772461",
        "abstract": "A deep neural networks is proposed for the classification of premature ventricular contraction (PVC) beat, which is an irregular heartbeat initiated by Purkinje fibers rather than by sinoatrial node. Several machine learning approaches were proposed for the detection of PVC beats although they resulted in either achieving low accuracy of classification or using limited portion of data from existing electrocardiography (ECG) databases. In this paper, we propose an optimized deep neural networks for PVC beat classification. Our method is evaluated on TensorFlow, which is an open source machine learning platform initially developed by Google. Our method achieved overall 99.41% accuracy and a sensitivity of 96.08% with total 80,836 ECG beats including normal and PVC from the MIT-BIH Arrhythmia Database.",
        "versions": [],
        "rank": 755
    },
    {
        "authors": [
            "Rajeev Ranjan",
            "Vishal M. Patel",
            "Rama Chellappa"
        ],
        "title": "A Deep Pyramid Deformable Part Model for Face Detection",
        "publication_date": "2015-08-18 17:24:09+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1508.04389v1",
            "http://arxiv.org/abs/1508.04389v1",
            "http://arxiv.org/pdf/1508.04389v1"
        ],
        "id": "id-1844182269520349182",
        "abstract": "We present a face detection algorithm based on Deformable Part Models and\ndeep pyramidal features. The proposed method called DP2MFD is able to detect\nfaces of various sizes and poses in unconstrained conditions. It reduces the\ngap in training and testing of DPM on deep features by adding a normalization\nlayer to the deep convolutional neural network (CNN). Extensive experiments on\nfour publicly available unconstrained face detection datasets show that our\nmethod is able to capture the meaningful structure of faces and performs\nsignificantly better than many competitive face detection algorithms.",
        "versions": [],
        "rank": 756
    },
    {
        "authors": [
            "Abu-Naser, Samy S.",
            "Abu-Nasser, Bassem S.",
            "Barhoom, Alaa M.",
            "Khalil, Ahmed J.",
            "Musleh, Musleh M."
        ],
        "title": "Energy Efficiency Prediction using Artificial Neural Network",
        "publication_date": "2019-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "https://core.ac.uk/download/237182408.pdf"
        ],
        "id": "id4305543683669131010",
        "abstract": "Buildings energy consumption is growing gradually and put away around 40% of total energy use. Predicting heating and cooling loads of a building in the initial phase of the design to find out optimal solutions amongst different designs is very important, as  ell as in the operating phase after the building has been finished for efficient energy. In this study, an artificial neural network model was designed and developed for predicting heating and cooling loads of a building based on a dataset for building energy performance. The main factors for input variables are: relative compactness, roof area, overall height, surface area, glazing are a, wall area, glazing area distribution of a building, orientation, and the output variables: heating and cooling loads of the building. The dataset used for training are the data published in the literature for various 768 residential buildings. The model was trained and validated, most important factors affecting heating load and cooling load are identified, and the accuracy for the validation was 99.60%",
        "versions": [],
        "rank": 757
    },
    {
        "authors": [
            "Bashir Salisu Abubakar"
        ],
        "title": "Weed detection using machine learning: A systematic literature review",
        "publication_date": "2021-10-19 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "The Association of Professional Researchers and Academicians",
        "volume": "",
        "doi": "10.54480/slrm.v2i2.21",
        "urls": [
            "https://web.archive.org/web/20211102145430/http://slr-m.com/index.php/home/article/download/21/17"
        ],
        "id": "id-8364748714042973036",
        "abstract": "Recently, many researchers and practitioners used Machine Learning (ML) algorithms in digital agriculture to help farmers in decision making. This study aims to identify, assess and synthesize research papers that applied ML algorithms in weed detection using the Systematic Literature Review (SLR) Protocol. Based on our defined search string, we retrieved a total of 439 research papers from three electronic databases, of which 20 papers were selected based on the selection criteria and thus, were synthesized and analyzed in detail. The most applied ML algorithm is Neural Networks in these models. Thirteen evaluation parameters were identified, of which accuracy is the most used parameter. 75% of the selected papers used cross-validation as the evaluation approaches, while the rest used holdout. The challenges most encountered were insufficient data and manual labeling of the pixel during image segmentation. Based on the ML algorithms identified, we concluded that supervised learning techniques are the most used techniques in weed detection.",
        "versions": [],
        "rank": 758
    },
    {
        "authors": [
            "Hao Chen",
            "Susan McKeever",
            "Sarah Jane Delany"
        ],
        "title": "The Use of Deep Learning Distributed Representations in the Identification of Abusive Text",
        "publication_date": "2019-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20220804220609/https://ojs.aaai.org/index.php/ICWSM/article/download/3215/3083"
        ],
        "id": "id-4738690361117936709",
        "abstract": "The selection of optimal feature representations is a critical step in the use of machine learning in text classification. Traditional features (e.g. bag of words and n-grams) have dominated for decades, but in the past five years, the use of learned distributed representations has become increasingly common. In this paper, we summarise and present a categorisation of the stateof-the-art distributed representation techniques, including word and sentence embedding models. We carry out an empirical analysis of the performance of the various feature representations using the scenario of detecting abusive comments. We compare classification accuracies across a range of off-the-shelf embedding models using 10 labelled datasets gathered from different social media platforms. Our results show that multi-task sentence embedding models perform best with consistently highest classification results in comparison to other embedding models. We hope our work can be a guideline for practitioners in selecting appropriate features in text classification task, particularly in the domain of abuse detection.",
        "versions": [],
        "rank": 759
    },
    {
        "authors": [
            "Elmar Messner",
            "M. Fediuk",
            "P. Swatek",
            "S. Scheidl",
            "F. Smolle-J\u00fcttner",
            "H. Olschewski",
            "F. Pernkopf"
        ],
        "title": "Crackle and Breathing Phase Detection in Lung Sounds with Deep Bidirectional Gated Recurrent Neural Networks",
        "publication_date": "2018-07-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/EMBC.2018.8512237",
        "urls": [
            "https://www.semanticscholar.org/paper/dec89620beee354006ff5e58fa06e4b17c50be33"
        ],
        "id": "id-6979852959001960988",
        "abstract": "In this paper, we present a method for event detection in single-channel lung sound recordings. This includes the detection of crackles and breathing phase events (inspiration/expiration). Therefore, we propose an event detection approach with spectral features and bidirectional gated recurrent neural networks (BiGRNNs). In our experiments, we use multichannel lung sound recordings from lung-healthy subjects and patients diagnosed with idiopathic pulmonary fibrosis, collected within a clinical trial. We achieve an event-based F-score of F1 \u2248 86% for breathing phase events and F1 \u2248 72% for crackles. The proposed method shows robustness regarding the contamination of the lung sound recordings with noise, bowel and heart sounds.",
        "versions": [],
        "rank": 760
    },
    {
        "authors": [
            "Kursat Rasim Mestav",
            "Jaime Luengo-Rozas",
            "Lang Tong"
        ],
        "title": "Bayesian State Estimation for Unobservable Distribution Systems via Deep Learning",
        "publication_date": "2019-02-25 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20200827184923/https://arxiv.org/pdf/1811.02756v4.pdf"
        ],
        "id": "id-2120890499821849035",
        "abstract": "The problem of state estimation for unobservable distribution systems is considered. A deep learning approach to Bayesian state estimation is proposed for real-time applications. The proposed technique consists of distribution learning of stochastic power injection, a Monte Carlo technique for the training of a deep neural network for state estimation, and a Bayesian bad-data detection and filtering algorithm. Structural characteristics of the deep neural networks are investigated. Simulations illustrate the accuracy of Bayesian state estimation for unobservable systems and demonstrate the benefit of employing a deep neural network. Numerical results show the robustness of Bayesian state estimation against modeling and estimation errors and the presence of bad and missing data. Comparing with pseudo-measurement techniques, direct Bayesian state estimation via deep learning neural network outperforms existing benchmarks.",
        "versions": [],
        "rank": 761
    },
    {
        "authors": [
            "Jia Ding",
            "Aoxue Li",
            "Zhiqiang Hu",
            "Liwei Wang"
        ],
        "title": "Accurate Pulmonary Nodule Detection in Computed Tomography Images Using Deep Convolutional Neural Networks",
        "publication_date": "2017-06-14 03:31:04+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1706.04303v3",
            "http://arxiv.org/abs/1706.04303v3",
            "http://arxiv.org/pdf/1706.04303v3"
        ],
        "id": "id4904349238097767390",
        "abstract": "Early detection of pulmonary cancer is the most promising way to enhance a\npatient's chance for survival. Accurate pulmonary nodule detection in computed\ntomography (CT) images is a crucial step in diagnosing pulmonary cancer. In\nthis paper, inspired by the successful use of deep convolutional neural\nnetworks (DCNNs) in natural image recognition, we propose a novel pulmonary\nnodule detection approach based on DCNNs. We first introduce a deconvolutional\nstructure to Faster Region-based Convolutional Neural Network (Faster R-CNN)\nfor candidate detection on axial slices. Then, a three-dimensional DCNN is\npresented for the subsequent false positive reduction. Experimental results of\nthe LUng Nodule Analysis 2016 (LUNA16) Challenge demonstrate the superior\ndetection performance of the proposed approach on nodule detection(average\nFROC-score of 0.891, ranking the 1st place over all submitted results).",
        "versions": [],
        "rank": 762
    },
    {
        "authors": [
            "Li, Guanbin",
            "Yu, Yizhou"
        ],
        "title": "Deep Contrast Learning for Salient Object Detection",
        "publication_date": "2016-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": null,
        "volume": "",
        "doi": "10.1109/cvpr.2016.58",
        "urls": [
            "https://core.ac.uk/download/80962090.pdf"
        ],
        "id": "id3039284734836960270",
        "abstract": "Salient object detection has recently witnessed substantial progress due to\npowerful features extracted using deep convolutional neural networks (CNNs).\nHowever, existing CNN-based methods operate at the patch level instead of the\npixel level. Resulting saliency maps are typically blurry, especially near the\nboundary of salient objects. Furthermore, image patches are treated as\nindependent samples even when they are overlapping, giving rise to significant\nredundancy in computation and storage. In this CVPR 2016 paper, we propose an\nend-to-end deep contrast network to overcome the aforementioned limitations.\nOur deep network consists of two complementary components, a pixel-level fully\nconvolutional stream and a segment-wise spatial pooling stream. The first\nstream directly produces a saliency map with pixel-level accuracy from an input\nimage. The second stream extracts segment-wise features very efficiently, and\nbetter models saliency discontinuities along object boundaries. Finally, a\nfully connected CRF model can be optionally incorporated to improve spatial\ncoherence and contour localization in the fused result from these two streams.\nExperimental results demonstrate that our deep model significantly improves the\nstate of the art.Comment: To appear in CVPR 201",
        "versions": [],
        "rank": 763
    },
    {
        "authors": [
            "Feng Wang",
            "Fanshu Liao",
            "Huiqing Zhu"
        ],
        "title": "FPA-DNN: A Forward Propagation Acceleration based Deep Neural Network for Ship Detection",
        "publication_date": "2020-07-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/IJCNN48605.2020.9207603",
        "urls": [
            "https://www.semanticscholar.org/paper/819586419206abec72d254385569dfbef6067275"
        ],
        "id": "id-7253006804389685065",
        "abstract": "Ship detection in optical satellite images has played an important role in the field of remote sensing for a long time. Many detection methods have been proposed to address the ship detection problem, and most of them mainly focus on the improvement of detection accuracy but rarely pay attention to the detection speed. In this paper, we not only consider the improvement of detection accuracy, but also try to speed up the detection process. Based on the YOLOv2 model, we propose a forward propagation acceleration-based deep neural network model (FPA-DNN) to enhance the performance of the ship detection. The FPA-DNN model is a hybrid learning model, in which the deep neural network model LSDN can effectively reduce the number of parameters and improve the detection speed with no accuracy loss, and the pruning based forward propagation acceleration algorithm can remove the redundant convolution kernels and further speed up the detection process. Experimental results on the optical remote sensing image dataset show that, compared with several state-of-the-art deep learning models, 1) the LSDN model outperforms the others on the detection accuracy and detection speed; and 2) the FPA-DNN model can further improve the detection accuracy and speed up the detection process significantly.",
        "versions": [],
        "rank": 764
    },
    {
        "authors": [
            "Piyush Batra",
            "Gagan Raj Singh",
            "Neeraj Goyal"
        ],
        "title": "Application Of ADNN For Background Subtraction In Smart Surveillance System",
        "publication_date": "2022-12-31 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20230103081218/https://arxiv.org/ftp/arxiv/papers/2301/2301.00264.pdf"
        ],
        "id": "id3254617130786134457",
        "abstract": "Object movement identification is one of the most researched problems in the field of computer vision. In this task, we try to classify a pixel as foreground or background. Even though numerous traditional machine learning and deep learning methods already exist for this problem, the two major issues with most of them are the need for large amounts of ground truth data and their inferior performance on unseen videos. Since every pixel of every frame has to be labeled, acquiring large amounts of data for these techniques gets rather expensive. Recently, Zhao et al. [1] proposed one of a kind Arithmetic Distribution Neural Network (ADNN) for universal background subtraction which utilizes probability information from the histogram of temporal pixels and achieves promising results. Building onto this work, we developed an intelligent video surveillance system that uses ADNN architecture for motion detection, trims the video with parts only containing motion, and performs anomaly detection on the trimmed video.",
        "versions": [],
        "rank": 765
    },
    {
        "authors": [
            "Zhun Fan",
            "Jiewei Lu",
            "Maoguo Gong",
            "Honghui Xie",
            "E. Goodman"
        ],
        "title": "Automatic Tobacco Plant Detection in UAV Images via Deep Neural Networks",
        "publication_date": "2018-02-27 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
        "volume": "11",
        "doi": "10.1109/JSTARS.2018.2793849",
        "urls": [
            "https://www.semanticscholar.org/paper/e60606da48a9585d7cfc2d2487dec26898967b93"
        ],
        "id": "id-9015251958703379910",
        "abstract": "Tobacco plant detection plays an important role in the management of tobacco planting. In this paper, a new algorithm based on deep neural networks is proposed to detect tobacco plants in images captured by unmanned aerial vehicles (UAVs) (called UAV images). These UAV images are characterized by a very high spatial resolution (35 $\\text{mm}$), and consequently contain an extremely high level of detail for the development of automatic detection algorithms. The proposed algorithm consists of three stages. In the first stage, a number of candidate tobacco plant regions are extracted from UAV images with the morphological operations and watershed segmentation. Each candidate region contains a tobacco plant or a nontobacco plant. In the second stage, a deep convolutional neural network is built and trained with the purpose of classifying the candidate regions as tobacco plant regions or nontobacco plant regions. In the third stage, postprocessing is performed to further remove the nontobacco plant regions. The proposed algorithm is evaluated on a UAV image dataset. The experimental results show that the proposed algorithm performs well on the detection of tobacco plants in UAV images.",
        "versions": [],
        "rank": 766
    },
    {
        "authors": [
            "Fen Xiao",
            "Wenzheng Deng",
            "Liangchan Peng",
            "Chunhong Cao",
            "Kai Hu",
            "Xieping Gao"
        ],
        "title": "MSDNN: Multi-Scale Deep Neural Network for Salient Object Detection",
        "publication_date": "2018-01-12 14:54:36+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1801.04187v1",
            "http://arxiv.org/abs/1801.04187v1",
            "http://arxiv.org/pdf/1801.04187v1"
        ],
        "id": "id-5696553933820711550",
        "abstract": "Salient object detection is a fundamental problem and has been received a\ngreat deal of attentions in computer vision. Recently deep learning model\nbecame a powerful tool for image feature extraction. In this paper, we propose\na multi-scale deep neural network (MSDNN) for salient object detection. The\nproposed model first extracts global high-level features and context\ninformation over the whole source image with recurrent convolutional neural\nnetwork (RCNN). Then several stacked deconvolutional layers are adopted to get\nthe multi-scale feature representation and obtain a series of saliency maps.\nFinally, we investigate a fusion convolution module (FCM) to build a final\npixel level saliency map. The proposed model is extensively evaluated on four\nsalient object detection benchmark datasets. Results show that our deep model\nsignificantly outperforms other 12 state-of-the-art approaches.",
        "versions": [],
        "rank": 767
    },
    {
        "authors": [
            "T. Ozawa",
            "S. Ishihara",
            "M. Fujishiro",
            "Y. Kumagai",
            "S. Shichijo",
            "T. Tada"
        ],
        "title": "Automated endoscopic detection and classification of colorectal polyps using convolutional neural networks",
        "publication_date": "2020-03-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Therapeutic Advances in Gastroenterology",
        "volume": "13",
        "doi": "10.1177/1756284820910659",
        "urls": [
            "https://www.semanticscholar.org/paper/9dbe8f5f2a589dd0ea0bbbe5375fc7fdcfcf0954"
        ],
        "id": "id-624448394362992946",
        "abstract": "Background: Recently the American Society for Gastrointestinal Endoscopy addressed the \u2018resect and discard\u2019 strategy, determining that accurate in vivo differentiation of colorectal polyps (CP) is necessary. Previous studies have suggested a promising application of artificial intelligence (AI), using deep learning in object recognition. Therefore, we aimed to construct an AI system that can accurately detect and classify CP using stored still images during colonoscopy. Methods: We used a deep convolutional neural network (CNN) architecture called Single Shot MultiBox Detector. We trained the CNN using 16,418 images from 4752 CPs and 4013 images of normal colorectums, and subsequently validated the performance of the trained CNN in 7077 colonoscopy images, including 1172 CP images from 309 various types of CP. Diagnostic speed and yields for the detection and classification of CP were evaluated as a measure of performance of the trained CNN. Results: The processing time of the CNN was 20\u2009ms per frame. The trained CNN detected 1246 CP with a sensitivity of 92% and a positive predictive value (PPV) of 86%. The sensitivity and PPV were 90% and 83%, respectively, for the white light images, and 97% and 98% for the narrow band images. Among the correctly detected polyps, 83% of the CP were accurately classified through images. Furthermore, 97% of adenomas were precisely identified under the white light imaging. Conclusions: Our CNN showed promise in being able to detect and classify CP through endoscopic images, highlighting its high potential for future application as an AI-based CP diagnosis support system for colonoscopy.",
        "versions": [],
        "rank": 768
    },
    {
        "authors": [
            "Marc Combalia",
            "Ferran Hueto",
            "Susana Puig",
            "Josep Malvehy",
            "Veronica Vilaplana"
        ],
        "title": "Uncertainty Estimation in Deep Neural Networks for Dermoscopic Image Classification",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "IEEE",
        "volume": "",
        "doi": "10.1109/cvprw50498.2020.00380",
        "urls": [
            "https://web.archive.org/web/20220804155205/https://openaccess.thecvf.com/content_CVPRW_2020/papers/w42/Combalia_Uncertainty_Estimation_in_Deep_Neural_Networks_for_Dermoscopic_Image_Classification_CVPRW_2020_paper.pdf"
        ],
        "id": "id-5576773001422703173",
        "abstract": "The high performance of machine learning algorithms for the task of skin lesion classification has been shown over the past few years. However, real-world implementations are still scarce. One of the reasons could be that most methods do not quantify the uncertainty in the predictions and are not able to detect data that is anomalous or significantly different from that used in training, which may lead to a lack of confidence in the automated diagnosis or errors in the interpretation of results. In this work, we explore the use of uncertainty estimation techniques and metrics for deep neural networks based on Monte-Carlo sampling and apply them to the problem of skin lesion classification on data from ISIC Challenges 2018 and 2019. Our results show that uncertainty metrics can be successfully used to detect difficult and out-of-distribution samples.",
        "versions": [],
        "rank": 769
    },
    {
        "authors": [
            "David Berend"
        ],
        "title": "Distribution Awareness for AI System Testing",
        "publication_date": "2021-05-06 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20210508061234/https://arxiv.org/pdf/2105.02540v1.pdf"
        ],
        "id": "id5656915549411366410",
        "abstract": "As Deep Learning (DL) is continuously adopted in many safety critical applications, its quality and reliability start to raise concerns. Similar to the traditional software development process, testing the DL software to uncover its defects at an early stage is an effective way to reduce risks after deployment. Although recent progress has been made in designing novel testing techniques for DL software, the distribution of generated test data is not taken into consideration. It is therefore hard to judge whether the identified errors are indeed meaningful errors to the DL application. Therefore, we propose a new OOD-guided testing technique which aims to generate new unseen test cases relevant to the underlying DL system task. Our results show that this technique is able to filter up to 55.44% of error test case on CIFAR-10 and is 10.05% more effective in enhancing robustness.",
        "versions": [],
        "rank": 770
    },
    {
        "authors": [
            "Yan Shen",
            "Mingchen Gao"
        ],
        "title": "Dynamic Routing on Deep Neural Network for Thoracic Disease Classification and Sensitive Area Localization",
        "publication_date": "2018-08-17 04:00:25+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": "MLMI 2018",
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1808.05744v1",
            "http://arxiv.org/abs/1808.05744v1",
            "http://arxiv.org/pdf/1808.05744v1"
        ],
        "id": "id-4094181253619690800",
        "abstract": "We present and evaluate a new deep neural network architecture for automatic\nthoracic disease detection on chest X-rays. Deep neural networks have shown\ngreat success in a plethora of visual recognition tasks such as image\nclassification and object detection by stacking multiple layers of\nconvolutional neural networks (CNN) in a feed-forward manner. However, the\nperformance gain by going deeper has reached bottlenecks as a result of the\ntrade-off between model complexity and discrimination power. We address this\nproblem by utilizing the recently developed routing-by agreement mechanism in\nour architecture. A novel characteristic of our network structure is that it\nextends routing to two types of layer connections (1) connection between\nfeature maps in dense layers, (2) connection between primary capsules and\nprediction capsules in final classification layer. We show that our networks\nachieve comparable results with much fewer layers in the measurement of AUC\nscore. We further show the combined benefits of model interpretability by\ngenerating Gradient-weighted Class Activation Mapping (Grad-CAM) for\nlocalization. We demonstrate our results on the NIH chestX-ray14 dataset that\nconsists of 112,120 images on 30,805 unique patients including 14 kinds of lung\ndiseases.",
        "versions": [],
        "rank": 771
    },
    {
        "authors": [
            "Gautam, G.",
            "Mukhopadhyay, S."
        ],
        "title": "Contact Lens Detection using Transfer Learning with Deep Representations",
        "publication_date": "2018-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ijcnn.2018.8489590",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/8465565/8488986/08489590.pdf?arnumber=8489590",
            "http://dx.doi.org/10.1109/ijcnn.2018.8489590"
        ],
        "id": "id-2971634849359968119",
        "abstract": "",
        "versions": [],
        "rank": 772
    },
    {
        "authors": [
            "Ke Wang"
        ],
        "title": "Learning Scalable and Precise Representation of Program Semantics",
        "publication_date": "2019-05-13 19:16:22+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1905.05251v3",
            "http://arxiv.org/abs/1905.05251v3",
            "http://arxiv.org/pdf/1905.05251v3"
        ],
        "id": "id483062182064365823",
        "abstract": "Neural program embedding has shown potential in aiding the analysis of\nlarge-scale, complicated software. Newly proposed deep neural architectures\npride themselves on learning program semantics rather than superficial\nsyntactic features. However, by considering the source code only, the vast\nmajority of neural networks do not capture a deep, precise representation of\nprogram semantics. In this paper, we present \\dypro, a novel deep neural\nnetwork that learns from program execution traces. Compared to the prior\ndynamic models, not only is \\dypro capable of generalizing across multiple\nexecutions for learning a program's dynamic semantics in its entirety, but\n\\dypro is also more efficient when dealing with programs yielding long\nexecution traces. For evaluation, we task \\dypro with semantic classification\n(i.e. categorizing programs based on their semantics) and compared it against\ntwo prominent static models: Gated Graph Neural Network and TreeLSTM. We find\nthat \\dypro achieves the highest prediction accuracy among all models. To\nfurther reveal the capacity of all aforementioned deep neural architectures, we\nexamine if the models can learn to detect deeper semantic properties of a\nprogram. In particular given a task of recognizing loop invariants, we show\n\\dypro beats all static models by a wide margin.",
        "versions": [],
        "rank": 773
    },
    {
        "authors": [
            "Bongo, Lars Ailo",
            "M\u00f8llersen, Kajsa",
            "Voets, Mike"
        ],
        "title": "Replication study: Development and validation of deep learning algorithm  for detection of diabetic retinopathy in retinal fundus photographs",
        "publication_date": "2018-08-29 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "PLoS ONE",
        "volume": "",
        "doi": "10.1371/journal.pone.0217541",
        "urls": [
            "https://core.ac.uk/download/392176291.pdf"
        ],
        "id": "id-7382241732707631132",
        "abstract": "Replication studies are essential for validation of new methods, and are\ncrucial to maintain the high standards of scientific publications, and to use\nthe results in practice. We have attempted to replicate the main method in\n'Development and validation of a deep learning algorithm for detection of\ndiabetic retinopathy in retinal fundus photographs' published in JAMA 2016;\n316(22). We re-implemented the method since the source code is not available,\nand we used publicly available data sets. The original study used non-public\nfundus images from EyePACS and three hospitals in India for training. We used a\ndifferent EyePACS data set from Kaggle. The original study used the benchmark\ndata set Messidor-2 to evaluate the algorithm's performance. We used the same\ndata set. In the original study, ophthalmologists re-graded all images for\ndiabetic retinopathy, macular edema, and image gradability. There was one\ndiabetic retinopathy grade per image for our data sets, and we assessed image\ngradability ourselves. Hyper-parameter settings were not described in the\noriginal study. But some of these were later published. We were not able to\nreplicate the original study. Our algorithm's area under the receiver operating\ncurve (AUC) of 0.94 on the Kaggle EyePACS test set and 0.80 on Messidor-2 did\nnot come close to the reported AUC of 0.99 in the original study. This may be\ncaused by the use of a single grade per image, different data, or different not\ndescribed hyper-parameter settings. This study shows the challenges of\nreplicating deep learning, and the need for more replication studies to\nvalidate deep learning methods, especially for medical image analysis.\n  Our source code and instructions are available at:\nhttps://github.com/mikevoets/jama16-retina-replicationComment: The third version of this paper includes results from replication\n  after certain hyper-parameters were published in later article. 16 pages, 6\n  figures, 1 table, presented at NOBIM 201",
        "versions": [],
        "rank": 774
    },
    {
        "authors": [
            "Hayden Gunraj",
            "A. Sabri",
            "D. Koff",
            "A. Wong"
        ],
        "title": "COVID-Net CT-2: Enhanced Deep Neural Networks for Detection of COVID-19 From Chest CT Images Through Bigger, More Diverse Learning",
        "publication_date": "2021-01-19 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Frontiers in Medicine",
        "volume": "8",
        "doi": "10.3389/fmed.2021.729287",
        "urls": [
            "https://www.semanticscholar.org/paper/60dd8a30fc0f95ff6f42220ed73baa9427c9ce9c"
        ],
        "id": "id-4765740287108772409",
        "abstract": "The COVID-19 pandemic continues to rage on, with multiple waves causing substantial harm to health and economies around the world. Motivated by the use of computed tomography (CT) imaging at clinical institutes around the world as an effective complementary screening method to RT-PCR testing, we introduced COVID-Net CT, a deep neural network tailored for detection of COVID-19 cases from chest CT images, along with a large curated benchmark dataset comprising 1,489 patient cases as part of the open-source COVID-Net initiative. However, one potential limiting factor is restricted data quantity and diversity given the single nation patient cohort used in the study. To address this limitation, in this study we introduce enhanced deep neural networks for COVID-19 detection from chest CT images which are trained using a large, diverse, multinational patient cohort. We accomplish this through the introduction of two new CT benchmark datasets, the largest of which comprises a multinational cohort of 4,501 patients from at least 16 countries. To the best of our knowledge, this represents the largest, most diverse multinational cohort for COVID-19 CT images in open-access form. Additionally, we introduce a novel lightweight neural network architecture called COVID-Net CT S, which is significantly smaller and faster than the previously introduced COVID-Net CT architecture. We leverage explainability to investigate the decision-making behavior of the trained models and ensure that decisions are based on relevant indicators, with the results for select cases reviewed and reported on by two board-certified radiologists with over 10 and 30 years of experience, respectively. The best-performing deep neural network in this study achieved accuracy, COVID-19 sensitivity, positive predictive value, specificity, and negative predictive value of 99.0%/99.1%/98.0%/99.4%/99.7%, respectively. Moreover, explainability-driven performance validation shows consistency with radiologist interpretation by leveraging correct, clinically relevant critical factors. The results are promising and suggest the strong potential of deep neural networks as an effective tool for computer-aided COVID-19 assessment. While not a production-ready solution, we hope the open-source, open-access release of COVID-Net CT-2 and the associated benchmark datasets will continue to enable researchers, clinicians, and citizen data scientists alike to build upon them.",
        "versions": [],
        "rank": 775
    },
    {
        "authors": [
            "Jin-Hee Cho",
            "Shu Hu",
            "Feng Chen",
            "Xujiang Zhao"
        ],
        "title": "Uncertainty Aware Semi-Supervised Learning on Graph Data",
        "publication_date": "2020-10-24 00:00:00",
        "source": "SupportedSources.PAPERS_WITH_CODE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://arxiv.org/pdf/2010.12783v2.pdf",
            "https://github.com/zxj32/uncertainty-GNN",
            "http://proceedings.neurips.cc/paper/2020/file/968c9b4f09cbb7d7925f38aea3484111-Paper.pdf"
        ],
        "id": "id2087269344839667169",
        "abstract": "Thanks to graph neural networks (GNNs), semi-supervised node classification has shown the state-of-the-art performance in graph data. However, GNNs have not considered different types of uncertainties associated with class probabilities to minimize risk of increasing misclassification under uncertainty in real life. In this work, we propose a multi-source uncertainty framework using a GNN that reflects various types of predictive uncertainties in both deep learning and belief/evidence theory domains for node classification predictions. By collecting evidence from the given labels of training nodes, the Graph-based Kernel Dirichlet distribution Estimation (GKDE) method is designed for accurately predicting node-level Dirichlet distributions and detecting out-of-distribution (OOD) nodes. We validated the outperformance of our proposed model compared to the state-of-the-art counterparts in terms of misclassification detection and OOD detection based on six real network datasets. We found that dissonance-based detection yielded the best results on misclassification detection while vacuity-based detection was the best for OOD detection. To clarify the reasons behind the results, we provided the theoretical proof that explains the relationships between different types of uncertainties considered in this work.",
        "versions": [],
        "rank": 776
    },
    {
        "authors": [
            "Liu, C.",
            "Liu, Fuqiang"
        ],
        "title": "Towards Accurate and High-Speed Spiking Neuromorphic Systems with Data  Quantization-Aware Deep Networks",
        "publication_date": "2019-09-08 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1145/3195970.3196131",
        "urls": [
            "http://arxiv.org/abs/1805.03054"
        ],
        "id": "id8296375462705671463",
        "abstract": "Deep Neural Networks (DNNs) have gained immense success in cognitive\napplications and greatly pushed today's artificial intelligence forward. The\nbiggest challenge in executing DNNs is their extremely data-extensive\ncomputations. The computing efficiency in speed and energy is constrained when\ntraditional computing platforms are employed in such computational hungry\nexecutions. Spiking neuromorphic computing (SNC) has been widely investigated\nin deep networks implementation own to their high efficiency in computation and\ncommunication. However, weights and signals of DNNs are required to be\nquantized when deploying the DNNs on the SNC, which results in unacceptable\naccuracy loss. %However, the system accuracy is limited by quantizing data\ndirectly in deep networks deployment. Previous works mainly focus on weights\ndiscretize while inter-layer signals are mainly neglected. In this work, we\npropose to represent DNNs with fixed integer inter-layer signals and\nfixed-point weights while holding good accuracy. We implement the proposed DNNs\non the memristor-based SNC system as a deployment example. With 4-bit data\nrepresentation, our results show that the accuracy loss can be controlled\nwithin 0.02% (2.3%) on MNIST (CIFAR-10). Compared with the 8-bit dynamic\nfixed-point DNNs, our system can achieve more than 9.8x speedup, 89.1% energy\nsaving, and 30% area saving.Comment: 6 pages, 4 figure",
        "versions": [],
        "rank": 777
    },
    {
        "authors": [
            "Uma Narayanan",
            "Varghese Paul",
            "Shelbi Joseph"
        ],
        "title": "A novel approach to big data analysis using deep belief network for the detection of android malware",
        "publication_date": "2019-12-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Institute of Advanced Engineering and Science",
        "volume": "",
        "doi": "10.11591/ijeecs.v16.i3.pp1447-1454",
        "urls": [
            "https://web.archive.org/web/20200314200834/http://ijeecs.iaescore.com/index.php/IJEECS/article/download/17806/13178"
        ],
        "id": "id-5193818637505993356",
        "abstract": "Mobile and tablets are rapidly getting the chance to be basic device in the everyday life. Android has been the most well-known versatile working structure. Regardless, inferable from the open thought of Android, amount of malware is concealed in a broad number of kind applications in Android exhibits that really undermine Android security. Deep learning is another domain of AI explore that has expanded extending thought in artificial information. In this examination, we propose to relate the features from the static examination with features from the dynamic examination of Android applications and depict malware using Deep learning systems. What's more, besides distinguishing sensitive customer data sources is fundamental for security protection in portable applications. So we propose a Novel way to deal with overseeing tremendous information examination utilizing Deep learning for the affirmation of Android malware.",
        "versions": [],
        "rank": 778
    },
    {
        "authors": [
            "Abbeel, Pieter",
            "Darrell, Trevor",
            "Devin, Coline",
            "Levine, Sergey"
        ],
        "title": "Deep Object-Centric Representations for Generalizable Robot Learning",
        "publication_date": "2017-09-26 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/icra.2018.8461196",
        "urls": [
            "http://arxiv.org/abs/1708.04225"
        ],
        "id": "id-4954963076165549012",
        "abstract": "Robotic manipulation in complex open-world scenarios requires both reliable\nphysical manipulation skills and effective and generalizable perception. In\nthis paper, we propose a method where general purpose pretrained visual models\nserve as an object-centric prior for the perception system of a learned policy.\nWe devise an object-level attentional mechanism that can be used to determine\nrelevant objects from a few trajectories or demonstrations, and then\nimmediately incorporate those objects into a learned policy. A task-independent\nmeta-attention locates possible objects in the scene, and a task-specific\nattention identifies which objects are predictive of the trajectories. The\nscope of the task-specific attention is easily adjusted by showing\ndemonstrations with distractor objects or with diverse relevant objects. Our\nresults indicate that this approach exhibits good generalization across object\ninstances using very few samples, and can be used to learn a variety of\nmanipulation tasks using reinforcement learning",
        "versions": [],
        "rank": 779
    },
    {
        "authors": [
            "Jianxu Chen",
            "Chukka Srinivas"
        ],
        "title": "Automatic Lymphocyte Detection in H&E Images with Deep Neural Networks",
        "publication_date": "2016-12-09 23:31:35+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1612.03217v1",
            "http://arxiv.org/abs/1612.03217v1",
            "http://arxiv.org/pdf/1612.03217v1"
        ],
        "id": "id-7550907759273795670",
        "abstract": "Automatic detection of lymphocyte in H&E images is a necessary first step in\nlots of tissue image analysis algorithms. An accurate and robust automated\nlymphocyte detection approach is of great importance in both computer science\nand clinical studies. Most of the existing approaches for lymphocyte detection\nare based on traditional image processing algorithms and/or classic machine\nlearning methods. In the recent years, deep learning techniques have\nfundamentally transformed the way that a computer interprets images and have\nbecome a matchless solution in various pattern recognition problems. In this\nwork, we design a new deep neural network model which extends the fully\nconvolutional network by combining the ideas in several recent techniques, such\nas shortcut links. Also, we design a new training scheme taking the prior\nknowledge about lymphocytes into consideration. The training scheme not only\nefficiently exploits the limited amount of free-form annotations from\npathologists, but also naturally supports efficient fine-tuning. As a\nconsequence, our model has the potential of self-improvement by leveraging the\nerrors collected during real applications. Our experiments show that our deep\nneural network model achieves good performance in the images of different\nstaining conditions or different types of tissues.",
        "versions": [],
        "rank": 780
    },
    {
        "authors": [
            "O. E. Taylor",
            "P. S. Ezekiel"
        ],
        "title": "A Smart System for Detecting Behavioural Botnet Attacks using Random Forest Classifier with Principal Component Analysis",
        "publication_date": "2022-03-23 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "European Open Science Publishing",
        "volume": "",
        "doi": "10.24018/ejai.2022.1.2.4",
        "urls": [
            "https://web.archive.org/web/20220613151134/https://www.ej-ai.org/index.php/ejai/article/download/4/3"
        ],
        "id": "id4515553158544229483",
        "abstract": "Over the years, malware (malicious software) has become a major challenge for computer users, organizations, and even countries. In particular, a compromise of a set of inflamed hosts (aka zombies or bots) is one of the severe threats to Internet security. Botnet is described as some computer systems or devices controlled on the Internet to carry out unintentional and malicious acts without the owner's permission. Due to the continuously progressing behavior of botnets, the conventional methods fail to identify botnets. In other to solve the stated problem, this paper presents a smart system for detecting behavioural bootnet attacks using Random Forest Classifier and Principal Component Analysis (PCA). The system starts with a botnet dataset that was used in building a robust model in detecting Bootnet attacks. The dataset was pre-processed using pandas library for data cleaning. PCA was used in reducing the dimension of the dataset, so as to avoid data imbalance. The result of the PCA was used as input to the random forest classifier. The random forest classifier was trained using the number of estimators as 1000. The result of the model shows a promising accuracy of about 99%.",
        "versions": [],
        "rank": 781
    },
    {
        "authors": [
            "Abolmaesumi, P.",
            "Descoteaux, M.",
            "Fedorov, A.",
            "Franz, A.",
            "Ghafoorian, M.",
            "Ginneken, B. van",
            "Guttmann, C.R.G.",
            "Kapur, T.",
            "Karssemeijer, N.",
            "Leeuw, F.-E. de",
            "Maier-Hein, L.",
            "Marchiori, E.",
            "Mehrtash, A.",
            "Pesteie, M.",
            "Platel, B.",
            "Tempany, C.M.",
            "Wells, W.M."
        ],
        "title": "Transfer Learning for Domain Adaptation in MRI: Application in Brain  Lesion Segmentation",
        "publication_date": "2017-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": null,
        "volume": "",
        "doi": "10.1007/978-3-319-66179-7_59",
        "urls": [
            "https://core.ac.uk/download/132288646.pdf"
        ],
        "id": "id778591351840022524",
        "abstract": "Magnetic Resonance Imaging (MRI) is widely used in routine clinical diagnosis\nand treatment. However, variations in MRI acquisition protocols result in\ndifferent appearances of normal and diseased tissue in the images.\nConvolutional neural networks (CNNs), which have shown to be successful in many\nmedical image analysis tasks, are typically sensitive to the variations in\nimaging protocols. Therefore, in many cases, networks trained on data acquired\nwith one MRI protocol, do not perform satisfactorily on data acquired with\ndifferent protocols. This limits the use of models trained with large annotated\nlegacy datasets on a new dataset with a different domain which is often a\nrecurring situation in clinical settings. In this study, we aim to answer the\nfollowing central questions regarding domain adaptation in medical image\nanalysis: Given a fitted legacy model, 1) How much data from the new domain is\nrequired for a decent adaptation of the original network?; and, 2) What portion\nof the pre-trained model parameters should be retrained given a certain number\nof the new domain training samples? To address these questions, we conducted\nextensive experiments in white matter hyperintensity segmentation task. We\ntrained a CNN on legacy MR images of brain and evaluated the performance of the\ndomain-adapted network on the same task with images from a different domain. We\nthen compared the performance of the model to the surrogate scenarios where\neither the same trained network is used or a new network is trained from\nscratch on the new dataset.The domain-adapted network tuned only by two\ntraining examples achieved a Dice score of 0.63 substantially outperforming a\nsimilar network trained on the same set of examples from scratch.Comment: 8 pages, 3 figure",
        "versions": [],
        "rank": 782
    },
    {
        "authors": [
            "Jingyu Cui",
            "He Jia",
            "Haipeng Wang",
            "F. Xu"
        ],
        "title": "A Fast Threshold Neural Network for Ship Detection in Large-Scene SAR Images",
        "publication_date": "None",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
        "volume": "15",
        "doi": "10.1109/jstars.2022.3192455",
        "urls": [
            "https://www.semanticscholar.org/paper/f4e503c38b89d1bfbc40c67314069b138183b0bb"
        ],
        "id": "id7305919338581331077",
        "abstract": "Multiscale ship detection in large-scene offshore synthetic aperture radar (SAR) images is of great significance in civil and military fields, such as maritime management and wartime reconnaissance. Methods based on deep learning apply a deep neural network to extract multiscale information from SAR images, which improves detection performance. However, deep neural networks are computationally complex, and even with GPU acceleration, the timeliness of ship detection in large-scene SAR images is still constrained. Methods based on threshold segmentation, in contrast, are efficient and straightforward, but they are less robust and need to be adjusted with complex and changing scenes. This article combines two methods and proposes a lightweight framework based on a threshold neural network (TNN) to achieve fast detection. Specifically, the TNN is carefully designed to extract the grayscale features of the SAR image, which predicts the optimal detection threshold within the sliding window and separates the targets adaptively. In addition, a false alarm rejection network is used to discriminate candidate targets and improve detection accuracy. Experiments are carried out on the public SSDD offshore dataset and the FUSAR-Ship-Detection dataset. The results show that the proposed framework performs 14.43% better than the Multi-CFAR for the SSDD offshore dataset and 7.36% better for the FUSAR-Ship-Detection dataset when using F1 as the metric. Furthermore, the floating point operations of the proposed framework are only 1/240 of those of YOLO-v4 with comparable performance.",
        "versions": [],
        "rank": 783
    },
    {
        "authors": [
            "Guanbin Li",
            "Yizhou Yu"
        ],
        "title": "Contrast-Oriented Deep Neural Networks for Salient Object Detection",
        "publication_date": "2018-03-30 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "IEEE Transactions on Neural Networks and Learning Systems",
        "volume": "29",
        "doi": "10.1109/TNNLS.2018.2817540",
        "urls": [
            "https://www.semanticscholar.org/paper/31603f17397f0c69a8b02041d05abe9c96357996"
        ],
        "id": "id644599203090561269",
        "abstract": "Deep convolutional neural networks (CNNs) have become a key element in the recent breakthrough of salient object detection. However, existing CNN-based methods are based on either patchwise (regionwise) training and inference or fully convolutional networks. Methods in the former category are generally time-consuming due to severe storage and computational redundancies among overlapping patches. To overcome this deficiency, methods in the second category attempt to directly map a raw input image to a predicted dense saliency map in a single network forward pass. Though being very efficient, it is arduous for these methods to detect salient objects of different scales or salient regions with weak semantic information. In this paper, we develop hybrid contrast-oriented deep neural networks to overcome the aforementioned limitations. Each of our deep networks is composed of two complementary components, including a fully convolutional stream for dense prediction and a segment-level spatial pooling stream for sparse saliency inference. We further propose an attentional module that learns weight maps for fusing the two saliency predictions from these two streams. A tailored alternate scheme is designed to train these deep networks by fine-tuning pretrained baseline models. Finally, a customized fully connected conditional random field model incorporating a salient contour feature embedding can be optionally applied as a postprocessing step to improve spatial coherence and contour positioning in the fused result from these two streams. Extensive experiments on six benchmark data sets demonstrate that our proposed model can significantly outperform the state of the art in terms of all popular evaluation metrics.",
        "versions": [
            {
                "year": 2018,
                "source": "SupportedSources.ARXIV",
                "title": "Contrast-Oriented Deep Neural Networks for Salient Object Detection",
                "journal": null,
                "urls": [
                    "http://arxiv.org/pdf/1803.11395v1",
                    "http://arxiv.org/abs/1803.11395v1",
                    "http://arxiv.org/pdf/1803.11395v1"
                ],
                "doi": "",
                "publication_date": "2018-03-30 09:51:04+00:00"
            }
        ],
        "rank": 784
    },
    {
        "authors": [
            "Ting-En Lin",
            "Hua Xu"
        ],
        "title": "A Post-processing Method for Detecting Unknown Intent of Dialogue System via Pre-trained Deep Neural Network Classifier",
        "publication_date": "2020-03-07 03:29:01+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "10.1016/j.knosys.2019.104979",
        "urls": [
            "http://arxiv.org/pdf/2003.03504v1",
            "http://dx.doi.org/10.1016/j.knosys.2019.104979",
            "http://arxiv.org/abs/2003.03504v1",
            "http://arxiv.org/pdf/2003.03504v1"
        ],
        "id": "id656278073691500945",
        "abstract": "With the maturity and popularity of dialogue systems, detecting user's\nunknown intent in dialogue systems has become an important task. It is also one\nof the most challenging tasks since we can hardly get examples, prior knowledge\nor the exact numbers of unknown intents. In this paper, we propose SofterMax\nand deep novelty detection (SMDN), a simple yet effective post-processing\nmethod for detecting unknown intent in dialogue systems based on pre-trained\ndeep neural network classifiers. Our method can be flexibly applied on top of\nany classifiers trained in deep neural networks without changing the model\narchitecture. We calibrate the confidence of the softmax outputs to compute the\ncalibrated confidence score (i.e., SofterMax) and use it to calculate the\ndecision boundary for unknown intent detection. Furthermore, we feed the\nfeature representations learned by the deep neural networks into traditional\nnovelty detection algorithm to detect unknown intents from different\nperspectives. Finally, we combine the methods above to perform the joint\nprediction. Our method classifies examples that differ from known intents as\nunknown and does not require any examples or prior knowledge of it. We have\nconducted extensive experiments on three benchmark dialogue datasets. The\nresults show that our method can yield significant improvements compared with\nthe state-of-the-art baselines",
        "versions": [],
        "rank": 785
    },
    {
        "authors": [
            "H. A. Afolabi",
            "A. Aburas"
        ],
        "title": "Proposed Back Propagation Deep Neural Network for Intrusion Detection in Internet of Things Fog Computing",
        "publication_date": "None",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.30534/ijeter/2021/23942021",
        "urls": [
            "https://www.semanticscholar.org/paper/84ec55680ee8b2d0116f8b009e6def22b68b4769"
        ],
        "id": "id1249569802399536985",
        "abstract": "Internet of things (IoT) is an emerging concept which aims to connect billions of devices with each other anytime regardless of their location. Sadly, these IoT devices do not have enough computing resources to process huge amount of data. Therefore, Cloud computing is relied on to provide these resources. However, cloud computing based architecture fails in applications that demand very low and predictable latency, therefore the need for fog computing which is a new paradigm that is regarded as an extension of cloud computing to provide services between end users and the cloud user. Unfortunately, Fog-IoT is confronted with various security and privacy risks and prone to several cyberattacks which is a serious challenge. The purpose of this work is to present security and privacy threats towards Fog-IoT platform and discuss the security and privacy requirements in fog computing. We then proceed to propose an Intrusion Detection System (IDS) model using Standard Deep Neural Network's Back Propagation algorithm (BPDNN) to mitigate intrusions that attack Fog-IoT platform. The experimental Dataset for the proposed model is obtained from the Canadian Institute for Cybersecurity 2017 Dataset. Each instance of the attack in the dataset is separated into separate files, which are DoS (Denial of Service), DDoS (Distributed Denial of Service), Web Attack, Brute Force FTP, Brute Force SSH, Heartbleed, Infiltration and Botnet (Bot Network) Attack. The proposed model is trained using a 3-layer BP-DNN",
        "versions": [],
        "rank": 786
    },
    {
        "authors": [
            "M.-Marchsel Mesulam"
        ],
        "title": "A cortical network for directed attention and unilateral neglect",
        "publication_date": "1981-10-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Annals of Neurology",
        "volume": "10",
        "doi": "10.1002/ana.410100402",
        "urls": [
            "https://openalex.org/W2052318178",
            "https://doi.org/10.1002/ana.410100402"
        ],
        "id": "id-8095443547005478069",
        "abstract": "",
        "versions": [],
        "rank": 787
    },
    {
        "authors": [
            "Zhan Wei Lim",
            "Mong Li Lee",
            "Wynne Hsu",
            "Tien Yin Wong"
        ],
        "title": "Building Trust in Deep Learning System towards Automated Disease Detection",
        "publication_date": "2019-07-17 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Association for the Advancement of Artificial Intelligence (AAAI)",
        "volume": "",
        "doi": "10.1609/aaai.v33i01.33019516",
        "urls": [
            "https://web.archive.org/web/20200507095355/https://www.aaai.org/ojs/index.php/AAAI/article/download/5009/4882"
        ],
        "id": "id-3292465513923921347",
        "abstract": "Though deep learning systems have achieved high accuracy in detecting diseases from medical images, few such systems have been deployed in highly automated disease screening settings due to lack of trust in how well these systems can generalize to out-of-datasets. We propose to use uncertainty estimates of the deep learning system's prediction to know when to accept or to disregard its prediction. We evaluate the effectiveness of using such estimates in a real-life application for the screening of diabetic retinopathy. We also generate visual explanation of the deep learning system to convey the pixels in the image that influences its decision. Together, these reveal the deep learning system's competency and limits to the human, and in turn the human can know when to trust the deep learning system.",
        "versions": [],
        "rank": 788
    },
    {
        "authors": [
            "Dam, Hieu-Chi",
            "Gupta, Sunil",
            "Nguyen, Phuoc",
            "Rana, Santu",
            "Tran, Truyen",
            "Venkatesh, Svetha"
        ],
        "title": "HyperVAE: A Minimum Description Length Variational Hyper-Encoding  Network",
        "publication_date": "2020-05-18 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "http://arxiv.org/abs/2005.08482"
        ],
        "id": "id-909172923726208830",
        "abstract": "We propose a framework called HyperVAE for encoding distributions of\ndistributions. When a target distribution is modeled by a VAE, its neural\nnetwork parameters \\theta is drawn from a distribution p(\\theta) which is\nmodeled by a hyper-level VAE. We propose a variational inference using Gaussian\nmixture models to implicitly encode the parameters \\theta into a low\ndimensional Gaussian distribution. Given a target distribution, we predict the\nposterior distribution of the latent code, then use a matrix-network decoder to\ngenerate a posterior distribution q(\\theta). HyperVAE can encode the parameters\n\\theta in full in contrast to common hyper-networks practices, which generate\nonly the scale and bias vectors as target-network parameters. Thus HyperVAE\npreserves much more information about the model for each task in the latent\nspace. We discuss HyperVAE using the minimum description length (MDL) principle\nand show that it helps HyperVAE to generalize. We evaluate HyperVAE in density\nestimation tasks, outlier detection and discovery of novel design classes,\ndemonstrating its efficacy",
        "versions": [],
        "rank": 789
    },
    {
        "authors": [
            "B. Suresh Kumar",
            "D. Jayaraj"
        ],
        "title": "Survival study on cyclone prediction methods with remote sensing images",
        "publication_date": "2022-04-27 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Universidad Tecnica de Manabi",
        "volume": "",
        "doi": "10.53730/ijhs.v6ns1.6668",
        "urls": [
            "https://web.archive.org/web/20220506211924/https://sciencescholar.us/journal/index.php/ijhs/article/download/6668/2991"
        ],
        "id": "id1547680186031048322",
        "abstract": "Image classification has large interest for many decades in the remote sensing communities to reduce injure caused by cyclones. A cyclone is the leading rotating storm that includes the strong wind and rain. It included the number of interrelated features like eye, cyclone pathway, wind speed, generated storm surges, rainfall intensity and so on. Among the features, it is essential one to find in which direction cyclone travels and it influence the areas increasing the damage to life and assets. The cyclone prediction is a key issue where image intensity described the pattern characteristics at various stages. Many existing works have been designed in cyclone prediction for attaining better prediction accuracy. But, it is difficult to enhance the cyclone prediction accuracy with minimum time complexity. In order to address these issues, cyclone prediction can be carried out using deep leaning methods.",
        "versions": [],
        "rank": 790
    },
    {
        "authors": [
            "Ravi Sahu"
        ],
        "title": "Detecting and Counting Small Animal Species Using Drone Imagery by Applying Deep Learning",
        "publication_date": "2019-08-09 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "IntechOpen",
        "volume": "",
        "doi": "10.5772/intechopen.88437",
        "urls": [
            "https://web.archive.org/web/20200310102247/https://api.intechopen.com/chapter/pdf-download/68545.pdf"
        ],
        "id": "id-5626820376846320190",
        "abstract": "This work represents deep learning approach for detecting lizards on the summer grass background. It is the main part of general use case formulation-\"how many animals are located now on this substitute habitat. Determine in which parts they prefer to stay\". For this purpose, the U-Net architecture neural network was implemented. Dilated convolution layer was added to usual U-Net. Smoothly blending filter was applied to result probability patches for connecting them in one big probability map without sewed edges. Designed flexible architecture allows to train neural network for pixel-wise semantic segmentation with accuracy value 0.9863 on the tiny dataset.",
        "versions": [],
        "rank": 791
    },
    {
        "authors": [
            "Carl Gans",
            "R. Glenn Northcutt"
        ],
        "title": "Neural Crest and the Origin of Vertebrates: A New Head",
        "publication_date": "1983-04-15 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Science",
        "volume": "220",
        "doi": "10.1126/science.220.4594.268",
        "urls": [
            "https://openalex.org/W1997035797",
            "https://doi.org/10.1126/science.220.4594.268"
        ],
        "id": "id-7595041431073390976",
        "abstract": "",
        "versions": [],
        "rank": 792
    },
    {
        "authors": [
            "Weitong Guo",
            "Hongwu Yang",
            "Zhenyu Liu",
            "Yaping Xu",
            "B. Hu"
        ],
        "title": "Deep Neural Networks for Depression Recognition Based on 2D and 3D Facial Expressions Under Emotional Stimulus Tasks",
        "publication_date": "2021-04-23 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Frontiers in Neuroscience",
        "volume": "15",
        "doi": "10.3389/fnins.2021.609760",
        "urls": [
            "https://www.semanticscholar.org/paper/ff3ee2c1f02f999fed79634425cf6ffa1aef9cf5"
        ],
        "id": "id-3283508221635633623",
        "abstract": "The proportion of individuals with depression has rapidly increased along with the growth of the global population. Depression has been the currently most prevalent mental health disorder. An effective depression recognition system is especially crucial for the early detection of potential depression risk. A depression-related dataset is also critical while evaluating the system for depression or potential depression risk detection. Due to the sensitive nature of clinical data, availability and scale of such datasets are scarce. To our knowledge, there are few extensively practical depression datasets for the Chinese population. In this study, we first create a large-scale dataset by asking subjects to perform five mood-elicitation tasks. After each task, subjects' audio and video are collected, including 3D information (depth information) of facial expressions via a Kinect. The constructed dataset is from a real environment, i.e., several psychiatric hospitals, and has a specific scale. Then we propose a novel approach for potential depression risk recognition based on two kinds of different deep belief network (DBN) models. One model extracts 2D appearance features from facial images collected by an optical camera, while the other model extracts 3D dynamic features from 3D facial points collected by a Kinect. The final decision result comes from the combination of the two models. Finally, we evaluate all proposed deep models on our built dataset. The experimental results demonstrate that (1) our proposed method is able to identify patients with potential depression risk; (2) the recognition performance of combined 2D and 3D features model outperforms using either 2D or 3D features model only; (3) the performance of depression recognition is higher in the positive and negative emotional stimulus, and females' recognition rate is generally higher than that for males. Meanwhile, we compare the performance with other methods on the same dataset. The experimental results show that our integrated 2D and 3D features DBN is more reasonable and universal than other methods, and the experimental paradigm designed for depression is reasonable and practical.",
        "versions": [],
        "rank": 793
    },
    {
        "authors": [
            "Valliammal N",
            "Barani Shaju"
        ],
        "title": "Deep learning algorithm based cyber-attack detection in cyber-physical systems-a survey",
        "publication_date": "2018-12-21 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Association of Computer, Communication and Education for National Triumph Social and Welfare Society (ACCENTS)",
        "volume": "",
        "doi": "10.19101/ijatee.2018.547030",
        "urls": [
            "https://web.archive.org/web/20220308081814/https://www.accentsjournals.org/PaperDirectory/Journal/IJATEE/2018/12/3.pdf"
        ],
        "id": "id6939224718835176685",
        "abstract": "Over the last years, cyber-attack detection and control system design has become a significant area in cyber-physical systems (CPSs) due to the rapid growth of cyber-security challenges via sophisticated attacks like data injection attacks, replay attacks, etc. The effect of different attacks may provide system failure, malfunctioning, etc. As a result, an improved security system may require to implement the cyber defense system for upcoming CPSs. The different deep learning algorithm based cyber-attack detection schemes have been designed to detect and mitigate the different types of cyber-attacks through CPSs, smart grids, power systems, etc. This article presents a detailed survey of various deep learning algorithms proposed for CPSs to achieve cyber defense. At first, different algorithms developed by previous researchers are studied in detail. Then, a comparative analysis is carried out to know the limitations in each algorithm and provide a suggestion for further improvement of CPSs with more efficiently.",
        "versions": [],
        "rank": 794
    },
    {
        "authors": [
            "M. Schirrmann",
            "Niels Landwehr",
            "A. Giebel",
            "A. Garz",
            "K. Dammer"
        ],
        "title": "Early Detection of Stripe Rust in Winter Wheat Using Deep Residual Neural Networks",
        "publication_date": "2021-03-30 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Frontiers in Plant Science",
        "volume": "12",
        "doi": "10.3389/fpls.2021.469689",
        "urls": [
            "https://www.semanticscholar.org/paper/06ad833e019e0b58fa418b80fdd18090bad948fb"
        ],
        "id": "id3031230924606813072",
        "abstract": "Stripe rust (Pst) is a major disease of wheat crops leading untreated to severe yield losses. The use of fungicides is often essential to control Pst when sudden outbreaks are imminent. Sensors capable of detecting Pst in wheat crops could optimize the use of fungicides and improve disease monitoring in high-throughput field phenotyping. Now, deep learning provides new tools for image recognition and may pave the way for new camera based sensors that can identify symptoms in early stages of a disease outbreak within the field. The aim of this study was to teach an image classifier to detect Pst symptoms in winter wheat canopies based on a deep residual neural network (ResNet). For this purpose, a large annotation database was created from images taken by a standard RGB camera that was mounted on a platform at a height of 2 m. Images were acquired while the platform was moved over a randomized field experiment with Pst-inoculated and Pst-free plots of winter wheat. The image classifier was trained with 224 \u00d7 224 px patches tiled from the original, unprocessed camera images. The image classifier was tested on different stages of the disease outbreak. At patch level the image classifier reached a total accuracy of 90%. To test the image classifier on image level, the image classifier was evaluated with a sliding window using a large striding length of 224 px allowing for fast test performance. At image level, the image classifier reached a total accuracy of 77%. Even in a stage with very low disease spreading (0.5%) at the very beginning of the Pst outbreak, a detection accuracy of 57% was obtained. Still in the initial phase of the Pst outbreak with 2 to 4% of Pst disease spreading, detection accuracy with 76% could be attained. With further optimizations, the image classifier could be implemented in embedded systems and deployed on drones, vehicles or scanning systems for fast mapping of Pst outbreaks.",
        "versions": [],
        "rank": 795
    },
    {
        "authors": [
            "Irfan Khatik",
            "Nilesh Mahajan"
        ],
        "title": "FRACTURE DETECTION: A QUICK SURVEY OF DEEP LEARNING MODELS",
        "publication_date": "2021-05-17 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Zenodo",
        "volume": "",
        "doi": "10.5281/zenodo.5763104",
        "urls": [
            "https://web.archive.org/web/20211208181204/https://zenodo.org/record/5763105/files/IJCRT2105699.pdf"
        ],
        "id": "id3615750118594749464",
        "abstract": "Bone fracture is a common problem now days due to road accidents, unhealthy lifestyle and many other causes. Bone is an integral part of the human body to move and shape it. A small fracture in the bone affects normal functioning of the bone and in result affects the free movement of the person. Fracture is common in human bones. There are a lot of techniques to find out fractures. Normal technique is time consuming and expert dependent. It also has a high error rate. In case of suspected fractures, the patient visits emergency units and X-ray is the primary tool to assess the patient for fracture. X-ray detection is economical mean for fracture. Missing a fracture has severe consequences on patients. Automated detection of bone fracture is a hot research topic today. There are a lot of papers on automated fracture detection. This paper focuses on deep learning methods for bone fracture detection. Deep learning is a Neural Network based method where more hidden layers are used with the artificial neural network. Objective is to provide an overview of deep learning methods on bone fracture to help researchers to further explore the idea. This paper also discuss about the popular python APIs in deep learning",
        "versions": [],
        "rank": 796
    },
    {
        "authors": [
            "Anne Achieng Osio",
            "Ho\u00e0ng-\u00c2n L\u00ea",
            "Samson Ayugi",
            "Fred Onyango",
            "Peter Odwe",
            "S\u00e9bastien Lef\u00e8vre"
        ],
        "title": "Detection of Degraded Acacia tree species using deep neural networks on uav drone imagery",
        "publication_date": "2022-04-14 16:37:26+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2204.07096v1",
            "http://arxiv.org/abs/2204.07096v1",
            "http://arxiv.org/pdf/2204.07096v1"
        ],
        "id": "id-7798523878503380984",
        "abstract": "Deep-learning-based image classification and object detection has been\napplied successfully to tree monitoring. However, studies of tree crowns and\nfallen trees, especially on flood inundated areas, remain largely unexplored.\nDetection of degraded tree trunks on natural environments such as water,\nmudflats, and natural vegetated areas is challenging due to the mixed colour\nimage backgrounds. In this paper, Unmanned Aerial Vehicles (UAVs), or drones,\nwith embedded RGB cameras were used to capture the fallen Acacia Xanthophloea\ntrees from six designated plots around Lake Nakuru, Kenya. Motivated by the\nneed to detect fallen trees around the lake, two well-established deep neural\nnetworks, i.e. Faster Region-based Convolution Neural Network (Faster R-CNN)\nand Retina-Net were used for fallen tree detection. A total of 7,590\nannotations of three classes on 256 x 256 image patches were used for this\nstudy. Experimental results show the relevance of deep learning in this\ncontext, with Retina-Net model achieving 38.9% precision and 57.9% recall.",
        "versions": [],
        "rank": 797
    },
    {
        "authors": [
            "Ardimento, P.",
            "Aversano, L.",
            "Bernardi, M.",
            "Cimitile, M."
        ],
        "title": "Deep Neural Networks Ensemble for Lung Nodule Detection on Chest CT Scans",
        "publication_date": "2021-07-18 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ijcnn52387.2021.9534176",
        "urls": [
            "http://xplorestaging.ieee.org/ielx7/9533266/9533267/09534176.pdf?arnumber=9534176",
            "http://dx.doi.org/10.1109/ijcnn52387.2021.9534176"
        ],
        "id": "id-5119426605428334183",
        "abstract": "",
        "versions": [],
        "rank": 798
    },
    {
        "authors": [
            "Guo, Ning",
            "Li, Quanzheng",
            "Li, Xiang",
            "Lin, Ming",
            "Sitek, Arkadiusz",
            "Sun, Mu",
            "Thrall, James",
            "Ye, Jieping",
            "Zhong, Aoxiao"
        ],
        "title": "Self-paced Convolutional Neural Network for Computer Aided Detection in  Medical Imaging Analysis",
        "publication_date": "2017-07-19 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-3-319-67389-9_25",
        "urls": [
            "http://arxiv.org/abs/1707.06145"
        ],
        "id": "id9055348581114111734",
        "abstract": "Tissue characterization has long been an important component of Computer\nAided Diagnosis (CAD) systems for automatic lesion detection and further\nclinical planning. Motivated by the superior performance of deep learning\nmethods on various computer vision problems, there has been increasing work\napplying deep learning to medical image analysis. However, the development of a\nrobust and reliable deep learning model for computer-aided diagnosis is still\nhighly challenging due to the combination of the high heterogeneity in the\nmedical images and the relative lack of training samples. Specifically,\nannotation and labeling of the medical images is much more expensive and\ntime-consuming than other applications and often involves manual labor from\nmultiple domain experts. In this work, we propose a multi-stage, self-paced\nlearning framework utilizing a convolutional neural network (CNN) to classify\nComputed Tomography (CT) image patches. The key contribution of this approach\nis that we augment the size of training samples by refining the unlabeled\ninstances with a self-paced learning CNN. By implementing the framework on high\nperformance computing servers including the NVIDIA DGX1 machine, we obtained\nthe experimental result, showing that the self-pace boosted network\nconsistently outperformed the original network even with very scarce manual\nlabels. The performance gain indicates that applications with limited training\nsamples such as medical image analysis can benefit from using the proposed\nframework.Comment: accepted by 8th International Workshop on Machine Learning in Medical\n  Imaging (MLMI 2017",
        "versions": [],
        "rank": 799
    },
    {
        "authors": [
            "Duygu Sarikaya",
            "Jason J. Corso",
            "K. Guru"
        ],
        "title": "Detection and Localization of Robotic Tools in Robot-Assisted Surgery Videos Using Deep Neural Networks for Region Proposal and Detection",
        "publication_date": "2017-02-08 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "IEEE Transactions on Medical Imaging",
        "volume": "36",
        "doi": "10.1109/TMI.2017.2665671",
        "urls": [
            "https://www.semanticscholar.org/paper/f4c42c58c6649538c85b85b5357b29793798109b"
        ],
        "id": "id3616750299638195085",
        "abstract": "Video understanding of robot-assisted surgery (RAS) videos is an active research area. Modeling the gestures and skill level of surgeons presents an interesting problem. The insights drawn may be applied in effective skill acquisition, objective skill assessment, real-time feedback, and human\u2013robot collaborative surgeries. We propose a solution to the tool detection and localization open problem in RAS video understanding, using a strictly computer vision approach and the recent advances of deep learning. We propose an architecture using multimodal convolutional neural networks for fast detection and localization of tools in RAS videos. To the best of our knowledge, this approach will be the first to incorporate deep neural networks for tool detection and localization in RAS videos. Our architecture applies a region proposal network (RPN) and a multimodal two stream convolutional network for object detection to jointly predict objectness and localization on a fusion of image and temporal motion cues. Our results with an average precision of 91% and a mean computation time of 0.1 s per test frame detection indicate that our study is superior to conventionally used methods for medical imaging while also emphasizing the benefits of using RPN for precision and efficiency. We also introduce a new data set, ATLAS Dione, for RAS video understanding. Our data set provides video data of ten surgeons from Roswell Park Cancer Institute, Buffalo, NY, USA, performing six different surgical tasks on the daVinci Surgical System (dVSS) with annotations of robotic tools per frame.",
        "versions": [],
        "rank": 800
    },
    {
        "authors": [
            "Xiaoqing Zheng",
            "Hongcheng Wang",
            "Jie Chen",
            "Yaguang Kong",
            "Song Zheng"
        ],
        "title": "A Generic Semi-supervised Deep Learning-Based Approach for Automated Surface Inspection",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Institute of Electrical and Electronics Engineers (IEEE)",
        "volume": "",
        "doi": "10.1109/access.2020.3003588",
        "urls": [
            "https://web.archive.org/web/20210429041313/https://ieeexplore.ieee.org/ielx7/6287639/8948470/09121251.pdf"
        ],
        "id": "id-5502111477246182258",
        "abstract": "Automated surface inspection (ASI) is critical to quality control in industrial manufacturing processes. Recent advances in deep learning have produced new ASI methods that automatically learn high-level features from training samples while being robust to changes and capable of detecting different types of surfaces and defects. However, they usually rely heavily on manpower to collect and label training samples. In this paper, a generic semi-supervised deep learning-based approach for ASI that requires a small quantity of labeled training data is proposed. While the approach follows the MixMatch rules to conduct sophisticated data augmentation, we introduce a new loss function calculation method and propose a new convolutional neural network based on a residual structure to achieve accurate defect detection. An experiment on two public datasets (DAGM and NEU) and one industrial dataset (CCL) is carried out. For public datasets, the experimental results are compared against several best benchmarks in the literature. For the industrial dataset, the results are compared against deep learning methods based on benchmark neural networks. The proposed method achieves the best performance in all comparisons. In addition, a comparative experiment of model performance given a different number of labeled samples is conducted, demonstrating that the proposed method can achieve good performance with few labeled training samples. INDEX TERMS Automated surface inspection, defect detection, deep learning, machine vision, MixMatch, semi-supervised learning.",
        "versions": [],
        "rank": 801
    },
    {
        "authors": [
            "A. Ansari",
            "O. De Wel",
            "M. Lavanga",
            "A. Caicedo",
            "A. Dereymaeker",
            "K. Jansen",
            "J. Vervisch",
            "M. de Vos",
            "G. Naulaers",
            "S. Van Huffel"
        ],
        "title": "Quiet sleep detection in preterm infants using deep convolutional neural networks",
        "publication_date": "2018-08-22 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Journal of Neural Engineering",
        "volume": "15",
        "doi": "10.1088/1741-2552/aadc1f",
        "urls": [
            "https://www.semanticscholar.org/paper/da8034ce5541f7340d8c0f60ae7113d25ffb609c"
        ],
        "id": "id-5224199750196363091",
        "abstract": "Objective. Neonates spend most of their time asleep. Sleep of preterm infants evolves rapidly throughout maturation and plays an important role in brain development. Since visual labelling of the sleep stages is a time consuming task, automated analysis of electroencephalography (EEG) to identify sleep stages is of great interest to clinicians. This automated sleep scoring can aid in optimizing neonatal care and assessing brain maturation. Approach. In this study, we designed and implemented an 18-layer convolutional neural network to discriminate quiet sleep from non-quiet sleep in preterm infants. The network is trained on 54 recordings from 13 preterm neonates and the performance is assessed on 43 recordings from 13 independent patients. All neonates had a normal neurodevelopmental outcome and the EEGs were recorded between 27 and 42 weeks postmenstrual age. Main results. The proposed network achieved an area under the mean and median ROC curve equal to 92% and 98%, respectively. Significance. Our findings suggest that CNN is a suitable and fast approach to classify neonatal sleep stages in preterm infants.",
        "versions": [],
        "rank": 802
    },
    {
        "authors": [
            "Cohen, A.",
            "Cohen, A.",
            "Nissim, N."
        ],
        "title": "ASSAF: Advanced and Slim StegAnalysis Detection Framework for JPEG images based on deep convolutional denoising autoencoder and Siamese networks",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1016/j.neunet.2020.07.022",
        "urls": [
            "https://api.elsevier.com/content/article/PII:S089360802030263X?httpAccept=text/xml",
            "https://api.elsevier.com/content/article/PII:S089360802030263X?httpAccept=text/plain",
            "http://dx.doi.org/10.1016/j.neunet.2020.07.022"
        ],
        "id": "id-6141404373551875573",
        "abstract": "",
        "versions": [],
        "rank": 803
    },
    {
        "authors": [
            "Jacky C.K. Tang",
            "The Chinese University of Hong Kong, Hong Kong"
        ],
        "title": "Deep Learning-based Analysis of Voiceprint Data Mining",
        "publication_date": "2022-01-30 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Research Alliance Press Limited",
        "volume": "",
        "doi": "10.56828/jser.2022.1.1.1",
        "urls": [
            "https://web.archive.org/web/20221029084508/https://secureservercdn.net/160.153.137.128/696.5fb.myftpupload.com/archive/vol1_no1_2022/1.pdf"
        ],
        "id": "id-2524808885430955019",
        "abstract": "In the information age, the intelligent data mining method represented by deep learning is playing an important role in various fields at present. It is necessary to study how to efficiently use the intelligent data mining method to obtain valuable information from massive information. Open-set voiceprint recognition is realized by intelligent data mining technology. Therefore, it is of great practical significance to achieve rapid and accurate identification of the speaker's identity. Because the traditional voiceprint recognition method has insufficient ability to distinguish the speakers inside and outside the set, it often leads to a high false recognition rate. Mining parameters containing more speakers' personality characteristics and how to calculate the threshold become the bottleneck problems of open set voiceprint recognition. Therefore, this paper adopts the deep confidence network stacked by three layers of restricted Boltzmann machines as the deep acoustic feature extractor. The mel-frequency cepstral coefficients of 24-dimensional basic acoustic features are mapped to 256dimensional feature space, and the parameters of deep acoustic features containing more speaker's personality characteristics are obtained. Then, an open-set adaptive threshold calculation algorithm is obtained. In this paper, the similarity value of deep acoustic features is calculated by the Gaussian mixture model, and the maximum inter-class variance of the similarity value is calculated by the OTSU algorithm. When the inter-class variance is the maximum, the similarity value is the best threshold. The experimental test shows that the algorithm for calculating threshold based on deep learning proposed in this paper has a lower false rejection rate and lower false rejection rate.",
        "versions": [],
        "rank": 804
    },
    {
        "authors": [
            "J. Yu",
            "Yunhe Hou",
            "Albert Y. S. Lam",
            "V. Li"
        ],
        "title": "Intelligent Fault Detection Scheme for Microgrids With Wavelet-Based Deep Neural Networks",
        "publication_date": "2019-03-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "IEEE Transactions on Smart Grid",
        "volume": "10",
        "doi": "10.1109/TSG.2017.2776310",
        "urls": [
            "https://www.semanticscholar.org/paper/4fce253ac11420b478d34d5d396ddcea3ca0314f"
        ],
        "id": "id5913531897094572974",
        "abstract": "Fault detection is essential in microgrid control and operation, as it enables the system to perform fast fault isolation and recovery. The adoption of inverter-interfaced distributed generation in microgrids makes traditional fault detection schemes inappropriate due to their dependence on significant fault currents. In this paper, we devise an intelligent fault detection scheme for microgrid based on wavelet transform and deep neural networks. The proposed scheme aims to provide fast fault type, phase, and location information for microgrid protection and service recovery. In the scheme, branch current measurements sampled by protective relays are pre-processed by discrete wavelet transform to extract statistical features. Then all available data is input into deep neural networks to develop fault information. Compared with previous work, the proposed scheme can provide significantly better fault type classification accuracy. Moreover, the scheme can also detect the locations of faults, which are unavailable in previous work. To evaluate the performance of the proposed fault detection scheme, we conduct a comprehensive evaluation study on the CERTS microgrid and IEEE 34-bus system. The simulation results demonstrate the efficacy of the proposed scheme in terms of detection accuracy, computation time, and robustness against measurement uncertainty.",
        "versions": [],
        "rank": 805
    },
    {
        "authors": [
            "Jing Zhang",
            "Bo Li",
            "Yuchao Dai",
            "Fatih Porikli",
            "Mingyi He"
        ],
        "title": "Integrated Deep and Shallow Networks for Salient Object Detection",
        "publication_date": "2017-06-02 00:52:55+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1706.00530v1",
            "http://arxiv.org/abs/1706.00530v1",
            "http://arxiv.org/pdf/1706.00530v1"
        ],
        "id": "id-6913070008853557648",
        "abstract": "Deep convolutional neural network (CNN) based salient object detection\nmethods have achieved state-of-the-art performance and outperform those\nunsupervised methods with a wide margin. In this paper, we propose to integrate\ndeep and unsupervised saliency for salient object detection under a unified\nframework. Specifically, our method takes results of unsupervised saliency\n(Robust Background Detection, RBD) and normalized color images as inputs, and\ndirectly learns an end-to-end mapping between inputs and the corresponding\nsaliency maps. The color images are fed into a Fully Convolutional Neural\nNetworks (FCNN) adapted from semantic segmentation to exploit high-level\nsemantic cues for salient object detection. Then the results from deep FCNN and\nRBD are concatenated to feed into a shallow network to map the concatenated\nfeature maps to saliency maps. Finally, to obtain a spatially consistent\nsaliency map with sharp object boundaries, we fuse superpixel level saliency\nmap at multi-scale. Extensive experimental results on 8 benchmark datasets\ndemonstrate that the proposed method outperforms the state-of-the-art\napproaches with a margin.",
        "versions": [],
        "rank": 806
    },
    {
        "authors": [
            "D Chen",
            "K Zhang",
            "T Yamada",
            "T-Y Lin",
            "W Liu",
            "Y Li"
        ],
        "title": "Using LIP to Gloss Over Faces in Single-Stage Face Detection Networks",
        "publication_date": "2018-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": null,
        "volume": "",
        "doi": "10.1007/978-3-030-01267-0_39",
        "urls": [
            "http://arxiv.org/abs/1712.08263"
        ],
        "id": "id-5918826877797224614",
        "abstract": "This work shows that it is possible to fool/attack recent state-of-the-art\nface detectors which are based on the single-stage networks. Successfully\nattacking face detectors could be a serious malware vulnerability when\ndeploying a smart surveillance system utilizing face detectors. We show that\nexisting adversarial perturbation methods are not effective to perform such an\nattack, especially when there are multiple faces in the input image. This is\nbecause the adversarial perturbation specifically generated for one face may\ndisrupt the adversarial perturbation for another face. In this paper, we call\nthis problem the Instance Perturbation Interference (IPI) problem. This IPI\nproblem is addressed by studying the relationship between the deep neural\nnetwork receptive field and the adversarial perturbation. As such, we propose\nthe Localized Instance Perturbation (LIP) that uses adversarial perturbation\nconstrained to the Effective Receptive Field (ERF) of a target to perform the\nattack. Experiment results show the LIP method massively outperforms existing\nadversarial perturbation generation methods -- often by a factor of 2 to 10.Comment: to appear ECCV 2018 (accepted version",
        "versions": [],
        "rank": 807
    },
    {
        "authors": [
            "Catherine Tallon-Baudry",
            "Olivier F. Bertrand"
        ],
        "title": "Oscillatory gamma activity in humans and its role in object representation",
        "publication_date": "1999-04-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Trends in Cognitive Sciences",
        "volume": "3",
        "doi": "10.1016/s1364-6613(99)01299-1",
        "urls": [
            "https://openalex.org/W1989666886",
            "https://doi.org/10.1016/s1364-6613(99)01299-1"
        ],
        "id": "id-6459913658440539258",
        "abstract": "",
        "versions": [],
        "rank": 808
    },
    {
        "authors": [
            "Borji, Ali",
            "Callet, Patrick Le",
            "Che, Zhaohui",
            "Guo, Guodong",
            "Min, Xiongkuo",
            "Zhai, Guangtao"
        ],
        "title": "How is Gaze Influenced by Image Transformations? Dataset and Model",
        "publication_date": "2019-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/tip.2019.2945857",
        "urls": [
            "http://arxiv.org/abs/1905.06803"
        ],
        "id": "id5850585593752645597",
        "abstract": "Data size is the bottleneck for developing deep saliency models, because\ncollecting eye-movement data is very time consuming and expensive. Most of\ncurrent studies on human attention and saliency modeling have used high quality\nstereotype stimuli. In real world, however, captured images undergo various\ntypes of transformations. Can we use these transformations to augment existing\nsaliency datasets? Here, we first create a novel saliency dataset including\nfixations of 10 observers over 1900 images degraded by 19 types of\ntransformations. Second, by analyzing eye movements, we find that observers\nlook at different locations over transformed versus original images. Third, we\nutilize the new data over transformed images, called data augmentation\ntransformation (DAT), to train deep saliency models. We find that label\npreserving DATs with negligible impact on human gaze boost saliency prediction,\nwhereas some other DATs that severely impact human gaze degrade the\nperformance. These label preserving valid augmentation transformations provide\na solution to enlarge existing saliency datasets. Finally, we introduce a novel\nsaliency model based on generative adversarial network (dubbed GazeGAN). A\nmodified UNet is proposed as the generator of the GazeGAN, which combines\nclassic skip connections with a novel center-surround connection (CSC), in\norder to leverage multi level features. We also propose a histogram loss based\non Alternative Chi Square Distance (ACS HistLoss) to refine the saliency map in\nterms of luminance distribution. Extensive experiments and comparisons over 3\ndatasets indicate that GazeGAN achieves the best performance in terms of\npopular saliency evaluation metrics, and is more robust to various\nperturbations. Our code and data are available at:\nhttps://github.com/CZHQuality/Sal-CFS-GAN",
        "versions": [],
        "rank": 809
    },
    {
        "authors": [
            "Ashish Kumar",
            "L. Behera"
        ],
        "title": "Semi Supervised Deep Quick Instance Detection and Segmentation",
        "publication_date": "2021-01-16 08:50:36+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2101.06405v1",
            "http://arxiv.org/abs/2101.06405v1",
            "http://arxiv.org/pdf/2101.06405v1"
        ],
        "id": "id5871519622993104368",
        "abstract": "In this paper, we present a semi supervised deep quick learning framework for\ninstance detection and pixel-wise semantic segmentation of images in a dense\nclutter of items. The framework can quickly and incrementally learn novel items\nin an online manner by real-time data acquisition and generating corresponding\nground truths on its own. To learn various combinations of items, it can\nsynthesize cluttered scenes, in real time. The overall approach is based on the\ntutor-child analogy in which a deep network (tutor) is pretrained for\nclass-agnostic object detection which generates labeled data for another deep\nnetwork (child). The child utilizes a customized convolutional neural network\nhead for the purpose of quick learning. There are broadly four key components\nof the proposed framework semi supervised labeling, occlusion aware clutter\nsynthesis, a customized convolutional neural network head, and instance\ndetection. The initial version of this framework was implemented during our\nparticipation in Amazon Robotics Challenge (ARC), 2017. Our system was ranked\n3rd, 4th and 5th worldwide in pick, stow-pick and stow task respectively. The\nproposed framework is an improved version over ARC17 where novel features such\nas instance detection and online learning has been added.",
        "versions": [],
        "rank": 810
    },
    {
        "authors": [
            "Adler, Jonas",
            "Lunz, Sebastian",
            "Sch\u00f6nlieb, Carola-Bibiane",
            "Verdier, Olivier",
            "\u00d6ktem, Ozan"
        ],
        "title": "Task adapted reconstruction for inverse problems",
        "publication_date": "2018-08-27 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "http://arxiv.org/abs/1809.00948"
        ],
        "id": "id3971118471830177827",
        "abstract": "The paper considers the problem of performing a task defined on a model\nparameter that is only observed indirectly through noisy data in an ill-posed\ninverse problem. A key aspect is to formalize the steps of reconstruction and\ntask as appropriate estimators (non-randomized decision rules) in statistical\nestimation problems. The implementation makes use of (deep) neural networks to\nprovide a differentiable parametrization of the family of estimators for both\nsteps. These networks are combined and jointly trained against suitable\nsupervised training data in order to minimize a joint differentiable loss\nfunction, resulting in an end-to-end task adapted reconstruction method. The\nsuggested framework is generic, yet adaptable, with a plug-and-play structure\nfor adjusting both the inverse problem and the task at hand. More precisely,\nthe data model (forward operator and statistical model of the noise) associated\nwith the inverse problem is exchangeable, e.g., by using neural network\narchitecture given by a learned iterative method. Furthermore, any task that is\nencodable as a trainable neural network can be used. The approach is\ndemonstrated on joint tomographic image reconstruction, classification and\njoint tomographic image reconstruction segmentation",
        "versions": [],
        "rank": 811
    },
    {
        "authors": [
            "Adiraju, Prathyusha",
            "Catthoor, Francky",
            "Das, Anup",
            "Dutt, Nikil",
            "Groenendaal, Willemijn",
            "Krichmar, Jeffrey L.",
            "Pradhapan, Paruthi",
            "Rajan, Raj Thilak",
            "Schaafsma, Siebren",
            "Van Hoof, Chris"
        ],
        "title": "Unsupervised Heart-rate Estimation in Wearables With Liquid States and A  Probabilistic Readout",
        "publication_date": "2017-07-18 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": null,
        "volume": "",
        "doi": "10.1016/j.neunet.2017.12.015",
        "urls": [
            "http://arxiv.org/abs/1708.05356"
        ],
        "id": "id7036815008038119139",
        "abstract": "Heart-rate estimation is a fundamental feature of modern wearable devices. In\nthis paper we propose a machine intelligent approach for heart-rate estimation\nfrom electrocardiogram (ECG) data collected using wearable devices. The novelty\nof our approach lies in (1) encoding spatio-temporal properties of ECG signals\ndirectly into spike train and using this to excite recurrently connected\nspiking neurons in a Liquid State Machine computation model; (2) a novel\nlearning algorithm; and (3) an intelligently designed unsupervised readout\nbased on Fuzzy c-Means clustering of spike responses from a subset of neurons\n(Liquid states), selected using particle swarm optimization. Our approach\ndiffers from existing works by learning directly from ECG signals (allowing\npersonalization), without requiring costly data annotations. Additionally, our\napproach can be easily implemented on state-of-the-art spiking-based\nneuromorphic systems, offering high accuracy, yet significantly low energy\nfootprint, leading to an extended battery life of wearable devices. We\nvalidated our approach with CARLsim, a GPU accelerated spiking neural network\nsimulator modeling Izhikevich spiking neurons with Spike Timing Dependent\nPlasticity (STDP) and homeostatic scaling. A range of subjects are considered\nfrom in-house clinical trials and public ECG databases. Results show high\naccuracy and low energy footprint in heart-rate estimation across subjects with\nand without cardiac irregularities, signifying the strong potential of this\napproach to be integrated in future wearable devices.Comment: 51 pages, 12 figures, 6 tables, 95 references. Under submission at\n  Elsevier Neural Network",
        "versions": [],
        "rank": 812
    },
    {
        "authors": [
            "Shifu Hou",
            "Aaron Saas",
            "Lingwei Chen",
            "Yanfang Ye",
            "T. Bourlai"
        ],
        "title": "Deep Neural Networks for Automatic Android Malware Detection",
        "publication_date": "2017-07-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1145/3110025.3116211",
        "urls": [
            "https://www.semanticscholar.org/paper/ed73cad5ed5c95561dae13b670dce293f87fbea2"
        ],
        "id": "id-2651918899163219628",
        "abstract": "Because of the explosive growth of Android malware and due to the severity of its damages, the detection of Android malware has become an increasing important topic in cybersecurity. Currently, the major defense against Android malware is commercial mobile security products which mainly use signature-based method for detection. However, attackers can easily devise methods, such as obfuscation and repackaging, to evade the detection, which calls for new defensive techniques that are harder to evade. In this paper, resting on the analysis of Application Programming Interface (API) calls extracted from the smali files, we further categorize the API calls which belong to the some method in the smali code into a block. Based on the generated API call blocks, we then explore deep neural networks (i.e., Deep Belief Network (DBN) and Stacked AutoEncoders (SAEs)) for newly unknown Android malware detection. Using a real sample collection from Comodo Cloud Security Center, a comprehensive experimental study is performed to compare various malware detection approaches. The experimental results demonstrate that (1) our proposed feature extraction method (i.e., using API call blocks) outperforms using API calls directly in Android malware detection; (2) DBN works better than SAEs in this application; and (3) the detection performance of deep neural networks is better than shallow learning architectures.",
        "versions": [],
        "rank": 813
    },
    {
        "authors": [
            "Konstantinos Perifanos",
            "Eirini Florou",
            "Dionysis Goutsos"
        ],
        "title": "Deep Learning based, end-to-end metaphor detection in Greek language with Recurrent and Convolutional Neural Networks",
        "publication_date": "2020-07-23 12:02:40+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2007.11949v1",
            "http://arxiv.org/abs/2007.11949v1",
            "http://arxiv.org/pdf/2007.11949v1"
        ],
        "id": "id263306498747521391",
        "abstract": "This paper presents and benchmarks a number of end-to-end Deep Learning based\nmodels for metaphor detection in Greek. We combine Convolutional Neural\nNetworks and Recurrent Neural Networks with representation learning to bear on\nthe metaphor detection problem for the Greek language. The models presented\nachieve exceptional accuracy scores, significantly improving the previous state\nof the art results, which had already achieved accuracy 0.82. Furthermore, no\nspecial preprocessing, feature engineering or linguistic knowledge is used in\nthis work. The methods presented achieve accuracy of 0.92 and F-score 0.92 with\nConvolutional Neural Networks (CNNs) and bidirectional Long Short Term Memory\nnetworks (LSTMs). Comparable results of 0.91 accuracy and 0.91 F-score are also\nachieved with bidirectional Gated Recurrent Units (GRUs) and Convolutional\nRecurrent Neural Nets (CRNNs). The models are trained and evaluated only on the\nbasis of the training tuples, the sentences and their labels. The outcome is a\nstate of the art collection of metaphor detection models, trained on limited\nlabelled resources, which can be extended to other languages and similar tasks.",
        "versions": [],
        "rank": 814
    },
    {
        "authors": [
            "Bing Xue",
            "Baoxiang Huang",
            "Weibo Wei",
            "Ge Chen",
            "Haitao Li",
            "Nan Zhao",
            "Hongfeng Zhang"
        ],
        "title": "An Efficient Deep-Sea Debris Detection Method Using Deep Neural Networks",
        "publication_date": "None",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing",
        "volume": "14",
        "doi": "10.1109/jstars.2021.3130238",
        "urls": [
            "https://www.semanticscholar.org/paper/360ac6cb2f1d4009e86458d220eec1473ef842bc"
        ],
        "id": "id4443617590068583303",
        "abstract": "Marine debris impacts negatively upon the marine environment and the survival of marine life because they are some difficult-to-degrade substances, and most of them will sink into the deep sea and continue to exist in the ocean. Autonomous underwater vehicles can clean up the deep-sea debris to some extent. However, the efficient detection method plays a critical role in the collection rate. This article establishes an efficient deep-sea debris detection method with high speed using deep learning methods. First, a real deep-sea debris detection dataset (3-D dataset) is established for further research. The dataset contains seven types of debris: cloth, fishing net and rope, glass, metal, natural debris, rubber, and plastic. Second, the one-stage deep-sea debris detection network ResNet50-YOLOV3 is proposed. In addition, eight advanced detection models are also involved in the detection process of deep-sea debris. Finally, the performance of ResNet50-YOLOV3 is verified by experiments. Furthermore, the applicability and effectiveness of ResNet50-YOLOV3 in deep-sea debris detection are proved by the experimental results.",
        "versions": [],
        "rank": 815
    },
    {
        "authors": [
            "Paulo Augusto Vitorino",
            "Sandra Avila",
            "Mauricio D. Perez",
            "Anderson Rocha"
        ],
        "title": "Leveraging deep neural networks to fight child pornography in the age of social media",
        "publication_date": "2018-01-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Journal of Visual Communication and Image Representation",
        "volume": "50",
        "doi": "10.1016/j.jvcir.2017.12.005",
        "urls": [
            "https://openalex.org/W2780678160",
            "https://doi.org/10.1016/j.jvcir.2017.12.005"
        ],
        "id": "id-3903557426773352258",
        "abstract": "",
        "versions": [],
        "rank": 816
    },
    {
        "authors": [
            "Seyfullah Kiymet",
            "Muhammet Yavuz Aslankaya",
            "M. Taskiran",
            "B. Bolat"
        ],
        "title": "Breast Cancer Detection From Thermography Based on Deep Neural Networks",
        "publication_date": "2019-10-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ASYU48272.2019.8946367",
        "urls": [
            "https://www.semanticscholar.org/paper/d5ccbd4fdee038e90efb70b957b022d3391b95e3"
        ],
        "id": "id1130900174840985737",
        "abstract": "Breast cancer is one of the most common types of cancer that affects more than 15% of women throughout their lives. Early detection of this type of cancer is crucial for the positive outcome of the treatment process. There are several screening methods for the detection of breast cancer. In this study, a new method based on thermal imaging is proposed for the detection of breast cancer. Four deep learning networks that were successful in object recognition competitions in recent years were used for breast cancer detection from thermographic breast images and as a result of experimental studies, ResNet50 network achieved the highest test performance in detection of breast cancer by 88.89%. This study demonstrated the applicability of deep learning networks in breast cancer detection.",
        "versions": [],
        "rank": 817
    },
    {
        "authors": [
            "Hao Fang",
            "Saurabh Gupta",
            "Forrest Iandola",
            "Rupesh K. Srivastava",
            "Li Deng",
            "Piotr Doll\u00e1r",
            "Jianfeng Gao",
            "Xiaodong He",
            "Margaret Mitchell",
            "John Platt",
            "C. Lawrence Zitnick",
            "Geoffrey Zweig"
        ],
        "title": "From captions to visual concepts and back",
        "publication_date": "2015-06-07 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Computer Vision and Pattern Recognition",
        "volume": "",
        "doi": "10.1109/cvpr.2015.7298754",
        "urls": [
            "https://openalex.org/W1931639407",
            "https://doi.org/10.1109/cvpr.2015.7298754",
            "http://arxiv.org/pdf/1411.4952"
        ],
        "id": "id1310943514520965502",
        "abstract": "",
        "versions": [],
        "rank": 818
    },
    {
        "authors": [
            "Pedro Azevedo",
            "Sabrina S. Panceri",
            "R\u00e2nik Guidolini",
            "Vinicius B. Cardoso",
            "C. Badue",
            "Thiago Oliveira-Santos",
            "A. D. Souza"
        ],
        "title": "Bio-Inspired Foveated Technique for Augmented-Range Vehicle Detection Using Deep Neural Networks",
        "publication_date": "2019-07-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/IJCNN.2019.8851947",
        "urls": [
            "https://www.semanticscholar.org/paper/e31b38c41929af288b23a9112b2f1626fe7e74e9"
        ],
        "id": "id-1774472493215747484",
        "abstract": "We propose a bio-inspired foveated technique to detect cars in a long range camera view using a deep convolutional neural network (DCNN) for the IARA self-driving car. The DCNN receives as input (i) an image, which is captured by a camera installed on IARA\u2019s roof; and (ii) crops of the image, which are centered in the waypoints computed by IARA\u2019s path planner and whose sizes increase with the distance from IARA. We employ an overlap filter to discard detections of the same car in different crops of the same image based on the percentage of overlap of detections\u2019 bounding boxes. We evaluated the performance of the proposed augmented-range vehicle detection system (ARVDS) using the hardware and software infrastructure available in the IARA self-driving car. Using IARA, we captured thousands of images of real traffic situations containing cars in a long range. Experimental results show that ARVDS increases the Average Precision (AP) of long range car detection from 29.51% (using a single whole image) to 63.15%.",
        "versions": [],
        "rank": 819
    },
    {
        "authors": [
            "Ying Zhao",
            "Mohammad Noori",
            "Mohammad Noori",
            "Ramin Ghiasi",
            "Zhishen Wu"
        ],
        "title": "Deep Learning-Based Damage, Load and Support Identification for a Composite Pipeline by Extracting Modal Macro Strains from Dynamic Excitations",
        "publication_date": "2018-12-10 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Applied sciences",
        "volume": "8",
        "doi": "10.3390/app8122564",
        "urls": [
            "https://openalex.org/W2904269314",
            "https://doi.org/10.3390/app8122564",
            "https://www.mdpi.com/2076-3417/8/12/2564/pdf?version=1544774921"
        ],
        "id": "id-4716308408953000234",
        "abstract": "",
        "versions": [],
        "rank": 820
    },
    {
        "authors": [
            "Glocker, Ben",
            "Kamnitsas, Konstantinos",
            "Kane, Andrew D.",
            "Ledig, Christian",
            "Menon, David K.",
            "Newcombe, Virginia F. J.",
            "Rueckert, Daniel",
            "Simpson, Joanna P."
        ],
        "title": "Efficient Multi-Scale 3D CNN with Fully Connected CRF for Accurate Brain  Lesion Segmentation",
        "publication_date": "2016-10-12 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": null,
        "volume": "",
        "doi": "10.1016/j.media.2016.10.004",
        "urls": [
            "https://core.ac.uk/download/77010042.pdf"
        ],
        "id": "id-6562474671336964480",
        "abstract": "We propose a dual pathway, 11-layers deep, three-dimensional Convolutional\nNeural Network for the challenging task of brain lesion segmentation. The\ndevised architecture is the result of an in-depth analysis of the limitations\nof current networks proposed for similar applications. To overcome the\ncomputational burden of processing 3D medical scans, we have devised an\nefficient and effective dense training scheme which joins the processing of\nadjacent image patches into one pass through the network while automatically\nadapting to the inherent class imbalance present in the data. Further, we\nanalyze the development of deeper, thus more discriminative 3D CNNs. In order\nto incorporate both local and larger contextual information, we employ a dual\npathway architecture that processes the input images at multiple scales\nsimultaneously. For post-processing of the network's soft segmentation, we use\na 3D fully connected Conditional Random Field which effectively removes false\npositives. Our pipeline is extensively evaluated on three challenging tasks of\nlesion segmentation in multi-channel MRI patient data with traumatic brain\ninjuries, brain tumors, and ischemic stroke. We improve on the state-of-the-art\nfor all three applications, with top ranking performance on the public\nbenchmarks BRATS 2015 and ISLES 2015. Our method is computationally efficient,\nwhich allows its adoption in a variety of research and clinical settings. The\nsource code of our implementation is made publicly available.Comment: This version was accepted in the journal Medical Image Analysis\n  (MedIA",
        "versions": [],
        "rank": 821
    },
    {
        "authors": [
            "Xusheng Li",
            "Zhisheng Hu",
            "Yiwei Fu",
            "Ping Chen",
            "Minghui Zhu",
            "Peng Liu"
        ],
        "title": "ROPNN: Detection of ROP Payloads Using Deep Neural Networks",
        "publication_date": "2018-07-29 20:45:05+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1807.11110v2",
            "http://arxiv.org/abs/1807.11110v2",
            "http://arxiv.org/pdf/1807.11110v2"
        ],
        "id": "id6768073155781898143",
        "abstract": "Return-oriented programming (ROP) is a code reuse attack that chains short\nsnippets of existing code to perform arbitrary operations on target machines.\nExisting detection methods against ROP exhibit unsatisfactory detection\naccuracy and/or have high runtime overhead.\n  In this paper, we present ROPNN, which innovatively combines address space\nlayout guided disassembly and deep neural networks to detect ROP payloads. The\ndisassembler treats application input data as code pointers and aims to find\nany potential gadget chains, which are then classified by a deep neural network\nas benign or malicious. Our experiments show that ROPNN has high detection rate\n(99.3%) and a very low false positive rate (0.01%). ROPNN successfully detects\nall of the 100 real-world ROP exploits that are collected in-the-wild, created\nmanually or created by ROP exploit generation tools. Additionally, ROPNN\ndetects all 10 ROP exploits that can bypass Bin-CFI. ROPNN is non-intrusive and\ndoes not incur any runtime overhead to the protected program.",
        "versions": [],
        "rank": 822
    },
    {
        "authors": [
            "Farzan Erlik Nowruzi",
            "Dhanvin Kolhatkar",
            "Prince Kapoor",
            "Robert Laganiere"
        ],
        "title": "Point Cloud based Hierarchical Deep Odometry Estimation",
        "publication_date": "2021-03-05 00:17:58+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2103.03394v1",
            "http://arxiv.org/abs/2103.03394v1",
            "http://arxiv.org/pdf/2103.03394v1"
        ],
        "id": "id722312448358894687",
        "abstract": "Processing point clouds using deep neural networks is still a challenging\ntask. Most existing models focus on object detection and registration with deep\nneural networks using point clouds. In this paper, we propose a deep model that\nlearns to estimate odometry in driving scenarios using point cloud data. The\nproposed model consumes raw point clouds in order to extract frame-to-frame\nodometry estimation through a hierarchical model architecture. Also, a local\nbundle adjustment variation of this model using LSTM layers is implemented.\nThese two approaches are comprehensively evaluated and are compared against the\nstate-of-the-art.",
        "versions": [],
        "rank": 823
    },
    {
        "authors": [
            "Jinmei Zhang",
            "Zhiquan Bai",
            "Kaiyue Yang",
            "Abeer Mohamed",
            "K. Kwak",
            "Xinhong Hao"
        ],
        "title": "Deep Neural Network Based Parallel Signal Detection in SM-OFDM System",
        "publication_date": "2022-07-05 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/icufn55119.2022.9829700",
        "urls": [
            "https://www.semanticscholar.org/paper/46ec45fa130c56d28fcb5bfc6c11e01f2237eaaa"
        ],
        "id": "id8002838231154038289",
        "abstract": "A novel deep neural network based parallel signal detection (DNN-PSD) is proposed for the spatial modulation based orthogonal frequency division multiplexing (SM-OFDM) system. With the purpose to reduce the complexity of the conventional DNN, a uniform small-scale DNN with fewer parameters and less training time is exploited to detect the signals for each subcarrier parallelly. Apart from maximum likelihood (ML) and maximal ratio combining (MRC) detection schemes, the detailed DNN-PSD algorithm and its complexity analysis are presented. Simulation results confirm that the bit error rate (BER) performance of the proposed DNN-PSD is far superior to the MRC detection and similar to the optimal ML detection but with much lower complexity under different scenarios. It has more robustness and achieves a finer compromise between BER performance and complexity.",
        "versions": [],
        "rank": 824
    },
    {
        "authors": [
            "DM Blei",
            "E Cambria",
            "E Cambria",
            "E Cambria",
            "E Cambria",
            "E Cambria",
            "G Murray",
            "G Qiu",
            "GE Hinton",
            "GW Taylor",
            "H Tang",
            "I Chaturvedi",
            "L Oneto",
            "R Collobert",
            "R Ortega",
            "S Branavan",
            "S Poria",
            "S Rill",
            "T Wang",
            "X Ding",
            "Y Hu"
        ],
        "title": "Basic tasks of sentiment analysis",
        "publication_date": "2017-10-17 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-1-4614-7163-9_110159-1",
        "urls": [
            "http://arxiv.org/abs/1710.06536"
        ],
        "id": "id5857179739098249578",
        "abstract": "Subjectivity detection is the task of identifying objective and subjective\nsentences. Objective sentences are those which do not exhibit any sentiment.\nSo, it is desired for a sentiment analysis engine to find and separate the\nobjective sentences for further analysis, e.g., polarity detection. In\nsubjective sentences, opinions can often be expressed on one or multiple\ntopics. Aspect extraction is a subtask of sentiment analysis that consists in\nidentifying opinion targets in opinionated text, i.e., in detecting the\nspecific aspects of a product or service the opinion holder is either praising\nor complaining about",
        "versions": [],
        "rank": 825
    },
    {
        "authors": [],
        "title": "OUP accepted manuscript",
        "publication_date": "2019-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Oxford University Press (OUP)",
        "volume": "",
        "doi": "10.1093/mnras/stz1197",
        "urls": [
            "https://web.archive.org/web/20191018144652/https://arxiv.org/pdf/1904.12192v1.pdf"
        ],
        "id": "id4194341685351417101",
        "abstract": "Metal absorption line systems in distant quasar spectra probe of the history of gas content in the universe. The MgII \u03bb\u03bb 2796, 2803 doublet is one of the most important absorption lines since it is a proxy of the star formation rate and a tracer of the cold gas associated with high redshift galaxies. Machine learning algorithms have been used to detect absorption lines systems in large sky surveys, such as Principle Component Analysis (PCA), Gaussian Process (GP) and decision trees. A very powerful algorithm in the field of machine learning called deep neural networks, or \" deep learning\" is a new structure of neural network that automatically extracts semantic features from raw data and represents them at a high level. In this paper, we apply a deep convolutional neural network for absorption line detection. We use the previously published DR7 MgII catalog (Zhu et al. 2013) as the training and validation sample and the DR12 MgII catalog as the test set. Our deep learning algorithm is capable of detecting MgII absorption lines with an accuracy of \u223c94 spectra with our deep neural network, which is ten thousand times faster than traditional methods, while preserving high accuracy with little human interference. Our study shows that Mg II absorption line detection accuracy of a deep neutral network model strongly depends on the filter size in the filter layer of the neural network, and the best results are obtained when the filter size closely matches the absorption feature size.",
        "versions": [],
        "rank": 826
    },
    {
        "authors": [
            "C. Yeh",
            "Chu-Han Lin",
            "Li-Wei Kang",
            "Chih-Hsiang Huang",
            "Min-Hui Lin",
            "Chuan-Yu Chang",
            "Chua\u2010Chin Wang"
        ],
        "title": "Lightweight Deep Neural Network for Joint Learning of Underwater Object Detection and Color Conversion",
        "publication_date": "2021-04-26 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "IEEE Transactions on Neural Networks and Learning Systems",
        "volume": "33",
        "doi": "10.1109/TNNLS.2021.3072414",
        "urls": [
            "https://www.semanticscholar.org/paper/2fe0d92a7fe996ad0e35507c006635e6c4299220"
        ],
        "id": "id6788053586593441436",
        "abstract": "Underwater image processing has been shown to exhibit significant potential for exploring underwater environments. It has been applied to a wide variety of fields, such as underwater terrain scanning and autonomous underwater vehicles (AUVs)-driven applications, such as image-based underwater object detection. However, underwater images often suffer from degeneration due to attenuation, color distortion, and noise from artificial lighting sources as well as the effects of possibly low-end optical imaging devices. Thus, object detection performance would be degraded accordingly. To tackle this problem, in this article, a lightweight deep underwater object detection network is proposed. The key is to present a deep model for jointly learning color conversion and object detection for underwater images. The image color conversion module aims at transforming color images to the corresponding grayscale images to solve the problem of underwater color absorption to enhance the object detection performance with lower computational complexity. The presented experimental results with our implementation on the Raspberry pi platform have justified the effectiveness of the proposed lightweight jointly learning model for underwater object detection compared with the state-of-the-art approaches.",
        "versions": [],
        "rank": 827
    },
    {
        "authors": [
            "Qiong Cao",
            "Li Shen",
            "Weidi Xie",
            "Omkar M. Parkhi",
            "Andrew Zisserman"
        ],
        "title": "VGGFace2: A Dataset for Recognising Faces across Pose and Age",
        "publication_date": "2018-05-15 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "IEEE International Conference on Automatic Face & Gesture Recognition",
        "volume": "",
        "doi": "10.1109/fg.2018.00020",
        "urls": [
            "https://openalex.org/W2963839617",
            "https://doi.org/10.1109/fg.2018.00020",
            "http://arxiv.org/pdf/1710.08092"
        ],
        "id": "id-3162847922419652573",
        "abstract": "",
        "versions": [],
        "rank": 828
    },
    {
        "authors": [
            "Alexey Sholokhov",
            "Igor Fedorov",
            "Nikita Kuzmin"
        ],
        "title": "Magnitude-aware Probabilistic Speaker Embeddings",
        "publication_date": "2022-02-28 00:00:00",
        "source": "SupportedSources.PAPERS_WITH_CODE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://arxiv.org/pdf/2202.13826v3.pdf",
            "https://github.com/clovaai/voxceleb_trainer"
        ],
        "id": "id-8342596077492417050",
        "abstract": "Recently, hyperspherical embeddings have established themselves as a dominant technique for face and voice recognition. Specifically, Euclidean space vector embeddings are learned to encode person-specific information in their direction while ignoring the magnitude. However, recent studies have shown that the magnitudes of the embeddings extracted by deep neural networks may indicate the quality of the corresponding inputs. This paper explores the properties of the magnitudes of the embeddings related to quality assessment and out-of-distribution detection. We propose a new probabilistic speaker embedding extractor using the information encoded in the embedding magnitude and leverage it in the speaker verification pipeline. We also propose several quality-aware diarization methods and incorporate the magnitudes in those. Our results indicate significant improvements over magnitude-agnostic baselines both in speaker verification and diarization tasks.",
        "versions": [],
        "rank": 829
    },
    {
        "authors": [],
        "title": "An Effective Model for Detection of Dysfunctionality in Heart Based on Iridology using Deep Neural Networks",
        "publication_date": "2020-03-10 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Blue Eyes Intelligence Engineering and Sciences Engineering and Sciences Publication - BEIESP",
        "volume": "",
        "doi": "10.35940/ijitee.e2888.039520",
        "urls": [
            "https://web.archive.org/web/20220224035859/https://www.ijitee.org/wp-content/uploads/papers/v9i5/E2888039520.pdf"
        ],
        "id": "id-2937497690032649250",
        "abstract": "In today's world heart disease is the primary reason for deaths. WHO has anticipated that 12 million people die every year because of heart diseases. Every organ of the body is represented in the iris in a well-defined manner. The Iris is a micro-structure of the entire body. The abnormality of the heart can be detected using Iridology science. In this article, we examine the heart dysfunctionality through a chain of steps which are localization of iris, segmentation of iris, ROI extraction, histogram equalization of ROI and classification using deep convolutional neural network. The results are assessed based on various standards such as precision, recall, fscore & accuracy.",
        "versions": [],
        "rank": 830
    },
    {
        "authors": [
            "Liu, Fengze",
            "Xia, Yingda",
            "Xu, Daguang",
            "Yang, Dong",
            "Yuille, Alan"
        ],
        "title": "An Alarm System For Segmentation Algorithm Based On Shape Model",
        "publication_date": "2019-08-20 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/iccv.2019.01075",
        "urls": [
            "http://arxiv.org/abs/1903.10645"
        ],
        "id": "id1557135453713832648",
        "abstract": "It is usually hard for a learning system to predict correctly on rare events\nthat never occur in the training data, and there is no exception for\nsegmentation algorithms. Meanwhile, manual inspection of each case to locate\nthe failures becomes infeasible due to the trend of large data scale and\nlimited human resource. Therefore, we build an alarm system that will set off\nalerts when the segmentation result is possibly unsatisfactory, assuming no\ncorresponding ground truth mask is provided. One plausible solution is to\nproject the segmentation results into a low dimensional feature space; then\nlearn classifiers/regressors to predict their qualities. Motivated by this, in\nthis paper, we learn a feature space using the shape information which is a\nstrong prior shared among different datasets and robust to the appearance\nvariation of input data.The shape feature is captured using a Variational\nAuto-Encoder (VAE) network that trained with only the ground truth masks.\nDuring testing, the segmentation results with bad shapes shall not fit the\nshape prior well, resulting in large loss values. Thus, the VAE is able to\nevaluate the quality of segmentation result on unseen data, without using\nground truth. Finally, we learn a regressor in the one-dimensional feature\nspace to predict the qualities of segmentation results. Our alarm system is\nevaluated on several recent state-of-art segmentation algorithms for 3D medical\nsegmentation tasks. Compared with other standard quality assessment methods,\nour system consistently provides more reliable prediction on the qualities of\nsegmentation results.Comment: Accepted to ICCV 2019 (10 pages, 4 figures",
        "versions": [],
        "rank": 831
    },
    {
        "authors": [
            "Ling Dai",
            "Ruogu Fang",
            "Huating Li",
            "Xuhong Hou",
            "Bin Sheng",
            "Qiang Wu",
            "Weiping Jia"
        ],
        "title": "Clinical Report Guided Retinal Microaneurysm Detection With Multi-Sieving Deep Learning",
        "publication_date": "2018-01-18 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "IEEE Transactions on Medical Imaging",
        "volume": "37",
        "doi": "10.1109/tmi.2018.2794988",
        "urls": [
            "https://openalex.org/W2791447208",
            "https://doi.org/10.1109/tmi.2018.2794988",
            "https://doi.org/10.1109/tmi.2018.2794988"
        ],
        "id": "id-8874186371241134043",
        "abstract": "",
        "versions": [],
        "rank": 832
    },
    {
        "authors": [
            "Jasper Linmans",
            "Jeroen van der Laak",
            "Geert Litjens"
        ],
        "title": "Efficient Out-of-Distribution Detection in Digital Pathology Using Multi-Head Convolutional Neural Networks",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20220312232555/http://proceedings.mlr.press/v121/linmans20a/linmans20a.pdf"
        ],
        "id": "id8064040177577450147",
        "abstract": "Successful clinical implementation of deep learning in medical imaging depends, in part, on the reliability of the predictions. Specifically, the system should be accurate for classes seen during training while providing calibrated estimates of uncertainty for abnormalities and unseen classes. To efficiently estimate predictive uncertainty, we propose the use of multi-head CNNs (M-heads). We compare its performance to related and more prevalent approaches, such as deep ensembles, on the task of out-of-distribution (OOD) detection. To this end, we evaluate models trained to discriminate normal lymph node tissue from breast cancer metastases, on lymph nodes containing lymphoma. We show the ability to discriminate between in-distribution lymph node tissue and lymphoma by evaluating the AUROC based on the uncertainty signal. Here, the best performing multi-head CNN (91.7) outperforms both Monte Carlo dropout (88.3) and deep ensembles (86.8). Furthermore, we show that the meta-loss function of M-heads improves OOD detection in terms of AUROC.",
        "versions": [],
        "rank": 833
    },
    {
        "authors": [
            "Wang, Jianyu",
            "Xie, Cihang",
            "Xie, Lingxi",
            "Yuille, Alan",
            "Zhang, Zhishuai",
            "Zhu, Jun"
        ],
        "title": "Detecting Semantic Parts on Partially Occluded Objects",
        "publication_date": "2017-07-25 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "https://core.ac.uk/download/157613490.pdf"
        ],
        "id": "id-8195786758785845716",
        "abstract": "In this paper, we address the task of detecting semantic parts on partially\noccluded objects. We consider a scenario where the model is trained using\nnon-occluded images but tested on occluded images. The motivation is that there\nare infinite number of occlusion patterns in real world, which cannot be fully\ncovered in the training data. So the models should be inherently robust and\nadaptive to occlusions instead of fitting / learning the occlusion patterns in\nthe training data. Our approach detects semantic parts by accumulating the\nconfidence of local visual cues. Specifically, the method uses a simple voting\nmethod, based on log-likelihood ratio tests and spatial constraints, to combine\nthe evidence of local cues. These cues are called visual concepts, which are\nderived by clustering the internal states of deep networks. We evaluate our\nvoting scheme on the VehicleSemanticPart dataset with dense part annotations.\nWe randomly place two, three or four irrelevant objects onto the target object\nto generate testing images with various occlusions. Experiments show that our\nalgorithm outperforms several competitors in semantic part detection when\nocclusions are present.Comment: Accepted to BMVC 2017 (13 pages, 3 figures",
        "versions": [],
        "rank": 834
    },
    {
        "authors": [
            "Sangeeta N. Bhatia",
            "Donald E. Ingber"
        ],
        "title": "Microfluidic organs-on-chips",
        "publication_date": "2014-08-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Nature Biotechnology",
        "volume": "32",
        "doi": "10.1038/nbt.2989",
        "urls": [
            "https://openalex.org/W2013520568",
            "https://doi.org/10.1038/nbt.2989"
        ],
        "id": "id-8045725652323417207",
        "abstract": "",
        "versions": [],
        "rank": 835
    },
    {
        "authors": [
            "B. Harangi",
            "J\u00e1nos T\u00f3th",
            "A. Hajdu"
        ],
        "title": "Fusion of Deep Convolutional Neural Networks for Microaneurysm Detection in Color Fundus Images",
        "publication_date": "2018-07-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/EMBC.2018.8513035",
        "urls": [
            "https://www.semanticscholar.org/paper/b5f08201481f8b12f7cd01443e0e9dd1113fcdd2"
        ],
        "id": "id5647457322425632185",
        "abstract": "Microaneurysms (MAs) are common signsof several diseases, appearing as small circular darkish spots in color fundus images. The presence of even a single MA may suggest diseases (e.g. diabetic retinopathy), thus, their reliable recognition is a critical issue in both human clinical practice and computer-aided systems. As for their automatic recognition, deep learning techniques became very popular in the recent years. In this paper, we also apply such deep convolutional neural network (DCNN) based techniques; however, we organize them into a supernetwork with a fusionbased approach. The combination of the member DCNNs is achieved with interconnecting them in a joint fully-connected layer. The advantage of the method is that this large architecture can be trained as a single neural network, and thus, the member DCNNs are also trained with taking the predictions of the other members into consideration. The competitiveness of our approach is also validated with experimental studies, where the ensemble-based system outperformed each member DCNN. As a primary application domain with strong clinical motivation, the methodology was tested for image-level classification. More specifically, a retinal image is divided into subimages to provide the required inputs for the DCNN-based architecture, and the whole image is labeled as a positive case, if the presence of MA is predicted in any of the subimages. Additionally, we also demonstrate how our architecture can be trained to accurately localize MAs with training only the local neighborhoods of the lesions; empirical tests showing solid performance are also enclosed.",
        "versions": [],
        "rank": 836
    },
    {
        "authors": [
            "Yong-bo LI",
            "Mian-zai LV",
            "Hua-wei WANG",
            "Qiang FU"
        ],
        "title": "Aero-engine Health Monitoring Method Based on E-Bayes and DNN Fusion Decision",
        "publication_date": "2020-05-02 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "DEStech Publications",
        "volume": "",
        "doi": "10.12783/dtetr/acaai2020/34193",
        "urls": [
            "https://web.archive.org/web/20201106023707/http://dpi-proceedings.com/index.php/dtetr/article/download/34193/32780"
        ],
        "id": "id8059407550756107621",
        "abstract": "As a complex system, aero-engine running condition affects flight safety, so aero-engine health monitoring is necessary. We proposed an aero-engine health monitoring method based on E-Bayes method and deep neural network (DNN). Firstly, based on the fleet operation records, E-Bayes was used to calculate the reliability of aero-engine operation. Secondly, we constructed the DNN network base on the parameters collected by sensors and reliability parameter, fused the DNN results under different parameters according to the characteristics of different health condition of the aero-engine, and finally the fusion decision model based on the E-Bayes method and DNN was realized. We trained and verified the network with 9616 aero-engine running data samples contaminated by noise. The average accuracy was 96.15%, which shows that this method has good robustness.",
        "versions": [],
        "rank": 837
    },
    {
        "authors": [
            "Nurrida Aini Zuhroh",
            "Nur Aini Rakhmawati"
        ],
        "title": "Clickbait detection: A literature review of the methods used",
        "publication_date": "2019-10-29 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Universitas Pesantren Tinggi Darul Ulum (Unipdu)",
        "volume": "",
        "doi": "10.26594/register.v6i1.1561",
        "urls": [
            "https://web.archive.org/web/20200216014137/http://journal.unipdu.ac.id:8080/index.php/register/article/download/1561/pdf"
        ],
        "id": "id7902624561845524732",
        "abstract": "Online news portals are currently one of the fastest sources of information used by people. Its impact is due to the credibility of the news produced by actors from the media industry, which is sometimes questioned. However, one of the problems associated with this medium used to obtain information is clickbait. This technique aims to attract users to click hyperbolic headlines with content that often disappoints the reader. This study was, therefore, conducted to determine: 1) existing dataset available. 2) The method used in clickbait detection which consists of data preprocessing, analysis of features, and classification. 3) Difference steps from the method used.",
        "versions": [],
        "rank": 838
    },
    {
        "authors": [
            "Mohsin Hassan Albdery",
            "Istv\u00e1n Szab\u00f3"
        ],
        "title": "A Recent Machine Learning Techniques for Failure Diagnosis of Rolling Element Bearing",
        "publication_date": "2021-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Hungarian Agricultural Engineering",
        "volume": "",
        "doi": "10.17676/hae.2021.39.42",
        "urls": [
            "https://web.archive.org/web/20210722162713/http://real.mtak.hu/127570/1/39-2021-06-HAEDOI10.17676HAE.2021.39.42.pdf"
        ],
        "id": "id-3515039044343191357",
        "abstract": "Rolling element bearings are critical components of rotating machines, and fault in the bearing can cause the machine to fail. Bearing failure is one of the leading causes of failure in various rotating machines used in industry at high and low speeds. Fault diagnosis of various rotating equipment plays a significant role in industries as it guarantees safety, reliability and prevents breakdown and loss of any source of energy. Early identification is an essential element in the diagnosis of defects that saves time and expenses and avoids dangerous conditions. Investigations are being carried out for intelligent fault diagnosis using machine learning approaches. This article gives a short overview of recent trends in the use of machine learning for fault detection. Finally, Deep Learning techniques were recently developed to monitor the health of the intelligent machine are discussed.",
        "versions": [],
        "rank": 839
    },
    {
        "authors": [
            "Maxim Kalinin",
            "Vasiliy Krundyshev",
            "Evgeny Zubkov",
            "A. Sarygulov",
            "V. Sergeev",
            "L. Ungv\u00e1ri",
            "W. Semmler"
        ],
        "title": "Estimation of applicability of modern neural network methods for preventing cyberthreats to self-organizing network infrastructures of digital economy platforms,",
        "publication_date": "2018-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "EDP Sciences",
        "volume": "",
        "doi": "10.1051/shsconf/20184400044",
        "urls": [
            "https://web.archive.org/web/20180720184038/https://www.shs-conferences.org/articles/shsconf/pdf/2018/05/shsconf_cc-tesc2018_00044.pdf"
        ],
        "id": "id-8232631410343279808",
        "abstract": "The problems of applying neural network methods for solving problems of preventing cyberthreats to flexible self-organizing network infrastructures of digital economy platforms: vehicle adhoc networks, wireless sensor networks, industrial IoT, \"smart buildings\" and \"smart cities\" are considered. The applicability of the classic perceptron neural network, recurrent, deep, LSTM neural networks and neural networks ensembles in the restricting conditions of fast training and big data processing are estimated. The use of neural networks with a complex architecture-recurrent and LSTM neural networksis experimentally justified for building a system of intrusion detection for self-organizing network infrastructures.",
        "versions": [],
        "rank": 840
    },
    {
        "authors": [
            "Na Liang",
            "Chengliang Wang",
            "Shiying Li",
            "Xin Xie",
            "Jun Lin",
            "Wen Zhong"
        ],
        "title": "The classification of flash visual evoked potential based on deep learning",
        "publication_date": "2023-01-19 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Springer Science and Business Media LLC",
        "volume": "",
        "doi": "10.1186/s12911-023-02107-5",
        "urls": [
            "https://web.archive.org/web/20230121090817/https://bmcmedinformdecismak.biomedcentral.com/counter/pdf/10.1186/s12911-023-02107-5.pdf"
        ],
        "id": "id-1591556826847881922",
        "abstract": "Background Visual electrophysiology is an objective visual function examination widely used in clinical work and medical identification that can objectively evaluate visual function and locate lesions according to waveform changes. However, in visual electrophysiological examinations, the flash visual evoked potential (FVEP) varies greatly among individuals, resulting in different waveforms in different normal subjects. Moreover, most of the FVEP wave labelling is performed automatically by a machine, and manually corrected by professional clinical technicians. These labels may have biases due to the individual variations in subjects, incomplete clinical examination data, different professional skills, personal habits and other factors. Through the retrospective study of big data, an artificial intelligence algorithm is used to maintain high generalization abilities in complex situations and improve the accuracy of prescreening. Methods A novel multi-input neural network based on convolution and confidence branching (MCAC-Net) for retinitis pigmentosa RP recognition and out-of-distribution detection is proposed. The MCAC-Net with global and local feature extraction is designed for the FVEP signal that has different local and global information, and a confidence branch is added for out-of-distribution sample detection. For the proposed manual features,a new input layer is added. Results The model is verified by a clinically collected FVEP dataset, and an accuracy of 90.7% is achieved in the classification task and 93.3% in the out-of-distribution detection task. Conclusion We built a deep learning-based FVEP classification algorithm that promises to be an excellent tool for screening RP diseases by using FVEP signals.",
        "versions": [],
        "rank": 841
    },
    {
        "authors": [
            "Joshua Yao-Yu Lin",
            "Hang Yu",
            "Warren Morningstar",
            "Jian Peng",
            "Gilbert Holder"
        ],
        "title": "Hunting for Dark Matter Subhalos in Strong Gravitational Lensing with Neural Networks",
        "publication_date": "2020-10-27 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20201031073819/https://arxiv.org/pdf/2010.12960v1.pdf"
        ],
        "id": "id-8506235736939697854",
        "abstract": "Dark matter substructures are interesting since they can reveal the properties of dark matter. Collisionless N-body simulations of cold dark matter show more substructures compared with the population of dwarf galaxy satellites observed in our local group. Therefore, understanding the population and property of subhalos at cosmological scale would be an interesting test for cold dark matter. In recent years, it has become possible to detect individual dark matter subhalos near images of strongly lensed extended background galaxies. In this work, we discuss the possibility of using deep neural networks to detect dark matter subhalos, and showing some preliminary results with simulated data. We found that neural networks not only show promising results on detecting multiple dark matter subhalos, but also learn to reject the subhalos on the lensing arc of a smooth lens where there is no subhalo.",
        "versions": [],
        "rank": 842
    },
    {
        "authors": [
            "Peter Tompa"
        ],
        "title": "Intrinsically unstructured proteins",
        "publication_date": "2002-10-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Trends in Biochemical Sciences",
        "volume": "27",
        "doi": "10.1016/s0968-0004(02)02169-2",
        "urls": [
            "https://openalex.org/W2149472608",
            "https://doi.org/10.1016/s0968-0004(02)02169-2"
        ],
        "id": "id-1930555076724506496",
        "abstract": "",
        "versions": [],
        "rank": 843
    },
    {
        "authors": [
            "Dietmayer, Klaus",
            "Feng, Di",
            "Rosenbaum, Lars"
        ],
        "title": "Towards Safe Autonomous Driving: Capture Uncertainty in the Deep Neural  Network For Lidar 3D Vehicle Detection",
        "publication_date": "2018-09-07 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/itsc.2018.8569814",
        "urls": [
            "http://arxiv.org/abs/1804.05132"
        ],
        "id": "id-4697729273267211364",
        "abstract": "To assure that an autonomous car is driving safely on public roads, its\nobject detection module should not only work correctly, but show its prediction\nconfidence as well. Previous object detectors driven by deep learning do not\nexplicitly model uncertainties in the neural network. We tackle with this\nproblem by presenting practical methods to capture uncertainties in a 3D\nvehicle detector for Lidar point clouds. The proposed probabilistic detector\nrepresents reliable epistemic uncertainty and aleatoric uncertainty in\nclassification and localization tasks. Experimental results show that the\nepistemic uncertainty is related to the detection accuracy, whereas the\naleatoric uncertainty is influenced by vehicle distance and occlusion. The\nresults also show that we can improve the detection performance by 1%-5% by\nmodeling the aleatoric uncertainty.Comment: Accepted to present in the 21st IEEE International Conference on\n  Intelligent Transportation Systems (ITSC 2018",
        "versions": [],
        "rank": 844
    },
    {
        "authors": [
            "Anabik Pal",
            "Sounak Ray",
            "Utpal Garain"
        ],
        "title": "Skin disease identification from dermoscopy images using deep convolutional neural network",
        "publication_date": "2018-07-24 14:48:57+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1807.09163v1",
            "http://arxiv.org/abs/1807.09163v1",
            "http://arxiv.org/pdf/1807.09163v1"
        ],
        "id": "id1553174059570224863",
        "abstract": "In this paper, a deep neural network based ensemble method is experimented\nfor automatic identification of skin disease from dermoscopic images. The\ndeveloped algorithm is applied on the task3 of the ISIC 2018 challenge dataset\n(Skin Lesion Analysis Towards Melanoma Detection).",
        "versions": [],
        "rank": 845
    },
    {
        "authors": [
            "Varun Singh",
            "Varun Danda",
            "Richard Gorniak",
            "Adam Flanders",
            "Paras Lakhani"
        ],
        "title": "Assessment of Critical Feeding Tube Malpositions on Radiographs Using Deep Learning",
        "publication_date": "2019-05-09 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Springer Science and Business Media LLC",
        "volume": "",
        "doi": "10.1007/s10278-019-00229-9",
        "urls": [
            "https://web.archive.org/web/20200311094420/https://link.springer.com/content/pdf/10.1007%2Fs10278-019-00229-9.pdf"
        ],
        "id": "id-5276604642982142127",
        "abstract": "Assess the efficacy of deep convolutional neural networks (DCNNs) in detection of critical enteric feeding tube malpositions on radiographs. 5475 de-identified HIPAA compliant frontal view chest and abdominal radiographs were obtained, consisting of 174 x-rays of bronchial insertions and 5301 non-critical radiographs, including normal course, normal chest, and normal abdominal x-rays. The ground-truth classification for enteric feeding tube placement was performed by two board-certified radiologists. Untrained and pretrained deep convolutional neural network models for Inception V3, ResNet50, and DenseNet 121 were each employed. The radiographs were fed into each deep convolutional neural network, which included untrained and pretrained models. The Tensorflow framework was used for Inception V3, ResNet50, and DenseNet. Images were split into training (4745), validation (630), and test (100). Both real-time and preprocessing image augmentation strategies were performed. Receiver operating characteristic (ROC) and area under the curve (AUC) on the test data were used to assess the models. Statistical differences among the AUCs were obtained. p < 0.05 was considered statistically significant. The pretrained Inception V3, which had an AUC of 0.87 (95 CI; 0.80-0.94), performed statistically significantly better (p < .001) than the untrained Inception V3, with an AUC of 0.60 (95 CI; 0.52-0.68). The pretrained Inception V3 also had the highest AUC overall, as compared with ResNet50 and DenseNet121, with AUC values ranging from 0.82 to 0.85. Each pretrained network outperformed its untrained counterpart. (p < 0.05). Deep learning demonstrates promise in differentiating critical vs. non-critical placement with an AUC of 0.87. Pretrained networks outperformed untrained ones in all cases. DCNNs may allow for more rapid identification and communication of critical feeding tube malpositions.",
        "versions": [],
        "rank": 846
    },
    {
        "authors": [
            "Bo Liu",
            "Xiangguo Sun",
            "Qing Meng",
            "Xinyan Yang",
            "Yang Lee",
            "Jiuxin Cao",
            "Junzhou Luo",
            "R. Lee"
        ],
        "title": "Nowhere to Hide: Online Rumor Detection Based on Retweeting Graph Neural Networks.",
        "publication_date": "2022-04-06 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "IEEE transactions on neural networks and learning systems",
        "volume": "PP",
        "doi": "10.1109/TNNLS.2022.3161697",
        "urls": [
            "https://www.semanticscholar.org/paper/a15b1b6ec57f3addd387dcb859369b103282ae28"
        ],
        "id": "id3006571379828254729",
        "abstract": "Online rumor detection is crucial for a healthier online environment. Traditional methods mainly rely on content understanding. However, these contents can be easily adjusted to avoid such supervision and are insufficient to improve the detection result. Compared with the content, information propagation patterns are more informative to support further performance promotion. Unfortunately, learning the propagation patterns is difficult, since the retweeting tree is more topologically complicated than linear sequences or binary trees. In light of this, we propose a novel rumor detection framework based on structure-aware retweeting graph neural networks. To capture the propagation patterns, we first design a novel conversion method to transform the complex retweeting tree as more tractable binary tree without losing the reconstruction information. Then, we serialize the retweeting tree as a corpus of meta-tree paths, where each meta-tree can preserve a basic substructure. A deep neural network is then designed to integrate all meta-trees and to generate the global structural embeddings. Furthermore, we propose to integrate content, users, and propagation patterns to enhance more reliable performance. To this end, we propose a novel self-attention-based retweeting neural network to learn individual features from both content and users. We then fuse the node-level features with our global structural embeddings via a mutual attention unit. In this way, we can generate more comprehensive representations for rumor detection. Extensive evaluations on two real-world datasets show remarkable superiorities of our model compared with existing methods.",
        "versions": [],
        "rank": 847
    },
    {
        "authors": [
            "P. Ardimento",
            "Lerina Aversano",
            "M. Bernardi",
            "Marta Cimitile"
        ],
        "title": "Deep Neural Networks Ensemble for Lung Nodule Detection on Chest CT Scans",
        "publication_date": "2021-07-18 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/IJCNN52387.2021.9534176",
        "urls": [
            "https://www.semanticscholar.org/paper/0a6f4ecbd057f06c67ae2cc6f20e84ad190cbd97"
        ],
        "id": "id-5224601856248985129",
        "abstract": "Identifying and diagnosing as early as possible malignant lung nodules is essential to reduce the mortality of lung cancer patients. Radiologists employ computer tomography scan to detect cancer in the body and track its growth. Interpretation of tomography scan, today still not automated, can lead to cancer detection at early stages, thus leading to the treatment of cancer which can decrease the death rates. Image processing, a branch of computer-assisted diagnostic, can support radiologists for the early detection of cancer. Against that background, we propose a novel ensemble-based approach for more accurate lung cancer classification using Computer tomography scan images. This work exploits transfer learning using pre-trained deep networks (e.g., VGG, Xception, and ResNet), combined into an ensemble architecture to classify clustered images of lung lobes. The approach is validated on a real dataset and shows that the ensemble classifier ensures effective performance, exhibiting better generalization capabilities.",
        "versions": [],
        "rank": 848
    },
    {
        "authors": [
            "Hao Chang"
        ],
        "title": "Skin cancer reorganization and classification with deep neural network",
        "publication_date": "2017-03-01 22:21:21+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1703.00534v1",
            "http://arxiv.org/abs/1703.00534v1",
            "http://arxiv.org/pdf/1703.00534v1"
        ],
        "id": "id2164801245881823022",
        "abstract": "As one kind of skin cancer, melanoma is very dangerous. Dermoscopy based\nearly detection and recarbonization strategy is critical for melanoma therapy.\nHowever, well-trained dermatologists dominant the diagnostic accuracy. In order\nto solve this problem, many effort focus on developing automatic image analysis\nsystems. Here we report a novel strategy based on deep learning technique, and\nachieve very high skin lesion segmentation and melanoma diagnosis accuracy: 1)\nwe build a segmentation neural network (skin_segnn), which achieved very high\nlesion boundary detection accuracy; 2) We build another very deep neural\nnetwork based on Google inception v3 network (skin_recnn) and its well-trained\nweight. The novel designed transfer learning based deep neural network\nskin_inceptions_v3_nn helps to achieve a high prediction accuracy.",
        "versions": [],
        "rank": 849
    },
    {
        "authors": [
            "Chen, Pin-Yu",
            "Liu, Yi-Chieh",
            "Ma, Xiaoli",
            "Tsai, Yi-Chang James",
            "Yang, Chao-Han Huck"
        ],
        "title": "When Causal Intervention Meets Adversarial Examples and Image Masking  for Deep Neural Networks",
        "publication_date": "2019-06-25 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/icip.2019.8803554",
        "urls": [
            "http://arxiv.org/abs/1902.03380"
        ],
        "id": "id-7131307265634146504",
        "abstract": "Discovering and exploiting the causality in deep neural networks (DNNs) are\ncrucial challenges for understanding and reasoning causal effects (CE) on an\nexplainable visual model. \"Intervention\" has been widely used for recognizing a\ncausal relation ontologically. In this paper, we propose a causal inference\nframework for visual reasoning via do-calculus. To study the intervention\neffects on pixel-level features for causal reasoning, we introduce pixel-wise\nmasking and adversarial perturbation. In our framework, CE is calculated using\nfeatures in a latent space and perturbed prediction from a DNN-based model. We\nfurther provide the first look into the characteristics of discovered CE of\nadversarially perturbed images generated by gradient-based methods\n\\footnote{~~https://github.com/jjaacckkyy63/Causal-Intervention-AE-wAdvImg}.\nExperimental results show that CE is a competitive and robust index for\nunderstanding DNNs when compared with conventional methods such as\nclass-activation mappings (CAMs) on the Chest X-Ray-14 dataset for\nhuman-interpretable feature(s) (e.g., symptom) reasoning. Moreover, CE holds\npromises for detecting adversarial examples as it possesses distinct\ncharacteristics in the presence of adversarial perturbations.Comment: Noted our camera-ready version has changed the title. \"When Causal\n  Intervention Meets Adversarial Examples and Image Masking for Deep Neural\n  Networks\" as the v3 official paper title in IEEE Proceeding. Please use it in\n  your formal reference. Accepted at IEEE ICIP 2019. Pytorch code has released\n  on https://github.com/jjaacckkyy63/Causal-Intervention-AE-wAdvIm",
        "versions": [],
        "rank": 850
    },
    {
        "authors": [
            "Ahmed, Sheraz",
            "Bajwa, Muhammad Naseer",
            "Braun, Stephan Alexander",
            "Dengel, Andreas",
            "Lucieri, Adriano",
            "Malik, Muhammad Imran"
        ],
        "title": "On Interpretability of Deep Learning based Skin Lesion Classifiers using  Concept Activation Vectors",
        "publication_date": "2020-05-05 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ijcnn48605.2020.9206946",
        "urls": [
            "http://arxiv.org/abs/2005.02000"
        ],
        "id": "id5889742253223264496",
        "abstract": "Deep learning based medical image classifiers have shown remarkable prowess\nin various application areas like ophthalmology, dermatology, pathology, and\nradiology. However, the acceptance of these Computer-Aided Diagnosis (CAD)\nsystems in real clinical setups is severely limited primarily because their\ndecision-making process remains largely obscure. This work aims at elucidating\na deep learning based medical image classifier by verifying that the model\nlearns and utilizes similar disease-related concepts as described and employed\nby dermatologists. We used a well-trained and high performing neural network\ndeveloped by REasoning for COmplex Data (RECOD) Lab for classification of three\nskin tumours, i.e. Melanocytic Naevi, Melanoma and Seborrheic Keratosis and\nperformed a detailed analysis on its latent space. Two well established and\npublicly available skin disease datasets, PH2 and derm7pt, are used for\nexperimentation. Human understandable concepts are mapped to RECOD image\nclassification model with the help of Concept Activation Vectors (CAVs),\nintroducing a novel training and significance testing paradigm for CAVs. Our\nresults on an independent evaluation set clearly shows that the classifier\nlearns and encodes human understandable concepts in its latent representation.\nAdditionally, TCAV scores (Testing with CAVs) suggest that the neural network\nindeed makes use of disease-related concepts in the correct way when making\npredictions. We anticipate that this work can not only increase confidence of\nmedical practitioners on CAD but also serve as a stepping stone for further\ndevelopment of CAV-based neural network interpretation methods.Comment: Accepted for the IEEE International Joint Conference on Neural\n  Networks (IJCNN) 202",
        "versions": [],
        "rank": 851
    },
    {
        "authors": [
            "Dou, Yingtong",
            "He, Lifang",
            "Li, Bo",
            "Sun, Lichao",
            "Wang, Ji",
            "Yang, Carl",
            "Yu, Philip S."
        ],
        "title": "Adversarial Attack and Defense on Graph Data: A Survey",
        "publication_date": "2020-07-14 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "http://arxiv.org/abs/1812.10528"
        ],
        "id": "id906283238386438679",
        "abstract": "Deep neural networks (DNNs) have been widely applied to various applications\nincluding image classification, text generation, audio recognition, and graph\ndata analysis. However, recent studies have shown that DNNs are vulnerable to\nadversarial attacks. Though there are several works studying adversarial attack\nand defense strategies on domains such as images and natural language\nprocessing, it is still difficult to directly transfer the learned knowledge to\ngraph structure data due to its representation challenges. Given the importance\nof graph analysis, an increasing number of works start to analyze the\nrobustness of machine learning models on graph data. Nevertheless, current\nstudies considering adversarial behaviors on graph data usually focus on\nspecific types of attacks with certain assumptions. In addition, each work\nproposes its own mathematical formulation which makes the comparison among\ndifferent methods difficult. Therefore, in this paper, we aim to survey\nexisting adversarial learning strategies on graph data and first provide a\nunified formulation for adversarial learning on graph data which covers most\nadversarial learning studies on graph. Moreover, we also compare different\nattacks and defenses on graph data and discuss their corresponding\ncontributions and limitations. In this work, we systemically organize the\nconsidered works based on the features of each topic. This survey not only\nserves as a reference for the research community, but also brings a clear image\nresearchers outside this research domain. Besides, we also create an online\nresource and keep updating the relevant papers during the last two years. More\ndetails of the comparisons of various studies based on this survey are\nopen-sourced at\nhttps://github.com/YingtongDou/graph-adversarial-learning-literature.Comment: In submission to Journal. For more open-source and up-to-date\n  information, please check our Github repository:\n  https://github.com/YingtongDou/graph-adversarial-learning-literatur",
        "versions": [],
        "rank": 852
    },
    {
        "authors": [
            "Junseok Lee",
            "Jongwon Kim",
            "Jumi Park",
            "Seunghyeok Back",
            "Seongho Bak",
            "Kyoobin Lee"
        ],
        "title": "Automatic Detection of Injection and Press Mold Parts on 2D Drawing Using Deep Neural Network",
        "publication_date": "2021-10-22 05:20:13+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2110.11593v1",
            "http://arxiv.org/abs/2110.11593v1",
            "http://arxiv.org/pdf/2110.11593v1"
        ],
        "id": "id2802399525866832997",
        "abstract": "This paper proposes a method to automatically detect the key feature parts in\na CAD of commercial TV and monitor using a deep neural network. We developed a\ndeep learning pipeline that can detect the injection parts such as hook, boss,\nundercut and press parts such as DPS, Embo-Screwless, Embo-Burring, and EMBO in\nthe 2D CAD drawing images. We first cropped the drawing to a specific size for\nthe training efficiency of a deep neural network. Then, we use Cascade R-CNN to\nfind the position of injection and press parts and use Resnet-50 to predict the\norientation of the parts. Finally, we convert the position of the parts found\nthrough the cropped image to the position of the original image. As a result,\nwe obtained detection accuracy of injection and press parts with 84.1% in AP\n(Average Precision), 91.2% in AR(Average Recall), 72.0% in AP, 87.0% in AR, and\norientation accuracy of injection and press parts with 94.4% and 92.0%, which\ncan facilitate the faster design in industrial product design.",
        "versions": [],
        "rank": 853
    },
    {
        "authors": [
            "Chiappino, Dante",
            "Della Latta, Daniele",
            "Iacconi, Chiara",
            "Martini, Nicola",
            "Ripoli, Andrea",
            "Santini, Gianmarco",
            "Valvano, Gabriele"
        ],
        "title": "Convolutional Neural Networks for the segmentation of microcalcification  in Mammography Imaging",
        "publication_date": "2018-09-11 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "Journal of Healthcare Engineering",
        "volume": "",
        "doi": "10.1155/2019/9360941",
        "urls": [
            "http://arxiv.org/abs/1809.03788"
        ],
        "id": "id1462018506836006005",
        "abstract": "Cluster of microcalcifications can be an early sign of breast cancer. In this\npaper we propose a novel approach based on convolutional neural networks for\nthe detection and segmentation of microcalcification clusters. In this work we\nused 283 mammograms to train and validate our model, obtaining an accuracy of\n98.22% in the detection of preliminary suspect regions and of 97.47% in the\nsegmentation task. Our results show how deep learning could be an effective\ntool to effectively support radiologists during mammograms examination.Comment: 13 pages, 7 figure",
        "versions": [],
        "rank": 854
    },
    {
        "authors": [
            "A. Khan",
            "Shahzad Younis",
            "H. Algethami"
        ],
        "title": "Covid-19 Identification Using Deep Neural Networks",
        "publication_date": "2021-03-30 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/WiDSTaif52235.2021.9430219",
        "urls": [
            "https://www.semanticscholar.org/paper/33ccc45baf5555d10249e4a73345f7dff52f12df"
        ],
        "id": "id5575898806992716586",
        "abstract": "COVID-19 is a novel virus which is originated from Wuhan, a city in China. By March 2021, World Health Organization has confirmed the virus has increased in the number of infections to over 117 million cases globally. In this scenario of increasing Corona infected patients, most hospitals are lagging in the availability of the Corona test kits. Owing to the lack of precise automated toolkits, auxiliary diagnostic tools are in high demand. Therefore, it becomes necessary to enforce AI-based automatic detection techniques. It can also address the issue of unavailability of physicians in remote areas. This study proposes the use of deep neural networks and transfer learning for the detection of COVID-19 infectees through radio-graphs of chest X-rays. We have used hand-crafted Convolutional Neural Network (CNN) besides using the existing famous pre-trained networks employing transfer learning. Remarkable accuracy achieved was 96.89% for our hand-crafted CNN, 92.67% for ResNet34, and 98.26% on DenseNet-121, respectively. However, our hand-crafted CNN required 8 million less parameters than ResNet34 and comparable to DenseNet-121.",
        "versions": [],
        "rank": 855
    },
    {
        "authors": [
            "Salome Palani",
            "Arya Kulkarni",
            "Abishai Kochara",
            "Kiruthika M",
            "M.D. Patil",
            "V.A. Vyawahare"
        ],
        "title": "Detection of Thoracic Diseases using Deep Learning",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "EDP Sciences",
        "volume": "",
        "doi": "10.1051/itmconf/20203203024",
        "urls": [
            "https://web.archive.org/web/20200818101427/https://www.itm-conferences.org/articles/itmconf/pdf/2020/02/itmconf_icacc2020_03024.pdf"
        ],
        "id": "id-3858801493793036494",
        "abstract": "The study of using deep learning for detection of various thoracic diseases has been an active and challenging research area. Chest X-rays are currently the most common and globally used radiology practices for detecting thoracic diseases. Patients suffering from thoracic diseases need to take Chest X-Rays which are read by radiologists and a report is generated by them. However, today with the increase in the number of thoracic patients, a quick method to classify the disease and generate the report has become necessary. Also, patient history has to be considered for diagnosis. This paper offers a comparative study on the various deep learning techniques that can process chest x-rays and are capable of detecting the different thoracic diseases. Also, a technique has been proposed to classify 14 diseases namely Atelectasis, Cardiomegaly, Consolidation, Edema, Effusion, Emphysema, Fibrosis, Hernia, Infiltration, Mass, Nodule, Pneumonia, Pneumothorax, Pleural thickening based on the given X-rays using Residual Neural Network.",
        "versions": [],
        "rank": 856
    },
    {
        "authors": [
            "Hwang, Soonmin",
            "Kweon, In So",
            "Woo, Sanghyun"
        ],
        "title": "StairNet: Top-Down Semantic Aggregation for Accurate One Shot Detection",
        "publication_date": "2017-09-18 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/wacv.2018.00125",
        "urls": [
            "http://arxiv.org/abs/1709.05788"
        ],
        "id": "id-7685793255024598511",
        "abstract": "One-stage object detectors such as SSD or YOLO already have shown promising\naccuracy with small memory footprint and fast speed. However, it is widely\nrecognized that one-stage detectors have difficulty in detecting small objects\nwhile they are competitive with two-stage methods on large objects. In this\npaper, we investigate how to alleviate this problem starting from the SSD\nframework. Due to their pyramidal design, the lower layer that is responsible\nfor small objects lacks strong semantics(e.g contextual information). We\naddress this problem by introducing a feature combining module that spreads out\nthe strong semantics in a top-down manner. Our final model StairNet detector\nunifies the multi-scale representations and semantic distribution effectively.\nExperiments on PASCAL VOC 2007 and PASCAL VOC 2012 datasets demonstrate that\nStairNet significantly improves the weakness of SSD and outperforms the other\nstate-of-the-art one-stage detectors",
        "versions": [],
        "rank": 857
    },
    {
        "authors": [
            "Syntia Widyayuningtias Putri Listio"
        ],
        "title": "Performance of Deep Learning Inception Model and MobileNet Model on Gender Prediction Through Eye Image",
        "publication_date": "2022-11-11 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Politeknik Ganesha",
        "volume": "",
        "doi": "10.33395/sinkron.v7i4.11887",
        "urls": [
            "https://web.archive.org/web/20221115185921/https://www.jurnal.polgan.ac.id/index.php/sinkron/article/download/11887/1226"
        ],
        "id": "id7048341172918121632",
        "abstract": "Convolutional neural network (CNN) is one of the neural networks used in image data. CNN has a good ability to detect objects in an image. This study discusses the comparison of two deep learning models based on convolutional neural network, namely the Inception-V3 method and the MobileNet method. Both algorithms are analyzed fairly on gender classification using eye images. There have been many research completions that have conducted studies on gender classification based on faces, but gender classification based on eyes has many challenges. This gender classification is grouped into two classes, namely male and female. This study aims to build a gender classification model from eye image. The processes in this research include selecting the dataset, preprocessing the data, dividing the data which is divided into training data and test data, modeling, and evaluating the performance of the model. This study uses a public dataset, where the data contains a total of 2,681 images consisting of 1251 male eyes and 1430 female eyes. This study concludes that gender classification using eye image using the Inception-V3 method is better than the MobileNet method. This is obtained based on the accuracy value generated by the Inception-V3 method which is higher than the MobileNet-V2 method which obtains an accuracy of 91.82%.",
        "versions": [],
        "rank": 858
    },
    {
        "authors": [
            "M. Rozi",
            "Sangwook P. Kim",
            "S. Ozawa"
        ],
        "title": "Deep Neural Networks for Malicious JavaScript Detection Using Bytecode Sequences",
        "publication_date": "2020-07-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/IJCNN48605.2020.9207134",
        "urls": [
            "https://www.semanticscholar.org/paper/1302abf0c9ac17e776e5e5785dfadbf271e8bf40"
        ],
        "id": "id-4830366061558184732",
        "abstract": "JavaScript is a dynamic computer programming language that has been used for various cyberattacks on client-side web applications. Malicious behaviors in JavaScript are injected on purpose as the outputs of web applications, such as redirection and pop-up texts or images. It exploits vulnerabilities by using a variety of methods such as drive-by download or cross-site scripting. To protect users from such cyberattacks, we propose a deep neural network for detecting malicious JavaScript codes by examining their bytecode sequences. We use the V8 JavaScript compiler to generate a bytecode sequence, which corresponds to an abstract form of machine codes. The benefit of using bytecode representation is that we can easily break complex obfuscation in JavaScript. To identify the attacker\u2019s malicious intention, We adopt a deep pyramid convolutional neural network (DPCNN) combining with recurrent neural network models, which can handle long-range associations in a bytecode sequence. In our experiment, various recurrent networks are testified to encode temporal features of code behaviors, and our results show that the proposed approach provides high accuracy in detection of malicious JavaScript.",
        "versions": [],
        "rank": 859
    },
    {
        "authors": [
            "Mrinal Haloi"
        ],
        "title": "Improved Microaneurysm Detection using Deep Neural Networks",
        "publication_date": "2015-05-17 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "ArXiv",
        "volume": "abs/1505.04424",
        "doi": "",
        "urls": [
            "https://www.semanticscholar.org/paper/c270d9d9a2113600db3d517b930082655bd871e6"
        ],
        "id": "id4428123020826077401",
        "abstract": "In this work, we propose a novel microaneurysm (MA) detection for early diabetic retinopathy screening using color fundus images. Since MA usually the first lesions to appear as an indicator of diabetic retinopathy, accurate detection of MA is necessary for treatment. Each pixel of the image is classified as either MA or non-MA using a deep neural network with dropout training procedure using maxout activation function. No preprocessing step or manual feature extraction is required. Substantial improvements over standard MA detection method based on the pipeline of preprocessing, feature extraction, classification followed by post processing is achieved. The presented method is evaluated in publicly available Retinopathy Online Challenge (ROC) and Diaretdb1v2 database and achieved state-of-the-art accuracy.",
        "versions": [
            {
                "year": 2015,
                "source": "SupportedSources.ARXIV",
                "title": "Improved Microaneurysm Detection using Deep Neural Networks",
                "journal": null,
                "urls": [
                    "http://arxiv.org/pdf/1505.04424v2",
                    "http://arxiv.org/abs/1505.04424v2",
                    "http://arxiv.org/pdf/1505.04424v2"
                ],
                "doi": "",
                "publication_date": "2015-05-17 17:37:14+00:00"
            }
        ],
        "rank": 860
    },
    {
        "authors": [
            "Adam R. Aron",
            "Russell A. Poldrack"
        ],
        "title": "Cortical and Subcortical Contributions to Stop Signal Response Inhibition: Role of the Subthalamic Nucleus",
        "publication_date": "2006-01-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "The Journal of Neuroscience",
        "volume": "26",
        "doi": "10.1523/jneurosci.4682-05.2006",
        "urls": [
            "https://openalex.org/W2039729702",
            "https://doi.org/10.1523/jneurosci.4682-05.2006",
            "https://www.jneurosci.org/content/jneuro/26/9/2424.full.pdf"
        ],
        "id": "id-4815440950739312364",
        "abstract": "",
        "versions": [],
        "rank": 861
    },
    {
        "authors": [
            "Xiao Chen",
            "Miao Liu",
            "Guan Gui",
            "B. Adebisi",
            "H. Ga\u010danin",
            "H. Sari"
        ],
        "title": "Complex Deep Neural Network Based Intelligent Signal Detection Methods for OFDM-IM Systems",
        "publication_date": "2021-06-08 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/EuCNC/6GSummit51104.2021.9482564",
        "urls": [
            "https://www.semanticscholar.org/paper/2a099506148efc0a61a09b292619ee5e6197d6ac"
        ],
        "id": "id-6532188416096019269",
        "abstract": "Advanced signal detectors pose a lot of technical challenges for designing signal detection methods in orthogonal frequency division multiplexing (OFDM) with index modulation (IM). Traditional signal detection methods such as maximum likelihood have an excessive complexity, and existing deep learning (DL) based detection methods can reduce the complexity significantly. To further improve the detection performance, in this paper, we propose a complex deep neural network (C-DNN) and a complex convolution neural network (C-CNN) based intelligent signal detection method for OFDM-IM. Specifically, the proposed intelligent signal detection method is designed by C-DNN and C-CNN. The proposed signal detection methods for OFDM-IM use pilots to achieve semi-blind channel estimation, and to reconstruct the transmitted symbols based on channel state information (CSI). Simulation results are given to confirm the performance of the proposed signal detection method in terms of bit error rate and convergence speed.",
        "versions": [],
        "rank": 862
    },
    {
        "authors": [
            "Ejaz, N.",
            "Khan, U. A.",
            "Mart\u00ednez del Amor, Miguel \u00c1ngel",
            "Sparenberg, Heiko"
        ],
        "title": "Movies Tags Extraction Using Deep Learning",
        "publication_date": "2017-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "https://core.ac.uk/download/222572691.pdf"
        ],
        "id": "id-1646488792059710227",
        "abstract": "Retrieving information from movies is becoming increasingly\r\ndemanding due to the enormous amount of multimedia\r\ndata generated each day. Not only it helps in efficient\r\nsearch, archiving and classification of movies, but is also instrumental\r\nin content censorship and recommendation systems.\r\nExtracting key information from a movie and summarizing\r\nit in a few tags which best describe the movie presents\r\na dedicated challenge and requires an intelligent approach\r\nto automatically analyze the movie. In this paper, we formulate\r\nmovies tags extraction problem as a machine learning\r\nclassification problem and train a Convolution Neural Network\r\n(CNN) on a carefully constructed tag vocabulary. Our\r\nproposed technique first extracts key frames from a movie\r\nand applies the trained classifier on the key frames. The\r\npredictions from the classifier are assigned scores and are\r\nfiltered based on their relative strengths to generate a compact\r\nset of most relevant key tags. We performed a rigorous\r\nsubjective evaluation of our proposed technique for a\r\nwide variety of movies with different experiments. The evaluation\r\nresults presented in this paper demonstrate that our\r\nproposed approach can efficiently extract the key tags of a\r\nmovie with a good accuracy",
        "versions": [],
        "rank": 863
    },
    {
        "authors": [
            "Hakan Koyuncu",
            "Dinesh Sharma"
        ],
        "title": "Deep learning approach to analyse, detect and classify COVID-19 patients",
        "publication_date": "2021-07-04 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "New Trends in Mathematical Science",
        "volume": "",
        "doi": "10.20852/ntmsci.2021.420",
        "urls": [
            "https://web.archive.org/web/20210708082730/https://ntmsci.com/AjaxTool/GetArticleByPublishedArticleId?PublishedArticleId=8618"
        ],
        "id": "id3976049021245413707",
        "abstract": "An early-stage classification model is presented to classify between the COVID and non-COVID patients. World health organization (WHO) and many governmental and private organizations have presented a significant approach in solving the world pandemic problem. In this study, the analysis, detection, and classification of COVID-19 patients with the help of the different worldwide chest x-ray dataset and for the prediction, different updated statistics of COVID-19 cases have been used all over the world. The dataset consists of different COVID and non-COVID patients? x-ray details which will be further used for classification purposes. Different machine learning approaches were deployed like image filtration, image enhancement, feature extraction, detection, and evaluation. A deep learning classification approach was introduced by using the AdaBoost integrated with Convolution neural network (CNN) for the detection and evaluation of COVID-19 cases. The study has calculated an infection identification accuracy of 84.10%.",
        "versions": [],
        "rank": 864
    },
    {
        "authors": [
            "M. Elgendi",
            "M. U. Nasir",
            "Qunfeng Tang",
            "R. Fletcher",
            "Newton Howard",
            "C. Menon",
            "Rabab Ward",
            "William Parker",
            "S. Nicolaou"
        ],
        "title": "The Performance of Deep Neural Networks in Differentiating Chest X-Rays of COVID-19 Patients From Other Bacterial and Viral Pneumonias",
        "publication_date": "2020-08-18 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Frontiers in Medicine",
        "volume": "7",
        "doi": "10.3389/fmed.2020.00550",
        "urls": [
            "https://www.semanticscholar.org/paper/16c5df196b509b47d9ff9ddb4a73ebf21def72f7"
        ],
        "id": "id-5634651480778832415",
        "abstract": "Chest radiography is a critical tool in the early detection, management planning, and follow-up evaluation of COVID-19 pneumonia; however, in smaller clinics around the world, there is a shortage of radiologists to analyze large number of examinations especially performed during a pandemic. Limited availability of high-resolution computed tomography and real-time polymerase chain reaction in developing countries and regions of high patient turnover also emphasizes the importance of chest radiography as both a screening and diagnostic tool. In this paper, we compare the performance of 17 available deep learning algorithms to help identify imaging features of COVID19 pneumonia. We utilize an existing diagnostic technology (chest radiography) and preexisting neural networks (DarkNet-19) to detect imaging features of COVID-19 pneumonia. Our approach eliminates the extra time and resources needed to develop new technology and associated algorithms, thus aiding the front-line healthcare workers in the race against the COVID-19 pandemic. Our results show that DarkNet-19 is the optimal pre-trained neural network for the detection of radiographic features of COVID-19 pneumonia, scoring an overall accuracy of 94.28% over 5,854 X-ray images. We also present a custom visualization of the results that can be used to highlight important visual biomarkers of the disease and disease progression.",
        "versions": [],
        "rank": 865
    },
    {
        "authors": [
            "Tom\u00e1\u0161 Paus"
        ],
        "title": "Primate anterior cingulate cortex: Where motor control, drive and cognition interface",
        "publication_date": "2001-06-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Nature Reviews Neuroscience",
        "volume": "2",
        "doi": "10.1038/35077500",
        "urls": [
            "https://openalex.org/W2142106331",
            "https://doi.org/10.1038/35077500"
        ],
        "id": "id-635199161457052778",
        "abstract": "",
        "versions": [],
        "rank": 866
    },
    {
        "authors": [
            "Tingchun Wang",
            "Jun-Yan Zhu",
            "Andrew Tao",
            "Jan Kautz",
            "Bryan Catanzaro"
        ],
        "title": "High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs",
        "publication_date": "2018-06-18 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Computer Vision and Pattern Recognition",
        "volume": "",
        "doi": "10.1109/cvpr.2018.00917",
        "urls": [
            "https://openalex.org/W2963800363",
            "https://doi.org/10.1109/cvpr.2018.00917",
            "http://arxiv.org/pdf/1711.11585"
        ],
        "id": "id-5826089862480895207",
        "abstract": "",
        "versions": [],
        "rank": 867
    },
    {
        "authors": [
            "Zhixiang Yin",
            "Feng Ling",
            "Giles M. Foody",
            "Xinyan Li",
            "Yun Du"
        ],
        "title": "Cloud detection in Landsat-8 imagery in Google Earth Engine based on a deep neural network",
        "publication_date": "2020-06-18 08:32:01+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2006.10358v2",
            "http://arxiv.org/abs/2006.10358v2",
            "http://arxiv.org/pdf/2006.10358v2"
        ],
        "id": "id-3148211734884624919",
        "abstract": "Google Earth Engine (GEE) provides a convenient platform for applications\nbased on optical satellite imagery of large areas. With such data sets, the\ndetection of cloud is often a necessary prerequisite step. Recently, deep\nlearning-based cloud detection methods have shown their potential for cloud\ndetection but they can only be applied locally, leading to inefficient data\ndownloading time and storage problems. This letter proposes a method to\ndirectly perform cloud detection in Landsat-8 imagery in GEE based on deep\nlearning (DeepGEE-CD). A deep neural network (DNN) was first trained locally,\nand then the trained DNN was deployed in the JavaScript client of GEE. An\nexperiment was undertaken to validate the proposed method with a set of\nLandsat-8 images and the results show that DeepGEE-CD outperformed the widely\nused function of mask (Fmask) algorithm. The proposed DeepGEE-CD approach can\naccurately detect cloud in Landsat-8 imagery without downloading it, making it\na promising method for routine cloud detection of Landsat-8 imagery in GEE.",
        "versions": [],
        "rank": 868
    },
    {
        "authors": [
            "Bandi, Peter",
            "Bokhorst, John-Melle",
            "Bulten, Wouter",
            "Ciompi, Francesco",
            "Litjens, Geert",
            "Tellez, David",
            "van der Laak, Jeroen"
        ],
        "title": "Quantifying the effects of data augmentation and stain color  normalization in convolutional neural networks for computational pathology",
        "publication_date": "2019-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1016/j.media.2019.101544",
        "urls": [
            "http://arxiv.org/abs/1902.06543"
        ],
        "id": "id-4556880760210409807",
        "abstract": "Stain variation is a phenomenon observed when distinct pathology laboratories\nstain tissue slides that exhibit similar but not identical color appearance.\nDue to this color shift between laboratories, convolutional neural networks\n(CNNs) trained with images from one lab often underperform on unseen images\nfrom the other lab. Several techniques have been proposed to reduce the\ngeneralization error, mainly grouped into two categories: stain color\naugmentation and stain color normalization. The former simulates a wide variety\nof realistic stain variations during training, producing stain-invariant CNNs.\nThe latter aims to match training and test color distributions in order to\nreduce stain variation. For the first time, we compared some of these\ntechniques and quantified their effect on CNN classification performance using\na heterogeneous dataset of hematoxylin and eosin histopathology images from 4\norgans and 9 pathology laboratories. Additionally, we propose a novel\nunsupervised method to perform stain color normalization using a neural\nnetwork. Based on our experimental results, we provide practical guidelines on\nhow to use stain color augmentation and stain color normalization in future\ncomputational pathology applications.Comment: Accepted in the Medical Image Analysis journa",
        "versions": [],
        "rank": 869
    },
    {
        "authors": [
            "Jidong Xu",
            "Jinglun Yu",
            "Jianing Yao",
            "Rendong Zhang"
        ],
        "title": "The Neural Networks Based Needle Detection for Medical Retinal Surgery",
        "publication_date": "2023-02-10 03:12:09+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2302.05034v2",
            "http://arxiv.org/abs/2302.05034v2",
            "http://arxiv.org/pdf/2302.05034v2"
        ],
        "id": "id1867887570387471258",
        "abstract": "In recent years, deep learning technology has developed rapidly, and the\napplication of deep neural networks in the medical image processing field has\nbecome the focus of the spotlight. This paper aims to achieve needle position\ndetection in medical retinal surgery by adopting the target detection algorithm\nbased on YOLOv5 as the basic deep neural network model. The state-of-the-art\nneedle detection approaches for medical surgery mainly focus on needle\nstructure segmentation. Instead of the needle segmentation, the proposed method\nin this paper contains the angle examination during the needle detection\nprocess. This approach also adopts a novel classification method based on the\ndifferent positions of the needle to improve the model. The experiments\ndemonstrate that the proposed network can accurately detect the needle position\nand measure the needle angle. The performance test of the proposed method\nachieves 4.80 for the average Euclidean distance between the detected tip\nposition and the actual tip position. It also obtains an average error of 0.85\ndegrees for the tip angle across all test sets.",
        "versions": [],
        "rank": 870
    },
    {
        "authors": [
            "Chinnappa Guggilla"
        ],
        "title": "CogALex-V Shared Task: CGSRC - Classifying Semantic Relations using Convolutional Neural Networks",
        "publication_date": "2016-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20220806192638/https://aclanthology.org/W16-5314.pdf"
        ],
        "id": "id9025033091141569466",
        "abstract": "In this paper, we describe a system (CGSRC) for classifying four semantic relations: synonym, hypernym, antonym and meronym using convolutional neural networks (CNN). We have participated in CogALex-V semantic shared task of corpus-based identification of semantic relations. Proposed approach using CNN-based deep neural networks leveraging pre-compiled word2vec distributional neural embeddings achieved 43.15% weighted-F1 accuracy on subtask-1 (checking existence of a relation between two terms) and 25.24% weighted-F1 accuracy on subtask-2 (classifying relation types).",
        "versions": [],
        "rank": 871
    },
    {
        "authors": [
            "Yingying Hua",
            "Daichi Zhang",
            "Pengju Wang",
            "Shiming Ge"
        ],
        "title": "Interpretable Face Manipulation Detection via Feature Whitening",
        "publication_date": "2021-06-21 03:51:43+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2106.10834v1",
            "http://arxiv.org/abs/2106.10834v1",
            "http://arxiv.org/pdf/2106.10834v1"
        ],
        "id": "id-5550134444865305694",
        "abstract": "Why should we trust the detections of deep neural networks for manipulated\nfaces? Understanding the reasons is important for users in improving the\nfairness, reliability, privacy and trust of the detection models. In this work,\nwe propose an interpretable face manipulation detection approach to achieve the\ntrustworthy and accurate inference. The approach could make the face\nmanipulation detection process transparent by embedding the feature whitening\nmodule. This module aims to whiten the internal working mechanism of deep\nnetworks through feature decorrelation and feature constraint. The experimental\nresults demonstrate that our proposed approach can strike a balance between the\ndetection accuracy and the model interpretability.",
        "versions": [],
        "rank": 872
    },
    {
        "authors": [
            "Elham Gholami",
            "Seyed Reza Kamel Tabbakh",
            "Maryam Kheirabadi"
        ],
        "title": "Proposing method to Increase the detection accuracy of stomach cancer based on colour and lint features of tongue using CNN and SVM",
        "publication_date": "2020-11-18 12:06:29+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2011.09962v1",
            "http://arxiv.org/abs/2011.09962v1",
            "http://arxiv.org/pdf/2011.09962v1"
        ],
        "id": "id-7074514020841860397",
        "abstract": "Today, gastric cancer is one of the diseases which affected many people's\nlife. Early detection and accuracy are the main and crucial challenges in\nfinding this kind of cancer. In this paper, a method to increase the accuracy\nof the diagnosis of detecting cancer using lint and colour features of tongue\nbased on deep convolutional neural networks and support vector machine is\nproposed. In the proposed method, the region of tongue is first separated from\nthe face image by {deep RCNN} \\color{black} Recursive Convolutional Neural\nNetwork (R-CNN) \\color{black}. After the necessary preprocessing, the images to\nthe convolutional neural network are provided and the training and test\noperations are triggered. The results show that the proposed method is\ncorrectly able to identify the area of the tongue as well as the patient's\nperson from the non-patient. Based on experiments, the DenseNet network has the\nhighest accuracy compared to other deep architectures. The experimental results\nshow that the accuracy of this network for gastric cancer detection reaches 91%\nwhich shows the superiority of method in comparison to the state-of-the-art\nmethods.",
        "versions": [],
        "rank": 873
    },
    {
        "authors": [
            "Joonyoung Cho",
            "I. Suh",
            "Tae-Yeong Kwak",
            "Sun Woo Kim",
            "H. Chang",
            "N. Palanisamy"
        ],
        "title": "Abstract 5061: Molecular mapping of prostate cancer on whole mount prostatectomy specimens using deep neural networks to quantify genotypic heterogeneity",
        "publication_date": "2022-06-15 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1158/1538-7445.am2022-5061",
        "urls": [
            "https://www.semanticscholar.org/paper/09c3e5b8ec943ae71dc9a9848cb805825b09fde5"
        ],
        "id": "id-1857307793475308468",
        "abstract": "\n Most primary prostate cancers are multifocal, with multiple genomically independent tumors identified in up to 80% of men undergoing radical prostatectomy for clinically localized disease. The heterogeneity in prostate cancer and the clinical significance of secondary tumors have been explored. However, studies to date have been limited to analyzing prostate biopsies or sections using dominant tumor foci only, not allowing for the evaluation of the inter and intra tumor molecular heterogeneity of the prostate cancer landscape. Recently, we identified mutually exclusive expression patterns of more than one driver molecular aberration in distinct tumor foci. Here, we present a quantitative analysis of tumors with distinct markers and correlate with clinical outcomes.\n We developed a model to quantify cancerous regions and genotype expression on immunohistochemical (IHC) slides. Our algorithm combines multiple modeling strategies, including deep neural networks and color deconvolution. Dual ERG/SPINK1 IHC staining was performed on whole mount prostatectomy slides.\n Patches from corresponding slides stained with Hematoxylin/eosin (H&E) were generated to train the model. A color devolution method was used to separate the patches into H&E and other stain channels. For evaluation, patches were generated from IHC slides, which were then transformed into Hematoxylin-only stained patches. Sample patches were analyzed for detection of cancerous regions at the pixel-level. The ratios of cancerous regions were calculated.\n Our segmentation results were compared with the area positive for ERG or SPINK1. For the ERG stain, the model demonstrated a sensitivity of 62.72% per pixel, whereas it was associated with a sensitivity of 48.37% per pixel for SPINK1. This represents a robust performance for a proof-of-concept model, and sensitivities are expected to improve significantly with additional annotations. To investigate the entire landscape of whole mount samples, training to include recognition of morphological variations such as HGPIN is underway and expected to also increase sensitivity. More detailed analysis will be shared at the time of presentation.\n We present here a quantitative analysis model that reveals unprecedented details on tumor heterogeneity with respect to molecular markers and tumor localization. To our knowledge, this is the first study on quantitative molecular mapping of cancer and biomarker expression using whole mount samples.\n The marker expression in each tumor foci can be correlated with clinicopathologic findings. Different molecular subtypes presented with more than one driver molecular aberration in distinct tumor foci may be associated with distinct clinical outcomes such as biochemical recurrence or metastasis, allowing for predicting disease progression and targeted approaches for effective prostate cancer management.\n Citation Format: Joonyoung Cho, In Hye Suh, Tae-Yeong Kwak, Sun Woo Kim, Hyeyoon Chang, Nallasivam Palanisamy. Molecular mapping of prostate cancer on whole mount prostatectomy specimens using deep neural networks to quantify genotypic heterogeneity [abstract]. In: Proceedings of the American Association for Cancer Research Annual Meeting 2022; 2022 Apr 8-13. Philadelphia (PA): AACR; Cancer Res 2022;82(12_Suppl):Abstract nr 5061.",
        "versions": [],
        "rank": 874
    },
    {
        "authors": [
            "Ferdous, Syeda Nyma",
            "Mostofa, Moktari",
            "Nasrabadi, Nasser M.",
            "Riggan, Benjamin S."
        ],
        "title": "Joint-SRVDNet: Joint Super Resolution and Vehicle Detection Network",
        "publication_date": "2020-05-03 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "https://core.ac.uk/download/478907067.pdf"
        ],
        "id": "id-8232366811415915633",
        "abstract": "In many domestic and military applications, aerial vehicle detection and\nsuper-resolutionalgorithms are frequently developed and applied independently.\nHowever, aerial vehicle detection on super-resolved images remains a\nchallenging task due to the lack of discriminative information in the\nsuper-resolved images. To address this problem, we propose a Joint\nSuper-Resolution and Vehicle DetectionNetwork (Joint-SRVDNet) that tries to\ngenerate discriminative, high-resolution images of vehicles fromlow-resolution\naerial images. First, aerial images are up-scaled by a factor of 4x using a\nMulti-scaleGenerative Adversarial Network (MsGAN), which has multiple\nintermediate outputs with increasingresolutions. Second, a detector is trained\non super-resolved images that are upscaled by factor 4x usingMsGAN architecture\nand finally, the detection loss is minimized jointly with the super-resolution\nloss toencourage the target detector to be sensitive to the subsequent\nsuper-resolution training. The network jointlylearns hierarchical and\ndiscriminative features of targets and produces optimal super-resolution\nresults. Weperform both quantitative and qualitative evaluation of our proposed\nnetwork on VEDAI, xView and DOTAdatasets. The experimental results show that\nour proposed framework achieves better visual quality than thestate-of-the-art\nmethods for aerial super-resolution with 4x up-scaling factor and improves the\naccuracy ofaerial vehicle detection",
        "versions": [],
        "rank": 875
    },
    {
        "authors": [
            "Ivan Vishniakou",
            "Johannes D. Seelig"
        ],
        "title": "Adaptive optics with reflected light and deep neural networks",
        "publication_date": "2020-04-09 15:39:51+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": "Opt. Express 28 (2020) 15459-15471",
        "volume": "",
        "doi": "10.1364/OE.392794",
        "urls": [
            "http://arxiv.org/pdf/2004.04603v1",
            "http://dx.doi.org/10.1364/OE.392794",
            "http://arxiv.org/abs/2004.04603v1",
            "http://arxiv.org/pdf/2004.04603v1"
        ],
        "id": "id-5123595179272015449",
        "abstract": "Light scattering and aberrations limit optical microscopy in biological\ntissue, which motivates the development of adaptive optics techniques. Here, we\ndevelop a method for adaptive optics with reflected light and deep neural\nnetworks compatible with an epi-detection configuration. Large datasets of\nsample aberrations which consist of excitation and detection path aberrations\nas well as the corresponding reflected focus images are generated. These\ndatasets are used for training deep neural networks. After training, these\nnetworks can disentangle and independently correct excitation and detection\naberrations based on reflected light images recorded from scattering samples. A\nsimilar deep learning approach is also demonstrated with scattering guide\nstars. The predicted aberration corrections are validated using two photon\nimaging.",
        "versions": [],
        "rank": 876
    },
    {
        "authors": [
            "Devjani Mallick",
            "Mantasha Shaikh",
            "Anuja Gulhane",
            "Tabassum Maktum",
            "M.D. Patil",
            "V.A. Vyawahare"
        ],
        "title": "Copy Move and Splicing Image Forgery Detection using CNN",
        "publication_date": "2022-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "EDP Sciences",
        "volume": "",
        "doi": "10.1051/itmconf/20224403052",
        "urls": [
            "https://web.archive.org/web/20220507022727/https://www.itm-conferences.org/articles/itmconf/pdf/2022/04/itmconf_icacc2022_03052.pdf"
        ],
        "id": "id-3089274635634485412",
        "abstract": "The boom of digital images coupled with the development of approachable image manipulation software has made image tampering easier than ever. As a result, there is massive increase in number of forged or falsified images that represent incorrect or false information. Hence, the issue of image forgery has become a major concern and it must be addressed with appropriate solution. Throughout the years, various computer vision and deep learning solutions have emerged with a purpose to detect forgery in case of digital images. This paper presents a novel approach to detect copy move and splicing image forgery using a Convolutional Neural Network (CNN) with three different models i.e. ELA (Error Level Analysis), VGG16 and VGG19. The proposed method applies the pre-processing technique to obtain the images at a particular compression rate. These images are then utilized to train the model and further the images are classified as authentic or forged. The paper also presents the experimental results of the proposed method and performance evaluation in terms of accuracy.",
        "versions": [],
        "rank": 877
    },
    {
        "authors": [
            "Bryan Liu",
            "Shuangyang Li",
            "Yixuan Xie",
            "Jinhong Yuan"
        ],
        "title": "Deep Learning Assisted Sum-Product Detection Algorithm for Faster-than-Nyquist Signaling",
        "publication_date": "2019-07-22 10:51:51+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1907.09225v1",
            "http://arxiv.org/abs/1907.09225v1",
            "http://arxiv.org/pdf/1907.09225v1"
        ],
        "id": "id-696225549044757934",
        "abstract": "A deep learning assisted sum-product detection algorithm (DL-SPA) for\nfaster-than-Nyquist (FTN) signaling is proposed in this paper. The proposed\ndetection algorithm concatenates a neural network to the variable nodes of the\nconventional factor graph of the FTN system to help the detector converge to\nthe a posterior probabilities based on the received sequence. More\nspecifically, the neural network performs as a function node in the modified\nfactor graph to deal with the residual intersymbol interference (ISI) that is\nnot modeled by the conventional detector with a limited number of ISI taps. We\nmodify the updating rule in the conventional sum-product algorithm so that the\nneural network assisted detector can be complemented to a Turbo equalization.\nFurthermore, a simplified convolutional neural network is employed as the\nneural network function node to enhance the detector's performance and the\nneural network needs a small number of batches to be trained. Simulation\nresults have shown that the proposed DL-SPA achieves a performance gain up to\n2.5 dB with the same bit error rate compared to the conventional sum-product\ndetection algorithm under the same ISI responses.",
        "versions": [],
        "rank": 878
    },
    {
        "authors": [
            "Mengge Chen",
            "Jonathan Li"
        ],
        "title": "Deep convolutional neural network application on rooftop detection for aerial image",
        "publication_date": "2019-10-29 20:04:02+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1910.13509v1",
            "http://arxiv.org/abs/1910.13509v1",
            "http://arxiv.org/pdf/1910.13509v1"
        ],
        "id": "id5369640850605472166",
        "abstract": "As one of the most destructive disasters in the world, earthquake causes\ndeath, injuries, destruction and enormous damage to the affected area. It is\nsignificant to detect buildings after an earthquake in response to\nreconstruction and damage evaluation. In this research, we proposed an\nautomatic rooftop detection method based on the convolutional neural network\n(CNN) to extract buildings in the city of Christchurch and tuned\nhyperparameters to detect small detached houses from the aerial image. The\nexperiment result shows that our approach can effectively and accurately detect\nand segment buildings and has competitive performance.",
        "versions": [],
        "rank": 879
    },
    {
        "authors": [
            "Glib Kechyn"
        ],
        "title": "Automatic lesion boundary detection in dermoscopy",
        "publication_date": "2018-11-23 22:36:36+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1812.00877v1",
            "http://arxiv.org/abs/1812.00877v1",
            "http://arxiv.org/pdf/1812.00877v1"
        ],
        "id": "id-6814554355275830524",
        "abstract": "This manuscript addresses the problem of the automatic lesion boundary\ndetection in dermoscopy, using deep neural networks. An approach is based on\nthe adaptation of the U-net convolutional neural network with skip connections\nfor lesion boundary segmentation task. I hope this paper could serve, to some\nextent, as an experiment of using deep convolutional networks in biomedical\nsegmentation task and as a guideline of the boundary detection benchmark,\ninspiring further attempts and researches.",
        "versions": [],
        "rank": 880
    },
    {
        "authors": [
            "Michelucci, U."
        ],
        "title": "Cost Functions and Style Transfer",
        "publication_date": "2019-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-1-4842-4976-5_5",
        "urls": [
            "http://link.springer.com/content/pdf/10.1007/978-1-4842-4976-5_5",
            "http://dx.doi.org/10.1007/978-1-4842-4976-5_5"
        ],
        "id": "id4043029536837267941",
        "abstract": "",
        "versions": [],
        "rank": 881
    },
    {
        "authors": [
            "Xiaoyue Xie",
            "Yuan-yuan Ma",
            "B. Liu",
            "Jinrong He",
            "Shuqin Li",
            "Hongyan Wang"
        ],
        "title": "A Deep-Learning-Based Real-Time Detector for Grape Leaf Diseases Using Improved Convolutional Neural Networks",
        "publication_date": "2020-06-03 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Frontiers in Plant Science",
        "volume": "11",
        "doi": "10.3389/fpls.2020.00751",
        "urls": [
            "https://www.semanticscholar.org/paper/999e36eea46f3fed80d203fb93568aa8aa78f196"
        ],
        "id": "id-7663784023449878953",
        "abstract": "Black rot, Black measles, Leaf blight and Mites of grape are four common grape leaf diseases that seriously affect grape yield. However, the existing research lacks a real-time detecting method for grape leaf diseases, which cannot guarantee the healthy growth of grape plants. In this article, a real-time detector for grape leaf diseases based on improved deep convolutional neural networks is proposed. This article first expands the grape leaf disease images through digital image processing technology, constructing the grape leaf disease dataset (GLDD). Based on GLDD and the Faster R-CNN detection algorithm, a deep-learning-based Faster DR-IACNN model with higher feature extraction capability is presented for detecting grape leaf diseases by introducing the Inception-v1 module, Inception-ResNet-v2 module and SE-blocks. The experimental results show that the detection model Faster DR-IACNN achieves a precision of 81.1% mAP on GLDD, and the detection speed reaches 15.01 FPS. This research indicates that the real-time detector Faster DR-IACNN based on deep learning provides a feasible solution for the diagnosis of grape leaf diseases and provides guidance for the detection of other plant diseases.",
        "versions": [],
        "rank": 882
    },
    {
        "authors": [
            "Nikhil Tandon",
            "Ananya Choudhury"
        ],
        "title": "A review of vibration and acoustic measurement methods for the detection of defects in rolling element bearings",
        "publication_date": "1999-08-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Tribology International",
        "volume": "32",
        "doi": "10.1016/s0301-679x(99)00077-8",
        "urls": [
            "https://openalex.org/W2016324154",
            "https://doi.org/10.1016/s0301-679x(99)00077-8"
        ],
        "id": "id6785847071945231774",
        "abstract": "",
        "versions": [],
        "rank": 883
    },
    {
        "authors": [
            "Batra, Dhruv",
            "Lu, Jiasen",
            "Parikh, Devi",
            "Yang, Jianwei"
        ],
        "title": "Neural Baby Talk",
        "publication_date": "2018-03-26 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/cvpr.2018.00754",
        "urls": [
            "http://arxiv.org/abs/1803.09845"
        ],
        "id": "id-3588202957305790924",
        "abstract": "We introduce a novel framework for image captioning that can produce natural\nlanguage explicitly grounded in entities that object detectors find in the\nimage. Our approach reconciles classical slot filling approaches (that are\ngenerally better grounded in images) with modern neural captioning approaches\n(that are generally more natural sounding and accurate). Our approach first\ngenerates a sentence `template' with slot locations explicitly tied to specific\nimage regions. These slots are then filled in by visual concepts identified in\nthe regions by object detectors. The entire architecture (sentence template\ngeneration and slot filling with object detectors) is end-to-end\ndifferentiable. We verify the effectiveness of our proposed model on different\nimage captioning tasks. On standard image captioning and novel object\ncaptioning, our model reaches state-of-the-art on both COCO and Flickr30k\ndatasets. We also demonstrate that our model has unique advantages when the\ntrain and test distributions of scene compositions -- and hence language priors\nof associated captions -- are different. Code has been made available at:\nhttps://github.com/jiasenlu/NeuralBabyTalkComment: 12 pages, 7 figures, CVPR 201",
        "versions": [],
        "rank": 884
    },
    {
        "authors": [
            "Xiaoqiao Zhang",
            "L. Zhang",
            "S. Defilla",
            "W. Chu"
        ],
        "title": "Application of Convolution Network Model Based on Deep Learning in Sports Image Information Detection",
        "publication_date": "2021-01-01 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "EDP Sciences",
        "volume": "",
        "doi": "10.1051/e3sconf/202123302024",
        "urls": [
            "https://web.archive.org/web/20210130153326/https://www.e3s-conferences.org/articles/e3sconf/pdf/2021/09/e3sconf_iaecst20_02024.pdf"
        ],
        "id": "id-3650333825517061480",
        "abstract": "In recent years, convolution neural network has achieved great success in single image super-resolution detection. Compared with the traditional method, this method achieves better reconstruction detection effect. However, the network structure of the existing reconstruction model is shallow, and the convolution kernel has a small acceptance, so it is difficult to learn a wide range of motion image features, which affects the quality of motion image information detection. Aiming at the problems and shortcomings of the existing sports image information detection based on convolution neural network, this paper proposes the application of convolution network model based on deep learning in sports image information detection. In this paper, we get the average SSIM value from the data of set5, set14, bsd100 and urban100 by using the X4 model of different algorithms. The average SSIM value of set5 is 0.865, which shows that the quality of sports image reconstruction and the reconstruction efficiency of the model can be improved by using the local image features of different scales, which provides technical support for sports image information detection. The research in this paper has important practical significance for the further development of the two and the reform of the convolution network model in sports image information detection.",
        "versions": [],
        "rank": 885
    },
    {
        "authors": [
            "Dipti D. Patil",
            "S. Bindu",
            "SushilThale"
        ],
        "title": "Arc Fault Detection in DC Microgrid Using Deep Neural Network",
        "publication_date": "2021-01-15 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ICNTE51185.2021.9487585",
        "urls": [
            "https://www.semanticscholar.org/paper/024d5edb5d5943a514320b5010a10e554ad9ba89"
        ],
        "id": "id-1674927277880073453",
        "abstract": "DC microgrid getting acceptance because of recent development in renewable energy technology. The solar PV is the major part of DC microgrid. Solar PV is always at risk of fire hazard due to arc fault and if the fault is not detected in time then it not only damages the microgrid but also causes a serious threat to the safety of the operator. Exiting pattern base fault recognition techniques do not perform properly due to the nonperiodic nature of arc fault. Also, switching noise signals from power electronics converters affect the detection techniques. This paper proposes a deep neural network based approach for the detection of the arc faults in DC microgrid. Multi-layer perception(MLP)/Dense neural networks and Convolution Neural Networks(CNN) have been employed for the detection of the arc fault. A detailed analysis for both dense and convolution network have been performed to validate the choice of the neural network. The MATLAB simulation is developed to test the proposed methodology. Both MLP and CNN percentage accuracy was comparable under arc fault detection. However, CNN performance was better under noisy environment.",
        "versions": [],
        "rank": 886
    },
    {
        "authors": [
            "Ramin Nateghi",
            "Fattaneh Pourakpour"
        ],
        "title": "Perineural Invasion Detection in Multiple Organ Cancer Based on Deep Convolutional Neural Network",
        "publication_date": "2021-10-23 19:39:08+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2110.12283v1",
            "http://arxiv.org/abs/2110.12283v1",
            "http://arxiv.org/pdf/2110.12283v1"
        ],
        "id": "id-5011512605135737622",
        "abstract": "Perineural invasion (PNI) by malignant tumor cells has been reported as an\nindependent indicator of poor prognosis in various cancers. Assessment of PNI\nin small nerves on glass slides is a labor-intensive task. In this study, we\npropose an algorithm to detect the perineural invasions in colon, prostate, and\npancreas cancers based on a convolutional neural network (CNN).",
        "versions": [],
        "rank": 887
    },
    {
        "authors": [
            "Burnaev, Evgeny",
            "Nazarov, Ivan",
            "Volkhonskiy, Denis"
        ],
        "title": "Steganographic Generative Adversarial Networks",
        "publication_date": "2019-10-07 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1117/12.2559429",
        "urls": [
            "http://arxiv.org/abs/1703.05502"
        ],
        "id": "id-6550217389289634773",
        "abstract": "Steganography is collection of methods to hide secret information (\"payload\")\nwithin non-secret information \"container\"). Its counterpart, Steganalysis, is\nthe practice of determining if a message contains a hidden payload, and\nrecovering it if possible. Presence of hidden payloads is typically detected by\na binary classifier. In the present study, we propose a new model for\ngenerating image-like containers based on Deep Convolutional Generative\nAdversarial Networks (DCGAN). This approach allows to generate more\nsetganalysis-secure message embedding using standard steganography algorithms.\nExperiment results demonstrate that the new model successfully deceives the\nsteganography analyzer, and for this reason, can be used in steganographic\napplications.Comment: 15 pages, 10 figures, 5 tables, Workshop on Adversarial Training\n  (NIPS 2016, Barcelona, Spain",
        "versions": [],
        "rank": 888
    },
    {
        "authors": [
            "Jincai Chang",
            "Lijia Tian",
            "Jiaying Xing",
            "Heyu Zhao"
        ],
        "title": "The research on intelligent extraction of furnace mouth flame characteristics based on DNN",
        "publication_date": "2018-03-31 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "JVE International Ltd.",
        "volume": "",
        "doi": "10.21595/mme.2018.19765",
        "urls": [
            "https://web.archive.org/web/20180722232151/https://www.jvejournals.com/article/19765/pdf"
        ],
        "id": "id5747425014462993517",
        "abstract": "Deep neural networks are a focus of artificial intelligence and big data analysis in recent years. The monitor of the converter mouth is essential to the quality of the steel material production while the requirement of the steel material production is increasingly higher in China. The end-point control of converter blowing is the ultimate regulation of the carbon content and temperature. The severity of carbon-oxygen reaction and the temperature of molten steel can be reflected by the converter mouth flame. Operators judge the end of the steel by watching the converter mouth flame, the converter mouth spark and the time of oxygen supply. So, it is very important to offer a quantitative analysis to converter mouth flame characteristics. We quote the deep neural network into the intelligent extraction of the flame characteristics of the furnace mouth and construct a flame color recognition algorithm based on the deepness letter neural network. This paper belongs to the data science problem in the intelligent research of steel production. By observing the converter flame during the steel flame changes, this paper records the data of light intensity and end-point carbon content of each steel making furnace. When this paper then uses the temperature of flame emission spectrum to deduce and the absorption of the molten steel to judge the contents of the carbon during the converter steel blew process, it is more feasible and accurate than watching by operators. At the same time, by using deep learning algorithm, this paper makes the control process get automatic learning ability and achieve intelligent production so that we can provide a basis for solving the problem of predicting the end-point carbon content in molten steel during the blowing process.",
        "versions": [],
        "rank": 889
    },
    {
        "authors": [
            "Ahmed Hosny",
            "Chintan Parmar",
            "John Quackenbush",
            "Lawrence B. Schwartz",
            "Hugo J.W.L. Aerts"
        ],
        "title": "Artificial intelligence in radiology",
        "publication_date": "2018-08-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Nature Reviews Cancer",
        "volume": "18",
        "doi": "10.1038/s41568-018-0016-5",
        "urls": [
            "https://openalex.org/W2803760365",
            "https://doi.org/10.1038/s41568-018-0016-5",
            "https://europepmc.org/articles/pmc6268174?pdf=render"
        ],
        "id": "id-2673058848189409069",
        "abstract": "",
        "versions": [],
        "rank": 890
    },
    {
        "authors": [
            "Sai Ma",
            "Qingxiao Guan",
            "Xianfeng Zhao",
            "Yaqi Liu"
        ],
        "title": "Weakening the Detecting Capability of CNN-based Steganalysis",
        "publication_date": "2018-03-29 01:10:22+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1803.10889v1",
            "http://arxiv.org/abs/1803.10889v1",
            "http://arxiv.org/pdf/1803.10889v1"
        ],
        "id": "id-3832725862624553482",
        "abstract": "Recently, the application of deep learning in steganalysis has drawn many\nresearchers' attention. Most of the proposed steganalytic deep learning models\nare derived from neural networks applied in computer vision. These kinds of\nneural networks have distinguished performance. However, all these kinds of\nback-propagation based neural networks may be cheated by forging input named\nthe adversarial example. In this paper we propose a method to generate\nsteganographic adversarial example in order to enhance the steganographic\nsecurity of existing algorithms. These adversarial examples can increase the\ndetection error of steganalytic CNN. The experiments prove the effectiveness of\nthe proposed method.",
        "versions": [],
        "rank": 891
    },
    {
        "authors": [
            "Zehra KARHAN",
            "Fuat AKAL"
        ],
        "title": "Covid-19 Classification Using Deep Learning in Chest X-Ray Images",
        "publication_date": "2020-11-19 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "IEEE",
        "volume": "",
        "doi": "10.1109/tiptekno50054.2020.9299315",
        "urls": [
            "https://web.archive.org/web/20210428223410/https://ieeexplore.ieee.org/ielx7/9298896/9299212/09299315.pdf"
        ],
        "id": "id-2111235755761730273",
        "abstract": "Covid-19 virus, which has emerged in the Republic of China in an undetermined cause, has affected the whole world quickly. It is important to detect positive cases early to prevent further spread of the outbreak. In the diagnostic phase, radiological images of the chest are determinative as well as the RT-PCR (Reverse Transcription-Polymerase Chain Reaction) test. It was classified with the ResNet50 model, which is a convolutional neural network architecture in Covid-19 detection using chest x-ray images. Chest X-Ray image analysis can be done and infected individuals can be identified thanks to artificial intelligence quickly. The experimental results are encouraging in terms of the use of computer-aided in the field of pathology. It can also be used in situations where the possibilities and RT-PCR tests are insufficient.",
        "versions": [],
        "rank": 892
    },
    {
        "authors": [
            "Merve Turhan",
            "Ersin \u00d6zt\u00fcrk",
            "Hakan Ali \u00c7\u0131rpan"
        ],
        "title": "Deep Convolutional Learning-Aided Detector for Generalized Frequency Division Multiplexing with Index Modulation",
        "publication_date": "2022-02-06 22:18:42+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2202.02876v1",
            "http://arxiv.org/abs/2202.02876v1",
            "http://arxiv.org/pdf/2202.02876v1"
        ],
        "id": "id7295770096683865989",
        "abstract": "In this paper, a deep convolutional neural network-based symbol detection and\ndemodulation is proposed for generalized frequency division multiplexing with\nindex modulation (GFDM-IM) scheme in order to improve the error performance of\nthe system. The proposed method first pre-processes the received signal by\nusing a zero-forcing (ZF) detector and then uses a neural network consisting of\na convolutional neural network (CNN) followed by a fully-connected neural\nnetwork (FCNN). The FCNN part uses only two fully-connected layers, which can\nbe adapted to yield a trade-off between complexity and bit error rate (BER)\nperformance. This two-stage approach prevents the getting stuck of neural\nnetwork in a saddle point and enables IM blocks processing independently. It\nhas been demonstrated that the proposed deep convolutional neural network-based\ndetection and demodulation scheme provides better BER performance compared to\nZF detector with a reasonable complexity increase. We conclude that\nnon-orthogonal waveforms combined with IM schemes with the help of deep\nlearning is a promising physical layer (PHY) scheme for future wireless\nnetworks",
        "versions": [],
        "rank": 893
    },
    {
        "authors": [
            "Dincy Davis",
            "Reena Murali",
            "Remesh Babu"
        ],
        "title": "Abusive Language Detection and Characterization of Twitter Behavior",
        "publication_date": "2020-09-26 07:38:11+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": "International Journal of Computer Sciences and Engineering, Vol.8,\n  Issue.7, July 2020",
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2009.14261v1",
            "http://arxiv.org/abs/2009.14261v1",
            "http://arxiv.org/pdf/2009.14261v1"
        ],
        "id": "id436546919109055717",
        "abstract": "In this work, abusive language detection in online content is performed using\nBidirectional Recurrent Neural Network (BiRNN) method. Here the main objective\nis to focus on various forms of abusive behaviors on Twitter and to detect\nwhether a speech is abusive or not. The results are compared for various\nabusive behaviors in social media, with Convolutional Neural Netwrok (CNN) and\nRecurrent Neural Network (RNN) methods and proved that the proposed BiRNN is a\nbetter deep learning model for automatic abusive speech detection.",
        "versions": [],
        "rank": 894
    },
    {
        "authors": [
            "Campos, Victor",
            "Chang, Shih-Fu",
            "Fernandez, Delia",
            "Giro-i-Nieto, Xavier",
            "Jou, Brendan",
            "Woodward, Alejandro"
        ],
        "title": "More cat than cute? Interpretable Prediction of Adjective-Noun Pairs",
        "publication_date": "2017-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1145/3132515.3132520",
        "urls": [
            "http://arxiv.org/abs/1708.06039"
        ],
        "id": "id686692638882500761",
        "abstract": "The increasing availability of affect-rich multimedia resources has bolstered\ninterest in understanding sentiment and emotions in and from visual content.\nAdjective-noun pairs (ANP) are a popular mid-level semantic construct for\ncapturing affect via visually detectable concepts such as \"cute dog\" or\n\"beautiful landscape\". Current state-of-the-art methods approach ANP prediction\nby considering each of these compound concepts as individual tokens, ignoring\nthe underlying relationships in ANPs. This work aims at disentangling the\ncontributions of the `adjectives' and `nouns' in the visual prediction of ANPs.\nTwo specialised classifiers, one trained for detecting adjectives and another\nfor nouns, are fused to predict 553 different ANPs. The resulting ANP\nprediction model is more interpretable as it allows us to study contributions\nof the adjective and noun components. Source code and models are available at\nhttps://imatge-upc.github.io/affective-2017-musa2/ .Comment: Oral paper at ACM Multimedia 2017 Workshop on Multimodal\n  Understanding of Social, Affective and Subjective Attributes (MUSA2",
        "versions": [],
        "rank": 895
    },
    {
        "authors": [
            "Languang Lu",
            "Xuebing Han",
            "Jianqiu Li",
            "Jianfeng Hua",
            "Minggao Ouyang"
        ],
        "title": "A review on the key issues for lithium-ion battery management in electric vehicles",
        "publication_date": "2013-03-15 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Journal of Power Sources",
        "volume": "226",
        "doi": "10.1016/j.jpowsour.2012.10.060",
        "urls": [
            "https://openalex.org/W2079985616",
            "https://doi.org/10.1016/j.jpowsour.2012.10.060"
        ],
        "id": "id-8313844965545971852",
        "abstract": "",
        "versions": [],
        "rank": 896
    },
    {
        "authors": [
            "Gadre, Gayatri"
        ],
        "title": "Classification of Humans into Ayurvedic Prakruti Types using Computer Vision",
        "publication_date": "2019-05-22 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "https://core.ac.uk/download/215423277.pdf"
        ],
        "id": "id-5928779398393619088",
        "abstract": "Ayurveda, a 5000 years old Indian medical science, believes that the universe and hence humans are made up of five elements namely ether, fire, water, earth, and air. The three Doshas (Tridosha) Vata, Pitta, and Kapha originated from the combinations of these elements. Every person has a unique combination of Tridosha elements contributing to a person\u2019s \u2018Prakruti\u2019. Prakruti governs the physiological and psychological tendencies in all living beings as well as the way they interact with the environment. This balance influences their physiological features like the texture and colour of skin, hair, eyes, length of fingers, the shape of the palm, body frame, strength of digestion and many more as well as the psychological features like their nature (introverted, extroverted, calm, excitable, intense, laidback), and their reaction to stress and diseases. All these features are coded in the constituents at the time of a person\u2019s creation and do not change throughout their lifetime. Ayurvedic doctors analyze the Prakruti of a person either by assessing the physical features manually and/or by examining the nature of their heartbeat (pulse). Based on this analysis, they diagnose, prevent and cure the disease in patients by prescribing precision medicine.\nThis project focuses on identifying Prakruti of a person by analysing his facial features like hair, eyes, nose, lips and skin colour using facial recognition techniques in computer vision. This is the first of its kind research in this problem area that attempts to bring image processing into the domain of Ayurveda",
        "versions": [],
        "rank": 897
    },
    {
        "authors": [
            "Bai, Yunfei",
            "Fang, Kuan",
            "Hinterstoisser, Stefan",
            "Kalakrishnan, Mrinal",
            "Savarese, Silvio"
        ],
        "title": "Multi-Task Domain Adaptation for Deep Learning of Instance Grasping from  Simulation",
        "publication_date": "2018-03-03 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/icra.2018.8461041",
        "urls": [
            "http://arxiv.org/abs/1710.06422"
        ],
        "id": "id-7449259096052917415",
        "abstract": "Learning-based approaches to robotic manipulation are limited by the\nscalability of data collection and accessibility of labels. In this paper, we\npresent a multi-task domain adaptation framework for instance grasping in\ncluttered scenes by utilizing simulated robot experiments. Our neural network\ntakes monocular RGB images and the instance segmentation mask of a specified\ntarget object as inputs, and predicts the probability of successfully grasping\nthe specified object for each candidate motor command. The proposed transfer\nlearning framework trains a model for instance grasping in simulation and uses\na domain-adversarial loss to transfer the trained model to real robots using\nindiscriminate grasping data, which is available both in simulation and the\nreal world. We evaluate our model in real-world robot experiments, comparing it\nwith alternative model architectures as well as an indiscriminate grasping\nbaseline.Comment: ICRA 201",
        "versions": [],
        "rank": 898
    },
    {
        "authors": [
            "Dou, Pengfei",
            "Kakadiaris, Ioannis A.",
            "Shah, Shishir K."
        ],
        "title": "End-to-end 3D face reconstruction with deep neural networks",
        "publication_date": "2017-04-17 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/cvpr.2017.164",
        "urls": [
            "http://arxiv.org/abs/1704.05020"
        ],
        "id": "id-212001703855602298",
        "abstract": "Monocular 3D facial shape reconstruction from a single 2D facial image has\nbeen an active research area due to its wide applications. Inspired by the\nsuccess of deep neural networks (DNN), we propose a DNN-based approach for\nEnd-to-End 3D FAce Reconstruction (UH-E2FAR) from a single 2D image. Different\nfrom recent works that reconstruct and refine the 3D face in an iterative\nmanner using both an RGB image and an initial 3D facial shape rendering, our\nDNN model is end-to-end, and thus the complicated 3D rendering process can be\navoided. Moreover, we integrate in the DNN architecture two components, namely\na multi-task loss function and a fusion convolutional neural network (CNN) to\nimprove facial expression reconstruction. With the multi-task loss function, 3D\nface reconstruction is divided into neutral 3D facial shape reconstruction and\nexpressive 3D facial shape reconstruction. The neutral 3D facial shape is\nclass-specific. Therefore, higher layer features are useful. In comparison, the\nexpressive 3D facial shape favors lower or intermediate layer features. With\nthe fusion-CNN, features from different intermediate layers are fused and\ntransformed for predicting the 3D expressive facial shape. Through extensive\nexperiments, we demonstrate the superiority of our end-to-end framework in\nimproving the accuracy of 3D face reconstruction.Comment: Accepted to CVPR1",
        "versions": [],
        "rank": 899
    },
    {
        "authors": [
            "Nour Eldeen M. Khalifa",
            "Mohamed Hamed N. Taha",
            "Aboul Ella Hassanien, Sally Elghamrawy"
        ],
        "title": "Detection of Coronavirus (COVID-19) Associated Pneumonia based on Generative Adversarial Networks and a Fine-Tuned Deep Transfer Learning Model using Chest X-ray Dataset",
        "publication_date": "2020-04-02 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20200407010132/https://arxiv.org/ftp/arxiv/papers/2004/2004.01184.pdf"
        ],
        "id": "id-364413113529721206",
        "abstract": "The COVID-19 coronavirus is one of the devastating viruses according to the world health organization. This novel virus leads to pneumonia, which is an infection that inflames the lungs' air sacs of a human. One of the methods to detect those inflames is by using x-rays for the chest. In this paper, a pneumonia chest x-ray detection based on generative adversarial networks (GAN) with a fine-tuned deep transfer learning for a limited dataset will be presented. The use of GAN positively affects the proposed model robustness and made it immune to the overfitting problem and helps in generating more images from the dataset. The dataset used in this research consists of 5863 X-ray images with two categories: Normal and Pneumonia. This research uses only 10% of the dataset for training data and generates 90% of images using GAN to prove the efficiency of the proposed model. Through the paper, AlexNet, GoogLeNet, Squeeznet, and Resnet18 are selected as deep transfer learning models to detect the pneumonia from chest x-rays. Those models are selected based on their small number of layers on their architectures, which will reflect in reducing the complexity of the models and the consumed memory and time. Using a combination of GAN and deep transfer models proved it is efficiency according to testing accuracy measurement. The research concludes that the Resnet18 is the most appropriate deep transfer model according to testing accuracy measurement and achieved 99% with the other performance metrics such as precision, recall, and F1 score while using GAN as an image augmenter. Finally, a comparison result was carried out at the end of the research with related work which used the same dataset except that this research used only 10% of original dataset. The presented work achieved a superior result than the related work in terms of testing accuracy.",
        "versions": [],
        "rank": 900
    },
    {
        "authors": [
            "Wei Yin",
            "Hanjin Wen",
            "Zheng Ning",
            "Jian Ye",
            "Zhiqiang Dong",
            "Lufeng Luo"
        ],
        "title": "Fruit Detection and Pose Estimation for Grape Cluster\u2013Harvesting Robot Using Binocular Imagery Based on Deep Neural Networks",
        "publication_date": "2021-06-22 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Frontiers in Robotics and AI",
        "volume": "8",
        "doi": "10.3389/frobt.2021.626989",
        "urls": [
            "https://www.semanticscholar.org/paper/8cad251fc7e6738866cbb8621a3713f4ebc62b7c"
        ],
        "id": "id-8856838968617878563",
        "abstract": "Reliable and robust fruit-detection algorithms in nonstructural environments are essential for the efficient use of harvesting robots. The pose of fruits is crucial to guide robots to approach target fruits for collision-free picking. To achieve accurate picking, this study investigates an approach to detect fruit and estimate its pose. First, the state-of-the-art mask region convolutional neural network (Mask R-CNN) is deployed to segment binocular images to output the mask image of the target fruit. Next, a grape point cloud extracted from the images was filtered and denoised to obtain an accurate grape point cloud. Finally, the accurate grape point cloud was used with the RANSAC algorithm for grape cylinder model fitting, and the axis of the cylinder model was used to estimate the pose of the grape. A dataset was acquired in a vineyard to evaluate the performance of the proposed approach in a nonstructural environment. The fruit detection results of 210 test images show that the average precision, recall, and intersection over union (IOU) are 89.53, 95.33, and 82.00%, respectively. The detection and point cloud segmentation for each grape took approximately 1.7 s. The demonstrated performance of the developed method indicates that it can be applied to grape-harvesting robots.",
        "versions": [],
        "rank": 901
    },
    {
        "authors": [
            "S. R\u00fcger",
            "M. Firsching",
            "J. Lucic",
            "Alexander Ennen",
            "N. Uhlmann",
            "T. Wittenberg"
        ],
        "title": "Automated detection of bone splinters in DEXA phantoms using deep neural networks",
        "publication_date": "2019-09-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Current Directions in Biomedical Engineering",
        "volume": "5",
        "doi": "10.1515/cdbme-2019-0071",
        "urls": [
            "https://www.semanticscholar.org/paper/f5941f7b62c79fd9d6972665e002add31bc6504d"
        ],
        "id": "id6814264149945217747",
        "abstract": "Abstract Dual energy radiographic imaging is a method to provide material information and can be used to differentiate between various tissue types. Dual energy X-ray absorption (DEXA) can be applied for breast density, osteoporosis or bone fracture analysis. To support radiologists with the assessment of DEXA images, machine learning can be applied. Specifically, deep convolutional neural networks (DCNNs) can be used for medical image analysis. In this work a DCNN is proposed and evaluated for automated detection of bone splinters in DEXA phantom images. The image data consists of 47 phantoms with (35) and without (12) bone splinters. Material decomposition and energy weighting results in additional image channels. Various DCNN architectures and parameters were explored. A classification rate in regions with 90 % and without 99 % bone splinters was achieved.",
        "versions": [],
        "rank": 902
    },
    {
        "authors": [
            "Fox, Dieter",
            "Schenck, Connor"
        ],
        "title": "Visual Closed-Loop Control for Pouring Liquids",
        "publication_date": "2017-02-25 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/icra.2017.7989307",
        "urls": [
            "http://arxiv.org/abs/1610.02610"
        ],
        "id": "id2852506504868054417",
        "abstract": "Pouring a specific amount of liquid is a challenging task. In this paper we\ndevelop methods for robots to use visual feedback to perform closed-loop\ncontrol for pouring liquids. We propose both a model-based and a model-free\nmethod utilizing deep learning for estimating the volume of liquid in a\ncontainer. Our results show that the model-free method is better able to\nestimate the volume. We combine this with a simple PID controller to pour\nspecific amounts of liquid, and show that the robot is able to achieve an\naverage 38ml deviation from the target amount. To our knowledge, this is the\nfirst use of raw visual feedback to pour liquids in robotics.Comment: To appear at ICRA 201",
        "versions": [],
        "rank": 903
    },
    {
        "authors": [
            "Qian Wang",
            "Toby P. Breckon"
        ],
        "title": "Contraband Materials Detection Within Volumetric 3D Computed Tomography Baggage Security Screening Imagery",
        "publication_date": "2020-12-21 23:48:06+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2012.11753v1",
            "http://arxiv.org/abs/2012.11753v1",
            "http://arxiv.org/pdf/2012.11753v1"
        ],
        "id": "id-8477092640105898621",
        "abstract": "Automatic prohibited object detection within 2D/3D X-ray Computed Tomography\n(CT) has been studied in literature to enhance the aviation security screening\nat checkpoints. Deep Convolutional Neural Networks (CNN) have demonstrated\nsuperior performance in 2D X-ray imagery. However, there exists very limited\nproof of how deep neural networks perform in materials detection within\nvolumetric 3D CT baggage screening imagery. We attempt to close this gap by\napplying Deep Neural Networks in 3D contraband substance detection based on\ntheir material signatures. Specifically, we formulate it as a 3D semantic\nsegmentation problem to identify material types for all voxels based on which\ncontraband materials can be detected. To this end, we firstly investigate 3D\nCNN based semantic segmentation algorithms such as 3D U-Net and its variants.\nIn contrast to the original dense representation form of volumetric 3D CT data,\nwe propose to convert the CT volumes into sparse point clouds which allows the\nuse of point cloud processing approaches such as PointNet++ towards more\nefficient processing. Experimental results on a publicly available dataset (NEU\nATR) demonstrate the effectiveness of both 3D U-Net and PointNet++ in materials\ndetection in 3D CT imagery for baggage security screening.",
        "versions": [],
        "rank": 904
    },
    {
        "authors": [
            "Wenquan Shi",
            "Qibao Huang",
            "Kehui Sun"
        ],
        "title": "The Blockchain Technology Applied in the Development of Real Economy in Jiangsu under Deep Learning",
        "publication_date": "2022-05-06 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Hindawi Limited",
        "volume": "",
        "doi": "10.1155/2022/3088043",
        "urls": [
            "https://web.archive.org/web/20220508143741/https://downloads.hindawi.com/journals/cin/2022/3088043.pdf"
        ],
        "id": "id6133265108308951542",
        "abstract": "This study focuses on the financing difficulties of small and medium enterprises (SMEs) in China to study the application of blockchain technology in developing the real economy. Deep learning neural network is applied to the vulnerability analysis and detection of smart contracts in blockchain technology by analyzing the connotation of blockchain technology and deep learning. A multiparty joint financial service platform based on blockchain technology is established to help SMEs financing institutions reduce transaction costs, thereby helping them reduce loan interest rates. Finally, Jiangsu Province is studied as a pilot unit. The results show that the Recall and F-score of Bidirectional Neural Network for smart contract vulnerability detection are higher than those of the original neural network. The Recall rate and F-score value of the Wide and Deep model are up to 96.2% and 94.7%, which are higher than those of other vulnerability detection schemes. The Timestamp vulnerability has the highest Recall rate, 94.2%, which can rely on a large amount of valid data to improve detection efficiency. The distribution of financing needs of SMEs in Jiangsu Province from 2020 to 2021 shows that the loan number of SMEs is generally not high. Still, financial institutions and enterprises must spend the same transaction cost. After a technology company in Nanjing made a loan through a blockchain financial service platform, its financing cost decreased by 0.5331%. Blockchain technology has played a great role in the financing process of SMEs, reducing intermediate links and credit costs, and promoting the development of SMEs and the real economy.",
        "versions": [],
        "rank": 905
    },
    {
        "authors": [
            "Zhenyu Yang",
            "Xiaoling Zhang",
            "Xu Zhan"
        ],
        "title": "Complicated Background Suppression of ViSAR Image For Moving Target Shadow Detection",
        "publication_date": "2022-09-21 15:26:42+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "10.1109/IGARSS46834.2022.9883465",
        "urls": [
            "http://arxiv.org/pdf/2209.10431v1",
            "http://dx.doi.org/10.1109/IGARSS46834.2022.9883465",
            "http://arxiv.org/abs/2209.10431v1",
            "http://arxiv.org/pdf/2209.10431v1"
        ],
        "id": "id-1722042385491570232",
        "abstract": "The existing Video Synthetic Aperture Radar (ViSAR) moving target shadow\ndetection methods based on deep neural networks mostly generate numerous false\nalarms and missing detections, because of the foreground-background\nindistinguishability. To solve this problem, we propose a method to suppress\ncomplicated background of ViSAR for moving target detection. In this work, the\nproposed method is used to suppress background; then, we use several target\ndetection networks to detect the moving target shadows. The experimental result\nshows that the proposed method can effectively suppress the interference of\ncomplicated back-ground information and improve the accuracy of moving target\nshadow detection in ViSAR. The existing Video Synthetic Aperture Radar (ViSAR)\nmoving target shadow detection methods based on deep neural networks mostly\ngenerate numerous false alarms and missing detections, because of the\nforeground-background indistinguishability. To solve this problem, we propose a\nmethod to suppress complicated background of ViSAR for moving target detection.\nIn this work, the proposed method is used to suppress background; then, we use\nseveral target detection networks to detect the moving target shadows. The\nexperimental result shows that the proposed method can effectively suppress the\ninterference of complicated back-ground information and improve the accuracy of\nmoving target shadow detection in ViSAR.",
        "versions": [],
        "rank": 906
    },
    {
        "authors": [],
        "title": "Dynamic Resource Allocation and Memory Management using Deep Convolutional Neural Network",
        "publication_date": "2019-12-30 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "Blue Eyes Intelligence Engineering and Sciences Engineering and Sciences Publication - BEIESP",
        "volume": "",
        "doi": "10.35940/ijeat.a9961.129219",
        "urls": [
            "https://web.archive.org/web/20200107014558/https://www.ijeat.org/wp-content/uploads/papers/v9i2/A9961109119.pdf"
        ],
        "id": "id-3173342428170512936",
        "abstract": "Memory management is very essential task for large-scale storage systems; in mobile platform generate storage errors due to insufficient memory as well as additional task overhead. Many existing systems have illustrated different solution for such issues, like load balancing and load rebalancing. Different unusable applications which are already installed in mobile platform user never access frequently but it allocates some memory space on hard device storage. In the proposed research work we describe dynamic resource allocation for mobile platforms using deep learning approach. In Real world mobile systems users may install different kind of applications which required ad-hoc basis. Such applications may be affect to execution performance of system as well space complexity, sometime they also affect another runnable applications performance. To eliminate of such issues, we carried out an approach to allocate runtime resources for data storage for mobile platform. When system connected with cloud data server it store complete file system on remote Virtual Machine (VM) and whenever a single application required which immediately install beginning as remote server to local device. For developed of proposed system we implemented deep learning base Convolutional Neural Network (CNN), algorithm has used with tensorflow environment which reduces the time complexity for data storage as well as extraction respectively.",
        "versions": [],
        "rank": 907
    },
    {
        "authors": [
            "H. O'Brien",
            "J. Whitaker",
            "Baldeep Singh Sidhu",
            "J. Gould",
            "T. Kurzendorfer",
            "M. O'Neill",
            "R. Rajani",
            "K. Grigoryan",
            "C. Rinaldi",
            "Jonathan Taylor",
            "K. Rhode",
            "P. Mountney",
            "S. Niederer"
        ],
        "title": "Automated Left Ventricle Ischemic Scar Detection in CT Using Deep Neural Networks",
        "publication_date": "2021-07-02 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Frontiers in Cardiovascular Medicine",
        "volume": "8",
        "doi": "10.3389/fcvm.2021.655252",
        "urls": [
            "https://www.semanticscholar.org/paper/50a0bc666b4a8c89f16d01cd17ef14296081be8a"
        ],
        "id": "id2733623125837868576",
        "abstract": "Objectives: The aim of this study is to develop a scar detection method for routine computed tomography angiography (CTA) imaging using deep convolutional neural networks (CNN), which relies solely on anatomical information as input and is compatible with existing clinical workflows. Background: Identifying cardiac patients with scar tissue is important for assisting diagnosis and guiding interventions. Late gadolinium enhancement (LGE) magnetic resonance imaging (MRI) is the gold standard for scar imaging; however, there are common instances where it is contraindicated. CTA is an alternative imaging modality that has fewer contraindications and is faster than Cardiovascular magnetic resonance imaging but is unable to reliably image scar. Methods: A dataset of LGE MRI (200 patients, 83 with scar) was used to train and validate a CNN to detect ischemic scar slices using segmentation masks as input to the network. MRIs were segmented to produce 3D left ventricle meshes, which were sampled at points along the short axis to extract anatomical masks, with scar labels from LGE as ground truth. The trained CNN was tested with an independent CTA dataset (25 patients, with ground truth established with paired LGE MRI). Automated segmentation was performed to provide the same input format of anatomical masks for the network. The CNN was compared against manual reading of the CTA dataset by 3 experts. Results: Note that 84.7% cross-validated accuracy (AUC: 0.896) for detecting scar slices in the left ventricle on the MRI data was achieved. The trained network was tested against the CTA-derived data, with no further training, where it achieved an 88.3% accuracy (AUC: 0.901). The automated pipeline outperformed the manual reading by clinicians. Conclusion: Automatic ischemic scar detection can be performed from a routine cardiac CTA, without any scar-specific imaging or contrast agents. This requires only a single acquisition in the cardiac cycle. In a clinical setting, with near zero additional cost, scar presence could be detected to triage images, reduce reading times, and guide clinical decision-making.",
        "versions": [],
        "rank": 908
    },
    {
        "authors": [
            "Julieta Martinez",
            "Rayat Hossain",
            "Javier Romero",
            "James J. Little"
        ],
        "title": "A Simple Yet Effective Baseline for 3d Human Pose Estimation",
        "publication_date": "2017-05-08 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "International Conference on Computer Vision",
        "volume": "",
        "doi": "10.1109/iccv.2017.288",
        "urls": [
            "https://openalex.org/W2612706635",
            "https://doi.org/10.1109/iccv.2017.288",
            "http://arxiv.org/pdf/1705.03098"
        ],
        "id": "id-6040149537739725328",
        "abstract": "",
        "versions": [],
        "rank": 909
    },
    {
        "authors": [
            "Quanzhi An",
            "Zongxu Pan",
            "Hongjian You"
        ],
        "title": "Ship Detection in Gaofen-3 SAR Images Based on Sea Clutter Distribution Analysis and Deep Convolutional Neural Network",
        "publication_date": "2018-01-24 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "MDPI AG",
        "volume": "",
        "doi": "10.3390/s18020334",
        "urls": [
            "https://web.archive.org/web/20180729103940/https://res.mdpi.com/def502005f2f353c172b73ab5259ca16c10e9f3095983c10e6fa5c491b279ee430dca630d25e83275d9be116e28975dcfe3f2632c2abf79bd4e6e845e26a8cb65b8096ce4c381a5ff06363dd589283b1186f226fd1d9e5dfe936e2146dd08a6a7452f63f4409443f2a132b64f883a73406337f02269110490f6a88e1f610a34dc9fc6324367f82321a120d1aabcf98d6?filename=&attachment=1"
        ],
        "id": "id6700895167963538792",
        "abstract": "Target detection is one of the important applications in the field of remote sensing. The Gaofen-3 (GF-3) Synthetic Aperture Radar (SAR) satellite launched by China is a powerful tool for maritime monitoring. This work aims at detecting ships in GF-3 SAR images using a new land masking strategy, the appropriate model for sea clutter and a neural network as the discrimination scheme. Firstly, the fully convolutional network (FCN) is applied to separate the sea from the land. Then, by analyzing the sea clutter distribution in GF-3 SAR images, we choose the probability distribution model of Constant False Alarm Rate (CFAR) detector from K-distribution, Gamma distribution and Rayleigh distribution based on a tradeoff between the sea clutter modeling accuracy and the computational complexity. Furthermore, in order to better implement CFAR detection, we also use truncated statistic (TS) as a preprocessing scheme and iterative censoring scheme (ICS) for boosting the performance of detector. Finally, we employ a neural network to re-examine the results as the discrimination stage. Experiment results on three GF-3 SAR images verify the effectiveness and efficiency of this approach.",
        "versions": [],
        "rank": 910
    },
    {
        "authors": [
            "Christopher D. Fjell",
            "Jan A. Hiss",
            "Robert E. W. Hancock",
            "Gisbert Schneider"
        ],
        "title": "Designing antimicrobial peptides: form follows function",
        "publication_date": "2012-01-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Nature Reviews Drug Discovery",
        "volume": "11",
        "doi": "10.1038/nrd3591",
        "urls": [
            "https://openalex.org/W2097099115",
            "https://doi.org/10.1038/nrd3591",
            "https://www.nature.com/articles/nrd3591.pdf"
        ],
        "id": "id6582429823380349068",
        "abstract": "",
        "versions": [],
        "rank": 911
    },
    {
        "authors": [
            "Gehler, Peter V.",
            "Lassner, Christoph",
            "Pons-Moll, Gerard"
        ],
        "title": "A Generative Model of People in Clothing",
        "publication_date": "2017-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/iccv.2017.98",
        "urls": [
            "http://arxiv.org/abs/1705.04098"
        ],
        "id": "id8795659025077971750",
        "abstract": "We present the first image-based generative model of people in clothing for\nthe full body. We sidestep the commonly used complex graphics rendering\npipeline and the need for high-quality 3D scans of dressed people. Instead, we\nlearn generative models from a large image database. The main challenge is to\ncope with the high variance in human pose, shape and appearance. For this\nreason, pure image-based approaches have not been considered so far. We show\nthat this challenge can be overcome by splitting the generating process in two\nparts. First, we learn to generate a semantic segmentation of the body and\nclothing. Second, we learn a conditional model on the resulting segments that\ncreates realistic images. The full model is differentiable and can be\nconditioned on pose, shape or color. The result are samples of people in\ndifferent clothing items and styles. The proposed model can generate entirely\nnew people with realistic clothing. In several experiments we present\nencouraging results that suggest an entirely data-driven approach to people\ngeneration is possible",
        "versions": [],
        "rank": 912
    },
    {
        "authors": [
            "Alex Chortos",
            "Jia Liu",
            "Zhenan Bao"
        ],
        "title": "Pursuing prosthetic electronic skin",
        "publication_date": "2016-09-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Nature Materials",
        "volume": "15",
        "doi": "10.1038/nmat4671",
        "urls": [
            "https://openalex.org/W2468965001",
            "https://doi.org/10.1038/nmat4671"
        ],
        "id": "id4642168524580432011",
        "abstract": "",
        "versions": [],
        "rank": 913
    },
    {
        "authors": [
            "Jihwan Youn",
            "Ben Luijten",
            "Matthias Bo Stuart",
            "Yonina C. Eldar",
            "Ruud J. G. van Sloun",
            "Jorgen Arendt Jensen"
        ],
        "title": "Deep Learning Models for Fast Ultrasound Localization Microscopy",
        "publication_date": "2020-09-07 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "IEEE",
        "volume": "",
        "doi": "10.1109/ius46767.2020.9251561",
        "urls": [
            "https://web.archive.org/web/20210427152324/https://backend.orbit.dtu.dk/ws/files/220706421/main_3_.pdf"
        ],
        "id": "id4805180967451587230",
        "abstract": "Ultrasound localization microscopy (ULM) can surpass the resolution limit of conventional ultrasound imaging. However, a trade-off between resolution and data acquisition time is introduced. For microbubble (MB) localization, centroid detection is commonly used. Therefore, low-concentrations of MBs are required to avoid overlapping point spread functions (PSFs), leading to a long data acquisition time due to the limited number of detectable MBs in an image frame. Recently, deep learning-based MB localization methods across high-concentration regimes have been proposed to shorten the data acquisition time. In this work, a data-driven encoderdecoder convolutional neural network (deep-ULM) and a modelbased deep unfolded network embedding a sparsity prior (deep unfolded ULM) are analyzed in terms of localization accuracy and computational complexity. The results of simulated test data showed that both deep learning methods could handle overlapping PSFs better than centroid detection. Additionally, thanks to its model-based approach, deep unfolded ULM needed much fewer learning parameters and was computationally more efficient, and consequently achieved better generalizability than deep-ULM. It is expected that deep unfolded ULM will be more robust in-vivo. Index Terms-deep unfolded network, high-concentration microbubble localization, model-based neural network, superresolution ultrasound imaging, ultrasound localization microscopy",
        "versions": [],
        "rank": 914
    }
]