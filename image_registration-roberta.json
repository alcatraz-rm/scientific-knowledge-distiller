[
    {
        "authors": [
            "Srikanchana, R.",
            "Xuan, J.",
            "Freedman, M.",
            "Nguyen, C.",
            "Wang, Y."
        ],
        "title": "Non-Rigid Image Registration by Neural Computation",
        "publication_date": "2004-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1023/b:vlsi.0000027488.23703.ba",
        "urls": [
            "http://dx.doi.org/10.1023/b:vlsi.0000027488.23703.ba"
        ],
        "id": "id-8256384533610082667",
        "abstract": "",
        "versions": [
            {
                "year": 2001,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Non-Rigid Image Registration by Neural Computation",
                "journal": "Journal of VLSI signal processing systems for signal, image and video technology",
                "urls": [
                    "https://www.semanticscholar.org/paper/13055d3a9c64aace891f593015ed0e392fbc9f90"
                ],
                "doi": "10.1023/B:VLSI.0000027488.23703.ba",
                "publication_date": "2001-09-10 00:00:00"
            }
        ],
        "rank": 0
    },
    {
        "authors": [
            "Elizabeth McKenzie"
        ],
        "title": "A Neural Network Approach to Deformable Image Registration",
        "publication_date": "None",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://www.semanticscholar.org/paper/05a25d08a3118d65237b5d9c50dc9f4bd215498a"
        ],
        "id": "id-4999663628602917250",
        "abstract": null,
        "versions": [],
        "rank": 1
    },
    {
        "authors": [
            "Caianiello, E.",
            "Petrosino, A."
        ],
        "title": "Neural Networks, Fuzziness and Image Processing",
        "publication_date": "1994-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-1-4899-1004-2_23",
        "urls": [
            "http://link.springer.com/content/pdf/10.1007/978-1-4899-1004-2_23",
            "http://dx.doi.org/10.1007/978-1-4899-1004-2_23"
        ],
        "id": "id-9054195883035656962",
        "abstract": "",
        "versions": [
            {
                "year": 0,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Neural Networks, Fuzziness and Image Processing",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/05c2b7a2f927f9e619b4d06860a2e47ae70dd86f"
                ],
                "doi": "10.1007/978-1-4899-1004-2_23",
                "publication_date": "None"
            }
        ],
        "rank": 2
    },
    {
        "authors": [
            "\u6731\u6bc5"
        ],
        "title": "Image recognition method based on convolutional neural network in non-finite category",
        "publication_date": "2014-09-23 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://www.semanticscholar.org/paper/eb44e1381f9b684108727eda0c50a3888a535093"
        ],
        "id": "id-3799883969887607094",
        "abstract": "The invention discloses an image recognition method based on a convolutional neural network in a non-finite category. The method includes the steps of model training, data registration and match recognition, wherein in the model training process, a training sample is input in a convolutional neural network model, the error of a binary code of an output layer and a category binary code of the sample is calculated, and parameters of the model are adjusted; in the data registration process, sample images needing to be registered are input in the convolutional neural network model, and an output result of a hidden layer before the output layer serves as a feature vector and is stored; in the match recognition process, matches to be recognized are input in the convolutional neural network, an output result of the hidden layer before the output layer serves as a feature vector, the feature vector is matched with the registered feature vector, and therefore a match recognition judgment result is acquired.",
        "versions": [],
        "rank": 3
    },
    {
        "authors": [
            "Mitchell, R."
        ],
        "title": "Artificial neural networks for image understanding",
        "publication_date": "1994-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1016/0262-8856(94)90045-0",
        "urls": [
            "https://api.elsevier.com/content/article/PII:0262885694900450?httpAccept=text/xml",
            "https://api.elsevier.com/content/article/PII:0262885694900450?httpAccept=text/plain",
            "http://dx.doi.org/10.1016/0262-8856(94)90045-0"
        ],
        "id": "id-560992950318723340",
        "abstract": "",
        "versions": [
            {
                "year": 1994,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Artificial neural networks for image understanding",
                "journal": "Image Vis. Comput.",
                "urls": [
                    "https://www.semanticscholar.org/paper/ef1d2465c592851eb1edf4e09cf329e394e71ed3"
                ],
                "doi": "10.1016/0262-8856(94)90045-0",
                "publication_date": "1994-12-01 00:00:00"
            }
        ],
        "rank": 4
    },
    {
        "authors": [
            "Sipes, S."
        ],
        "title": "Image quality reconstruction with neural networks",
        "publication_date": "None",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.31979/etd.368v-gxbd",
        "urls": [
            "https://scholarworks.sjsu.edu/cgi/viewcontent.cgi?article=3155&amp;context=etd_theses&amp;unstamped=1",
            "http://dx.doi.org/10.31979/etd.368v-gxbd"
        ],
        "id": "id2299501148617465711",
        "abstract": "",
        "versions": [
            {
                "year": 0,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Image quality reconstruction with neural networks",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/b0eb39d9cef712a3d5c501686d582988f99abc98",
                    "https://scholarworks.sjsu.edu/cgi/viewcontent.cgi?article=3155&context=etd_theses"
                ],
                "doi": "10.31979/etd.368v-gxbd",
                "publication_date": "None"
            }
        ],
        "rank": 5
    },
    {
        "authors": [
            "Dinh-Luan Nguyen",
            "Vinh-Tiep Nguyen",
            "M. Tran",
            "A. Yoshitaka"
        ],
        "title": "Deep Convolutional Neural Network in Deformable Part Models for Face Detection",
        "publication_date": "2015-11-25 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-3-319-29451-3_53",
        "urls": [
            "https://www.semanticscholar.org/paper/f94f366ce14555cf0d5d34248f9467c18241c3ee"
        ],
        "id": "id-8740457534809418428",
        "abstract": null,
        "versions": [],
        "rank": 6
    },
    {
        "authors": [
            "Qi Zhang",
            "Jingyu Xiao",
            "Chunwei Tian",
            "Jerry Chun-Wei Lin",
            "Shichao Zhang"
        ],
        "title": "A robust deformed convolutional neural network (CNN) for image denoising",
        "publication_date": "2022-06-15 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1049/cit2.12110",
        "urls": [
            "https://www.semanticscholar.org/paper/c6daaf1c5edb1d31833cecea91cac207b9322e4c"
        ],
        "id": "id-8998031950523756413",
        "abstract": null,
        "versions": [],
        "rank": 7
    },
    {
        "authors": [
            "Murino, V.",
            "Vernazza, G."
        ],
        "title": "Artificial Neural Networks for Image Analysis and Computer Vision",
        "publication_date": "2001-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1016/s0262-8856(00)00112-8",
        "urls": [
            "https://api.elsevier.com/content/article/PII:S0262885600001128?httpAccept=text/xml",
            "https://api.elsevier.com/content/article/PII:S0262885600001128?httpAccept=text/plain",
            "http://dx.doi.org/10.1016/s0262-8856(00)00112-8"
        ],
        "id": "id-6659661837307814576",
        "abstract": "",
        "versions": [
            {
                "year": 2001,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Artificial Neural Networks for Image Analysis and Computer Vision",
                "journal": "Image Vis. Comput.",
                "urls": [
                    "https://www.semanticscholar.org/paper/c87cabf4120c5a84d9d98c266c214e64610664cd"
                ],
                "doi": "10.1016/S0262-8856(00)00112-8",
                "publication_date": "2001-08-01 00:00:00"
            }
        ],
        "rank": 8
    },
    {
        "authors": [
            "Yao Su",
            "Xin Dai",
            "Lifang He",
            "Xiangnan Kong"
        ],
        "title": "ABN: Anti-Blur Neural Networks for Multi-Stage Deformable Image Registration",
        "publication_date": "2022-11-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ICDM54844.2022.00057",
        "urls": [
            "https://www.semanticscholar.org/paper/605555cf258d1582d774f85e3089da646eab40de"
        ],
        "id": "id4100349577142513781",
        "abstract": "Deformable image registration, i.e., the task of aligning multiple images into one coordinate system by non-linear transformation, serves as an essential preprocessing step for neuroimaging data. Recent research on deformable image registration is mainly focused on improving the registration accuracy using multi-stage alignment methods, where the source image is repeatedly deformed in stages by a same neural network until it is well-aligned with the target image. Conventional methods for multi-stage registration can often blur the source image as the pixel/voxel values are repeatedly interpolated from the image generated by the previous stage. However, maintaining image quality such as sharpness during image registration is crucial to medical data analysis. In this paper, we study the problem of anti-blur deformable image registration and propose a novel solution, called Anti-Blur Network (ABN), for multi-stage image registration. Specifically, we use a pair of short-term registration and long-term memory networks to learn the nonlinear deformations at each stage, where the short-term registration network learns how to improve the registration accuracy incrementally and the long-term memory network combines all the previous deformations to allow an interpolation to perform on the raw image directly and preserve image sharpness. Extensive experiments on both natural and medical image datasets demonstrated that ABN can accurately register images while preserving their sharpness.",
        "versions": [
            {
                "year": 2022,
                "source": "SupportedSources.CROSSREF",
                "title": "ABN: Anti-Blur Neural Networks for Multi-Stage Deformable Image Registration",
                "journal": "",
                "urls": [
                    "http://xplorestaging.ieee.org/ielx7/10027565/10027596/10027782.pdf?arnumber=10027782",
                    "http://dx.doi.org/10.1109/icdm54844.2022.00057"
                ],
                "doi": "10.1109/icdm54844.2022.00057",
                "publication_date": "2022-01-01 00:00:00"
            }
        ],
        "rank": 9
    },
    {
        "authors": [
            "Yao Su",
            "Xin Dai",
            "Lifang He",
            "Xiangnan Kong"
        ],
        "title": "ABN: Anti-Blur Neural Networks for Multi-Stage Deformable Image Registration",
        "publication_date": "2022-12-06 19:21:43+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "10.1109/ICDM54844.2022.00057",
        "urls": [
            "http://arxiv.org/pdf/2212.03277v1",
            "http://dx.doi.org/10.1109/ICDM54844.2022.00057",
            "http://arxiv.org/abs/2212.03277v1",
            "http://arxiv.org/pdf/2212.03277v1"
        ],
        "id": "id4333930918092383599",
        "abstract": "Deformable image registration, i.e., the task of aligning multiple images\ninto one coordinate system by non-linear transformation, serves as an essential\npreprocessing step for neuroimaging data. Recent research on deformable image\nregistration is mainly focused on improving the registration accuracy using\nmulti-stage alignment methods, where the source image is repeatedly deformed in\nstages by a same neural network until it is well-aligned with the target image.\nConventional methods for multi-stage registration can often blur the source\nimage as the pixel/voxel values are repeatedly interpolated from the image\ngenerated by the previous stage. However, maintaining image quality such as\nsharpness during image registration is crucial to medical data analysis. In\nthis paper, we study the problem of anti-blur deformable image registration and\npropose a novel solution, called Anti-Blur Network (ABN), for multi-stage image\nregistration. Specifically, we use a pair of short-term registration and\nlong-term memory networks to learn the nonlinear deformations at each stage,\nwhere the short-term registration network learns how to improve the\nregistration accuracy incrementally and the long-term memory network combines\nall the previous deformations to allow an interpolation to perform on the raw\nimage directly and preserve image sharpness. Extensive experiments on both\nnatural and medical image datasets demonstrated that ABN can accurately\nregister images while preserving their sharpness. Our code and data can be\nfound at https://github.com/anonymous3214/ABN",
        "versions": [
            {
                "year": 2022,
                "source": "SupportedSources.PAPERS_WITH_CODE",
                "title": "ABN: Anti-Blur Neural Networks for Multi-Stage Deformable Image Registration",
                "journal": "",
                "urls": [
                    "https://arxiv.org/pdf/2212.03277v1.pdf",
                    "https://github.com/anonymous3214/abn"
                ],
                "doi": "",
                "publication_date": "2022-12-06 00:00:00"
            },
            {
                "year": 2022,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "ABN: Anti-Blur Neural Networks for Multi-Stage Deformable Image Registration",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/605555cf258d1582d774f85e3089da646eab40de"
                ],
                "doi": "10.1109/ICDM54844.2022.00057",
                "publication_date": "2022-11-01 00:00:00"
            }
        ],
        "rank": 10
    },
    {
        "authors": [
            "Swarnendu Ghosh",
            "Nibaran Das",
            "Mita Nasipuri"
        ],
        "title": "Reshaping inputs for convolutional neural network: Some common and uncommon methods",
        "publication_date": "2019-09-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Pattern Recognition",
        "volume": "93",
        "doi": "10.1016/j.patcog.2019.04.009",
        "urls": [
            "https://openalex.org/W2937557681",
            "https://doi.org/10.1016/j.patcog.2019.04.009"
        ],
        "id": "id4072638055681755437",
        "abstract": "",
        "versions": [
            {
                "year": 2019,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Reshaping inputs for convolutional neural network: Some common and uncommon methods",
                "journal": "Pattern Recognit.",
                "urls": [
                    "https://www.semanticscholar.org/paper/9b829f6dc95b619107fa294a26bcbb3c8eba0e06"
                ],
                "doi": "10.1016/J.PATCOG.2019.04.009",
                "publication_date": "2019-09-01 00:00:00"
            }
        ],
        "rank": 11
    },
    {
        "authors": [
            "D. Banarse",
            "A. Duller"
        ],
        "title": "Vision Experiments with Neural Deformable Template Matching",
        "publication_date": "1997-04-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Neural Processing Letters",
        "volume": "5",
        "doi": "10.1023/A:1009661908220",
        "urls": [
            "https://www.semanticscholar.org/paper/d8e75a9c1660780637a5884adae96cec85a61127"
        ],
        "id": "id4082596148915485590",
        "abstract": null,
        "versions": [],
        "rank": 12
    },
    {
        "authors": [
            "Zhuo Chen",
            "Weisi Lin",
            "Shiqi Wang",
            "Long Xu",
            "Leida Li"
        ],
        "title": "Image Quality Assessment Guided Deep Neural Networks Training",
        "publication_date": "2017-08-13 09:51:07+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1708.03880v1",
            "http://arxiv.org/abs/1708.03880v1",
            "http://arxiv.org/pdf/1708.03880v1"
        ],
        "id": "id-3670369933128297741",
        "abstract": "For many computer vision problems, the deep neural networks are trained and\nvalidated based on the assumption that the input images are pristine (i.e.,\nartifact-free). However, digital images are subject to a wide range of\ndistortions in real application scenarios, while the practical issues regarding\nimage quality in high level visual information understanding have been largely\nignored. In this paper, in view of the fact that most widely deployed deep\nlearning models are susceptible to various image distortions, the distorted\nimages are involved for data augmentation in the deep neural network training\nprocess to learn a reliable model for practical applications. In particular, an\nimage quality assessment based label smoothing method, which aims at\nregularizing the label distribution of training images, is further proposed to\ntune the objective functions in learning the neural network. Experimental\nresults show that the proposed method is effective in dealing with both low and\nhigh quality images in the typical image classification task.",
        "versions": [],
        "rank": 13
    },
    {
        "authors": [
            "Deng, Y.",
            "Wang, X.",
            "Chen, L."
        ],
        "title": "Learning visual-based deformable object rearrangement with local graph neural networks",
        "publication_date": "2023-04-12 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/s40747-023-01048-w",
        "urls": [
            "https://link.springer.com/content/pdf/10.1007/s40747-023-01048-w.pdf",
            "https://link.springer.com/article/10.1007/s40747-023-01048-w/fulltext.html",
            "https://link.springer.com/content/pdf/10.1007/s40747-023-01048-w.pdf",
            "http://dx.doi.org/10.1007/s40747-023-01048-w"
        ],
        "id": "id1711985395006184905",
        "abstract": "",
        "versions": [
            {
                "year": 2023,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Learning visual-based deformable object rearrangement with local graph neural networks",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/4143c3c6a6336c5b3855c7516b540ebe988e41ee"
                ],
                "doi": "10.1007/s40747-023-01048-w",
                "publication_date": "2023-04-12 00:00:00"
            }
        ],
        "rank": 14
    },
    {
        "authors": [
            "Ameneh Sheikhjafari",
            "Michelle Noga",
            "Kumaradevan Punithakumar",
            "Nilanjan Ray"
        ],
        "title": "Unsupervised deformable image registration with fully connected generative neural network",
        "publication_date": "2018-04-11 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "",
        "volume": "",
        "doi": null,
        "urls": [
            "https://openalex.org/W2902335457"
        ],
        "id": "id6280519423437271572",
        "abstract": "",
        "versions": [],
        "rank": 15
    },
    {
        "authors": [
            "Lei Qu",
            "Wan Wan",
            "Kaixuan Guo",
            "Yu Liu",
            "Jun Tang",
            "Xiaolei Li",
            "Jun Wu"
        ],
        "title": "Triple-Input-Unsupervised neural Networks for deformable image registration",
        "publication_date": "2021-11-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Pattern Recognit. Lett.",
        "volume": "151",
        "doi": "10.1016/j.patrec.2021.08.032",
        "urls": [
            "https://www.semanticscholar.org/paper/51bf2cc2e5085ba8e958eddfceffd85a00e3bfb1"
        ],
        "id": "id9071586503956642373",
        "abstract": null,
        "versions": [
            {
                "year": 2021,
                "source": "SupportedSources.OPENALEX",
                "title": "Triple-Input-Unsupervised neural Networks for deformable image registration",
                "journal": "Pattern Recognition Letters",
                "urls": [
                    "https://openalex.org/W3201182454",
                    "https://doi.org/10.1016/j.patrec.2021.08.032"
                ],
                "doi": "10.1016/j.patrec.2021.08.032",
                "publication_date": "2021-11-01 00:00:00"
            },
            {
                "year": 2021,
                "source": "SupportedSources.CROSSREF",
                "title": "Triple-Input-Unsupervised neural Networks for deformable image registration",
                "journal": "",
                "urls": [
                    "https://api.elsevier.com/content/article/PII:S0167865521003287?httpAccept=text/xml",
                    "https://api.elsevier.com/content/article/PII:S0167865521003287?httpAccept=text/plain",
                    "http://dx.doi.org/10.1016/j.patrec.2021.08.032"
                ],
                "doi": "10.1016/j.patrec.2021.08.032",
                "publication_date": "2021-01-01 00:00:00"
            }
        ],
        "rank": 16
    },
    {
        "authors": [
            "Chi Wing Mok"
        ],
        "title": "Unsupervised affine and deformable medical image registration with convolutional neural networks",
        "publication_date": "None",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.14711/thesis-991013106358203412",
        "urls": [
            "https://www.semanticscholar.org/paper/9daae223cd9c1b757b2336a8a1b1428898090d1f"
        ],
        "id": "id8858893884460291330",
        "abstract": null,
        "versions": [
            {
                "year": 0,
                "source": "SupportedSources.CROSSREF",
                "title": "Unsupervised affine and deformable medical image registration with convolutional neural networks",
                "journal": "",
                "urls": [
                    "http://dx.doi.org/10.14711/thesis-991013106358203412"
                ],
                "doi": "10.14711/thesis-991013106358203412",
                "publication_date": "None"
            }
        ],
        "rank": 17
    },
    {
        "authors": [
            "Ghennam, S.",
            "Benmahammed, K."
        ],
        "title": "Multiresolution Support for Adaptive Image Restoration Using Neural Networks",
        "publication_date": "2002-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/3-540-46084-5_194",
        "urls": [
            "http://link.springer.com/content/pdf/10.1007/3-540-46084-5_194",
            "http://dx.doi.org/10.1007/3-540-46084-5_194"
        ],
        "id": "id-8299430497381750102",
        "abstract": "",
        "versions": [
            {
                "year": 2002,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Multiresolution Support for Adaptive Image Restoration Using Neural Networks",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/af41250ead44668ad1c88eb9975e678d8a930a0f"
                ],
                "doi": "10.1007/3-540-46084-5_194",
                "publication_date": "2002-08-28 00:00:00"
            }
        ],
        "rank": 18
    },
    {
        "authors": [
            "Xiaodong Yang",
            "Daping Li",
            "Qiaolin He",
            "Zhu Wang",
            "Ying Fu",
            "Jiliu Zhou",
            "Jinrong Hu"
        ],
        "title": "A Novel Keypoints-Based Image Registration Method with Fully Convolutional Neural Network",
        "publication_date": "None",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-981-15-8083-3_9",
        "urls": [
            "https://www.semanticscholar.org/paper/c11a917a3c393fb2c851ce7fcfee19c185eaeda9"
        ],
        "id": "id-5027949502640973491",
        "abstract": null,
        "versions": [],
        "rank": 19
    },
    {
        "authors": [
            "Kulshrestha, S."
        ],
        "title": "What Is A Convolutional Neural Network?",
        "publication_date": "2019-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-1-4842-5572-8_6",
        "urls": [
            "http://link.springer.com/content/pdf/10.1007/978-1-4842-5572-8_6",
            "http://dx.doi.org/10.1007/978-1-4842-5572-8_6"
        ],
        "id": "id1121380756763871118",
        "abstract": "",
        "versions": [
            {
                "year": 0,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "What Is A Convolutional Neural Network?",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/70544d550d5c8d2d26038ace7346bd75f33b3e24"
                ],
                "doi": "10.1007/978-1-4842-5572-8_6",
                "publication_date": "None"
            }
        ],
        "rank": 20
    },
    {
        "authors": [
            "Nicholas J. Tustison",
            "Brian B. Avants",
            "James C. Gee"
        ],
        "title": "Learning image-based spatial transformations via convolutional neural networks: A review",
        "publication_date": "2019-06-11 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Magnetic Resonance Imaging",
        "volume": "64",
        "doi": "10.1016/j.mri.2019.05.037",
        "urls": [
            "https://openalex.org/W2951445562",
            "https://doi.org/10.1016/j.mri.2019.05.037"
        ],
        "id": "id2467205017769860515",
        "abstract": "",
        "versions": [
            {
                "year": 2019,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Learning image-based spatial transformations via convolutional neural networks: A review.",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/42478c4cf731ba5a98d345cba6a8c049c4906a8e"
                ],
                "doi": "10.1016/j.mri.2019.05.037",
                "publication_date": "2019-06-11 00:00:00"
            }
        ],
        "rank": 21
    },
    {
        "authors": [
            "Aoki, H."
        ],
        "title": "Applications of Complex-Valued Neural Networks for Image Processing",
        "publication_date": "2003-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1142/9789812791184_0009",
        "urls": [
            "http://dx.doi.org/10.1142/9789812791184_0009"
        ],
        "id": "id-3511941119267472926",
        "abstract": "",
        "versions": [
            {
                "year": 2003,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Applications of Complex-Valued Neural Networks for Image Processing",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/61ab10307ed7360b3c48caaeabd7cbd55604cb5b"
                ],
                "doi": "10.1142/9789812791184_0009",
                "publication_date": "2003-11-01 00:00:00"
            }
        ],
        "rank": 22
    },
    {
        "authors": [
            "Wang, F.",
            "Liu, H.",
            "Cheng, J."
        ],
        "title": "Visualizing deep neural network by alternately image blurring and deblurring",
        "publication_date": "2018-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1016/j.neunet.2017.09.007",
        "urls": [
            "https://api.elsevier.com/content/article/PII:S0893608017302095?httpAccept=text/xml",
            "https://api.elsevier.com/content/article/PII:S0893608017302095?httpAccept=text/plain",
            "http://dx.doi.org/10.1016/j.neunet.2017.09.007"
        ],
        "id": "id7548632536394570526",
        "abstract": "",
        "versions": [
            {
                "year": 0,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Visualizing deep neural network by alternately image blurring and deblurring",
                "journal": "Neural networks : the official journal of the International Neural Network Society",
                "urls": [
                    "https://www.semanticscholar.org/paper/d969a71991fec1bf79c5042f4702e041fbfea87d"
                ],
                "doi": "10.1016/j.neunet.2017.09.007",
                "publication_date": "None"
            }
        ],
        "rank": 23
    },
    {
        "authors": [
            "Haim Karniely",
            "H. Siegelmann"
        ],
        "title": "Sensor registration using neural networks",
        "publication_date": "None",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "IEEE Trans. Aerosp. Electron. Syst.",
        "volume": "36",
        "doi": "10.1109/7.826314",
        "urls": [
            "https://www.semanticscholar.org/paper/a907982a5c5ad6024dbe8cef9e2b1a3a29836350"
        ],
        "id": "id8424682806356306733",
        "abstract": "One of the major problems in multiple sensor surveillance systems is inadequate sensor registration. We propose a new approach to sensor registration based on layered neural networks. The nonparametric nature of this approach enables many different kinds of sensor biases to be solved. As part of the implementation we develop some modifications to the common network training algorithm to tackle the inherent randomness in all components of the training set.",
        "versions": [
            {
                "year": 2000,
                "source": "SupportedSources.CROSSREF",
                "title": "Sensor registration using neural networks",
                "journal": "",
                "urls": [
                    "http://xplorestaging.ieee.org/ielx5/7/17885/00826314.pdf?arnumber=826314",
                    "http://dx.doi.org/10.1109/7.826314"
                ],
                "doi": "10.1109/7.826314",
                "publication_date": "2000-01-01 00:00:00"
            }
        ],
        "rank": 24
    },
    {
        "authors": [
            "Fracastoro, G.",
            "Valsesia, D."
        ],
        "title": "Graph Neural Networks for Image Processing",
        "publication_date": "2021-08-05 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1002/9781119850830.ch10",
        "urls": [
            "https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119850830.ch10",
            "https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119850830.ch10",
            "http://dx.doi.org/10.1002/9781119850830.ch10"
        ],
        "id": "id-4799261627739658507",
        "abstract": "",
        "versions": [
            {
                "year": 2021,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Graph Neural Networks for Image Processing",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/4ed203e0f84c93f400b4c1c3c494aad905d3198b"
                ],
                "doi": "10.1002/9781119850830.ch10",
                "publication_date": "2021-08-05 00:00:00"
            }
        ],
        "rank": 25
    },
    {
        "authors": [
            "Axel Wism\u00fcller",
            "Florian Vietze",
            "Dominik R. Dersch",
            "Johannes Behrends",
            "Klaus M. Hahn",
            "Helge Ritter"
        ],
        "title": "The deformable feature map - a novel neurocomputing algorithm for adaptive plasticity in pattern analysis",
        "publication_date": "2002-10-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Neurocomputing",
        "volume": "48",
        "doi": "10.1016/s0925-2312(01)00641-5",
        "urls": [
            "https://openalex.org/W1997269994",
            "https://doi.org/10.1016/s0925-2312(01)00641-5"
        ],
        "id": "id511418045915621507",
        "abstract": "",
        "versions": [
            {
                "year": 2002,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "The deformable feature map - a novel neurocomputing algorithm for adaptive plasticity in pattern analysis",
                "journal": "Neurocomputing",
                "urls": [
                    "https://www.semanticscholar.org/paper/a7dbe9baab431c41d1936ad2e0ac88de1286949d"
                ],
                "doi": "10.1016/S0925-2312(01)00641-5",
                "publication_date": "2002-10-01 00:00:00"
            }
        ],
        "rank": 26
    },
    {
        "authors": [
            "K. Fukushima"
        ],
        "title": "Neural network model restoring partly occluded patterns",
        "publication_date": "2003-09-03 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Int. J. Knowl. Based Intell. Eng. Syst.",
        "volume": "8",
        "doi": "10.3233/KES-2004-8202",
        "urls": [
            "https://www.semanticscholar.org/paper/62306f35068bd0a30f5018df7a314799fc2cb58a"
        ],
        "id": "id-5937076661333008104",
        "abstract": "Even the identical image is perceived differently by human beings depending on the shape of occluding objects. This paper proposes a neural network model that has an ability to recognize and restore partly occluded patterns in a similar way as our perception. It is a multi-layered hierarchical neural network, in which visual information is processed by interaction of bottom-up and top-down signals. Occluded parts of a pattern are restored mainly by feedback signals from the highest stage of the network, while the unoccluded parts are reproduced mainly by signals from lower stages. The model does not use a simple template matching method. It can recognize and restore even deformed versions of learned patterns.",
        "versions": [],
        "rank": 27
    },
    {
        "authors": [
            "Vikram, D.",
            "G.H. Raisoni College of Engineering & management, Wagholi, Pune"
        ],
        "title": "Convolution Neural Networks by Image Net",
        "publication_date": "2017-09-30 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.18535/ijetst/v4i9.30",
        "urls": [
            "http://dx.doi.org/10.18535/ijetst/v4i9.30"
        ],
        "id": "id9063106753605919707",
        "abstract": "",
        "versions": [
            {
                "year": 2017,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Convolution Neural Networks by Image Net",
                "journal": "International journal of emerging trends in science and technology",
                "urls": [
                    "https://www.semanticscholar.org/paper/72837e5facb1c2b7465145c509735cb88141aead",
                    "https://doi.org/10.18535/ijetst/v4i9.30"
                ],
                "doi": "10.18535/IJETST/V4I9.30",
                "publication_date": "2017-09-30 00:00:00"
            }
        ],
        "rank": 28
    },
    {
        "authors": [
            "S. Phandi",
            "C. Velayutham"
        ],
        "title": "Neural Network Based Image Registration Using Synthetic Reference Image Rotation",
        "publication_date": "2018-05-16 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-3-030-00665-5_88",
        "urls": [
            "https://www.semanticscholar.org/paper/dd4935366f229eab3de4a89fbd7e07065f0f8df2"
        ],
        "id": "id-4861055391521087302",
        "abstract": null,
        "versions": [],
        "rank": 29
    },
    {
        "authors": [
            "Onur Kele\u015f",
            "A. Murat Tekalp",
            "Junaid Malik",
            "Serkan K\u0131ranyaz"
        ],
        "title": "Self-Organized Residual Blocks for Image Super-Resolution",
        "publication_date": "2021-05-31 12:47:51+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2105.14926v1",
            "http://arxiv.org/abs/2105.14926v1",
            "http://arxiv.org/pdf/2105.14926v1"
        ],
        "id": "id9029786346196223456",
        "abstract": "It has become a standard practice to use the convolutional networks (ConvNet)\nwith RELU non-linearity in image restoration and super-resolution (SR).\nAlthough the universal approximation theorem states that a multi-layer neural\nnetwork can approximate any non-linear function with the desired precision, it\ndoes not reveal the best network architecture to do so. Recently, operational\nneural networks (ONNs) that choose the best non-linearity from a set of\nalternatives, and their \"self-organized\" variants (Self-ONN) that approximate\nany non-linearity via Taylor series have been proposed to address the\nwell-known limitations and drawbacks of conventional ConvNets such as network\nhomogeneity using only the McCulloch-Pitts neuron model. In this paper, we\npropose the concept of self-organized operational residual (SOR) blocks, and\npresent hybrid network architectures combining regular residual and SOR blocks\nto strike a balance between the benefits of stronger non-linearity and the\noverall number of parameters. The experimental results demonstrate that\nthe~proposed architectures yield performance improvements in both PSNR and\nperceptual metrics.",
        "versions": [],
        "rank": 30
    },
    {
        "authors": [
            "Lei, Y.",
            "Fu, Y.",
            "Harms, J.",
            "Wang, T.",
            "Curran, W.",
            "Liu, T.",
            "Higgins, K.",
            "Yang, X."
        ],
        "title": "4D-CT Deformable Image Registration Using an Unsupervised Deep Convolutional Neural Network",
        "publication_date": "2019-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-3-030-32486-5_4",
        "urls": [
            "http://link.springer.com/content/pdf/10.1007/978-3-030-32486-5_4",
            "http://dx.doi.org/10.1007/978-3-030-32486-5_4"
        ],
        "id": "id-3829904049448130474",
        "abstract": "",
        "versions": [
            {
                "year": 2019,
                "source": "SupportedSources.OPENALEX",
                "title": "4D-CT Deformable Image Registration Using an Unsupervised Deep Convolutional Neural Network",
                "journal": "Springer eBooks",
                "urls": [
                    "https://openalex.org/W2979484108",
                    "https://doi.org/10.1007/978-3-030-32486-5_4"
                ],
                "doi": "10.1007/978-3-030-32486-5_4",
                "publication_date": "2019-10-17 00:00:00"
            },
            {
                "year": 2019,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "4D-CT Deformable Image Registration Using an Unsupervised Deep Convolutional Neural Network",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/cd7bc01b27aa97d1d1504f77ec04fe9cecc4e21e"
                ],
                "doi": "10.1007/978-3-030-32486-5_4",
                "publication_date": "2019-10-17 00:00:00"
            }
        ],
        "rank": 31
    },
    {
        "authors": [
            "Pekar, V.",
            "Gladilin, E."
        ],
        "title": "Deformable Image Registration by Adaptive Gaussian Forces",
        "publication_date": "2004-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-3-540-27816-0_27",
        "urls": [
            "http://link.springer.com/content/pdf/10.1007/978-3-540-27816-0_27.pdf",
            "http://dx.doi.org/10.1007/978-3-540-27816-0_27"
        ],
        "id": "id5403119546453753856",
        "abstract": "",
        "versions": [
            {
                "year": 2004,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Deformable Image Registration by Adaptive Gaussian Forces",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/8e6b11492743d450063da61b54a1e663c4e8f2a7"
                ],
                "doi": "10.1007/978-3-540-27816-0_27",
                "publication_date": "2004-05-15 00:00:00"
            }
        ],
        "rank": 32
    },
    {
        "authors": [
            "Gadde, P."
        ],
        "title": "AFFINE IMAGE REGISTRATION USING ARTIFICIAL NEURAL NETWORKS",
        "publication_date": "None",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.15368/theses.2013.133",
        "urls": [
            "http://dx.doi.org/10.15368/theses.2013.133"
        ],
        "id": "id-7870121135489613672",
        "abstract": "",
        "versions": [
            {
                "year": 0,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "AFFINE IMAGE REGISTRATION USING ARTIFICIAL NEURAL NETWORKS",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/17538ed6a9730853eaf7201a3ae3167cd563cf9a",
                    "https://digitalcommons.calpoly.edu/cgi/viewcontent.cgi?article=2047&context=theses"
                ],
                "doi": "10.15368/THESES.2013.133",
                "publication_date": "None"
            }
        ],
        "rank": 33
    },
    {
        "authors": [
            "Karol Gregor",
            "Ivo Danihelka",
            "Alex Graves",
            "Danilo Jimenez Rezende",
            "Daan Wierstra"
        ],
        "title": "DRAW: A Recurrent Neural Network For Image Generation",
        "publication_date": "2015-02-16 16:48:56+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1502.04623v2",
            "http://arxiv.org/abs/1502.04623v2",
            "http://arxiv.org/pdf/1502.04623v2"
        ],
        "id": "id-504191471565187661",
        "abstract": "This paper introduces the Deep Recurrent Attentive Writer (DRAW) neural\nnetwork architecture for image generation. DRAW networks combine a novel\nspatial attention mechanism that mimics the foveation of the human eye, with a\nsequential variational auto-encoding framework that allows for the iterative\nconstruction of complex images. The system substantially improves on the state\nof the art for generative models on MNIST, and, when trained on the Street View\nHouse Numbers dataset, it generates images that cannot be distinguished from\nreal data with the naked eye.",
        "versions": [],
        "rank": 34
    },
    {
        "authors": [
            "Delibasis, K.",
            "Maglogiannis, I.",
            "Georgakopoulos, S.",
            "Kottari, K.",
            "Plagianakos, V."
        ],
        "title": "Assessing Image Analysis Filters as Augmented Input to Convolutional Neural Networks for Image Classification",
        "publication_date": "2018-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-3-030-01418-6_19",
        "urls": [
            "http://link.springer.com/content/pdf/10.1007/978-3-030-01418-6_19",
            "http://dx.doi.org/10.1007/978-3-030-01418-6_19"
        ],
        "id": "id-926506791069975156",
        "abstract": "",
        "versions": [
            {
                "year": 2018,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Assessing Image Analysis Filters as Augmented Input to Convolutional Neural Networks for Image Classification",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/cead8d028d05d35fb465c4b464605d2a5acdf514"
                ],
                "doi": "10.1007/978-3-030-01418-6_19",
                "publication_date": "2018-10-04 00:00:00"
            }
        ],
        "rank": 35
    },
    {
        "authors": [
            "Yun Gong",
            "Mengjia Yang"
        ],
        "title": "An Improved Indoor Image Registration Algorithm Based on Shallow Convolutional Neural Network Descriptor",
        "publication_date": "2019-08-23 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-3-030-34110-7_22",
        "urls": [
            "https://www.semanticscholar.org/paper/4b065e090ffd179546aa38177656b64767e9cbfb"
        ],
        "id": "id-8490991971385785631",
        "abstract": null,
        "versions": [],
        "rank": 36
    },
    {
        "authors": [
            "Kulshrestha, S."
        ],
        "title": "Developing An Image Classifier Using Convolutional Neural Networks",
        "publication_date": "2019-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-1-4842-5572-8_7",
        "urls": [
            "http://link.springer.com/content/pdf/10.1007/978-1-4842-5572-8_7",
            "http://dx.doi.org/10.1007/978-1-4842-5572-8_7"
        ],
        "id": "id-2511223393310899885",
        "abstract": "",
        "versions": [
            {
                "year": 0,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Developing An Image Classifier Using Convolutional Neural Networks",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/333c805c9ce8124486c9b59b29492c846fccaabd"
                ],
                "doi": "10.1007/978-1-4842-5572-8_7",
                "publication_date": "None"
            }
        ],
        "rank": 37
    },
    {
        "authors": [
            "Andresen, J.",
            "Kepp, T.",
            "Ehrhardt, J.",
            "von\u00a0der Burchard, C.",
            "Roider, J.",
            "Handels, H."
        ],
        "title": "Unsupervised Non-correspondence Detection in\u00a0Medical Images Using an\u00a0Image Registration Convolutional Neural Network",
        "publication_date": "2022-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-3-031-11203-4_1",
        "urls": [
            "https://link.springer.com/content/pdf/10.1007/978-3-031-11203-4_1",
            "http://dx.doi.org/10.1007/978-3-031-11203-4_1"
        ],
        "id": "id-7101359394437730104",
        "abstract": "",
        "versions": [
            {
                "year": 0,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Unsupervised Non-correspondence Detection in Medical Images Using an Image Registration Convolutional Neural Network",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/d2b926e0fb1bcb0447f5954e0345ac8b68becc85"
                ],
                "doi": "10.1007/978-3-031-11203-4_1",
                "publication_date": "None"
            }
        ],
        "rank": 38
    },
    {
        "authors": [
            "Singh, G."
        ],
        "title": "Think positive: An interpretable neural network for image recognition",
        "publication_date": "2022-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1016/j.neunet.2022.03.034",
        "urls": [
            "https://api.elsevier.com/content/article/PII:S0893608022001125?httpAccept=text/xml",
            "https://api.elsevier.com/content/article/PII:S0893608022001125?httpAccept=text/plain",
            "http://dx.doi.org/10.1016/j.neunet.2022.03.034"
        ],
        "id": "id1833426539591635640",
        "abstract": "",
        "versions": [
            {
                "year": 2022,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Think positive: An interpretable neural network for image recognition",
                "journal": "Neural Networks",
                "urls": [
                    "https://www.semanticscholar.org/paper/4027d04cd1b4746688ce5a78d378aa753e91467c"
                ],
                "doi": "10.1016/j.neunet.2022.03.034",
                "publication_date": "2022-04-01 00:00:00"
            }
        ],
        "rank": 39
    },
    {
        "authors": [
            "Cierniak, R."
        ],
        "title": "A Practical Approach To Image Reconstruction From Projections Using Neural Networks Structure",
        "publication_date": "2003-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-3-7908-1902-1_69",
        "urls": [
            "http://link.springer.com/content/pdf/10.1007/978-3-7908-1902-1_69",
            "http://dx.doi.org/10.1007/978-3-7908-1902-1_69"
        ],
        "id": "id6185000429434719969",
        "abstract": "",
        "versions": [
            {
                "year": 0,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "A Practical Approach To Image Reconstruction From Projections Using Neural Networks Structure",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/d194c46f44a315df48bb7f992a06e863fcf6dc21"
                ],
                "doi": "10.1007/978-3-7908-1902-1_69",
                "publication_date": "None"
            }
        ],
        "rank": 40
    },
    {
        "authors": [
            "Milosevic, N."
        ],
        "title": "What are Artificial Neural Networks? Part 1",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-1-4842-5648-0_2",
        "urls": [
            "http://link.springer.com/content/pdf/10.1007/978-1-4842-5648-0_2",
            "http://dx.doi.org/10.1007/978-1-4842-5648-0_2"
        ],
        "id": "id-3448815419236310505",
        "abstract": "",
        "versions": [
            {
                "year": 0,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "What are Artificial Neural Networks? Part 1",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/6abeb249755efb3facdfad0341bbc49f075514b9"
                ],
                "doi": "10.1007/978-1-4842-5648-0_2",
                "publication_date": "None"
            }
        ],
        "rank": 41
    },
    {
        "authors": [
            "Hessam Sokooti",
            "B. D. Vos",
            "F. Berendsen",
            "B. Lelieveldt",
            "I. I\u0161gum",
            "M. Staring"
        ],
        "title": "Nonrigid Image Registration Using Multi-scale 3D Convolutional Neural Networks",
        "publication_date": "2017-09-10 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-3-319-66182-7_27",
        "urls": [
            "https://www.semanticscholar.org/paper/bbee923434518e92ee9c03dcd487e7f0b6042b78"
        ],
        "id": "id-7184454907718857900",
        "abstract": null,
        "versions": [
            {
                "year": 2017,
                "source": "SupportedSources.CROSSREF",
                "title": "Nonrigid Image Registration Using Multi-scale 3D Convolutional Neural Networks",
                "journal": "",
                "urls": [
                    "https://link.springer.com/content/pdf/10.1007/978-3-319-66182-7_27",
                    "http://dx.doi.org/10.1007/978-3-319-66182-7_27"
                ],
                "doi": "10.1007/978-3-319-66182-7_27",
                "publication_date": "2017-01-01 00:00:00"
            },
            {
                "year": 2017,
                "source": "SupportedSources.OPENALEX",
                "title": "Nonrigid Image Registration Using Multi-scale 3D Convolutional Neural Networks",
                "journal": "Lecture Notes in Computer Science",
                "urls": [
                    "https://openalex.org/W2751297520",
                    "https://doi.org/10.1007/978-3-319-66182-7_27"
                ],
                "doi": "10.1007/978-3-319-66182-7_27",
                "publication_date": "2017-09-10 00:00:00"
            }
        ],
        "rank": 42
    },
    {
        "authors": [
            "Fracastoro, G.",
            "Valsesia, D."
        ],
        "title": "Graph Neural Networks",
        "publication_date": "2021-08-05 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1002/9781119850830.ch3",
        "urls": [
            "https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119850830.ch3",
            "https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119850830.ch3",
            "http://dx.doi.org/10.1002/9781119850830.ch3"
        ],
        "id": "id8812815888958228430",
        "abstract": "",
        "versions": [
            {
                "year": 2021,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Graph Neural Networks",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/c7bc3f571a75392daaf0f9cfc57e6a31fb2edb70"
                ],
                "doi": "10.1002/9781119850830.ch3",
                "publication_date": "2021-08-05 00:00:00"
            }
        ],
        "rank": 43
    },
    {
        "authors": [
            "Milosevic, N."
        ],
        "title": "Introduction to Convolutional Neural Networks",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-1-4842-5648-0",
        "urls": [
            "http://link.springer.com/content/pdf/10.1007/978-1-4842-5648-0.pdf",
            "http://link.springer.com/content/pdf/10.1007/978-1-4842-5648-0",
            "http://dx.doi.org/10.1007/978-1-4842-5648-0"
        ],
        "id": "id5434223964312540893",
        "abstract": "",
        "versions": [
            {
                "year": 0,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Introduction to Convolutional Neural Networks",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/a07a7ae063b17bf1196c44b241d314a1037062c8"
                ],
                "doi": "10.1007/978-1-4842-5648-0",
                "publication_date": "None"
            }
        ],
        "rank": 44
    },
    {
        "authors": [
            "Joshua Bowren"
        ],
        "title": "A Sparse Coding Interpretation of Neural Networks and Theoretical Implications",
        "publication_date": "2021-08-14 21:54:47+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2108.06622v2",
            "http://arxiv.org/abs/2108.06622v2",
            "http://arxiv.org/pdf/2108.06622v2"
        ],
        "id": "id-6395186815615961169",
        "abstract": "Neural networks, specifically deep convolutional neural networks, have\nachieved unprecedented performance in various computer vision tasks, but the\nrationale for the computations and structures of successful neural networks is\nnot fully understood. Theories abound for the aptitude of convolutional neural\nnetworks for image classification, but less is understood about why such models\nwould be capable of complex visual tasks such as inference and anomaly\nidentification. Here, we propose a sparse coding interpretation of neural\nnetworks that have ReLU activation and of convolutional neural networks in\nparticular. In sparse coding, when the model's basis functions are assumed to\nbe orthogonal, the optimal coefficients are given by the soft-threshold\nfunction of the basis functions projected onto the input image. In a\nnon-negative variant of sparse coding, the soft-threshold function becomes a\nReLU. Here, we derive these solutions via sparse coding with orthogonal-assumed\nbasis functions, then we derive the convolutional neural network forward\ntransformation from a modified non-negative orthogonal sparse coding model with\nan exponential prior parameter for each sparse coding coefficient. Next, we\nderive a complete convolutional neural network without normalization and\npooling by adding logistic regression to a hierarchical sparse coding model.\nFinally we motivate potentially more robust forward transformations by\nmaintaining sparse priors in convolutional neural networks as well performing a\nstronger nonlinear transformation.",
        "versions": [],
        "rank": 45
    },
    {
        "authors": [
            "\u6731\u6bc5"
        ],
        "title": "Convolutional neural network image recognition method based on dynamic adjustment of training targets",
        "publication_date": "2014-09-24 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://www.semanticscholar.org/paper/370f998e561a63bb7499906610aa27b7e21e8153"
        ],
        "id": "id4593801754692927467",
        "abstract": "The invention discloses a convolutional neural network image recognition method based on dynamic adjustment of training targets. The method comprises the three steps of training model building, data registration, and recognition and matching. In the training model building process, training samples are input into a convolutional neural network model, the mean value of output vectors of output layers of the same class of samples is worked out to serve as the target vector of the current round of training, and then the error between the output vector of each sample and the target vector is reversely transmitted to adjust the parameters of a convolutional neural network till the training requirement is met; in the data registration process, sample images needing to be registered are input into the convolutional neural network model, and output results of the output layers serve as feature vectors to be stored; in the recognition and matching process, sample images needing to be recognized and matched are input into the convolutional neural network, output results of the output layers serve as feature vectors, and then matching is carried out on the feature vectors and registered feature vectors so as to provide the judgment result of recognition and matching.",
        "versions": [],
        "rank": 46
    },
    {
        "authors": [
            "J. Wolterink",
            "Jesse C. Zwienenberg",
            "C. Brune"
        ],
        "title": "Implicit Neural Representations for Deformable Image Registration",
        "publication_date": "None",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://www.semanticscholar.org/paper/d3857fcd457aa50cec2b198d40800078472ef3ea"
        ],
        "id": "id-2222937153736925841",
        "abstract": "Deformable medical image registration has in past years been revolutionized by the use of convolutional neural networks. These methods surpass conventional image registration techniques in speed but not in accuracy. Here, we present an alternative approach to leveraging neural networks for image registration. Instead of using a convolutional neural network to predict the transformation between images, we optimize a multi-layer perceptron to represent this transformation function. Using recent insights from differentiable rendering, we show how such an implicit deformable image registration (idir) model can be naturally combined with regularization terms based on standard automatic differentiation techniques. We demonstrate the effectiveness of this model on 4D chest CT registration in the DIR-LAB data set and find that a three-layer multi-layer perceptron with periodic activation functions outperforms all published deep learning-based results on this problem, without any folding and without the need for training data. The model is implemented using standard deep learning libraries and flexible enough to be extended to include different losses, regularizers, and optimization schemes.",
        "versions": [],
        "rank": 47
    },
    {
        "authors": [
            "Sanghun Park",
            "Kwanggyoon Seo",
            "Junyong Noh"
        ],
        "title": "Neural Crossbreed: Neural Based Image Metamorphosis",
        "publication_date": "2020-09-02 08:56:47+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": "ACM Transactions on Graphics (Proceeding of SIGGRAPH Asia), 2020",
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2009.00905v1",
            "http://arxiv.org/abs/2009.00905v1",
            "http://arxiv.org/pdf/2009.00905v1"
        ],
        "id": "id-5023646313843789508",
        "abstract": "We propose Neural Crossbreed, a feed-forward neural network that can learn a\nsemantic change of input images in a latent space to create the morphing\neffect. Because the network learns a semantic change, a sequence of meaningful\nintermediate images can be generated without requiring the user to specify\nexplicit correspondences. In addition, the semantic change learning makes it\npossible to perform the morphing between the images that contain objects with\nsignificantly different poses or camera views. Furthermore, just as in\nconventional morphing techniques, our morphing network can handle shape and\nappearance transitions separately by disentangling the content and the style\ntransfer for rich usability. We prepare a training dataset for morphing using a\npre-trained BigGAN, which generates an intermediate image by interpolating two\nlatent vectors at an intended morphing value. This is the first attempt to\naddress image morphing using a pre-trained generative model in order to learn\nsemantic transformation. The experiments show that Neural Crossbreed produces\nhigh quality morphed images, overcoming various limitations associated with\nconventional approaches. In addition, Neural Crossbreed can be further extended\nfor diverse applications such as multi-image morphing, appearance transfer, and\nvideo frame interpolation.",
        "versions": [],
        "rank": 48
    },
    {
        "authors": [
            "Huang, Y.",
            "Ahmad, S.",
            "Fan, J.",
            "Shen, D.",
            "Yap, P."
        ],
        "title": "Difficulty-aware hierarchical convolutional neural networks for deformable registration of brain MR images",
        "publication_date": "2021-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1016/j.media.2020.101817",
        "urls": [
            "https://api.elsevier.com/content/article/PII:S136184152030181X?httpAccept=text/xml",
            "https://api.elsevier.com/content/article/PII:S136184152030181X?httpAccept=text/plain",
            "http://dx.doi.org/10.1016/j.media.2020.101817"
        ],
        "id": "id-3738993667022661177",
        "abstract": "",
        "versions": [
            {
                "year": 2020,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Difficulty-aware hierarchical convolutional neural networks for deformable registration of brain MR images",
                "journal": "Medical image analysis",
                "urls": [
                    "https://www.semanticscholar.org/paper/228d452fb3c5831ea77457a945b8d091e99a3bf7"
                ],
                "doi": "10.1016/J.MEDIA.2020.101817",
                "publication_date": "2020-09-30 00:00:00"
            },
            {
                "year": 2021,
                "source": "SupportedSources.OPENALEX",
                "title": "Difficulty-aware hierarchical convolutional neural networks for deformable registration of brain MR images",
                "journal": "Medical Image Analysis",
                "urls": [
                    "https://openalex.org/W3091131821",
                    "https://doi.org/10.1016/j.media.2020.101817",
                    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7725910"
                ],
                "doi": "10.1016/j.media.2020.101817",
                "publication_date": "2021-01-01 00:00:00"
            }
        ],
        "rank": 49
    },
    {
        "authors": [
            "Nalin Gupta",
            "M. P. Ross"
        ],
        "title": "Disorders of Neural Tube Development",
        "publication_date": "2017-01-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Swaiman's Pediatric Neurology (Sixth Edition)",
        "volume": "",
        "doi": "10.1016/b978-0-323-37101-8.00025-4",
        "urls": [
            "https://openalex.org/W2497105953",
            "https://doi.org/10.1016/b978-0-323-37101-8.00025-4"
        ],
        "id": "id8612615094161990287",
        "abstract": "",
        "versions": [
            {
                "year": 0,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "25 \u2013 Disorders of Neural Tube Development",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/a0b3f9c4f5b0692449e3beba26d48945b42d0b27"
                ],
                "doi": "10.1016/B978-0-323-37101-8.00025-4",
                "publication_date": "None"
            }
        ],
        "rank": 50
    },
    {
        "authors": [
            "Y. Xing",
            "Jing Sun",
            "B. Li"
        ],
        "title": "New method for medical image registration based on neural networks",
        "publication_date": "None",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://www.semanticscholar.org/paper/9b64affa58aaf53812d6df883fb2f7081c31e604"
        ],
        "id": "id910375447594255123",
        "abstract": null,
        "versions": [],
        "rank": 51
    },
    {
        "authors": [
            "Hang Yang",
            "Xiaotian Wu",
            "Xinglong Sun"
        ],
        "title": "Select Good Regions for Deblurring based on Convolutional Neural Networks",
        "publication_date": "2020-08-12 01:58:35+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2008.05065v1",
            "http://arxiv.org/abs/2008.05065v1",
            "http://arxiv.org/pdf/2008.05065v1"
        ],
        "id": "id-1462410306391438408",
        "abstract": "The goal of blind image deblurring is to recover sharp image from one input\nblurred image with an unknown blur kernel. Most of image deblurring approaches\nfocus on developing image priors, however, there is not enough attention to the\ninfluence of image details and structures on the blur kernel estimation. What\nis the useful image structure and how to choose a good deblurring region? In\nthis work, we propose a deep neural network model method for selecting good\nregions to estimate blur kernel. First we construct image patches with labels\nand train a deep neural networks, then the learned model is applied to\ndetermine which region of the image is most suitable to deblur. Experimental\nresults illustrate that the proposed approach is effective, and could be able\nto select good regions for image deblurring.",
        "versions": [],
        "rank": 52
    },
    {
        "authors": [
            "Matthew C. Humphrey",
            "G. Holmes",
            "S. Cunningham"
        ],
        "title": "Improving the image recognition capability of Hopfield neural networks",
        "publication_date": "1993-11-24 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ANNES.1993.323072",
        "urls": [
            "https://www.semanticscholar.org/paper/bb2c2323251bd6e299a56b441c544136eeba8138"
        ],
        "id": "id4490935768524820452",
        "abstract": "Hopfield neural networks can be used for image recognition when only a partial image is available. However, the image recognition process is very sensitive to the position of the input; shifting the image by only one pixel can cause the network to fail to find a matching exemplar. The authors present a technique for modifying the input image so that an ordinary Hopfield neural network will recognize a shifted image. This technique makes use of the image. The authors run an experiment with random bitmap images to determine how accurately a Hopfield neural network can recognize shifted and blurred images. The results indicate that the neural network can recognize shifted images only if they are modified.<<ETX>>",
        "versions": [
            {
                "year": 0,
                "source": "SupportedSources.CROSSREF",
                "title": "Improving the image recognition capability of Hopfield neural networks",
                "journal": "",
                "urls": [
                    "http://xplorestaging.ieee.org/ielx2/924/7708/00323072.pdf?arnumber=323072",
                    "http://dx.doi.org/10.1109/annes.1993.323072"
                ],
                "doi": "10.1109/annes.1993.323072",
                "publication_date": "None"
            }
        ],
        "rank": 53
    },
    {
        "authors": [
            "Yang, J.",
            "Liao, X.",
            "Deng, S.",
            "Yu, M.",
            "Zheng, H."
        ],
        "title": "Neural Networks Based Image Recognition: A New Approach",
        "publication_date": "None",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-3-540-72393-6_86",
        "urls": [
            "http://link.springer.com/content/pdf/10.1007/978-3-540-72393-6_86.pdf",
            "http://dx.doi.org/10.1007/978-3-540-72393-6_86"
        ],
        "id": "id3995890152963975924",
        "abstract": "",
        "versions": [
            {
                "year": 2007,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Neural Networks Based Image Recognition: A New Approach",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/6f0b2b0ae82f0b1dbce2e2182e85145279fc949e"
                ],
                "doi": "10.1007/978-3-540-72393-6_86",
                "publication_date": "2007-06-03 00:00:00"
            }
        ],
        "rank": 54
    },
    {
        "authors": [
            "Han, L.",
            "Dou, H.",
            "Huang, Y.",
            "Yap, P."
        ],
        "title": "Deformable Registration of Brain MR Images via a Hybrid Loss",
        "publication_date": "2022-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-3-030-97281-3_20",
        "urls": [
            "https://link.springer.com/content/pdf/10.1007/978-3-030-97281-3_20",
            "http://dx.doi.org/10.1007/978-3-030-97281-3_20"
        ],
        "id": "id-3319677979685474005",
        "abstract": "",
        "versions": [
            {
                "year": 2021,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Deformable Registration of Brain MR Images via a Hybrid Loss",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/69682eaf0f3e438bb76686f0c5193518661c28ad",
                    "http://arxiv.org/pdf/2110.15027"
                ],
                "doi": "10.1007/978-3-030-97281-3_20",
                "publication_date": "2021-10-28 00:00:00"
            }
        ],
        "rank": 55
    },
    {
        "authors": [
            "Goltsev, A.",
            "Gritsenko, V."
        ],
        "title": "Investigation of efficient features for image recognition by neural networks",
        "publication_date": "2012-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1016/j.neunet.2011.12.002",
        "urls": [
            "https://api.elsevier.com/content/article/PII:S0893608011003170?httpAccept=text/xml",
            "https://api.elsevier.com/content/article/PII:S0893608011003170?httpAccept=text/plain",
            "http://dx.doi.org/10.1016/j.neunet.2011.12.002"
        ],
        "id": "id7867563192079788827",
        "abstract": "",
        "versions": [
            {
                "year": 2012,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Investigation of efficient features for image recognition by neural networks",
                "journal": "Neural networks : the official journal of the International Neural Network Society",
                "urls": [
                    "https://www.semanticscholar.org/paper/59601c18b16a325da5a0f119e05e93107b337cd1"
                ],
                "doi": "10.1016/j.neunet.2011.12.002",
                "publication_date": "2012-04-01 00:00:00"
            }
        ],
        "rank": 56
    },
    {
        "authors": [
            "Han Zhou"
        ],
        "title": "Deformable Image Registration Using Attentional Generative Adversarial Networks",
        "publication_date": "2021-01-22 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.11575/PRISM/38593",
        "urls": [
            "https://www.semanticscholar.org/paper/b1232074d0dc1b41f0729fab90184daec92edd08"
        ],
        "id": "id-898247484638464517",
        "abstract": null,
        "versions": [],
        "rank": 57
    },
    {
        "authors": [
            "Romuald A. Janik"
        ],
        "title": "Aesthetics and neural network image representations",
        "publication_date": "2021-09-16 16:50:22+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2109.08103v2",
            "http://arxiv.org/abs/2109.08103v2",
            "http://arxiv.org/pdf/2109.08103v2"
        ],
        "id": "id3903856751812325692",
        "abstract": "We analyze the spaces of images encoded by generative neural networks of the\nBigGAN architecture. We find that generic multiplicative perturbations of\nneural network parameters away from the photo-realistic point often lead to\nnetworks generating images which appear as \"artistic renditions\" of the\ncorresponding objects. This demonstrates an emergence of aesthetic properties\ndirectly from the structure of the photo-realistic visual environment as\nencoded in its neural network parametrization. Moreover, modifying a deep\nsemantic part of the neural network leads to the appearance of symbolic visual\nrepresentations. None of the considered networks had any access to images of\nhuman-made art.",
        "versions": [],
        "rank": 58
    },
    {
        "authors": [
            "Hartmut Maennel",
            "Ibrahim Alabdulmohsin",
            "Ilya Tolstikhin",
            "Robert J. N. Baldock",
            "Olivier Bousquet",
            "Sylvain Gelly",
            "Daniel Keysers"
        ],
        "title": "What Do Neural Networks Learn When Trained With Random Labels?",
        "publication_date": "2020-06-18 12:07:22+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2006.10455v2",
            "http://arxiv.org/abs/2006.10455v2",
            "http://arxiv.org/pdf/2006.10455v2"
        ],
        "id": "id-6647185777623416124",
        "abstract": "We study deep neural networks (DNNs) trained on natural image data with\nentirely random labels. Despite its popularity in the literature, where it is\noften used to study memorization, generalization, and other phenomena, little\nis known about what DNNs learn in this setting. In this paper, we show\nanalytically for convolutional and fully connected networks that an alignment\nbetween the principal components of network parameters and data takes place\nwhen training with random labels. We study this alignment effect by\ninvestigating neural networks pre-trained on randomly labelled image data and\nsubsequently fine-tuned on disjoint datasets with random or real labels. We\nshow how this alignment produces a positive transfer: networks pre-trained with\nrandom labels train faster downstream compared to training from scratch even\nafter accounting for simple effects, such as weight scaling. We analyze how\ncompeting effects, such as specialization at later layers, may hide the\npositive transfer. These effects are studied in several network architectures,\nincluding VGG16 and ResNet18, on CIFAR10 and ImageNet.",
        "versions": [],
        "rank": 59
    },
    {
        "authors": [
            "Wajdi Bellil",
            "Hajer Ben Brahim",
            "Chokri Ben Amar"
        ],
        "title": "Gappy wavelet neural network for 3D occluded faces: detection and recognition",
        "publication_date": "2016-01-01 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Multimedia Tools and Applications",
        "volume": "75",
        "doi": "10.1007/s11042-014-2294-6",
        "urls": [
            "https://openalex.org/W2071881355",
            "https://doi.org/10.1007/s11042-014-2294-6"
        ],
        "id": "id8549477621070942204",
        "abstract": "",
        "versions": [
            {
                "year": 2014,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Gappy wavelet neural network for 3D occluded faces: detection and recognition",
                "journal": "Multimedia Tools and Applications",
                "urls": [
                    "https://www.semanticscholar.org/paper/c7efe52121f526791f5b414d60aa3e97bc058aef"
                ],
                "doi": "10.1007/s11042-014-2294-6",
                "publication_date": "2014-10-16 00:00:00"
            }
        ],
        "rank": 60
    },
    {
        "authors": [
            "Zhang, S.",
            "Salari, E."
        ],
        "title": "A Neural Network Method for Image Resolution Enhancement from a Multiple of Image Frames",
        "publication_date": "2011-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-3-642-21111-9_22",
        "urls": [
            "http://link.springer.com/content/pdf/10.1007/978-3-642-21111-9_22",
            "http://dx.doi.org/10.1007/978-3-642-21111-9_22"
        ],
        "id": "id4475854242893959917",
        "abstract": "",
        "versions": [
            {
                "year": 2011,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "A Neural Network Method for Image Resolution Enhancement from a Multiple of Image Frames",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/966464d40f5deda05f97c0f6739ed86e4ec5dd63"
                ],
                "doi": "10.1007/978-3-642-21111-9_22",
                "publication_date": "2011-05-29 00:00:00"
            }
        ],
        "rank": 61
    },
    {
        "authors": [
            "M. B. Sukhaswami",
            "Arun K. Pujari"
        ],
        "title": "Restoration of geometrically aberrated images using a self-organising neural network",
        "publication_date": "1996-01-10 00:00:00",
        "source": "SupportedSources.OPENALEX",
        "journal": "Pattern Recognition Letters",
        "volume": "17",
        "doi": "10.1016/0167-8655(95)00053-4",
        "urls": [
            "https://openalex.org/W2069185367",
            "https://doi.org/10.1016/0167-8655(95)00053-4"
        ],
        "id": "id4386480684723154938",
        "abstract": "",
        "versions": [
            {
                "year": 1996,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Restoration of geometrically aberrated images using a self-organising neural network",
                "journal": "Pattern Recognit. Lett.",
                "urls": [
                    "https://www.semanticscholar.org/paper/9075fec3f14c7e585bc8063b4254b0e372d02f01"
                ],
                "doi": "10.1016/0167-8655(95)00053-4",
                "publication_date": "1996-01-10 00:00:00"
            }
        ],
        "rank": 62
    },
    {
        "authors": [
            "Liu, J."
        ],
        "title": "Deformable Model-Based Image Registration",
        "publication_date": "2007-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-0-387-68413-0_15",
        "urls": [
            "http://link.springer.com/content/pdf/10.1007/978-0-387-68413-0_15.pdf",
            "http://dx.doi.org/10.1007/978-0-387-68413-0_15"
        ],
        "id": "id1878570210670648184",
        "abstract": "",
        "versions": [
            {
                "year": 0,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Deformable Model-Based Image Registration",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/e7136aecc1ecec7662bf60c93bf02ccff02e5000",
                    "http://www.cs.kent.edu/~lucc/69995/JundongChapterVersion-1.pdf"
                ],
                "doi": "10.1007/978-0-387-68413-0_15",
                "publication_date": "None"
            }
        ],
        "rank": 63
    },
    {
        "authors": [
            "Sahni, M.",
            "Sahni, R.",
            "M Merigo, J."
        ],
        "title": "Neural Networks, Machine Learning, and Image Processing",
        "publication_date": "2022-11-03 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1201/9781003303053",
        "urls": [
            "http://dx.doi.org/10.1201/9781003303053"
        ],
        "id": "id-3681516035538187302",
        "abstract": "",
        "versions": [
            {
                "year": 2022,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Neural Networks, Machine Learning, and Image Processing",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/483063757090aefe76a215936a57207cb2428aeb"
                ],
                "doi": "10.1201/9781003303053",
                "publication_date": "2022-11-03 00:00:00"
            }
        ],
        "rank": 64
    },
    {
        "authors": [
            "Alhussein Fawzi",
            "Horst Samulowitz",
            "D. Turaga",
            "P. Frossard"
        ],
        "title": "Image inpainting through neural networks hallucinations",
        "publication_date": "2016-07-11 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/IVMSPW.2016.7528221",
        "urls": [
            "https://www.semanticscholar.org/paper/ea9f0d5bb700ddb6d6e3c53d9050b48c0210cb73"
        ],
        "id": "id-6155605499613025966",
        "abstract": "We consider in this paper the problem of image inpainting, where the objective is to reconstruct large continuous regions of missing or deteriorated parts of an image. Traditional in-painting algorithms are unfortunately not well adapted to handle such corruptions as they rely on image processing techniques that cannot properly infer missing information when the corrupted holes are too large. To tackle this problem, we propose a novel approach where we rely on the hallucinations of pre-trained neural networks to fill large holes in images. To generate globally coherent images, we further impose smoothness and consistency regularization, thereby constraining the neural network hallucinations. Through illustrative experiments, we show that pre-trained neural networks contain crucial prior information that can effectively guide the reconstruction process of complex inpainting problems.",
        "versions": [
            {
                "year": 2016,
                "source": "SupportedSources.CROSSREF",
                "title": "Image inpainting through neural networks hallucinations",
                "journal": "",
                "urls": [
                    "http://xplorestaging.ieee.org/ielx7/7518124/7528174/07528221.pdf?arnumber=7528221",
                    "http://dx.doi.org/10.1109/ivmspw.2016.7528221"
                ],
                "doi": "10.1109/ivmspw.2016.7528221",
                "publication_date": "2016-01-01 00:00:00"
            }
        ],
        "rank": 65
    },
    {
        "authors": [
            "S. Perry",
            "L. Guan"
        ],
        "title": "Weight assignment for adaptive image restoration by neural networks",
        "publication_date": "None",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "IEEE transactions on neural networks",
        "volume": "11 1",
        "doi": "10.1109/72.822518",
        "urls": [
            "https://www.semanticscholar.org/paper/9bb8913c550d7e053c2d3214981b0d38d53deb05"
        ],
        "id": "id-4132550598810024294",
        "abstract": "This paper presents a scheme for adaptively training the weights, in terms of varying the regularization parameter, in a neural network for the restoration of digital images. The flexibility of neural-network-based image restoration algorithms easily allow the variation of restoration parameters such as blur statistics and regularization value spatially and temporally within the image. This paper focuses on spatial variation of the regularization parameter.We first show that the previously proposed neural-network method based on gradient descent can only find suboptimal solutions, and then introduce a regional processing approach based on local statistics. A method is presented to vary the regularization parameter spatially. This method is applied to a number of images degraded by various levels of noise, and the results are examined. The method is also applied to an image degraded by spatially variant blur. In all cases, the proposed method provides visually satisfactory results in an efficient way.",
        "versions": [
            {
                "year": 2000,
                "source": "SupportedSources.CROSSREF",
                "title": "Weight assignment for adaptive image restoration by neural networks",
                "journal": "",
                "urls": [
                    "http://xplorestaging.ieee.org/ielx5/72/17821/00822518.pdf?arnumber=822518",
                    "http://dx.doi.org/10.1109/72.822518"
                ],
                "doi": "10.1109/72.822518",
                "publication_date": "2000-01-01 00:00:00"
            }
        ],
        "rank": 66
    },
    {
        "authors": [
            "Bashkirova, D."
        ],
        "title": "Convolutional Neural Networks for Image Steganalysis",
        "publication_date": "2016-08-02 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/s12668-016-0215-z",
        "urls": [
            "http://link.springer.com/content/pdf/10.1007/s12668-016-0215-z.pdf",
            "http://link.springer.com/article/10.1007/s12668-016-0215-z/fulltext.html",
            "http://link.springer.com/content/pdf/10.1007/s12668-016-0215-z",
            "http://dx.doi.org/10.1007/s12668-016-0215-z"
        ],
        "id": "id-8495409112578463333",
        "abstract": "",
        "versions": [
            {
                "year": 2016,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Convolutional Neural Networks for Image Steganalysis",
                "journal": "BioNanoScience",
                "urls": [
                    "https://www.semanticscholar.org/paper/ff1ce894d4d6c7fb638d6d4090259cbb8cdc55e5"
                ],
                "doi": "10.1007/s12668-016-0215-z",
                "publication_date": "2016-08-02 00:00:00"
            }
        ],
        "rank": 67
    },
    {
        "authors": [
            "Jeripothula Prudviraj",
            "Vishnu Chalavadi",
            "C. Mohan"
        ],
        "title": "Attentive Contextual Network for Image Captioning",
        "publication_date": "2021-07-18 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/IJCNN52387.2021.9533970",
        "urls": [
            "https://www.semanticscholar.org/paper/6d9c777c870cb31399971a3bc3d49bfe8b1b820c"
        ],
        "id": "id-1883592907475228851",
        "abstract": "Existing image captioning approaches fail to generate fine-grained captions due to the lack of rich encoding representation of an image. In this paper, we present an attentive contextual network (ACN) to learn the spatially transformed image features and dense multi-scale contextual information of an image to generate semantically meaningful captions. At first, we construct deformable network on intermediate layers of convolutional neural network (CNN) to cultivate spatial invariant features. And the multi-scale contextual features are produced by employing contextual network on top of last layers of CNN. Then, we exploit attention mechanism on contextual network to extract dense contextual features. Further, the extracted spatial and contextual features are combined to encode the holistic representation of an image. Finally, a multi-stage caption decoder with visual attention module is incorporated to generate fine-grained captions. The performance of the proposed approach is demonstrated on COCO dataset, the largest dataset for image captioning.",
        "versions": [],
        "rank": 68
    },
    {
        "authors": [
            "Yuanwei Wang",
            "Mei Yu",
            "G. Jiang",
            "Zhiyong Pan",
            "Jiqiang Lin"
        ],
        "title": "Image Registration Algorithm Based on Convolutional Neural Network and Local Homography Transformation",
        "publication_date": "2020-01-21 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.3390/app10030732",
        "urls": [
            "https://www.semanticscholar.org/paper/7b9bfbe4ce287ee21c3d0ebbb46560a64c4040c2",
            "https://www.mdpi.com/2076-3417/10/3/732/pdf?version=1580809798"
        ],
        "id": "id-7027400222285569494",
        "abstract": "In order to overcome the poor robustness of traditional image registration algorithms in illuminating and solving the problem of low accuracy of a learning-based image homography matrix estimation algorithm, an image registration algorithm based on convolutional neural network (CNN) and local homography transformation is proposed. Firstly, to ensure the diversity of samples, a sample and label generation method based on moving direct linear transformation (MDLT) is designed. The generated samples and labels can effectively reflect the local characteristics of images and are suitable for training the CNN model with which multiple pairs of local matching points between two images to be registered can be calculated. Then, the local homography matrices between the two images are estimated by using the MDLT and finally the image registration can be realized. The experimental results show that the proposed image registration algorithm achieves higher accuracy than other commonly used algorithms such as the SIFT, ORB, ECC, and APAP algorithms, as well as another two learning-based algorithms, and it has good robustness for different types of illumination imaging.",
        "versions": [
            {
                "year": 2020,
                "source": "SupportedSources.INTERNET_ARCHIVE",
                "title": "Image Registration Algorithm Based on Convolutional Neural Network and Local Homography Transformation",
                "journal": "MDPI AG",
                "urls": [
                    "https://web.archive.org/web/20200217010450/https://res.mdpi.com/d_attachment/applsci/applsci-10-00732/article_deploy/applsci-10-00732-v2.pdf"
                ],
                "doi": "10.3390/app10030732",
                "publication_date": "2020-01-21 00:00:00"
            }
        ],
        "rank": 69
    },
    {
        "authors": [
            "Fanfani, M.",
            "Piva, A.",
            "Colombo, C."
        ],
        "title": "PRNU registration under scale and rotation transform based on convolutional neural networks",
        "publication_date": "2022-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1016/j.patcog.2021.108413",
        "urls": [
            "https://api.elsevier.com/content/article/PII:S0031320321005896?httpAccept=text/xml",
            "https://api.elsevier.com/content/article/PII:S0031320321005896?httpAccept=text/plain",
            "http://dx.doi.org/10.1016/j.patcog.2021.108413"
        ],
        "id": "id1730101144791271019",
        "abstract": "",
        "versions": [
            {
                "year": 2021,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "PRNU registration under scale and rotation transform based on convolutional neural networks",
                "journal": "Pattern Recognit.",
                "urls": [
                    "https://www.semanticscholar.org/paper/f28c3ce5994d90c0c6986af15e9980aaa3016cff",
                    "https://flore.unifi.it/bitstream/2158/1247437/4/1-s2.0-S0031320321005896-main.pdf"
                ],
                "doi": "10.1016/j.patcog.2021.108413",
                "publication_date": "2021-11-01 00:00:00"
            }
        ],
        "rank": 70
    },
    {
        "authors": [
            "H. Sarnel",
            "Y. Senol"
        ],
        "title": "Accurate affine image registration using radial basis neural networks",
        "publication_date": "2008-05-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "6",
        "doi": "10.21608/ICEENG.2008.34357",
        "urls": [
            "https://www.semanticscholar.org/paper/afbae8c22437bdcd6558486a1b0b200f65d2bfcd",
            "http://iceeng.journals.ekb.eg/article_34357_80c1e83071ce81dc54ec011880d0c763.pdf"
        ],
        "id": "id-7365631546676487020",
        "abstract": null,
        "versions": [
            {
                "year": 2008,
                "source": "SupportedSources.CROSSREF",
                "title": "Accurate affine image registration using radial basis neural networks",
                "journal": "",
                "urls": [
                    "http://iceeng.journals.ekb.eg/article_34357_80c1e83071ce81dc54ec011880d0c763.pdf",
                    "http://dx.doi.org/10.21608/iceeng.2008.34357"
                ],
                "doi": "10.21608/iceeng.2008.34357",
                "publication_date": "2008-05-01 00:00:00"
            }
        ],
        "rank": 71
    },
    {
        "authors": [
            "Liu, D.",
            "Wang, Z."
        ],
        "title": "A Method of X-Ray Image Recognition Based on Fuzzy Rule and Parallel Neural Networks",
        "publication_date": "None",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/978-3-540-72393-6_145",
        "urls": [
            "http://link.springer.com/content/pdf/10.1007/978-3-540-72393-6_145.pdf",
            "http://dx.doi.org/10.1007/978-3-540-72393-6_145"
        ],
        "id": "id728223158157907900",
        "abstract": "",
        "versions": [
            {
                "year": 2007,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "A Method of X-Ray Image Recognition Based on Fuzzy Rule and Parallel Neural Networks",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/3ddc17359be25bd0b519663281d942c73b03daba"
                ],
                "doi": "10.1007/978-3-540-72393-6_145",
                "publication_date": "2007-06-03 00:00:00"
            }
        ],
        "rank": 72
    },
    {
        "authors": [
            "Dongming Zhou",
            "Canlong Zhang",
            "Zhixin Li",
            "Zhiwen Wang"
        ],
        "title": "Multi-level Visual Fusion Networks for Image Captioning",
        "publication_date": "2020-07-01 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/IJCNN48605.2020.9206932",
        "urls": [
            "https://www.semanticscholar.org/paper/a32ac0995afcbc748fa6533b941e9834ec7bfc2e"
        ],
        "id": "id-7322899872251701867",
        "abstract": "Image captioning is a multi-modal complex task in machine learning. Traditional methods focus only on entities in visual strategy networks, and can\u2019t reason about the relationship between entities and attributes. There are problems of exposure bias and error accumulation in language strategy networks. To this end, this paper proposes a multi-level visual fusion network model based on reinforcement learning. In the visual strategy network, multi-level neural network modules are used to transform visual features into feature sets of visual knowledge. The fusion network generates function words that make the description more fluent, and is used for the interaction between the visual strategy network and the language strategy network. The self-criticism strategy gradient algorithm based on reinforcement learning in language strategy networks is used to achieve end-to-end optimization of visual fusion networks. We evaluated our model on the Flickr 30K and MS-COCO datasets, and verified the accuracy of the model and the diversity of model learning subtitles through experiments. Our model achieves better performance over state-of-the-art methods.",
        "versions": [
            {
                "year": 2020,
                "source": "SupportedSources.CROSSREF",
                "title": "Multi-level Visual Fusion Networks for Image Captioning",
                "journal": "",
                "urls": [
                    "http://xplorestaging.ieee.org/ielx7/9200848/9206590/09206932.pdf?arnumber=9206932",
                    "http://dx.doi.org/10.1109/ijcnn48605.2020.9206932"
                ],
                "doi": "10.1109/ijcnn48605.2020.9206932",
                "publication_date": "2020-01-01 00:00:00"
            }
        ],
        "rank": 73
    },
    {
        "authors": [
            "Junyu Chen",
            "Ye Li",
            "E. Frey"
        ],
        "title": "Generating Patient-like Phantoms Using Fully Unsupervised Deformable Image Registration with Convolutional Neural Networks",
        "publication_date": "2019-12-06 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "ArXiv",
        "volume": "abs/1912.02942",
        "doi": "",
        "urls": [
            "https://www.semanticscholar.org/paper/be1a4a018df5c75244d39df70b4076604adfbd04"
        ],
        "id": "id6636480947215017843",
        "abstract": "The use of Convolutional neural networks (ConvNets) in medical imaging research has become widespread in recent years. However, a major drawback of these methods is that they require a large number of annotated training images. Data augmentation has been proposed to alleviate this. One data augmentation strategy is to apply random deformation to existing image data, but the deformed images often will not follow exhibit realistic shape or intensity patterns. In this paper, we present a novel, ConvNet based image registration method for creating patient-like digital phantoms from the existing computerized phantoms. Unlike existing learning-based registration techniques, for which the performance predominantly depends on the domain-specific training images, the proposed method is fully unsupervised, meaning that it optimizes an objective function independently of training data for a given image pair. While classical methods registration also do not require training data, they work in lower-dimensional parameter space; the proposed approach operates directly in the high-dimensional parameter space without any training beforehand. In this paper, we show that the resulting deformed phantom competently matches the anatomy model of a real human while providing the \"gold-standard\" for the anatomies. Combined with simulation programs, the generated phantoms could potentially serve as a data augmentation tool in today's deep learning studies.",
        "versions": [],
        "rank": 74
    },
    {
        "authors": [
            "Famao Ye",
            "W. Luo",
            "Yanfei Su",
            "Xuqing Zhao",
            "Hui Xiao",
            "Weidong Min"
        ],
        "title": "Application of convolutional neural network feature to remote sensing image registration",
        "publication_date": "2019-05-23 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Remote Sensing for Land & Resources",
        "volume": "31",
        "doi": "10.6046/GTZYYG.2019.02.05",
        "urls": [
            "https://www.semanticscholar.org/paper/604a05560368d8cd4ed14c8a9a9bc124bb69b796"
        ],
        "id": "id2237069305601404876",
        "abstract": null,
        "versions": [
            {
                "year": 2019,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Application of convolutional neural network feature to remote sensing image registration",
                "journal": "Remote Sensing for Land & Resources",
                "urls": [
                    "https://www.semanticscholar.org/paper/604a05560368d8cd4ed14c8a9a9bc124bb69b796"
                ],
                "doi": "10.6046/GTZYYG.2019.02.05",
                "publication_date": "2019-05-23 00:00:00"
            }
        ],
        "rank": 75
    },
    {
        "authors": [],
        "title": "Edge Detection Using Model-Based Neural Networks",
        "publication_date": "2001-12-21 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1201/9781420042269.ch8",
        "urls": [
            "http://dx.doi.org/10.1201/9781420042269.ch8"
        ],
        "id": "id796121442059404658",
        "abstract": "",
        "versions": [
            {
                "year": 2001,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Edge Detection Using Model-Based Neural Networks",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/799d0bccab002b62498d559578d64df606980b3c"
                ],
                "doi": "10.1201/9781420042269.CH8",
                "publication_date": "2001-12-21 00:00:00"
            }
        ],
        "rank": 76
    },
    {
        "authors": [
            "Adali, T.",
            "Wang, Y.",
            "Li, H."
        ],
        "title": "Applications of Neural Networks to Biomedical Image Processing",
        "publication_date": "2018-10-03 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1201/9781315220413-12",
        "urls": [
            "http://dx.doi.org/10.1201/9781315220413-12"
        ],
        "id": "id-8457135042233925834",
        "abstract": "",
        "versions": [
            {
                "year": 2018,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Applications of Neural Networks to Biomedical Image Processing",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/470a89a721e936b3c527181487328476b9271aae"
                ],
                "doi": "10.1201/9781315220413-12",
                "publication_date": "2018-10-03 00:00:00"
            }
        ],
        "rank": 77
    },
    {
        "authors": [
            "Danyang Cao",
            "Zhixin Chen",
            "Lei Gao"
        ],
        "title": "An improved object detection algorithm based on multi-scaled and deformable convolutional neural networks",
        "publication_date": "2020-04-11 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Human-centric Computing and Information Sciences",
        "volume": "10",
        "doi": "10.1186/s13673-020-00219-9",
        "urls": [
            "https://www.semanticscholar.org/paper/3530963234161950ba2aef95b6a2b8ce329f0da9"
        ],
        "id": "id-2242391794060551135",
        "abstract": null,
        "versions": [],
        "rank": 78
    },
    {
        "authors": [
            "Mali Halac",
            "Murat Isik",
            "Hasan Ayaz",
            "Anup Das"
        ],
        "title": "Multiscale Voxel Based Decoding For Enhanced Natural Image Reconstruction From Brain Activity",
        "publication_date": "2022-05-27 18:09:07+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2205.14177v1",
            "http://arxiv.org/abs/2205.14177v1",
            "http://arxiv.org/pdf/2205.14177v1"
        ],
        "id": "id4065192639289274533",
        "abstract": "Reconstructing perceived images from human brain activity monitored by\nfunctional magnetic resonance imaging (fMRI) is hard, especially for natural\nimages. Existing methods often result in blurry and unintelligible\nreconstructions with low fidelity. In this study, we present a novel approach\nfor enhanced image reconstruction, in which existing methods for object\ndecoding and image reconstruction are merged together. This is achieved by\nconditioning the reconstructed image to its decoded image category using a\nclass-conditional generative adversarial network and neural style transfer. The\nresults indicate that our approach improves the semantic similarity of the\nreconstructed images and can be used as a general framework for enhanced image\nreconstruction.",
        "versions": [],
        "rank": 79
    },
    {
        "authors": [
            "Srivastava, S.",
            "Lall, B."
        ],
        "title": "Brain-Inspired Machine Intelligence for Image Analysis: Convolutional Neural Networks",
        "publication_date": "2017-08-14 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1002/9781119242963.ch6",
        "urls": [
            "https://api.wiley.com/onlinelibrary/tdm/v1/articles/10.1002%2F9781119242963.ch6",
            "https://onlinelibrary.wiley.com/doi/full/10.1002/9781119242963.ch6",
            "http://dx.doi.org/10.1002/9781119242963.ch6"
        ],
        "id": "id-1573925970375617288",
        "abstract": "",
        "versions": [
            {
                "year": 2017,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Brain-Inspired Machine Intelligence for Image Analysis: Convolutional Neural Networks",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/0d6c77b08bcdad80221f5c9645cbb9cad144650f"
                ],
                "doi": "10.1002/9781119242963.CH6",
                "publication_date": "2017-08-14 00:00:00"
            }
        ],
        "rank": 80
    },
    {
        "authors": [
            "Bhavin Choksi",
            "Milad Mozafari",
            "Callum Biggs O'May",
            "Benjamin Ador",
            "Andrea Alamia",
            "Rufin VanRullen"
        ],
        "title": "Predify: Augmenting deep neural networks with brain-inspired predictive coding dynamics",
        "publication_date": "2021-06-04 22:48:13+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2106.02749v2",
            "http://arxiv.org/abs/2106.02749v2",
            "http://arxiv.org/pdf/2106.02749v2"
        ],
        "id": "id-6024416234537397398",
        "abstract": "Deep neural networks excel at image classification, but their performance is\nfar less robust to input perturbations than human perception. In this work we\nexplore whether this shortcoming may be partly addressed by incorporating\nbrain-inspired recurrent dynamics in deep convolutional networks. We take\ninspiration from a popular framework in neuroscience: 'predictive coding'. At\neach layer of the hierarchical model, generative feedback 'predicts' (i.e.,\nreconstructs) the pattern of activity in the previous layer. The reconstruction\nerrors are used to iteratively update the network's representations across\ntimesteps, and to optimize the network's feedback weights over the natural\nimage dataset-a form of unsupervised training. We show that implementing this\nstrategy into two popular networks, VGG16 and EfficientNetB0, improves their\nrobustness against various corruptions and adversarial attacks. We hypothesize\nthat other feedforward networks could similarly benefit from the proposed\nframework. To promote research in this direction, we provide an open-sourced\nPyTorch-based package called Predify, which can be used to implement and\ninvestigate the impacts of the predictive coding dynamics in any convolutional\nneural network.",
        "versions": [],
        "rank": 81
    },
    {
        "authors": [
            "A. Zhu",
            "Tian Wang",
            "H. Snoussi"
        ],
        "title": "Hierarchical graphical-based human pose estimation via local multi-resolution convolutional neural network",
        "publication_date": "2018-03-20 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "AIP Advances",
        "volume": "8",
        "doi": "10.1063/1.5024463",
        "urls": [
            "https://www.semanticscholar.org/paper/03968973b0bd4842c7d24fb96a7893242c7aa6ff",
            "https://aip.scitation.org/doi/pdf/10.1063/1.5024463"
        ],
        "id": "id-6516204616627792759",
        "abstract": "This paper addresses the problems of the graphical-based human pose estimation in still images, including the diversity of appearances and confounding background clutter. We present a new architecture for estimating human pose using a Convolutional Neural Network (CNN). Firstly, a Relative Mixture Deformable Model (RMDM) is defined by each pair of connected parts to compute the relative spatial information in the graphical model. Secondly, a Local Multi-Resolution Convolutional Neural Network (LMR-CNN) is proposed to train and learn the multi-scale representation of each body parts by combining different levels of part context. Thirdly, a LMR-CNN based hierarchical model is defined to explore the context information of limb parts. Finally, the experimental results demonstrate the effectiveness of the proposed deep learning approach for human pose estimation.",
        "versions": [],
        "rank": 82
    },
    {
        "authors": [
            "Gary Tam",
            "Michael Edwards",
            "Robert Palmer",
            "Xianghua Xie"
        ],
        "title": "Graph convolutional neural network for multi-scale feature learning",
        "publication_date": "2019-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1016/j.cviu.2019.102881",
        "urls": [
            "https://core.ac.uk/download/266980797.pdf"
        ],
        "id": "id2167200526147469710",
        "abstract": null,
        "versions": [
            {
                "year": 2020,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Graph convolutional neural network for multi-scale feature learning",
                "journal": "Comput. Vis. Image Underst.",
                "urls": [
                    "https://www.semanticscholar.org/paper/325383d6eb4343f00fe317358bd48f0b5c84ca09",
                    "https://cronfa.swan.ac.uk/Record/cronfa52916/Download/52916__16177__3df04b90fbf8434fb8587c617587723d.pdf"
                ],
                "doi": "10.1016/j.cviu.2019.102881",
                "publication_date": "2020-05-01 00:00:00"
            }
        ],
        "rank": 83
    },
    {
        "authors": [
            "Dhara, A.",
            "Bagaini, C."
        ],
        "title": "Seismic Registration Using Convolutional Neural Networks",
        "publication_date": "2021-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.3997/2214-4609.202011141",
        "urls": [
            "http://dx.doi.org/10.3997/2214-4609.202011141"
        ],
        "id": "id-1413477559511203205",
        "abstract": "",
        "versions": [
            {
                "year": 0,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Seismic Registration Using Convolutional Neural Networks",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/6bbf8b931eb6ec94c4f56c482e820c720bd984da"
                ],
                "doi": "10.3997/2214-4609.202011141",
                "publication_date": "None"
            }
        ],
        "rank": 84
    },
    {
        "authors": [
            "Matan Atzmon",
            "David Novotny",
            "Andrea Vedaldi",
            "Yaron Lipman"
        ],
        "title": "Augmenting Implicit Neural Shape Representations with Explicit Deformation Fields",
        "publication_date": "2021-08-19 00:00:00",
        "source": "SupportedSources.INTERNET_ARCHIVE",
        "journal": "",
        "volume": "",
        "doi": "",
        "urls": [
            "https://web.archive.org/web/20210826002227/https://arxiv.org/pdf/2108.08931v1.pdf"
        ],
        "id": "id5013290118567902877",
        "abstract": "Implicit neural representation is a recent approach to learn shape collections as zero level-sets of neural networks, where each shape is represented by a latent code. So far, the focus has been shape reconstruction, while shape generalization was mostly left to generic encoder-decoder or auto-decoder regularization. In this paper we advocate deformation-aware regularization for implicit neural representations, aiming at producing plausible deformations as latent code changes. The challenge is that implicit representations do not capture correspondences between different shapes, which makes it difficult to represent and regularize their deformations. Thus, we propose to pair the implicit representation of the shapes with an explicit, piecewise linear deformation field, learned as an auxiliary function. We demonstrate that, by regularizing these deformation fields, we can encourage the implicit neural representation to induce natural deformations in the learned shape space, such as as-rigid-as-possible deformations.",
        "versions": [
            {
                "year": 2021,
                "source": "SupportedSources.ARXIV",
                "title": "Augmenting Implicit Neural Shape Representations with Explicit Deformation Fields",
                "journal": null,
                "urls": [
                    "http://arxiv.org/pdf/2108.08931v1",
                    "http://arxiv.org/abs/2108.08931v1",
                    "http://arxiv.org/pdf/2108.08931v1"
                ],
                "doi": "",
                "publication_date": "2021-08-19 22:07:08+00:00"
            }
        ],
        "rank": 85
    },
    {
        "authors": [
            "Zhang, Y.",
            "Shi, L.",
            "Wu, Y.",
            "Cheng, K.",
            "Cheng, J.",
            "Lu, H."
        ],
        "title": "Gesture recognition based on deep deformable 3D convolutional neural networks",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1016/j.patcog.2020.107416",
        "urls": [
            "https://api.elsevier.com/content/article/PII:S0031320320302193?httpAccept=text/xml",
            "https://api.elsevier.com/content/article/PII:S0031320320302193?httpAccept=text/plain",
            "http://dx.doi.org/10.1016/j.patcog.2020.107416"
        ],
        "id": "id2528813082401862589",
        "abstract": "",
        "versions": [
            {
                "year": 2020,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Gesture recognition based on deep deformable 3D convolutional neural networks",
                "journal": "Pattern Recognit.",
                "urls": [
                    "https://www.semanticscholar.org/paper/ec7cbc6ef1599bff31816c003d18821fcf6d1bde"
                ],
                "doi": "10.1016/j.patcog.2020.107416",
                "publication_date": "2020-11-01 00:00:00"
            }
        ],
        "rank": 86
    },
    {
        "authors": [
            "Aaron Hertzmann"
        ],
        "title": "Aesthetics of Neural Network Art",
        "publication_date": "2019-03-13 19:45:54+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1903.05696v2",
            "http://arxiv.org/abs/1903.05696v2",
            "http://arxiv.org/pdf/1903.05696v2"
        ],
        "id": "id-3938733527338250211",
        "abstract": "This paper proposes a way to understand neural network artworks as\njuxtapositions of natural image cues. It is hypothesized that images with\nunusual combinations of realistic visual cues are interesting, and, neural\nmodels trained to model natural images are well-suited to creating interesting\nimages. Art using neural models produces new images similar to those of natural\nimages, but with weird and intriguing variations. This analysis is applied to\nneural art based on Generative Adversarial Networks, image stylization, Deep\nDreams, and Perception Engines.",
        "versions": [],
        "rank": 87
    },
    {
        "authors": [
            "Teuwen, J.",
            "Moriakov, N."
        ],
        "title": "Convolutional neural networks",
        "publication_date": "2020-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1016/b978-0-12-816176-0.00025-9",
        "urls": [
            "https://api.elsevier.com/content/article/PII:B9780128161760000259?httpAccept=text/xml",
            "https://api.elsevier.com/content/article/PII:B9780128161760000259?httpAccept=text/plain",
            "http://dx.doi.org/10.1016/b978-0-12-816176-0.00025-9"
        ],
        "id": "id5283563841241919382",
        "abstract": "",
        "versions": [
            {
                "year": 0,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Convolutional neural networks",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/4f36ca4e813f7913d2b94edced1b35b05670c8cb"
                ],
                "doi": "10.1016/b978-0-12-816176-0.00025-9",
                "publication_date": "None"
            }
        ],
        "rank": 88
    },
    {
        "authors": [
            "Nie, Z.",
            "Li, C.",
            "Liu, H.",
            "Yang, X."
        ],
        "title": "Deformable Image Registration Based on Functions of Bounded Generalized Deformation",
        "publication_date": "2021-02-04 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1007/s11263-021-01439-x",
        "urls": [
            "https://link.springer.com/content/pdf/10.1007/s11263-021-01439-x.pdf",
            "https://link.springer.com/article/10.1007/s11263-021-01439-x/fulltext.html",
            "https://link.springer.com/content/pdf/10.1007/s11263-021-01439-x.pdf",
            "http://dx.doi.org/10.1007/s11263-021-01439-x"
        ],
        "id": "id3311702325082962236",
        "abstract": "",
        "versions": [
            {
                "year": 2021,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Deformable Image Registration Based on Functions of Bounded Generalized Deformation",
                "journal": "International Journal of Computer Vision",
                "urls": [
                    "https://www.semanticscholar.org/paper/2ed543601df7411444160c113271535e60fed6d3"
                ],
                "doi": "10.1007/s11263-021-01439-x",
                "publication_date": "2021-02-04 00:00:00"
            }
        ],
        "rank": 89
    },
    {
        "authors": [
            "Elmahdy, M.S.",
            "Lelieveldt, B.P.F.",
            "Sokooti, H.",
            "Staring, M.",
            "Yousefi, S."
        ],
        "title": "Hierarchical prediction of registration misalignment using a convolutional LSTM: application to chest CT scans",
        "publication_date": "2021-01-01 00:00:00",
        "source": "SupportedSources.CORE",
        "journal": "",
        "volume": "",
        "doi": "10.1109/access.2021.3074124",
        "urls": [
            "https://core.ac.uk/download/493012218.pdf"
        ],
        "id": "id3660661495335053772",
        "abstract": "In this paper we propose a supervised method to predict registration misalignment using convolutional neural networks (CNNs). This task is casted to a classification problem with multiple classes of misalignment: \"correct\" 0-3 mm, \"poor\" 3-6 mm and \"wrong\" over 6 mm. Rather than a direct prediction, we propose a hierarchical approach, where the prediction is gradually refined from coarse to fine. Our solution is based on a convolutional Long Short-Term Memory (LSTM), using hierarchical misalignment predictions on three resolutions of the image pair, leveraging the intrinsic strengths of an LSTM for this problem. The convolutional LSTM is trained on a set of artificially generated image pairs obtained from artificial displacement vector fields (DVFs). Results on chest CT scans show that incorporating multi-resolution information, and the hierarchical use via an LSTM for this, leads to overall better F1 scores, with fewer misclassifications in a well-tuned registration setup. The final system yields an accuracy of 87.1%, and an average F1 score of 66.4% aggregated in two independent chest CT scan studies.Radiolog",
        "versions": [
            {
                "year": 0,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Hierarchical Prediction of Registration Misalignment Using a Convolutional LSTM: Application to Chest CT Scans",
                "journal": "IEEE Access",
                "urls": [
                    "https://www.semanticscholar.org/paper/183cfcd9f3053a1b55836c90df4562b7de100d10",
                    "https://ieeexplore.ieee.org/ielx7/6287639/9312710/09408621.pdf"
                ],
                "doi": "10.1109/ACCESS.2021.3074124",
                "publication_date": "None"
            },
            {
                "year": 2021,
                "source": "SupportedSources.INTERNET_ARCHIVE",
                "title": "Hierarchical Prediction of Registration Misalignment using a Convolutional LSTM: Application to Chest CT Scans",
                "journal": "Institute of Electrical and Electronics Engineers (IEEE)",
                "urls": [
                    "https://web.archive.org/web/20210422165652/https://ieeexplore.ieee.org/ielx7/6287639/6514899/09408621.pdf?tp=&arnumber=9408621&isnumber=6514899&ref="
                ],
                "doi": "10.1109/access.2021.3074124",
                "publication_date": "2021-01-01 00:00:00"
            }
        ],
        "rank": 90
    },
    {
        "authors": [
            "Daniel J. Saunders",
            "Hava T. Siegelmann",
            "Robert Kozma",
            "Mikl\u00f3s Ruszink\u00f3"
        ],
        "title": "STDP Learning of Image Patches with Convolutional Spiking Neural Networks",
        "publication_date": "2018-08-24 15:27:39+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1808.08173v1",
            "http://arxiv.org/abs/1808.08173v1",
            "http://arxiv.org/pdf/1808.08173v1"
        ],
        "id": "id1987071325395716141",
        "abstract": "Spiking neural networks are motivated from principles of neural systems and\nmay possess unexplored advantages in the context of machine learning. A class\nof \\textit{convolutional spiking neural networks} is introduced, trained to\ndetect image features with an unsupervised, competitive learning mechanism.\nImage features can be shared within subpopulations of neurons, or each may\nevolve independently to capture different features in different regions of\ninput space. We analyze the time and memory requirements of learning with and\noperating such networks. The MNIST dataset is used as an experimental testbed,\nand comparisons are made between the performance and convergence speed of a\nbaseline spiking neural network.",
        "versions": [],
        "rank": 91
    },
    {
        "authors": [
            "Abidi, M.",
            "Yasuki, S.",
            "Crilly, P."
        ],
        "title": "Image Compression Using Hybrid Neural Networks",
        "publication_date": "1994-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1109/icce.1994.582157",
        "urls": [
            "http://xplorestaging.ieee.org/ielx2/4451/12624/00582157.pdf?arnumber=582157",
            "http://dx.doi.org/10.1109/icce.1994.582157"
        ],
        "id": "id5918517209262242859",
        "abstract": "",
        "versions": [
            {
                "year": 1994,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Image Compression Using Hybrid Neural Networks",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/f352b5bab55f3f67817ad4ae8be8a729e9efdbdb"
                ],
                "doi": "10.1109/ICCE.1994.582157",
                "publication_date": "1994-06-21 00:00:00"
            }
        ],
        "rank": 92
    },
    {
        "authors": [
            "Xuanyi Dong",
            "Yan Yan",
            "Wanli Ouyang",
            "Yi Yang"
        ],
        "title": "Style Aggregated Network for Facial Landmark Detection",
        "publication_date": "2018-03-12 03:46:12+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/1803.04108v4",
            "http://arxiv.org/abs/1803.04108v4",
            "http://arxiv.org/pdf/1803.04108v4"
        ],
        "id": "id6606211135474903547",
        "abstract": "Recent advances in facial landmark detection achieve success by learning\ndiscriminative features from rich deformation of face shapes and poses. Besides\nthe variance of faces themselves, the intrinsic variance of image styles, e.g.,\ngrayscale vs. color images, light vs. dark, intense vs. dull, and so on, has\nconstantly been overlooked. This issue becomes inevitable as increasing web\nimages are collected from various sources for training neural networks. In this\nwork, we propose a style-aggregated approach to deal with the large intrinsic\nvariance of image styles for facial landmark detection. Our method transforms\noriginal face images to style-aggregated images by a generative adversarial\nmodule. The proposed scheme uses the style-aggregated image to maintain face\nimages that are more robust to environmental changes. Then the original face\nimages accompanying with style-aggregated ones play a duet to train a landmark\ndetector which is complementary to each other. In this way, for each face, our\nmethod takes two images as input, i.e., one in its original style and the other\nin the aggregated style. In experiments, we observe that the large variance of\nimage styles would degenerate the performance of facial landmark detectors.\nMoreover, we show the robustness of our method to the large variance of image\nstyles by comparing to a variant of our approach, in which the generative\nadversarial module is removed, and no style-aggregated images are used. Our\napproach is demonstrated to perform well when compared with state-of-the-art\nalgorithms on benchmark datasets AFLW and 300-W. Code is publicly available on\nGitHub: https://github.com/D-X-Y/SAN",
        "versions": [],
        "rank": 93
    },
    {
        "authors": [
            "Hongyun Ye",
            "Zhanping Yang",
            "Jun Li",
            "Shiling Li"
        ],
        "title": "BP Neural Networks Based Sensor Registration Algorithm",
        "publication_date": "2011-10-21 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ICCIS.2011.107",
        "urls": [
            "https://www.semanticscholar.org/paper/4a02836d44282a38725f471a2d66d5aa24fc2025"
        ],
        "id": "id3823063828135401506",
        "abstract": "In multi-sensor multi-target fusion systems the sensor registration is the major problem which is generally inadequate. The typical registration algorithms are based on statistics, such as LSE, ML etc. and on filtering theory, such as KF, EKF etc. They all are parametric methods namely. We propose a new algorithm that is based on ANN, nonparametric and many different kinds of sensor error variables to be solved. The algorithm is modified by adjusting the learning rate in which fuzzy logic is applied. That is to say, the learning rate of the NN is adaptive.",
        "versions": [
            {
                "year": 2011,
                "source": "SupportedSources.CROSSREF",
                "title": "BP Neural Networks Based Sensor Registration Algorithm",
                "journal": "",
                "urls": [
                    "http://xplorestaging.ieee.org/ielx5/6085643/6086119/06086310.pdf?arnumber=6086310",
                    "http://dx.doi.org/10.1109/iccis.2011.107"
                ],
                "doi": "10.1109/iccis.2011.107",
                "publication_date": "2011-01-01 00:00:00"
            }
        ],
        "rank": 94
    },
    {
        "authors": [
            "Gajraj Kuldeep"
        ],
        "title": "Image Classification using Sequence of Pixels",
        "publication_date": "2022-09-23 09:42:44+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2209.11495v1",
            "http://arxiv.org/abs/2209.11495v1",
            "http://arxiv.org/pdf/2209.11495v1"
        ],
        "id": "id-5456684192543573026",
        "abstract": "This study compares sequential image classification methods based on\nrecurrent neural networks. We describe methods based on recurrent neural\nnetworks such as Long-Short-Term memory(LSTM), bidirectional Long-Short-Term\nmemory(BiLSTM) architectures, etc. We also review the state-of-the-art\nsequential image classification architectures. We mainly focus on LSTM, BiLSTM,\ntemporal convolution network, and independent recurrent neural network\narchitecture in the study. It is known that RNN lacks in learning long-term\ndependencies in the input sequence. We use a simple feature construction method\nusing orthogonal Ramanujan periodic transform on the input sequence.\nExperiments demonstrate that if these features are given to LSTM or BiLSTM\nnetworks, the performance increases drastically.\n  Our focus in this study is to increase the training accuracy simultaneously\nreducing the training time for the LSTM and BiLSTM architecture, but not on\npushing the state-of-the-art results, so we use simple LSTM/BiLSTM\narchitecture. We compare sequential input with the constructed feature as input\nto single layer LSTM and BiLSTM network for MNIST and CIFAR datasets. We\nobserve that sequential input to the LSTM network with 128 hidden unit training\nfor five epochs results in training accuracy of 33% whereas constructed\nfeatures as input to the same LSTM network results in training accuracy of 90%\nwith 1/3 lesser time.",
        "versions": [],
        "rank": 95
    },
    {
        "authors": [
            "Kumar, A.",
            "Tesfaye Jule, L.",
            "Ramaswamy, K.",
            "Sountharrajan, S.",
            "Yuuvaraj, N.",
            "Gandomi, A."
        ],
        "title": "Analysis of false data detection rate in generative adversarial networks using recurrent neural network",
        "publication_date": "2021-01-01 00:00:00",
        "source": "SupportedSources.CROSSREF",
        "journal": "",
        "volume": "",
        "doi": "10.1016/b978-0-12-823519-5.00012-9",
        "urls": [
            "https://api.elsevier.com/content/article/PII:B9780128235195000129?httpAccept=text/xml",
            "https://api.elsevier.com/content/article/PII:B9780128235195000129?httpAccept=text/plain",
            "http://dx.doi.org/10.1016/b978-0-12-823519-5.00012-9"
        ],
        "id": "id4231243138716478540",
        "abstract": "",
        "versions": [
            {
                "year": 0,
                "source": "SupportedSources.SEMANTIC_SCHOLAR",
                "title": "Analysis of false data detection rate in generative adversarial networks using recurrent neural network",
                "journal": "",
                "urls": [
                    "https://www.semanticscholar.org/paper/3f20fe77eb3f84025a01082bfe3c1a09f7b2f252"
                ],
                "doi": "10.1016/b978-0-12-823519-5.00012-9",
                "publication_date": "None"
            }
        ],
        "rank": 96
    },
    {
        "authors": [
            "Qingguang Li",
            "Cen Gao",
            "Xianfeng Wu",
            "Dehua Li"
        ],
        "title": "A method for range image registration via neural network and ICP algorithm",
        "publication_date": "2010-09-28 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "Wuhan University Journal of Natural Sciences",
        "volume": "15",
        "doi": "10.1007/s11859-010-0673-z",
        "urls": [
            "https://www.semanticscholar.org/paper/3da165cf69e0f8f4169d2ce08db1d02eb0740c9f"
        ],
        "id": "id7860993983820469019",
        "abstract": null,
        "versions": [],
        "rank": 97
    },
    {
        "authors": [
            "Motasem Alfarra",
            "Adel Bibi",
            "Naeemullah Khan",
            "Philip H. S. Torr",
            "Bernard Ghanem"
        ],
        "title": "DeformRS: Certifying Input Deformations with Randomized Smoothing",
        "publication_date": "2021-07-02 12:20:15+00:00",
        "source": "SupportedSources.ARXIV",
        "journal": null,
        "volume": "",
        "doi": "",
        "urls": [
            "http://arxiv.org/pdf/2107.00996v2",
            "http://arxiv.org/abs/2107.00996v2",
            "http://arxiv.org/pdf/2107.00996v2"
        ],
        "id": "id-4641170860455459952",
        "abstract": "Deep neural networks are vulnerable to input deformations in the form of\nvector fields of pixel displacements and to other parameterized geometric\ndeformations e.g. translations, rotations, etc. Current input deformation\ncertification methods either 1. do not scale to deep networks on large input\ndatasets, or 2. can only certify a specific class of deformations, e.g. only\nrotations. We reformulate certification in randomized smoothing setting for\nboth general vector field and parameterized deformations and propose\nDeformRS-VF and DeformRS-Par, respectively. Our new formulation scales to large\nnetworks on large input datasets. For instance, DeformRS-Par certifies rich\ndeformations, covering translations, rotations, scaling, affine deformations,\nand other visually aligned deformations such as ones parameterized by\nDiscrete-Cosine-Transform basis. Extensive experiments on MNIST, CIFAR10, and\nImageNet show competitive performance of DeformRS-Par achieving a certified\naccuracy of $39\\%$ against perturbed rotations in the set\n$[-10\\degree,10\\degree]$ on ImageNet.",
        "versions": [],
        "rank": 98
    },
    {
        "authors": [
            "Michael Blot",
            "M. Cord",
            "Nicolas Thome"
        ],
        "title": "Max-min convolutional neural networks for image classification",
        "publication_date": "2016-08-19 00:00:00",
        "source": "SupportedSources.SEMANTIC_SCHOLAR",
        "journal": "",
        "volume": "",
        "doi": "10.1109/ICIP.2016.7533046",
        "urls": [
            "https://www.semanticscholar.org/paper/8e94bc5ee1a4cfe890fbc0920818a25e6f59fef8",
            "http://arxiv.org/pdf/1610.07882"
        ],
        "id": "id-4950475107790681544",
        "abstract": "Convolutional neural networks (CNN) are widely used in computer vision, especially in image classification. However, the way in which information and invariance properties are encoded through in deep CNN architectures is still an open question. In this paper, we propose to modify the standard convolutional block of CNN in order to transfer more information layer after layer while keeping some invariance within the network. Our main idea is to exploit both positive and negative high scores obtained in the convolution maps. This behavior is obtained by modifying the traditional activation function step before pooling. We are doubling the maps with specific activations functions, called MaxMin strategy, in order to achieve our pipeline. Extensive experiments on two classical datasets, MNIST and CIFAR-10, show that our deep MaxMin convolutional net outperforms standard CNN.",
        "versions": [
            {
                "year": 2016,
                "source": "SupportedSources.CROSSREF",
                "title": "Max-min convolutional neural networks for image classification",
                "journal": "",
                "urls": [
                    "http://xplorestaging.ieee.org/ielx7/7527113/7532277/07533046.pdf?arnumber=7533046",
                    "http://dx.doi.org/10.1109/icip.2016.7533046"
                ],
                "doi": "10.1109/icip.2016.7533046",
                "publication_date": "2016-01-01 00:00:00"
            }
        ],
        "rank": 99
    }
]