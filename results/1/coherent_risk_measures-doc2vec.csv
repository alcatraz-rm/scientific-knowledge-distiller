authors,title,pub_date,source,doi,abstract,rank,url
Ju Hong Kim,THE MAXIMAL PRIOR SET IN THE REPRESENTATION OF COHERENT RISK MEASURE,2016-11-30 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.7468/JKSMEB.2016.23.4.377,"The set of priors in the representation of coherent risk measure is expressed in terms of quantile function and increasing concave function. We show that the set of prior, Qc in (1.2) is equal to the set of Qm in (1.6), as maximal representing set Qmax defined in (1.7).",0,"https://www.semanticscholar.org/paper/5c0f3ae5650918813f339bfee61a36c7d1b95b7f
http://society.kisti.re.kr/sv/SV_svpsbs03V.do?method=download&cn1=JAKO201608259726729"
"Patel, H.,Hapani, K.,Dave, J.",Stakeholders’ perspective in implementation of additional risk minimisation measures: Reflection on challenges &amp; solutions,2020-03-02 00:00:00,SupportedSources.CROSSREF,10.26226/morressier.5e20352214799ab1e7e07b0a,,1,http://dx.doi.org/10.26226/morressier.5e20352214799ab1e7e07b0a
"Strbac, Goran,Tindemans, Simon H.",Robust estimation of risks from small samples,2017-04-05 00:00:00,SupportedSources.CORE,10.1098/rsta.2016.0299,"Data-driven risk analysis involves the inference of probability distributions
from measured or simulated data. In the case of a highly reliable system, such
as the electricity grid, the amount of relevant data is often exceedingly
limited, but the impact of estimation errors may be very large. This paper
presents a robust nonparametric Bayesian method to infer possible underlying
distributions. The method obtains rigorous error bounds even for small samples
taken from ill-behaved distributions. The approach taken has a natural
interpretation in terms of the intervals between ordered observations, where
allocation of probability mass across intervals is well-specified, but the
location of that mass within each interval is unconstrained. This formulation
gives rise to a straightforward computational resampling method: Bayesian
Interval Sampling. In a comparison with common alternative approaches, it is
shown to satisfy strict error bounds even for ill-behaved distributions.Comment: 13 pages, 3 figures; supplementary information provided. A revised
  version of this manuscript has been accepted for publication in Philosophical
  Transactions of the Royal Society A: Mathematical, Physical and Engineering
  Science",2,https://core.ac.uk/download/82985284.pdf
"L. Cronbach,P. Meehl",Construct validity in psychological tests.,None,SupportedSources.SEMANTIC_SCHOLAR,10.1037/H0040957,"Validation of psychological tests has not yet been adequately conceptualized, as the APA Committee on Psychological Tests learned when it undertook (1950-54) to specify what qualities should be investigated before a test is published. In order to make coherent recommendations the Committee found it necessary to distinguish four types of validity, established by different types of research and requiring different interpretation. The chief innovation in the Committee's report was the term construct validity.[2] This idea was first formulated by a subcommittee (Meehl and R. C. Challman) studying how proposed recommendations would apply to projective techniques, and later modified and clarified by the entire Committee (Bordin, Challman, Conrad, Humphreys, Super, and the present writers). The statements agreed upon by the Committee (and by committees of two other associations) were published in the Technical Recommendations (59). The present interpretation of construct validity is not ""official"" and deals with some areas where the Committee would probably not be unanimous. The present writers are solely responsible for this attempt to explain the concept and elaborate its implications.",3,"https://www.semanticscholar.org/paper/4ad27aca9e99022f7bad613ea690507bf618172d
http://conservancy.umn.edu/bitstream/11299/184279/1/1_07_Cronbach.pdf"
"Kavitha Mediratta,Sara McAlister,Seema Shah",Building a Campaign for Reading Reform in Miami,2009-09-09 00:00:00,SupportedSources.CORE,,"Presents a case study of community organizing for school reform by Miami's People Acting for Community Together: how its campaign for a new literacy program shaped leadership development, district-level policy, school-level capacity, and student outcomes",4,https://core.ac.uk/download/71347279.pdf
"S. Thekdi,J. Santos",Supply Chain Vulnerability Analysis Using Scenario‐Based Input‐Output Modeling: Application to Port Operations,2016-05-01 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.1111/risa.12473,"Disruptive events such as natural disasters, loss or reduction of resources, work stoppages, and emergent conditions have potential to propagate economic losses across trade networks. In particular, disruptions to the operation of container port activity can be detrimental for international trade and commerce. Risk assessment should anticipate the impact of port operation disruptions with consideration of how priorities change due to uncertain scenarios and guide investments that are effective and feasible for implementation. Priorities for protective measures and continuity of operations planning must consider the economic impact of such disruptions across a variety of scenarios. This article introduces new performance metrics to characterize resiliency in interdependency modeling and also integrates scenario‐based methods to measure economic sensitivity to sudden‐onset disruptions. The methods will be demonstrated on a U.S. port responsible for handling $36.1 billion of cargo annually. The methods will be useful to port management, private industry supply chain planning, and transportation infrastructure management.",5,https://www.semanticscholar.org/paper/303c28a53f7091a60d9d13020175bb20fc595201
"Álvaro Labella,K. Koasidis,A. Nikas,A. Arsenopoulos,H. Doukas",APOLLO: A Fuzzy Multi-criteria Group Decision-Making Tool in Support of Climate Policy,2020-10-01 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.2991/IJCIS.D.200924.002,"Multi-criteria decision-making is a daily process in everyday life, in which different alternatives are evaluated over a set of conflicting criteria. Decision-making is becoming increasingly complex, and the apparition of uncertainty and vagueness is inevitable, especially when related to sustainability issues. To model such lack of information, decision makers often use linguistic information to express their opinions, closer to their way of thinking, giving place to linguistic decision-making. However, the participation of multiple experts usually involves disagreements within the group, leading to unreliable solutions. To assist in decision-making and reduce such complexities, A grouP decisiOn fuzzy TOoL in support of cLimate change pOlicy making (APOLLO), a fuzzy decision support system, is introduced to deal with such problems in climate change and policy. The tool implements a framework for group decision-making, using 2-tuple Technique for Order Preference by Similarity to Ideal Solution (TOPSIS), coupled with a new consensus measuring model to increase robustness of selected solutions. The operation of the software tool is showcased in a real case carried out in Austria, where stakeholders were asked to assess the risks embedded in pathways for decarbonizing the country’s iron and steel sector. Results indicate that a coherent strategy addressing funding and competition issues is necessary, with experts displaying a consensus level of 85% in that these risks are the most threatening for the transition.",6,"https://www.semanticscholar.org/paper/86e24cb83cbb0c0254ab8d47b45f1a35daa2070a
https://www.atlantis-press.com/article/125944792.pdf"
Ahmed Kamal,Assessment of Autonomic Function in Children with Autism and Normal Children Using Spectral Analysis and Posture Entrainment: A Pilot Study,2015-01-01 00:00:00,SupportedSources.INTERNET_ARCHIVE,10.21767/2171-6625.100037,"Objective: The dysfunction of the autonomic nervous system investigated in Children with Autism compared with healthy one. Cardiovascular autonomic disturbances are possibly associated with the pathogenesis of Autism in children. The purpose of this study is to use the spectral and coherence analysis of heart rate variability signal (HRV), respiration signal and peripheral blood flow signal (PBF) to assess the autonomic activity of normal children and children with Autism for the clinical usefulness of the applied methods of signal processing and timefrequency analysis for screening and treatment of Autism in children. Methods: Twenty four children who had Autism and who were not taking any medications and Twenty three age and sex matched controls (Children) were participated in this study . PBF and respiration signals as well as HRV signal derived from Electrocardiogram (ECG) were measured during supine and standing positions. Autopower, cross power and coherence spectra were produced to investigate the sympathetic and parasympathetic activity in both groups. Results: The results clearly indicate that in children with Autism, the coherence values are less than in control group in both low frequency (LF) and high frequency (HF) bands at coherence spectra between HRV and PBF as well as HRV and respiration in both supine and standing position. Also, the ratio of amplitude at nearly frequency of 0.",7,https://web.archive.org/web/20170812073137/http://www.jneuro.com/neurology-neuroscience/assessment-of-autonomic-function-in-children-with-autism-and-normal-children-using-spectral-analysis-and-posture-entrainment-a-pilot-study.pdf
A. Włodarczyk,Koherentne miary ryzyka w zarządzaniu ryzykiem cen uprawnień do emisji CO2 w przedsiębiorstwach objętych systemem EU ETS,None,SupportedSources.SEMANTIC_SCHOLAR,10.29119/1641-3466.2018.113.42,"Managing the European Emission Allowances (EUA) price risk is becoming increasingly important for companies covered by the European Union Emissions Trading Scheme (EU ETS). The increase in the price volatility of the CO2 allowances in the secondary market and the reduction in the amount of free carbon emissions allowances, which are granted to companies, cause the increase in companies' exposure to price risk. The aim of this article is to present the concept of coherent risk measures and to compare the differences in the EUA futures portfolio risk assessment by means of two different measures: Expected Shortfall and Value at Risk.",8,https://www.semanticscholar.org/paper/83215fadabc9ecd4eebe6b65c07ca9db06762d0f
"Crowther, Michael J,Morris, Tim P,White, Ian R",Using simulation studies to evaluate statistical methods,2018-12-05 00:00:00,SupportedSources.CORE,10.1002/sim.8086,"Simulation studies are computer experiments that involve creating data by
pseudorandom sampling. The key strength of simulation studies is the ability to
understand the behaviour of statistical methods because some 'truth' (usually
some parameter/s of interest) is known from the process of generating the data.
This allows us to consider properties of methods, such as bias. While widely
used, simulation studies are often poorly designed, analysed and reported. This
tutorial outlines the rationale for using simulation studies and offers
guidance for design, execution, analysis, reporting and presentation. In
particular, this tutorial provides: a structured approach for planning and
reporting simulation studies, which involves defining aims, data-generating
mechanisms, estimands, methods and performance measures ('ADEMP'); coherent
terminology for simulation studies; guidance on coding simulation studies; a
critical discussion of key performance measures and their estimation; guidance
on structuring tabular and graphical presentation of results; and new graphical
presentations. With a view to describing recent practice, we review 100
articles taken from Volume 34 of Statistics in Medicine that included at least
one simulation study and identify areas for improvement.Comment: 31 pages, 9 figures (2 in appendix), 8 tables (1 in appendix",9,https://core.ac.uk/download/195314086.pdf
"Casey R. Myers,Marcus Silva,Kae Nemoto,William J. Munro",Stabilizer Quantum Error Correction with Qubus Computation,2006-12-12 17:40:55+00:00,SupportedSources.ARXIV,10.1103/PhysRevA.76.012303,"In this paper we investigate stabilizer quantum error correction codes using
controlled phase rotations of strong coherent probe states. We explicitly
describe two methods to measure the Pauli operators which generate the
stabilizer group of a quantum code. First, we show how to measure a Pauli
operator acting on physical qubits using a single coherent state with large
average photon number, displacement operations, and photon detection. Second,
we show how to measure the stabilizer operators fault-tolerantly by the
deterministic preparation of coherent cat states along with one-bit
teleportations between a qubit-like encoding of coherent states and physical
qubits.",10,"http://arxiv.org/pdf/quant-ph/0612097v1
http://dx.doi.org/10.1103/PhysRevA.76.012303
http://arxiv.org/abs/quant-ph/0612097v1
http://arxiv.org/pdf/quant-ph/0612097v1"
"Mike K. P. So,Chi-Ming Wong",Estimation of multiple period expected shortfall and median shortfall for risk management,2012-01-01 00:00:00,SupportedSources.INTERNET_ARCHIVE,10.1080/14697681003785967,"With the regulatory requirements for risk management, Value at Risk (VaR) has become an essential tool in determining capital reserves to protect the risk induced by adverse market movements. The fact that VaR is not coherent has motivated the industry to explore alternative risk measures like expected shortfall. The first objective of this paper is to propose statistical methods for estimating multiple-period expected shortfall under GARCH models. In addition to the expected shortfall, we investigate a new tool called median shortfall to measure risk. The second objective of this paper is to develop backtesting methods for assessing the performance of expected shortfall and median shortfall estimators from statistical and financial perspectives. By applying our expected shortfall estimators and other existing approaches to seven international markets, we demonstrate the superiority of our methods with respect to statistical and practical evaluations. Our expected shortfall estimators likely provide an unbiased reference for setting the minimum capital required for safeguarding against expected loss.",11,https://web.archive.org/web/20170921233322/https://opus.lib.uts.edu.au/bitstream/10453/18911/1/2010001243.pdf
"Zachary Feinstein,Birgit Rudloff",Time consistency for scalar multivariate risk measures,2021-11-19 00:00:00,SupportedSources.INTERNET_ARCHIVE,,"In this paper we present results on dynamic multivariate scalar risk measures, which arise in markets with transaction costs and systemic risk. Dual representations of such risk measures are presented. These are then used to obtain the main results of this paper on time consistency; namely, an equivalent recursive formulation of multivariate scalar risk measures to multiportfolio time consistency. We are motivated to study time consistency of multivariate scalar risk measures as the superhedging risk measure in markets with transaction costs (with a single eligible asset) (Jouini and Kallal (1995), Roux and Zastawniak (2016), Loehne and Rudloff (2014)) does not satisfy the usual scalar concept of time consistency. In fact, as demonstrated in (Feinstein and Rudloff (2021)), scalar risk measures with the same scalarization weight at all times would not be time consistent in general. The deduced recursive relation for the scalarizations of multiportfolio time consistent set-valued risk measures provided in this paper requires consideration of the entire family of scalarizations. In this way we develop a direct notion of a ""moving scalarization"" for scalar time consistency that corroborates recent research on scalarizations of dynamic multi-objective problems (Karnam, Ma, and Zhang (2017), Kovacova and Rudloff (2021)).",12,https://web.archive.org/web/20211128160038/https://arxiv.org/pdf/1810.04978v5.pdf
"J. Gross,R. Muñoz",Emotion Regulation and Mental Health,1995-06-01 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.1111/J.1468-2850.1995.TB00036.X,"In this article, we argue that emotion regulation is an essential (and traditionally underemphasized) feature of mental health. To develop this idea, we first define the terms emotion, emotion regulation, and mental health. We then chart the development of emotion regulation and describe its role in various facets of normal functioning. Next, we consider what happens when emotion becomes dysregulated in a major depressive episode. We suggest that an emotion regulatory perspective integrates diverse theoretical views of depression and has implications for the assessment, treatment, and prevention of depression. We conclude by speculating about the role of emotion regulation in the broader context of public mental health.",13,https://www.semanticscholar.org/paper/2b4994cd456292db5a53e87de5b1efa6fb24f167
B. Douglass,Doing hard time: developing real-time systems with uml,1999-05-21 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,,"(Chapters begin with an Introduction and conclude with a Summary, Looking Ahead, Exercises and References.) Figure List. About the Author. Preface. Acknowledgments. SECTION 1: BASICS. 1. Introduction to Objects and the Unified Modeling Language. Advantages of Objects. Terms and Concepts. Object Orientation with UML. Objects. Attributes. Behavior. Messaging. Responsibility. Concurrency. Objects as Autonomous Machines. Class Diagrams. Relations Among Classes and Objects. Use Cases. Sequence Diagrams. Physical Representation. Things Common to Diagrams. Notes. Packages. Constraints. Stereotypes. 2. Basic Concepts of Real-Time Systems. What is Real-Time? Terms and Concepts. Timeliness. Responsiveness. Concurrency. Scheduling Concurrent Threads. Event Arrival Patterns. Thread Rendezvous Patterns. Sharing Resources. Predictability. Memory Management. Correctness and Robustness. Deadlock. Exceptional Conditions. Race Conditions. Distributed Systems. Fault Tolerance and Safety. Dealing with Resource-Limited Target Environments. Low-Level Hardware Interfacing. Real-Time Operating Systems. Scalability. Scheduling. Typical RTOS Features. 3. Basic Concepts of Safety-Critical Systems. Introduction to Safety. The Therac-25 Story. Other Stories. Terms and Concepts. Safety Related Faults. Safety is a System Issue. Random Faults Versus Systematic Faults. Single Point Failures. Common Mode Failures. Latent Faults. Fail-Safe State. Achieving Safety. Safety Architectures. Single Channel Protected Design. Eight Steps to Safety. Step 1: Identify the Hazards. Step 2: Determine the Risks. Step 3: Define the Safety Measures. Step 4: Create Safe Requirements. Step 5: Create Safe Design. Step 6: Implementing Safely. Step 7: Assure Safety Process. Step 8: Test, Test, Test. Few Safety Related Standards. 4. Rapid Object-Oriented Process for Embedded Systems. Terms and Concepts. Development Phases. Ordering. Maturity. Development Task Sequencing. Waterfall Lifecycle. Iterative Lifecycles. Prototyping. Scheduling and Estimation. Advantages of Accurate Schedules. Difficulties of Accurate Scheduling. The ROPES Macro Cycle. Analysis. Requirements Analysis. Systems Analysis. Object Analysis. Design. Architectural Design. Mechanistic Design. Detailed Design. Translation. Activities. Artifacts. Testing. Activities. SECTION 2: ANALYSIS. 5. Requirements Analysis of Real-Time Systems. Terms and Concepts. Use Cases. Messages and Events. Scenarios, Protocols, and State Machines. Use Cases. Use Case Relations. Use Case Example: Air Traffic Control System. External Events. Context-Level Messages. Specifying External Messages. External Event List. Response Time. Detailing Use Case Behavior. Informal Textual Description. Scenarios. Sequence Diagrams. Statecharts for Defining Use Case Behavior. Identifying Use Cases. Using Use Cases. Heuristics for Good Requirements Analysis Diagrams. Use Case Diagram Heuristics. Use Case Heuristics. Use Case Sequence Diagram Heuristics. 6. Structural Object Analysis. Terms and Concepts. Key Strategies for Object Identification. Underline the Noun. Identify Causal Agents. Identify Coherent Services. Identify Real-World Items. Identify Physical Devices. Identify Essential Abstractions of Domains. Identify Transactions. Identify Persistent Information. Identify Visual Elements. Identify Control Elements. Execute Scenarios on the Object Model. Reification of Objects into Classes. Identify Object Associations. Multiplicity. Associations and Links. Aggregation and Composition. Object Attributes. Generalization Relationships. AATCS Example: Class Diagrams. Heuristics for Good Class Diagrams. Rules for Good Class Diagrams. 7. Object Behavioral Analysis. Terms and Concepts. Simple Behavior. State Behavior. Continuous Behavior. UML Statecharts. Basic State Semantics. Transitions and Events. Actions and Activities. Pseudostates. Orthogonal Regions and Synchronization. Basic Statechart Syntax. Inherited State Models. Ill-formed State Models. Example: AATCS Alarm System. The Role of Scenarios in the Definition of Behavior. Timing Diagrams. Sequence Diagrams. Activity Diagrams. Defining Operations. Types of Operations. Strategies for Defining Operations. Statechart Heuristics. Timing Diagram Heuristics. Activity Diagram Heuristics. SECTION 3: DESIGN. 8. Architectural Design. Terms and Concepts. Tasking Model. Representing Tasks. Defining Task Threads. Assigning Objects to Tasks. Defining Task Rendezvous. Component Model. Deployment Model. Representing Physical Architecture in the UML. Multiprocessor Systems. Safety/Reliability Model. 9. Mechanistic Design. Terms and Concepts. Design Pattern Basics. Mechanistic Design Patterns. Correctness Patterns. Execution Control Patterns. 10. Detailed Design. Introduction to Detailed Design. Terms and Concepts. Data Structure. Primitive Representational Types. Subrange Constraints. Derived Attributes. Data Collection Structure. Associations. The Object Interface. Definition of Operations. Detailed Algorithmic Design. Representing Algorithms in the UML. Algorithmic Example: Run-Time Data Interpolation. Exceptions. Source Language-based Exception Handling. State-based Exception Handling. SECTION 4. ADVANCED REAL-TIME MODELING. 11. Threads and Schedulability. Terms and Concepts. Time-Based Systems. Reactive Systems. Time Concepts. Scheduling Threads. Rate Monotonic Scheduling. Earliest Deadline Scheduling. Least Laxity Dynamic Scheduling. Maximum Urgency First Scheduling. Weighted Shortest Processing Time First (WSPTF) Scheduling. Minimizing Maximum Lateness Scheduling. Thread Synchronization and Resource Sharing. Mutual Exclusion Semaphore. Dekker's Algorithm. Spinlocks. Counting Semaphores. Condition Variables. Barriers. Rendezvous Objects. Schedulability Analysis of Hard Real-Time Systems. Global Analysis. Global Method with Blocking. Computing Blocking. Separate Task Utilization Bounds. Aperiodic Tasks. Schedulability Analysis of Soft Real-Time Systems. Warm and Fuzzy: Timeliness in the Soft Context. Soft Schedulability. 12. Dynamic Modeling. Terms and Concepts. But is it the Right State Machine? Behavioral Patterns. Latch State Pattern. Polling State Pattern. Latched Data Pattern. Device Mode State Pattern. Transaction State Pattern. Component Synchronization State Pattern. Barrier State Pattern. Event Hierarchy State Pattern. Random State Pattern. Null State Pattern. Watchdog State Pattern. Retriggerable Counter State Pattern. Model-Level Debugging and Testing. Animated Debugging. Animated Testing. Sample Debugging Session. 13. Real-Time Frameworks. Terms and Concepts. Real-Time Frameworks. Architectural Support Patterns. Safety and Reliability Patterns. Behavioral Patterns. Framework Design Principles and Metrics. Set of Services. Generalization Hierarchy Structure. Replaceable Components. Portability. Naming and Syntax Conventions. Performance. The Rhapsody Object Execution Framework (OXF). Rhapsody Architecture. Execution Framework. Interobject Association Patterns. Using C++ Standard Template Library. Abstract Operating System. Animation Framework. Sample Application Using the Rhapsody OXF Framework. Appendix A: UML Notation Summary. Appendix B: Introduction to Rhapsody. Appendix C: Introduction to Timewiz. Index. CD-ROM Warranty. 0201498375T04062001",14,https://www.semanticscholar.org/paper/827bef1a82c604c5bb63b48036b223780afcb8e3
"E. Duku,Molly M. Pottruff,M. Janus",Creating and Evaluating Two Cumulative Developmental Vulnerability Risk Measures.,2022-08-25 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.23889/ijpds.v7i3.1813,"ObjectivesThe Early Development Instrument (EDI) is a valid and reliable population-level tool measuring child developmental vulnerability in Kindergarten. The objective of this study was to derive and validate new EDI-based development “cumulative vulnerability” risk indicators using a cumulative risk index approach (Rutter, 1979). 
ApproachThe EDI has two main outcome measures: individual domain scores and vulnerability (scoring below a 10% cutpoint). To account for more complexity, we derived two new “cumulative vulnerability” measures. The Mean EDI Domain Score (MEDS) is the mean of the domain scores, and the Total EDI Vulnerability Index (TEVI) is an ordinal summative measure using domain vulnerability indicators. In Study I, we examined the relationship of the MEDS and TEVI measures with neighbourhood-level SES. In Study II, we examined the predictive/explanatory power of the MEDS and TEVI measures with Grade 3 provincial assessments in Ontario, Canada. 
ResultsStudy I used EDI Kindergarten data from twelve provincial and territorial data collections between 2008 and 2013 in Canada (316,015 children) aggregated to 2,038 customized neighbourhoods. The two new cumulative vulnerability measures worked as expected, with positive association between MEDS and neighbourhood SES (r=0.58), and a negative association between TEVI and neighbourhood SES (r=-0.57). Study II used data from 61,039 Kindergarten children matched between the EDI and Grade 3 EQAO datasets. The predictive/explanatory power of Mean EDI Domain Scores (MEDS; R2=0.11 to 0.15) was twice that of new ordinal summative measure (TEVI; R2=0.06 to 0.08). Interestingly, the predictive power of the TEVI was similar to that of the composite EDI outcome measure, overall vulnerability (vulnerable on one or more domains). 
ConclusionThe MEDS and TEVI work as expected and can be used for research and reporting purposes. More specifically, the TEVI can also be used as a severity metric evaluating the impact of multiple developmental vulnerabilities. It is recommended that further research be conducted to validate the measures with other datasets.",15,"https://www.semanticscholar.org/paper/2c6e129de2c5ec6c9ff1e2a32a9622d93eafd52f
https://ijpds.org/article/download/1813/3498"
"D. Batchelar,M. Westmore,Hao Lai,I. Cunningham",Quantitative coherent-scatter-computed tomography,1998-07-24 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.1117/12.317076,"Conventional means of diagnosiing and assessing the progression of osteoporosis, including radiographic absorptiometry and quantitative CT, are directly or indirectly dependent upon bone density. This is, how ever, not always a reliable indicator of fracture risk. Changes in the trabecular structure and bone mineral content (BMC) are thought to provide a better indication of the change of spontaneous fractures occurring. Coherent-scatter CT (CSCT) is a technique which produces images based on the low angle (0 - 10 degrees) x-ray diffraction properties of tissue. Diffraction patterns from an object are acquired using first-generation CT geometry with a diagnostic x-ray image intensifier based system. These patterns are used to reconstruct a series of maps of the angle dependent coherent scatter cross section in a tomographic slice which are dependent upon the molecular structure of the scatterer. Hydroxyapatite has a very different cross section to that of soft tissue, and the CSCT method may, therefore, form the basis for a more direct measure of BMC. Our original CSCT images suffered from a 'cupping' artifact, resulting in increased intensities for pixels at the periphery of the object. This artifact, which is due to self-attenuation of scattered x rays, caused a systematic error of up to 20% in cross-sections measured from a CT image. This effect has been removed by monitoring the transmitted intensity using a photodiode mounted on the primary beam stop, and normalizing the scatter intensity to that of the transmitted beam for each projection. Images reconstructed from data normalized in this way do not exhibit observable attenuation artifacts. Elimination of this artifact enables the determination of accurate quantitative measures of BMC at each pixel in a tomograph.",16,https://www.semanticscholar.org/paper/86c7bb705e008a6304d663162da78852f277d402
"Eduard J. de Bruin,Chris van Run,Janneke Staaks,Anne Marie Meijer",Effects of sleep manipulation on cognitive functioning of adolescents: A systematic review,2017-04-01 00:00:00,SupportedSources.OPENALEX,10.1016/j.smrv.2016.02.006,,17,"https://openalex.org/W2288547812
https://doi.org/10.1016/j.smrv.2016.02.006"
"J. L. Meyers,D. B. Chorlian,T. B. Bigdeli,E. C. Johnson,F. Aliev,A. Agrawal,L. Almasy,A. Anokhin,H. J. Edenberg,T. Foroud,A. Goate,C. Kamarajan,S. Kinreich,J. Nurnberger,A. K. Pandey,G. Pandey,M. H. Plawecki,J. E. Salvatore,J. Zhang,A. Fanous,B. Porjesz","The association of polygenic risk for schizophrenia, bipolar disorder, and depression with neural connectivity in adolescents and young adults: examining developmental and sex differences",2021-01-14 00:00:00,SupportedSources.INTERNET_ARCHIVE,10.1038/s41398-020-01185-7,"AbstractNeurodevelopmental abnormalities in neural connectivity have been long implicated in the etiology of schizophrenia (SCZ); however, it remains unclear whether these neural connectivity patterns are associated with genetic risk for SCZ in unaffected individuals (i.e., an absence of clinical features of SCZ or a family history of SCZ). We examine whether polygenic risk scores (PRS) for SCZ are associated with functional neural connectivity in adolescents and young adults without SCZ, whether this association is moderated by sex and age, and if similar associations are observed for genetically related neuropsychiatric PRS. One-thousand four-hundred twenty-six offspring from 913 families, unaffected with SCZ, were drawn from the Collaborative Study of the Genetics of Alcoholism (COGA) prospective cohort (median age at first interview = 15.6 (12–26), 51.6% female, 98.1% European American, 41% with a family history of alcohol dependence). Participants were followed longitudinally with resting-state EEG connectivity (i.e., coherence) assessed every two years. Higher SCZ PRS were associated with elevated theta (3–7 Hz) and alpha (7–12 Hz) EEG coherence. Associations differed by sex and age; the most robust associations were observed between PRS and parietal-occipital, central-parietal, and frontal-parietal alpha coherence among males between ages 15–19 (B: 0.15–0.21, p < 10–4). Significant associations among EEG coherence and Bipolar and Depression PRS were observed, but differed from SCZ PRS in terms of sex, age, and topography. Findings reveal that polygenic risk for SCZ is robustly associated with increased functional neural connectivity among young adults without a SCZ diagnosis. Striking differences were observed between men and women throughout development, mapping onto key periods of risk for the onset of psychotic illness and underlining the critical importance of examining sex differences in associations with neuropsychiatric PRS across development.",18,https://web.archive.org/web/20210429072948/https://www.nature.com/articles/s41398-020-01185-7.pdf?error=cookies_not_supported&code=5f46e665-0b51-4bab-8181-2044c888a125
"Marcelo Brutti Righi,Paulo Sergio Ceretta",Shortfall deviation risk: an alternative for risk measurement,2016-01-01 00:00:00,SupportedSources.INTERNET_ARCHIVE,10.21314/jor.2016.349,"We present the Shortfall Deviation Risk (SDR), a risk measure that represents the expected loss that occurs with certain probability penalized by the dispersion of results that are worse than such an expectation. SDR combines Expected Shortfall (ES) and Shortfall Deviation (SD), which we also introduce, contemplating two fundamental pillars of the risk concept, the probability of adverse events and the variability of an expectation, and considers extreme results. We demonstrate that SD is a generalized deviation measure, whereas SDR is a coherent risk measure. We achieve the dual representation of SDR, and we discuss issues such as its representation by a weighted ES, acceptance sets, convexity, continuity and the relationship with stochastic dominance. Illustrations with real and simulated data allow us to conclude that SDR offers greater protection in risk measurement compared with VaR and ES, especially in times of significant turbulence in riskier scenarios.",19,https://web.archive.org/web/20200824202717/https://arxiv.org/vc/arxiv/papers/1501/1501.02007v3.pdf
Christopher Wirbelauer,Noncontact Goniometry With Optical Coherence Tomography,2005-02-01 00:00:00,SupportedSources.INTERNET_ARCHIVE,10.1001/archopht.123.2.179,"Objective: To assess the value of noncontact goniometry with optical coherence tomography (OCT) compared with current clinical parameters in the evaluation of the anterior chamber angle (ACA). Design: Prospective observational study of 138 eyes of 109 patients. Methods: The ACA parameters and angle-opening distance (AOD) were measured with slitlamp-adapted OCT goniometry. The iris and scleral thickness and the iris convexity were assessed with OCT. Both ACA and AOD were compared with the clinical parameters of gonioscopy grade, limbal anterior chamber depth (ACD), ultrasonographic central ACD, and lens-axial length (LAL) ratio. Results: Noncontact goniometry with OCT revealed mean±SD values of 28°± 16°for the ACA and 381±234",20,https://web.archive.org/web/20190430233544/https://jamanetwork.com/journals/jamaophthalmology/articlepdf/416836/ecs30299.pdf
"Spencer Frei,Yuan Cao,Quanquan Gu",Agnostic Learning of a Single Neuron with Gradient Descent,2020-05-29 07:20:35+00:00,SupportedSources.ARXIV,,"We consider the problem of learning the best-fitting single neuron as
measured by the expected square loss $\mathbb{E}_{(x,y)\sim
\mathcal{D}}[(\sigma(w^\top x)-y)^2]$ over some unknown joint distribution
$\mathcal{D}$ by using gradient descent to minimize the empirical risk induced
by a set of i.i.d. samples $S\sim \mathcal{D}^n$. The activation function
$\sigma$ is an arbitrary Lipschitz and non-decreasing function, making the
optimization problem nonconvex and nonsmooth in general, and covers typical
neural network activation functions and inverse link functions in the
generalized linear model setting. In the agnostic PAC learning setting, where
no assumption on the relationship between the labels $y$ and the input $x$ is
made, if the optimal population risk is $\mathsf{OPT}$, we show that gradient
descent achieves population risk $O(\mathsf{OPT})+\epsilon$ in polynomial time
and sample complexity when $\sigma$ is strictly increasing. For the ReLU
activation, our population risk guarantee is $O(\mathsf{OPT}^{1/2})+\epsilon$.
When labels take the form $y = \sigma(v^\top x) + \xi$ for zero-mean
sub-Gaussian noise $\xi$, we show that the population risk guarantees for
gradient descent improve to $\mathsf{OPT} + \epsilon$. Our sample complexity
and runtime guarantees are (almost) dimension independent, and when $\sigma$ is
strictly increasing, require no distributional assumptions beyond boundedness.
For ReLU, we show the same results under a nondegeneracy assumption for the
marginal distribution of the input.",21,"http://arxiv.org/pdf/2005.14426v3
http://arxiv.org/abs/2005.14426v3
http://arxiv.org/pdf/2005.14426v3"
Jianming Xia,Optimal Investment with Risk Controlled by Weighted Entropic Risk Measures,2021-12-04 08:57:24+00:00,SupportedSources.ARXIV,,"A risk measure that is consistent with the second-order stochastic dominance
and additive for sums of independent random variables can be represented as a
weighted entropic risk measure (WERM). The expected utility maximization
problem with risk controlled by WERM and a related risk minimization problem
are investigated in this paper. The latter is same to a problem of maximizing a
weighted average of constant-absolute-risk-aversion (CARA) certainty
equivalents. The solutions of all the optimization problems are explicitly
characterized and an iterative method of the solutions is provided.",22,"http://arxiv.org/pdf/2112.02284v1
http://arxiv.org/abs/2112.02284v1
http://arxiv.org/pdf/2112.02284v1"
"H.X. Cai,Y.C. Zhu,S.N. Hu,H.B. Jia,L.L. Li,C. Zhao,Y. Lv,C. Fang,N. Feng,C.Y. Zhe,H.X. Gao,Y.P. Hu,J.B. Hou,S.S. Zhang,B. Yu",P4636Association of isolated low HDL-C level with morphological features of culprit plaques in patients with ST segment elevation myocardial infarction: an optical coherence tomography study,2017-08-01 00:00:00,SupportedSources.INTERNET_ARCHIVE,10.1093/eurheartj/ehx504.p4636,,23,https://web.archive.org/web/20180725074954/https://watermark.silverchair.com/ehx504.P4636.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAdAwggHMBgkqhkiG9w0BBwagggG9MIIBuQIBADCCAbIGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQM_QHmlLfa2YJZqTfmAgEQgIIBg1MZ9iVWnMyRf2qAW0y_68su4-Wc4UKl-kpOI03cxGTMBTYMtdvVDGNY6GOtMOz4eHZUmG8TV-uSJUoas3Gx1Cs5AvH1pjvUUZSS1QcrrOKT7PqvDWkUPNMrCUu1xdeqOJQ9iMLCJ_-n4gez86DxJCOHwS8jrpQGIYr4NswjUbxx7xDqNdrFt0xryQJp4NVBadWd0ZHOX3F6geLHNlYuS5QCYxhS__VHS63f7AQIUfoEX5SAGCKxONbDHRzYeB8eRMyJYIhAIJ2QJjShWx4T3v4nmnHNhB2uGAms8dtlS4_KCMsJSHdS6XsvA8_uyjzrzOJbaJWPhouhnKAvvu8F0M4lu2YPS2w37YTAdGj860qCDG4uWZ9aN5_zxTGPA9jVfBc8fDmlE0fioEznGcRvYFgQHIP8OSLPnrlz9pW2Z1SG34L5OOlg1cohIHt8uSNg22twMDhxJILXXBtMbwDqgcg_hi4JlqPZTT7SRkoWMOYc8rZOS8EGrebK1NP6nhoBKuW2Og
"Camerer, Colin F.,Loewenstein, George","Behavioral Economics: Past, Present, Future",2003-01-01 00:00:00,SupportedSources.CORE,,"Behavioral economics increases the explanatory power of economics by providing it with

more realistic psychological foundations. This book consists of representative recent articles in

behavioral economics. This chapter is intended to provide an introduction to the approach and

methods of behavioral economics, and to some of its major findings, applications, and promising

new directions. It also seeks to fill some unavoidable gaps in the chapters’ coverage of topics",24,https://core.ac.uk/download/4887838.pdf
,"14–19: Extending opportunities, raising standards",2002-01-01 00:00:00,SupportedSources.CORE,,,25,https://core.ac.uk/download/4159562.pdf
"Jorge Navarro,Camilla Calì,Maria Longobardi,Fabrizio Durante",Distortion Representations of Multivariate Distributions,2020-10-24 17:47:00+00:00,SupportedSources.ARXIV,,"The univariate distorted distribution were introduced in risk theory to
represent changes (distortions) in the expected distributions of some risks.
Later they were also applied to represent distributions of order statistics,
coherent systems, proportional hazard rate (PHR) and proportional reversed
hazard rate (PRHR) models, etc. In this paper we extend this concept to the
multivariate setup. We show that, in some cases, they are a valid alternative
to the copula representations especially when the marginal distributions may
not be easily handled. Several relevant examples illustrate the applications of
such representations in statistical modeling. They include the study of paired
(dependent) ordered data, joint residual lifetimes, order statistics and
coherent systems.",26,"http://arxiv.org/pdf/2010.14224v1
http://arxiv.org/abs/2010.14224v1
http://arxiv.org/pdf/2010.14224v1"
"Giovannucci, Daniele",Salient Trends in Organic Standards: Opportunities and Challenges for Developing Countries,2006-01-01 00:00:00,SupportedSources.CORE,,"This paper presents an overview of the fundamental issues in the production, trade and regulation of organic products. It notes the changing consumer and trade environments that are driving organics beyond the realm of niche products toward an increasingly relevant position among other important agricultural standards. 

Rather than a comprehensive analysis it outlines key elements that are most relevant to developing country producers including the likely impacts of adopting organics and the salient trends drawing from recent empirical research and the current literature on the subject. Finally, this document briefly assesses the significant constraints and opportunities facing the sector in order to draw some practical policy and investment conclusions",27,https://core.ac.uk/download/10926734.pdf
"Guanghui Huang,Jianping Wan,Cheng Chen",An Active Margin System and its Application in Chinese Margin Lending Market,2011-01-20 17:26:32+00:00,SupportedSources.ARXIV,,"In order to protect brokers from customer defaults in a volatile market, an
active margin system is proposed for the transactions of margin lending in
China. The probability of negative return under the condition that collaterals
are liquidated in a falling market is used to measure the risk associated with
margin loans, and a recursive algorithm is proposed to calculate this
probability under a Markov chain model. The optimal maintenance margin ratio
can be given under the constraint of the proposed risk measurement for a
specified amount of initial margin. An example of such a margin system is
constructed and applied to $26,800$ margin loans of 134 stocks traded on the
Shanghai Stock Exchange. The empirical results indicate that the proposed
method is an operational method for brokers to set margin system with a clearly
specified target of risk control.",28,"http://arxiv.org/pdf/1101.3974v1
http://arxiv.org/abs/1101.3974v1
http://arxiv.org/pdf/1101.3974v1"
"Paula Cutipa,Kirill Yu. Spasibko,Maria V. Chekhova",Measurement of coupled spatiotemporal coherence of parametric down-conversion under negative group velocity dispersion,2020-03-07 18:44:04+00:00,SupportedSources.ARXIV,10.1364/OL.397700,"We present a direct measurement of the spatiotemporal coherence of parametric
down-conversion in the range of negative group-velocity dispersion. In this
case, the frequency-angular spectra are ring-shaped and temporal coherence is
coupled to spatial coherence. Correspondingly, the lack of coherence due to
spatial displacement can be compensated with the introduction of time delay. We
show a simple technique, based on a modified Mach-Zehnder interferometer, which
allowed us to measure time coherence and near-field space coherence
simultaneously, with complete control of both variables. This technique will be
also suitable for the measurement of second-order coherence, where the main
applications are related to the two-photon spectroscopy.",29,"http://arxiv.org/pdf/2003.03635v1
http://dx.doi.org/10.1364/OL.397700
http://arxiv.org/abs/2003.03635v1
http://arxiv.org/pdf/2003.03635v1"
"Tania Paul,Tabish Qureshi",Measuring Quantum Coherence in Multi-Slit Interference,2017-01-30 09:06:32+00:00,SupportedSources.ARXIV,10.1103/PhysRevA.95.042110,"A quantitative measure of quantum coherence was recently introduced, in the
context of quantum information theory. This measure has also been propounded as
a good quantifier of the wave nature of quantum objects. However, actually
measuring coherence in an experiment is still considered a challenge. A
procedure for measuring coherence in a multi-slit interference is proposed
here. It can be used for experimentally testing duality relations for
interference experiments involving more than two slits.",30,"http://arxiv.org/pdf/1701.09091v3
http://dx.doi.org/10.1103/PhysRevA.95.042110
http://arxiv.org/abs/1701.09091v3
http://arxiv.org/pdf/1701.09091v3"
"Manikandan Parthasarathy,Segar Jambulingam,Tim Byrnes,Chandrashekar Radhakrishnan",Thermal coherence of the Heisenberg model with Dzyaloshinsky-Moriya interactions in an inhomogenous external field,2021-03-01 17:01:59+00:00,SupportedSources.ARXIV,10.1016/j.physa.2021.126239,"The quantum coherence of the two-site XYZ model with Dzyaloshinsky-Moriya
(DM) interactions in an external inhomogenous magnetic field is studied. The DM
interaction, the magnetic field and the measurement basis can be along
different directions, and we examine the quantum coherence at finite
temperature. With respect to the spin-spin interaction parameter, we find that
the quantum coherence decreases when the direction of measurement basis is the
same as that of the spin-spin interaction. When the spin-lattice interaction is
varied, the coherence always increases irrespective of the relation between its
direction and the measurement basis. Similar analysis of quantum coherence
based on the variation of the external inhomogenous magnetic field is also
carried out, where we find that the coherence decreases when the direction of
the measurement basis is the same as that of the external field.",31,"http://arxiv.org/pdf/2103.01130v1
http://dx.doi.org/10.1016/j.physa.2021.126239
http://arxiv.org/abs/2103.01130v1
http://arxiv.org/pdf/2103.01130v1"
"Jones, David",Partnership in action: providing flexible work-related curricula for 14 -16 year olds,2003-01-01 00:00:00,SupportedSources.CORE,,,32,https://core.ac.uk/download/4154143.pdf
"A. Masten,J. Powell","A Resilience Framework for Research, Policy, and Practice",None,SupportedSources.SEMANTIC_SCHOLAR,10.1017/CBO9780511615788.003,"It was a search for understanding the nature and origins of schizophrenia that brought Norman Garmezy to the study of children at risk for psychopathology, a pursuit that eventually led to the Project Competence studies of competence, adversity, and resilience (Garmezy, 1973). During the 1940s and 1950s, Garmezy developed an interest in the significance of competence in the history and prognosis of patients with serious mental disorders, with a particular focus on premorbid functioning in patients with schizophrenia (Garmezy & Rodnick, 1959). Eventually, the search for antecedents of psychopathology led Garmezy and others to study children of mentally ill parents because of their elevated risk of developing disorders. After his move to the University of Minnesota in 1961, Garmezy began to focus his work on children, and subsequently played a leading role in an international consortium of investigators who adopted the risk strategy for uncovering clues to the etiology and possible prevention or treatment of serious mental disorders (Watt, Anthony, Wynne, & Rolf, 1984). It was not long before Garmezy's interest in competence resurfaced. He became intrigued with observations that many children at risk for psychopathology were developing surprisingly well. By the early 1970s, he and his students turned their attention to the study of competence in children at risk due to parental mental illness and other risk factors, including poverty and stressful life experiences. At this time, Garmezy named his research program Project Competence.",33,https://www.semanticscholar.org/paper/f131f454466010dbe7e7ac698edcb9f78425f6a2
"Canagarajah, S.,Dar, A.,Nording, R.,Raju, D.",Effectiveness of lending for vocational education and training: lessons from World Bank experience,None,SupportedSources.CORE,,"This paper reviews the Bank involvement in the vocational education and training (VET) sub-sector in the 1990s. The paper aims to do just that, by mainly seeking answers to the following questions: 1) How has the Bank performed in its lending services to its clients in VET? 2) How have VET projects performed in terms of meeting stated objectives? 3) What factors led to the success, or failure of Bank operations? Based on what has been learned, the paper provides suggestions about how the performance of future VET interventions can be improved. This review concerns itself primarily with implementation performance, and proposes measures to improve project outcomes.ICT Policy and Strategies,Health Economics&Finance,Health Monitoring&Evaluation,Teaching and Learning,Banks&Banking Reform",34,https://core.ac.uk/download/pdf/6314343.pdf
Peter G. Shepard,Second Order Risk,2009-08-17 22:11:25+00:00,SupportedSources.ARXIV,,"Managing a portfolio to a risk model can tilt the portfolio toward weaknesses
of the model. As a result, the optimized portfolio acquires downside exposure
to uncertainty in the model itself, what we call ""second order risk."" We
propose a risk measure that accounts for this bias. Studies of real portfolios,
in asset-by-asset and factor model contexts, demonstrate that second order risk
contributes significantly to realized volatility, and that the proposed measure
accurately forecasts the out-of-sample behavior of optimized portfolios.",35,"http://arxiv.org/pdf/0908.2455v1
http://arxiv.org/abs/0908.2455v1
http://arxiv.org/pdf/0908.2455v1"
"Véronique Maume-Deschamps,Ibrahima Niang",Estimation of quantile oriented sensitivity indices,2017-02-03 07:34:31+00:00,SupportedSources.ARXIV,,"The paper concerns quantile oriented sensitivity analysis. We rewrite the
corresponding indices using the Conditional Tail Expectation risk measure.
Then, we use this new expression to built estimators.",36,"http://arxiv.org/pdf/1702.00925v1
http://arxiv.org/abs/1702.00925v1
http://arxiv.org/pdf/1702.00925v1"
"Maura Galletta,Igor Portoghese,Nicola Frau,Marco Pau,Federico Meloni,Gabriele Finco,Paolo Contu,Marcello Campagna",Association between burnout and sense of coherence among speech and language therapists: an exploratory study in Italy,2019-03-28 00:00:00,SupportedSources.INTERNET_ARCHIVE,10.23750/abm.v90i4-s.8261,"Job burnout has been recognized as a serious occupational hazard among professionals, such as health care professionals. The sense of coherence (SoC) is deemed to be a personal resource capable of reducing the impact of job stressors and, consequently, the experience of job burnout. The purpose of this study was to investigate the relationship between SoC and job burnout among speech and language therapists. A descriptive and cross-sectional analysis was carried out through an online self-reported questionnaire. A total of 217 Italian speech and language therapists were involved in the study. The Anova test, T-test and logistic regression were performed to study the association between SoC and job burnout. The Anova test showed that job tenure was not associated to job burnout. The T-test showed that speech and language therapists having a low SoC exhibited significantly higher emotional exhaustion, higher cynicism, and lower professional efficacy (t=-7.190 d.f.=215 p<.001) when compared to those having a high SoC. Finally, the odds ratio showed that low SoC was associated with high emotional exhaustion (OR=11.86; 95% CI=5.52-25.49; p<0.05), low SoC was associated with high cynicism (OR=4.41, CI=2.50-7.80; p<0.05), and low SoC was associated with low personal efficacy (OR=4.70; CI=2.59-8.52; p<0.05). Our results are in line with previous studies which showed that SoC is a fundamental personal resource which may activate workers' reaction to various stressors, thus reducing the experience of burnout.",37,https://web.archive.org/web/20200206080943/http://europepmc.org/backend/ptpmcrender.fcgi?accid=PMC6625562&blobtype=pdf
"Brandtner, M.,Kürsten, W.","Solvency II, regulatory capital, and optimal reinsurance: How good are Conditional Value-at-Risk and spectral risk measures?",2014-01-01 00:00:00,SupportedSources.CROSSREF,10.1016/j.insmatheco.2014.09.008,,38,"https://api.elsevier.com/content/article/PII:S016766871400122X?httpAccept=text/plain
https://api.elsevier.com/content/article/PII:S016766871400122X?httpAccept=text/xml
http://dx.doi.org/10.1016/j.insmatheco.2014.09.008"
"Kirilyuk, V.",Risk Measures in the Form of Infimal Convolution,2021-01-01 00:00:00,SupportedSources.CROSSREF,10.1007/s10559-021-00327-z,,39,"http://link.springer.com/content/pdf/10.1007/s10559-021-00327-z.pdf
http://link.springer.com/article/10.1007/s10559-021-00327-z/fulltext.html
http://link.springer.com/content/pdf/10.1007/s10559-021-00327-z.pdf
http://dx.doi.org/10.1007/s10559-021-00327-z"
"M. Abdullah,H. Abele,D. Akimov,G. Angloher,D. Aristizabal-Sierra,C. Augier,A. Balantekin,L. Balogh,P. Barbeau,L. Baudis,A. Baxter,C. Beaufort,G. Beaulieu,V. Belov,A. Bento,L. Bergé,I. Bernardi,J. Billard,A. Bolozdynya,A. Bonhomme,G. Brès,J. Bret,A. Broniatowski,A. Brossard,C. Buck,M. Cadeddu,M. Calvo,L. Canonica,F. Cappella,L. Cardani,N. Casali,A. Cazes,R. Cerulli,D. Chaize,C. Chang,M. Chapellier,L. Chaplinsky,G. Chemin,R. Chen,I. Colantoni,J. Colas,P. Coloma,E. Corcoran,S. Crawford,A. Cruciani,A. D. Fard,M. Jésus,P. Marcillac,V. Romeri,G. Castello,M. D. GalloRoccagiovine,D. Delicato,M. Demarteau,Y. Deng,J. Dent,P. Denton,K. Dering,A. Doblhammer,F. Dordei,S. Dorer,L. Dumoulin,D. Dunford,B. Dutta,A. Erhart,O. Exshaw,S. Ferriol,E. Figueroa-Feliciano,J. Filippini,L. .. Flores,J. Formaggio,M. Friedl,S. Fuard,F. Gao,A. Garai,E. Garcés,J. Gascon,J. Gehrlein,G. Gerbier,V. Ghete,I. Giomataris,G. Giroux,A. Giuliani,C. Giunti,P. Gorel,C. Goupy,J. Goupy,C. Goy,M. Green,M. Gros,C. Guerin,V. Guidi,O. Guillaudin,E. Guy,C. Ha,D. Hauff,J. Hakenmuller,P. M. Harrington,S. Hedges,S. Heine,S. Hertel,M. Heusch,C. Hoarau,M. Hoferichter,E. Hoppe,Z. Hong,S. Horiuchi,Philipp Huber,J. Ianigro,N. Jachowicz,E. Jericha,Y. Jin,J. Johnston,A. Juillard,I. Katsioulas,S. Kazarcev,M. Kaznacheeva,F. Kelly,K. Kelly,D. Kim,A. Kinast,L. Klinkenberg,H. Kluck,P. Knights,Y. Ko,T. Kosmas,L. Kwon,J. Lamblin,R. Lang,A. Langenkamper,S. Langrock,T. Lasserre,H. Lattaud,P. Lautridou,H. Lee,B. Lenardo,D. Lhuillier,M. Li,S. Li,Y. F. Li,Z. Li,M. Lindner,J. Liu,D. Loomba,A. Lubashevskiy,P. Machado,M. Mancuso,W. Maneschg,D. Markoff,S. Marnieros,R. Martin,R. D. Martin,B. Mauri,D. Mayer,A. Mazzolari,E. Mazzucato,J. Menéndez,J. Minet,O. Miranda,D. Misiak,J. Mols,A. Monfardini,F. Mounier,J. Muraz,T. Neep,R. Neilson,J. Newby,J. Newstead,H. Neyrial,K. Ni,K. Nikolopoulos,C. Nones,D. Norcini,V. Pandey,P. O'Brien,C. O’Hare,L. Oberauer,W. Oliver,E. Olivieri,A. Onillon,C. Oriol,T. Ortmann,R. Owen,K. Palladino,D. Papoulias,J. Park,D. Parno,P. Patel,L. Pattavina,E. Peinado,E. Perbet,L. Peters,F. Petricca,H. D. Pinckney,M. Piro,D. Ponomarev,D. Poda,W. Potzel,F. Probst,F. Pucci,F. Rarbi,R. Rapp,H.Ray,J.-S.Real,F. Reindl,G.C.Rich,J.S.Ricol,T.Rink,T.Redon,R.Rogly,A.Robert,J.Rothe,S.Rozov,I.Rozova,T.Salagnac,E. García,G. Garcia,O.Sanders,V.Sanglard,D.Santos,Y.Sarkis,V.Savu,G.Savvidis,I. Savvidis,N. Schermer,J. Schieck,B. Schmidt,S. Schonert,K. Scholberg,A. Schwenk,C. Schwertner,L. Scola,Ye. Shevchik,S. Shin,V. Sibille,I. Shoemaker,D. Snowden-Ifft,T. Soldner,G. Soum,N. Spooner,J. Stachurska,L. Stodolsky,R. Strauss,L. Strigari,A. Stutz,B. Suh,J. Suhonen,Z. Tabrizi,V. Takhistov,A. Thompson,C. Tomei,M. Tórtola,M. Tripathi,L. Vagneron,J. Valle,K. Mirbach,W. V. D. Ponteseele,M. Vignati,M. Vivier,F. Fernandez,F. Vezzu,M. Vidal,V. Wagner,J. Walker,R. Ward,A. Wex,L. Winslow,H. Wong,M. Wood,J. Xu,L. Yang,E. Yakushev,M. Zampaolo,J. Zettlemoyer,Y. Y. Zhang,D. Zinatulina",Coherent elastic neutrino-nucleus scattering: Terrestrial and astrophysical applications,2022-03-14 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.2172/1856010,"Coherent elastic neutrino-nucleus scattering (CEνNS) is a process in which neutrinos scatter on a nucleus which acts as a single particle. Though the total cross section is large by neutrino standards, CEνNS has long proven difficult to detect, since the deposited energy into the nucleus is ∼ keV. In 2017, the COHERENT collaboration announced the detection of CEνNS using a stopped-pion source with CsI detectors, followed up the detection of CEνNS using an Ar target. The detection of CEνNS has spawned a flurry of activities in high-energy physics, inspiring new constraints on beyond the Standard Model (BSM) physics, and new experimental methods. The CEνNS process has important implications for not only high-energy physics, but also astrophysics, nuclear physics, and beyond. This whitepaper discusses the scientific importance of CEνNS, highlighting how present experiments such as COHERENT are informing theory, and also how future experiments will provide a wealth of information across the aforementioned fields of physics.",40,"https://www.semanticscholar.org/paper/c9f01294f6360f6fa6aa4293f700ef80db0d3d68
http://arxiv.org/pdf/2203.07361"
C. Romano,APPLYING COPULA FUNCTION TO RISK MANAGEMENT,None,SupportedSources.SEMANTIC_SCHOLAR,,"This paper is part of the author’s Ph. D. Thesis “Extreme Value Theory and coherent risk measures: applications to risk management”. The copula function describes the dependence structure of a multivariate random variable. In this paper, it is used as a practical and flexible instrument to generate Monte Carlo scenarios of risk factor returns. These risk factors affect the value of a credit or market portfolio. In fact, many of the models commonly used assume a multinormal distribution of such risk factor returns (or log-returns). This hypothesis underestimates the probability that a catastrophic event, such as a simultaneous slump of equity prices or the joint default of several counterparties in a credit portfolio, might occur. This kind of event worries both risk managers and supervisors. Our goal is to show that the use of a copula function different from the Gaussian copula can model such extreme events effectively.",41,https://www.semanticscholar.org/paper/be5b8fe1399ed2fbac7a71bf08e850197abab1fd
"Anders M. Jorgensen,H. Schmitt,R. Hindsley,J. T. Armstrong,T. A. Pauls,D. Mozurkewich,D. J. Hutter,C. Tycner",Measurements of binary stars with coherent integration of NPOI data,2008-07-21 04:55:46+00:00,SupportedSources.ARXIV,10.1117/12.790290,"In this paper we use coherently integrated visibilities (see separate paper
in these proceedings, Jorgensen et al. 2008) to measure the properties of
binary stars. We use only the phase of the complex visibility and not the
amplitude. The reason for this is that amplitudes suffer from the calibration
effect (the same for coherent and incoherent averages) and thus effectively
provide lower accuracy measurements. We demonstrate that the baseline phase
alone can be used to measure the separation, orientation and brightness ratio
of a binary star, as a function of wavelength.",42,"http://arxiv.org/pdf/0807.3206v1
http://dx.doi.org/10.1117/12.790290
http://arxiv.org/abs/0807.3206v1
http://arxiv.org/pdf/0807.3206v1"
"Rosella Giacometti,Sergio Ortobelli,Tomáš Tichý",Portfolio Selection with Uncertainty Measures Consistent with Additive Shifts,2015-01-01 00:00:00,SupportedSources.INTERNET_ARCHIVE,10.18267/j.pep.497,"Assuming a non-satiable risk-averse investor, the standard approach to portfolio selection suggests discarding of all ineffi cient investment in terms of mean return and its standard deviation ratio within its fi rst step. However, in literature we can fi nd many alternative dispersion and risk measures that can help us to identify the most suitable investment opportunity. In this work two new dispersion measures, fulfi lling the condition that ""more is better than less"" are proposed. Moreover, their distinct characteristics are analysed and empirically compared. In particular, starting from the defi nition of dispersion measures, we discuss the property of consistency with respect to additive shifts and we examine two dispersion measures that satisfy this property. Finally, we empirically compare the proposed dispersion measures with the standard deviation and the conditional value at risk on the US stock market. Moreover, within the empirical example the so called ""alarm"" is incorporated in order to predict potential fails of the market.",43,https://web.archive.org/web/20180718222650/https://www.vse.cz/polek/download.php?lang=en&jnl=pep&pdf=497.pdf
"K. Dowd,D. Blake","After VAR: The Theory, Estimation, and Insurance Applications of Quantile-Based Risk Measures",2006-05-30 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.1111/j.1539-6975.2006.00171.x,"We discuss a number of quantile-based risk measures (QBRMs) that have recently been developed in the financial risk and actuarial/insurance literatures. The measures considered include the Value-at-Risk (VaR), coherent risk measures, spectral risk measures, and distortion risk measures. We discuss and compare the properties of these different measures, and point out that the VaR is seriously flawed. We then discuss how QBRMs can be estimated, and discuss some of the many ways they might be applied to insurance risk problems. These applications are typically very complex, and this complexity means that the most appropriate estimation method will often be some form of stochastic simulation.",44,https://www.semanticscholar.org/paper/ba9d6645047044bdb7cae169742cc1f51b906946
"S. Thorne,L. Jensen,M. Kearney,G. Noblit,M. Sandelowski",Qualitative Metasynthesis: Reflections on Methodological Orientation and Ideological Agenda,2004-12-01 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.1177/1049732304269888,"In an era of pressure toward evidence-based health care, we are witnessing a new enthusiasm for qualitative metasynthesis as an enterprise distinct from conventional literature reviews, secondary analyses, and the many other scholarly endeavors with which it is sometimes confused. This article represents the reflections of five scholars, each ofwhom has authored a distinct qualitative metasynthesis strategy. By providing the reader a glimpse into the tradition of their various qualitative metasynthesis projects, these authors offer a finely nuanced examination of the tensions between comparison and integration, deconstruction and synthesis, and reporting and integration within the metasynthesis endeavor. In so doing, they account for many of the current confusions about representation and generalization within the products of these inquiries. Through understanding the bases of their unique angles of vision, the reader is invited to engage in their commitment to scholarly integrity and intellectual credibility in this emerging methodological challenge.",45,https://www.semanticscholar.org/paper/294ff9e913faa1ab9769e65fd61734aa8d792e19
"Barker, Kim,Jurasz, Olga",Written Submission of Evidence to the Women and Equalities Committee inquiry into sexual harassment of women and girls in public spaces,2018-03-05 00:00:00,SupportedSources.CORE,,,46,https://core.ac.uk/download/153444206.pdf
"M. Jendrisak,B. Hong,S. Shenoy,J. Lowell,N. Desai,W. Chapman,A. Vijayan,R.D. Wetzel,M. Smith,J. Wagner,S. Brennan,D. Brockmeier,D. Kappel",Altruistic Living Donors: Evaluation for Nondirected Kidney or Liver Donation,2006-01-01 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.1111/j.1600-6143.2005.01148.x,A program was established within our regional procurement organization to permit evaluation of altruistic living donors (LD) interested in nondirected kidney or liver segment donation prior to transplant center referral.,47,"https://www.semanticscholar.org/paper/2fd248c36270bed6b8c83005979726a1c40fe149
http://www.amjtransplant.org/article/S1600613522025503/pdf"
"M. Buxton,M. Drummond,B. van Hout,R. L. Prince,T. Sheldon,T. Szucs,M. Vray",Modelling in economic evaluation: an unavoidable fact of life.,1997-05-01 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.1002/(SICI)1099-1050(199705)6:3<217::AID-HEC267>3.0.CO;2-W,"The role of modelling in economic evaluation is explored by discussing, with examples, the uses of models. The expanded use of pragmatic clinical trials as an alternative to models is discussed. Some suggestions for good modelling practice are made.",48,https://www.semanticscholar.org/paper/27ede6cd11269a0bcb8c5e18c1cc4138ca6d0193
,Analysis on Safety Risk Identification and Control Measures in Oil Production Operation Site,2021-11-10 00:00:00,SupportedSources.CROSSREF,10.47939/et.v2i11.76,,49,http://dx.doi.org/10.47939/et.v2i11.76
Damir Filipović,OPTIMAL NUMERAIRES FOR RISK MEASURES,2008-01-01 00:00:00,SupportedSources.INTERNET_ARCHIVE,10.1111/j.1467-9965.2007.00336.x,"Can the usage of a risky numeraire with a greater than risk free expected return reduce the capital requirements in a solvency test? I will show that this is not the case. In fact, under a reasonable technical condition, there exists no optimal numeraire which yields smaller capital requirements than any other numeraire.",50,https://web.archive.org/web/20120322225818/http://www.business.uts.edu.au/qfrc/research/research_papers/rp187.pdf
Adair Turner,Globalization in an Age of Crisis: Multilateral Economic Cooperation in the Twenty-First Century,None,SupportedSources.CORE,,,51,https://core.ac.uk/download/pdf/6653994.pdf
B. Johnson,Testing and Expanding a Model of Cognitive Processing of Risk Information,2005-06-01 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.1111/j.1539-6924.2005.00609.x,"Scholars have begun to explore the role of modes of information processing and related audience characteristics in reactions to risky situations and risk information.( 11, 12, 14, 17, 18, 20)“Information processing” concerns how people attend to and consider available information: systematic processors analyze messages and situations carefully, while heuristic processors skim and use cues (e.g., opinions of trusted reference groups) for quick judgments. This article uses scenarios about a semi‐hypothetical industrial facility, in particular risk comparisons being considered by its manager for inclusion in a talk to the community, to explore the impact of information processing. Information insufficiency, self‐assessed capacity to understand information, and information‐seeking propensities are tested for potential effects on information processing about industrial risks by people living near industry. As well as testing established models, this article explores the additional explanatory value of involvement, relevance, and ability (Earle et al., 1990) and objective knowledge. Both existing model variables and new ones have significant effects on information seeking and information processing in this case, and partly confirm earlier results. Trumbo( 17,18) found that heuristic processors saw lower risk and systematic processors higher risk from suspected cancer clusters. In this study, reporting knowledge about local industrial risks as insufficient for one's purposes and self‐reported avoidance of such information both raised ratings of the facility's risk and lowered ratings of its acceptability. Neither type of information processing significantly affected risk or acceptability judgments, but both increased risk ratings and heuristic processing had more effect than systematic processing. Positive ratings of risk comparisons' clarity and meaningfulness decreased risk and increased acceptability ratings, dominated other information variables in predictive power, and exceeded risk, benefit, and trust in contribution to acceptability judgments. Despite differences across studies in designs and variables, and the embryonic development of appropriate (self‐reported) measures for use in field surveys, these results confirm the potential value of further research in how information seeking and processing affect risk beliefs and reactions to risk communications.",52,https://www.semanticscholar.org/paper/26a36ce587955ba550f8463244f617fe4e3388d1
"AM Polansky,AP Dempster,AR Brazzale,AWF Edwards,B Clarke,B Efron,B Efron,B Efron,B Finetti De,D Fraser,D Heath,D Heath,DA Freedman,DA Sprott,DAS Fraser,DAS Fraser,DAS Fraser,DAS Fraser,DAS Fraser,DR Bickel,DR Bickel,DR Bickel,DR Bickel,DR Cox,DV Lindley,G Shafer,GA Barnard,GN Wilkinson,GS Datta,H Scheffe,HE Kyburg,I Hacking,I Hacking,IS Helland,J Cornfield,J Hannig,J Hannig,J Kiefer,J Kohlas,J Robins,J-Y Jaffray,JB Paris,JM Bernardo,JM Bernardo,JO Berger,JO Berger,JT Hwang,K Chaloner,K Singh,LJ Gleser,LJ Savage,M Goldstein,M Goldstein,MCM Troffaes,MJ Schervish,OE Barndorff-nielsen,P Maher,P Mccullagh,P Vos,PH Garthwaite,PM Grundy,PS Craig,R Carnap,R Jeffrey,R Liu,R Royall,R Royall,RA Fisher,RA Fisher,RJ Buehler,SL Zabell,SR Lele,SS Sharma,T Schweder",A frequentist framework of inductive reasoning,2009-12-24 00:00:00,SupportedSources.CORE,10.1007/s13171-012-0020-x,"Reacting against the limitation of statistics to decision procedures, R. A.
Fisher proposed for inductive reasoning the use of the fiducial distribution, a
parameter-space distribution of epistemological probability transferred
directly from limiting relative frequencies rather than computed according to
the Bayes update rule. The proposal is developed as follows using the
confidence measure of a scalar parameter of interest. (With the restriction to
one-dimensional parameter space, a confidence measure is essentially a fiducial
probability distribution free of complications involving ancillary statistics.)
  A betting game establishes a sense in which confidence measures are the only
reliable inferential probability distributions. The equality between the
probabilities encoded in a confidence measure and the coverage rates of the
corresponding confidence intervals ensures that the measure's rule for
assigning confidence levels to hypotheses is uniquely minimax in the game.
  Although a confidence measure can be computed without any prior distribution,
previous knowledge can be incorporated into confidence-based reasoning. To
adjust a p-value or confidence interval for prior information, the confidence
measure from the observed data can be combined with one or more independent
confidence measures representing previous agent opinion. (The former confidence
measure may correspond to a posterior distribution with frequentist matching of
coverage probabilities.) The representation of subjective knowledge in terms of
confidence measures rather than prior probability distributions preserves
approximate frequentist validity.Comment: major revisio",53,http://arxiv.org/abs/math/0602377
K. Dodge,Social-cognitive mechanisms in the development of conduct disorder and depression.,None,SupportedSources.SEMANTIC_SCHOLAR,10.1146/ANNUREV.PS.44.020193.003015,CONTENTS INTRODucnON 559 Mental Processes in Social Behavior 560 SOCIAL-INFORMA nON-PROCESSING THEORY . ... . . . . . . . . . . . .. . .. . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . 560 Application to Single Behavioral Events 562 Application to Child Psychopathology 563 Critique ..... ... . . . . . . . . . . . . . . . . . . . . .. 571 KNOWLEDGE STRUCTURES THAT GUIDE PROCESSING 573 Relation to Aggressive Behavior 575 Relation to Depression .. ... 577 DEVELOPMENTAL PSYCHOPATHOLOGY OF CONDUCT DISORDER AND DEPRESSION '''''''''''' 578 CONCLUSION 580,54,https://www.semanticscholar.org/paper/18a85fd2b586106218019df9aaffe1a2ca528ddb
Lazar Obradović,econstor Make Your Publications Visible . A Service of zbw,None,SupportedSources.SEMANTIC_SCHOLAR,,"This paper introduces a (coherent) risk measure that describes the uncertainty of the model (represented by a probability measure P0) by a set Pλ of probability measures each of which has a Radon-Nikodym’s derivative (with respect to P0) that lies within the interval [λ, 1 λ ] for some constant λ ∈ (0, 1]. Economic considerations are discussed and an explicit representation is obtained that gives a connection to both the expected loss of the financial position and its average value-at-risk. Optimal portfolio analysis is performed – different optimization criteria lead to Merton portfolio. Comparison with related problems reveals examples of extreme sensitivity of optimal portfolios to model parameters and the choice of risk measure.",55,https://www.semanticscholar.org/paper/f2fd76c51731add3b8931a5a5a41d01a7a7f0af2
"Mohammed Berkhouch,G. Lakhnati,M. Righi",A new class of spectral risk measures,2018-04-01 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.1109/ICOA.2018.8370533,"The aim of this paper is to introduce a class of spectral risk measures that extends the Gini-type measure of risk and variability, by taking risk aversion into consideration. Our class of risk measures is coherent and catches variability, an important concept for risk management. The analysis is made under the Choquet integral representation framework. We further provide a practical application.",56,https://www.semanticscholar.org/paper/559e1ab67f33bce0c381415e261f0d032b6bdf08
"Suparna Biswas,Rituparna Sen",Kernel Based Estimation of Spectral Risk Measures,2021-05-31 00:00:00,SupportedSources.INTERNET_ARCHIVE,,"Spectral risk measures (SRMs) belong to the family of coherent risk measures. A natural estimator for the class of SRMs has the form of L-statistics. Various authors have studied and derived the asymptotic properties of the empirical estimator of SRM. We propose a kernel based estimator of SRM. We investigate the large sample properties of general L-statistics based on i.i.d and dependent observations and apply them to our estimator. We prove that it is strongly consistent and asymptotically normal. We compare the finite sample performance of our proposed kernel estimator with that of several existing estimators for different SRMs using Monte Carlo simulation. We observe that our proposed kernel estimator outperforms all the estimators. Based on our simulation study we have estimated the exponential SRM of four future indices-that is Nikkei 225, Dax, FTSE 100, and Hang Seng. We also perform a backtesting exercise of SRM.",57,https://web.archive.org/web/20200826044731/https://arxiv.org/pdf/1903.03304v2.pdf
"Reisa A. Sperling,Paul S. Aisen,Laurel A. Beckett,David A. Bennett,Suzanne Craft,Anne M. Fagan,Takeshi Iwatsubo,Clifford R. Jack,Jeffrey Kaye,Thomas J. Montine,Denise C. Park,Eric M. Reiman,Christopher C. Rowe,Eric Siemers,Yaakov Stern,Kristine Yaffe,Maria C. Carrillo,Bill Thies,Marcelle Morrison-Bogorad,Molly V. Wagster,Creighton H. Phelps",Toward defining the preclinical stages of Alzheimer's disease: Recommendations from the National Institute on Aging‐Alzheimer's Association workgroups on diagnostic guidelines for Alzheimer's disease,2011-05-01 00:00:00,SupportedSources.OPENALEX,10.1016/j.jalz.2011.03.003,,58,"https://openalex.org/W2129497119
https://doi.org/10.1016/j.jalz.2011.03.003
https://academiccommons.columbia.edu/doi/10.7916/D8RZ0QJC/download"
"Sayeeda Rahman,Keerti Singh,S. Dhingra,J. Charan,Paras Sharma,Salequl Islam,Dilshad Jahan,K. Iskandar,N. Samad,M. Haque",The Double Burden of the COVID-19 Pandemic and Polypharmacy on Geriatric Population – Public Health Implications,2020-10-20 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.2147/TCRM.S272908,"Abstract COVID-19 pandemic is inducing acute respiratory distress syndrome, multi-organ failure, and eventual death. Respiratory failure is the leading cause of mortality in the elderly population with pre-existing medical conditions. This group is particularly vulnerable to infections due to a declined immune system, comorbidities, geriatric syndrome, and potentially inappropriate polypharmacy. These conditions make the elderly population more susceptible to the harmful effects of medications and the deleterious consequences of infections, including MERS-CoV, SARS-CoV, and SARS-CoV-2. Chronic diseases among elderlies, including respiratory diseases, hypertension, diabetes, and coronary heart diseases, present a significant challenge for healthcare professionals. To comply with the clinical guidelines, the practitioner may prescribe a complex medication regimen that adds up to the burden of pre-existing treatment, potentially inducing adverse drug reactions and leading to harmful side-effects. Consequently, the geriatric population is at increased risk of falls, frailty, and dependence that enhances their susceptibility to morbidity and mortality due to SARS-CoV-2 respiratory syndrome, particularly interstitial pneumonia. The major challenge resides in the detection of infection that may present as atypical manifestations in this age group. Healthy aging can be possible with adequate preventive measures and appropriate medication regimen and follow-up. Adherence to the guidelines and recommendations of WHO, CDC, and other national/regional/international agencies can reduce the risks of SARS-CoV-2 infection. Better training programs are needed to enhance the skill of health care professionals and patient’s caregivers. This review explains the public health implications associated with polypharmacy on the geriatric population with pre-existing co-morbidities during the COVID-19 pandemic.",59,"https://www.semanticscholar.org/paper/24ee430682b61674f014c4965d61076d7adb43a4
https://www.dovepress.com/getfile.php?fileID=62756"
"Mike Ludwig,Gareth Leng",Dendritic peptide release and peptide-dependent behaviours,2006-02-01 00:00:00,SupportedSources.OPENALEX,10.1038/nrn1845,,60,"https://openalex.org/W2090689542
https://doi.org/10.1038/nrn1845"
"Jiya, Tilimbe",A realisation of ethical concerns with smartphone personal health monitoring apps,2016-01-01 00:00:00,SupportedSources.CORE,10.1145/2874239.2874285,"The pervasiveness of smartphones has facilitated a new way in which owners of devices can monitor their health using applications (apps) that are installed on their smartphones. Smartphone personal health monitoring (SPHM) collects and stores health related data of the user either locally or in a third party storing mechanism. They are also capable of giving feedback to the user of the app in response to conditions are provided to the app therefore empowering the user to actively make decisions to adjust their lifestyle.
Regardless of the benefits that this new innovative technology offers to its users, there are some ethical concerns to the user of SPHM apps. These ethical concerns are in some way connected to the features of SPHM apps. From a literature survey, this paper attempts to recognize ethical issues with personal health monitoring apps on smartphones, viewed in light of general ethics of ubiquitous computing. The paper argues that there are ethical concerns with the use of SPHM apps regardless of the benefits that the technology offers to users due to SPHM apps’ ubiquity leaving them open to known and emerging ethical concerns. The paper then propose a need further empirical research to validate the claim",61,https://core.ac.uk/download/228192213.pdf
"Gambelli, D.,Vairo, D.,Zanoli, R.",Organic Farming in Europe by 2010: Scenarios for the future,2000-01-01 00:00:00,SupportedSources.CORE,,"How will organic farming in Europe evolve by the year 2010? The answer provides a basis for the development of different policy options and for anticipating the future relative competitiveness of organic and conventional farming. The authors tackle the question using an innovative approach based on scenario analysis, offering the reader a range of scenarios that encompass the main possible evolutions of the organic farming sector.

This book constitutes an innovative and reliable decision-supporting tool for policy makers, farmers and the private sector. Researchers and students operating in the field of agricultural economics will also benefit from the methodological approach adopted for the scenario analysis",62,https://core.ac.uk/download/10924249.pdf
"Abigail Dickinson,Charlotte DiStefano,Yin-Ying Lin,Aaron Wolfe Scheffler,Damla Senturk,Shafali Spurling Jeste",Interhemispheric alpha-band hypoconnectivity in children with autism spectrum disorder,2018-01-01 00:00:00,SupportedSources.INTERNET_ARCHIVE,10.1016/j.bbr.2018.04.026,"A B S T R A C T • Diverse genetic and environmental etiologies converge onto circuit level brain dysfunction in autism spectrum disorder (ASD), manifesting at a macroscopic level as aberrant neural connectivity. Previous studies have described atypical patterns of decreased short range and increased long range connectivity in ASD [1]. However, it remains unclear whether group level features of circuit dysfunction are consistently present across the range of cognitive function seen in the autism spectrum. • The dynamics of neural oscillations in the alpha range (6-12 Hz) are exquisitely sensitive to healthy development of functional and structural connectivity. Alpha-band coherence, measured with high temporalprecision electroencephalography (EEG) therefore represents an ideal tool for studying neural connectivity in developmental populations. • Here we examined spontaneous alpha phase coherence in a heterogeneous sample of 59 children with ASD and 39 age matched typically developing children. Using a data driven approach, we conducted an unbiased examination of all possible atypical connectivity patterns across all cortical regions. • Long-range hypoconnectivity was present in children with ASD compared to typically developing children, with temporal interhemispheric connectivity showing the largest difference between the two groups. • Decreased long range alpha coherence distinguishes a heterogeneous group of ASD children from typically developing children. Interhemispheric temporal hypoconnectivity represents a fundamental functional difference in children with ASD across a wide cognitive and age range that may reflect white matter disturbances or increased signal variability at temporal sites in ASD.",63,https://web.archive.org/web/20190502073018/https://cloudfront.escholarship.org/dist/prd/content/qt3gv354c3/qt3gv354c3.pdf?t=pc0rjl
"Anne K. Gauthier,Christina Miller,Kitty Purington,Shivani Patel",On the Road to Better Value: State Roles in Promoting Accountable Care Organizations,2011-02-02 00:00:00,SupportedSources.CORE,,"Outlines how accountable care organizations can deliver value through incentives to manage utilization, improve quality, and curb cost growth. Profiles states supporting the model with data, new payment methods, accountability measures, and other efforts",64,https://core.ac.uk/download/71353567.pdf
"Philip S. Brazio,Patrick C. Laird,Chenyang Xu,Junyan Gu,Nicholas S. Burris,Emile N. Brown,Zachary N. Kon,Robert S. Poston",Harmonic scalpel versus electrocautery for harvest of radial artery conduits: Reduced risk of spasm and intimal injury on optical coherence tomography,2008-01-01 00:00:00,SupportedSources.INTERNET_ARCHIVE,10.1016/j.jtcvs.2008.05.060,"Objective: Vasospasm is the primary obstacle to widespread adoption of the radial artery as a conduit in coronary artery bypass grafting. We used optical coherence tomography, a catheter-based intravascular imaging modality, to measure the degree of radial artery spasm induced by means of harvest with electrocautery or a harmonic scalpel in patients undergoing coronary artery bypass grafting. Methods: Radial arteries were harvested from 44 consecutive patients with a harmonic scalpel (n ¼ 15) or electrocautery (n ¼ 29). Vessels were imaged before harvesting and after removal from the arm, with saphenous vein tracts serving as internal controls. Optical coherence tomographic findings for the degree of harvesting-induced injury were validated against histologic measures. Results: Optical coherence tomographic measures of endovascular dimensions and injury correlated strongly with histologic findings. Mean luminal volume, a measure of vasospasm, decreased significantly less after harvesting with a harmonic scalpel (9% AE 7%) than with electrocautery (35% AE 6%, P ¼ .015). Completely intact intima was present in 11 (73%) of 15 radial arteries harvested with a harmonic scalpel (73%) compared with 9 of 29 arteries harvested by means of electrocautery (31%, P ¼ .011). Intraoperative flow measurements and patency rates at 5 days postoperatively were not significantly different among groups. Conclusions: Optical coherence tomography provides a level of speed and accuracy for quantifying endothelial injury and vasospasm that has not been described for any other modality, suggesting potential as an intraoperative quality assurance tool. Our optical coherence tomographic findings suggest that the harmonic scalpel induces less spasm and intimal injury compared with electrocautery.",65,https://web.archive.org/web/20190417140317/https://core.ac.uk/download/pdf/81941222.pdf
"Arshinder,Arun Kanda,S. G. Deshmukh",A coordination theoretic model for three level supply chains using contracts,2009-01-01 00:00:00,SupportedSources.INTERNET_ARCHIVE,10.1007/s12046-009-0045-6,"Typically, supply chain members are dependent on each other to manage various resources and information. The conflicting objectives and lack of coordination between supply chain members may often cause uncertainties in supply and demand. The basic elements of coordination theory like interdependency, coherency and mutuality may help in effective flow of information and material between the dependent supply chain members. Supply chain contract can be an effective coordination mechanism to motivate all the members to be a part of the entire supply chain. There are different types of supply chain contracts such as buy back and quantity flexibility contracts. Supply chain performance may be substantially improved by properly designing the contracts to share risks and rewards. The objective of this paper is to explore the applicability of coordination elements through an analytical model in three-level (Manufacturer-distributorretailer) serial supply chains using contracts. The model evaluates the impact of supply chain contracts on various performance measures. The impact of some contract may be on some specific performance measure only, which helps managers to choose the type of contract if there is an objective of improving certain performance measure before hand. In three-level supply chains, the contracts are designed at two distinct interfaces: Manufacturer-distributor and distributor-retailer. The model demonstrates the complexity in evaluating the decision variables of three level supply chains. The proposed model is a novel approach to apply coordination theory at various levels of supply chain. The model also presents how the coordination elements are related to each other in various coordination cases.",66,https://web.archive.org/web/20200508185855/https://www.ias.ac.in/article/fulltext/sadh/034/05/0767-0798
"C. Wong,Olivia Jensen",The paradox of trust: perceived risk and public compliance during the COVID-19 pandemic in Singapore,2020-04-28 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.1080/13669877.2020.1756386,"Abstract Public trust in the authorities has been recognised in risk research as a crucial component of effective and efficient risk management. But in a pandemic, where the primary responsibility of risk management is not centralised within institutional actors but defused across society, trust can become a double-edged sword. Under these conditions, public trust based on a perception of government competence, care and openness may in fact lead people to underestimate risks and thus reduce their belief in the need to take individual action to control the risks. In this paper, we examine the interaction between trust in government, risk perceptions and public compliance in Singapore in the period between January and April 2020. Using social media tracking and online focus group discussions, we present a preliminary assessment of public responses to government risk communication and risk management measures. We highlight the unique deployment of risk communication in Singapore based on the narrative of ‘defensive pessimism’ to heighten rather than lower levels perceived risk. But the persistence of low public risk perceptions and concomitant low levels of compliance with government risk management measures bring to light the paradox of trust. This calls for further reflection on another dimension of trust which focuses on the role of the public; and further investigation into other social and cultural factors that may have stronger influence over individual belief in the need to take personal actions to control the risks.",67,https://www.semanticscholar.org/paper/6be153247b30b640cb47c388520dc3143d62f74c
"Andrew G. Renehan,Matthias Egger,Marcel Zwahlen",Body Mass Index and Cancer Risk: The Evidence for Causal Association~!2009-04-22~!2009-06-16~!2010-07-13~!,2010-07-22 00:00:00,SupportedSources.INTERNET_ARCHIVE,10.2174/1876823701002020012,"Increased body mass index (BMI), as an approximation of body adiposity, is a risk factor for developing several adult malignancies. To quantify these risks, we reported a comprehensive systematic review (Lancet 2008; 371: 569-78) of prospective observational studies determining associations between BMI and risk of incident cancer for 20 cancer types. We demonstrated that associations are: (i) sex-specific; (ii) exist for a wider range of malignancies than previously thought; and (iii) are broadly consistent across geographic populations. In the present paper, we tested these data against the Bradford-Hill criteria of causal association, and argue that the available data support strength of association, consistency, specificity, temporality, biological gradient, plausibility, coherence and probably analogy. However, the experimental evidence supporting reversibility is currently lacking, though indirect evidence from longitudinal data in cohort studies and long-term follow-up post-bariatric surgery is emerging. We additionally assessed these data against appropriate adjustment for available confounding factors; measurement error and study design; and residual confounding; and found lack of alternative explanations. We conclude that there is considerable evidence to support a causal association between BMI and risk for many cancer types, but in order to establish the role of weight control in cancer prevention, there is a need to develop trial frameworks in which to better test reversibility. A Strong Association is More Likely to have a Causal Component than is a Modest Association Hill [4] illustrated this point with the high risk ratios for the association between exposure levels of smoking and incidence of lung cancer. However, he equally demonstrated with two counter-examples that the absence of a strong association does not rule out a causal effect and recognised that the impression of strength of association depended on the index used for the magnitude of association. For our systematic review, the index was BMI as an approximation of body adiposity. As BMI represents a spectrum of exposures (rather than a binary exposure), the size of the risk estimate is expressed relative to a given change in BMI. Accordingly, we chose 5 kg/m 2 increments (Table 1), such that increases in BMI of 5, 10 and 15 kg/m 2 are broadly equivalent to World Health Organisation [7] categories -source: https://doi.",68,https://web.archive.org/web/20170922084233/https://boris.unibe.ch/1155/1/Renehan%20OpenObesJ%202010.pdf
"Devlin, N,Maynard, A,Mays, N",New Zealand's new health sector reforms: back to the future?,2001-01-01 00:00:00,SupportedSources.CORE,10.1136/bmj.322.7295.1171,"New Zealand attracted much international attention in the late 1980s and 1990s for its radical economic and social reforms. This reforming tendency shows no signs of abating. In late 1999 the national (conservative) government was replaced by a Labour led coalition, which is rapidly and significantly changing the way publicly financed health services are organised. Before the general election, Labour had criticised the national government's quasimarket system for its narrow focus on the production of services rather than the improvement of health, for having fragmented a public service, for fostering inappropriate commercial behaviour, for increasing transaction costs, and for lacking local democratic input. These problems were attributed to the ""corporate model"" of public hospital provision and a single, national purchasing agency. Both will now be replaced with a system promoted as allowing greater community ""voice"" in health sector decision making and ""putting the public back into the public health system."" This paper reviews New Zealand's experience with the quasimarket model and appraises the rationale for another round of structural change. We identify challenges policymakers face in achieving their goals, consider the general lessons provided by New Zealand's frequent U-turns in policy, and offer a set of criteria against which the new system might be assessed",69,https://core.ac.uk/download/60149.pdf
"M. van Zeeland,R. Boivin,D. Brower,T. Carlstrom,J. A. Chávez,W. Ding,R. Feder,D. Johnson,L. Lin,R. O’NEILL,C. Watts",Conceptual design of the tangentially viewing combined interferometer-polarimeter for ITER density measurements.,2013-04-04 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.1063/1.4798602,"One of the systems planned for the measurement of electron density in ITER is a multi-channel tangentially viewing combined interferometer-polarimeter (TIP). This work discusses the current status of the design, including a preliminary optical table layout, calibration options, error sources, and performance projections based on a CO2/CO laser system. In the current design, two-color interferometry is carried out at 10.59 μm and 5.42 μm and a separate polarimetry measurement of the plasma induced Faraday effect, utilizing the rotating wave technique, is made at 10.59 μm. The inclusion of polarimetry provides an independent measure of the electron density and can also be used to correct the conventional two-color interferometer for fringe skips at all densities, up to and beyond the Greenwald limit. The system features five chords with independent first mirrors to reduce risks associated with deposition, erosion, etc., and a common first wall hole to minimize penetration sizes. Simulations of performance for a projected ITER baseline discharge show the diagnostic will function as well as, or better than, comparable existing systems for feedback density control. Calculations also show that finite temperature effects will be significant in ITER even for moderate temperature plasmas and can lead to a significant underestimate of electron density. A secondary role TIP will fulfill is that of a density fluctuation diagnostic; using a toroidal Alfvén eigenmode as an example, simulations show TIP will be extremely robust in this capacity and potentially able to resolve coherent mode fluctuations with perturbed densities as low as δn∕n ≈ 10(-5).",70,https://www.semanticscholar.org/paper/49fbf138dd99ce41ca3dc48f44253fee3d92733f
"D. Murdoch,D. Krewski,J. Wargo",Cancer risk assessment with intermittent exposure.,1992-12-01 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.1111/J.1539-6924.1992.TB00713.X,"Applications of methods for carcinogenic risk assessment often focus on estimating lifetime cancer risk. With intermittent or time-dependent exposures, lifetime risk is often approximated on the basis of a lifetime average daily dose (LADD). In this article, we show that there exists a lifetime equivalent constant dose (LECD) which leads to the same lifetime risk as the actual time-dependent exposure pattern. The ratio C = LECD/LADD then provides a measure of accuracy of risk estimates based on the LADD, as well as a basis for correcting such estimates. Theoretical results derived under the classical multistage model and the two-stage birth-death-mutation model suggest that the maximum value of C, which represents the factor by which the LADD may lead to underestimates of risk, will often lie in the range of 2- to 5-fold. The practical application of these results is illustrated in the case of astronauts subjected to relatively short-term exposure to volatile organics in a closed space station environment, and in the case of the ingestion of pesticide residues in food where consumption patterns vary with age.",71,https://www.semanticscholar.org/paper/76fcaecd894ea6e56afc098772da28ca02205f8e
"Andreas H. Hamel,Frank Heyde",Duality for Set-Valued Measures of Risk,2010-01-01 00:00:00,SupportedSources.INTERNET_ARCHIVE,10.1137/080743494,"Extending the approach of Jouini et al. we define set-valued (convex) measures of risk and its acceptance sets. Using a new duality theory for set-valued convex functions we give dual representation theorems. A scalarization concept is introduced that has economical meaning in terms of prices of portfolios of reference instruments. Using primal and dual descriptions, we introduce new examples for set-valued measures of risk, e.g. set-valued expectations, Value at Risk, Average Value at Risk and entropic risk measure.",72,https://web.archive.org/web/20170813004514/http://webdoc.sub.gwdg.de/ebook/serien/e/reports_Halle-Wittenberg_math/07-15report.pdf
"Songtian Zeng,Catherine P. Corr,Courtney O'Grady,Yiyang Guan",Adverse childhood experiences and preschool suspension expulsion: A population study,2019-08-29 00:00:00,SupportedSources.INTERNET_ARCHIVE,10.1016/j.chiabu.2019.104149,"Preschool suspension and expulsion rates are typically based on teacher reports, and don't simultaneously account for adverse childhood experiences (ACEs).",73,https://web.archive.org/web/20200212074745/http://downloads.hindawi.com/journals/mpe/2019/2196563.pdf
"J. Mueller,M. Stewart",Responsible Counterterrorism Policy,2014-09-10 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,,"Terrorism is a hazard to human life, and it should be dealt with in a manner similar to that applied to other hazards — albeit with an appreciation for the fact that terrorism often evokes extraordinary fear and anxiety. Although allowing emotion to overwhelm sensible analysis is both understandable and common among ordinary people, it is inappropriate for officials charged with keeping them safe. To do so is irresponsible, and it costs lives.Risk analysis is an aid to responsible decisionmaking that has been developed, codified, and applied over the past few decades — or in some respects centuries. We deal with four issues central to that approach and apply them to the hazard presented by terrorism: the cost per saved life, acceptable risk, cost-benefit analysis, and risk communication. We also assess the (very limited) degree to which risk analysis has been coherently applied to counterterrorism efforts by the U.S. government in making or evaluating decisions that have cost taxpayers hundreds of billions of dollars.At present, the process encourages decisionmaking that is exceptionally risk averse. In addition, decisionmakers appear to be overly fearful about negative reactions to any relaxations of security measures that fail to be cost-effective and also about the consequences of failing to overreact.If other uses of the funds available would more effectively save lives, a government obliged to allocate money in a manner that best benefits public safety must explain why spending billions of dollars on security measures with very little proven benefit is something other than a reckless waste of resources.",74,https://www.semanticscholar.org/paper/f19d2ce5f973a52fbad1086de37c026c16af881b
"Tomlinson, M,Walker, R,Williams, G",Child poverty and well-being in the here and now,2008-01-01 00:00:00,SupportedSources.CORE,,,75,https://core.ac.uk/download/30630664.pdf
Alexander S. Cherny,Equilibrium with coherent risk,2006-05-02 12:11:08+00:00,SupportedSources.ARXIV,,"This paper is the continuation of ""Pricing with coherent risk"" and deals with
further applications of coherent risk measures to problems of finance. First,
we study the optimization problem. Three forms of this problem are considered.
Furthermore, the results obtained are applied to the optimality pricing. Again
three forms of this technique are considered. Finally, we study the equilibrium
problem both in the unconstrained and in the constrained forms. We establish
the equivalence between the global and the competitive optima and give a dual
description of the equilibrium. Moreover, we provide an explicit geometric
solution of the constrained equilibrium problem. Most of the results are
presented on two levels: on a general level the results have a probabilistic
form; for a static model with a finite number of assets, the results have a
geometric form.",76,"http://arxiv.org/pdf/math/0605051v1
http://arxiv.org/abs/math/0605051v1
http://arxiv.org/pdf/math/0605051v1"
"J. Pearson,D. A. Cohn,P. Cowan,C. Cowan",Earned- and continuous-security in adult attachment: Relation to depressive symptomatology and parenting style,1994-03-01 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.1017/S0954579400004636,"Abstract The secure working model classification of adult attachment, as derived from Main and Goldwyn's (in press) Adult Attachment Interview scoring system, was considered in terms of earned-security and continuous-security. Earned-security was a classification given to adults who described difficult, early relationships with parents, but who also had current secure working models as indicated by high coherency scores; continuous-security referred to a classification in which individuals described secure early attachment relationship with parents and current secure working models. Working models of attachment were classified as earned-secure, continuous-secure, or insecure in a sample of 40 parents of preschool children. Comparisons among the classifications were conducted on a measure of depressive symptoms and two sets of ratings of observed parenting styles. Adults with earned-secure classifications had comparable depressive symptomatology to insecures, with 30% of the insecures, 40% of the earned-secures, and only 10% of the continuous-secures having scores exceeding the clinical cut-off. The rate of depressive symptomatology in the earned-secure group suggests that reconstructions of past difficulties may remain emotional liabilities despite a current secure working model. With regard to parenting styles with their preschoolers, the behavior of earned-secure parents was comparable to that of the continuous-secures. This refinement in conceptualizing secure working models suggests ways for understanding variation in pathways to competent parenting as well as a possible perspective on how adults' adverse early experiences may continue to place them and their children at risk.",77,https://www.semanticscholar.org/paper/5d637ef11f2885c2763ed2e49461c8dcc67f3dfe
"O'Brien, T",A Comparison of Leadership in Controlled Military Democratisation,2016-03-23 00:00:00,SupportedSources.CORE,,"Military coup d’état displace civilian regimes in the name of cleaning up, but such actions can also challenge the coherence of the military by undermining the recognition of governing institutions. The decision of military regimes to relinquish power from a position of strength and move towards democracy is conditioned by a number of factors, requiring the leader to navigate between the perceived need to maintain political order and military professionalism. This paper considers regime change in Ecuador and Niger as cases of conversion, where elites were able to maintain control in the face of relatively weak organised opposition. The aims of the paper are to (1) determine the factors that can initiate democratisation of military regimes and (2) identify the role of leaders in shaping the process. It is argued that the relative durability of the subsequent regime is determined by the ability of the outgoing military regime to find suitable opposition to maintain order and resist the temptation to return to politics",78,https://core.ac.uk/download/74410864.pdf
"José Orihuela,José Miguel Zapata",A note on conditional risk measures of Orlicz spaces and Orlicz-type modules,2016-12-12 13:58:09+00:00,SupportedSources.ARXIV,,"We consider conditional and dynamic risk measures of Orlicz spaces and study
their robust representation. For this purpose, given a probability space
$(\Omega,\mathcal{E},\mathbb{P})$, a sub-$\sigma$-algebra $\mathcal{F}$ of
$\mathcal{E}$, and a Young function $\varphi$, we study the relation between
the classical Orlicz space $L^\varphi(\mathcal{E})$ and the modular Orlicz-type
module $L^\varphi_\mathcal{F}(\mathcal{E})$; based on conditional set theory,
we describe the conditional order continuous dual of a Orlicz-type module; and
by using scalarization and modular extensions of conditional risk measures
together with elements of conditional set theory, we finally characterize the
robust representation of conditional risk measures of Orlicz spaces.",79,"http://arxiv.org/pdf/1612.03680v4
http://arxiv.org/abs/1612.03680v4
http://arxiv.org/pdf/1612.03680v4"
"Thierry Roncalli,Fatma Karray-Meziou,François Pan,Margaux Regnault",Liquidity Stress Testing in Asset Management -- Part 1. Modeling the Liability Liquidity Risk,2021-01-06 16:08:27+00:00,SupportedSources.ARXIV,10.13140/RG.2.2.14893.72165,"This article is part of a comprehensive research project on liquidity risk in
asset management, which can be divided into three dimensions. The first
dimension covers liability liquidity risk (or funding liquidity) modeling, the
second dimension focuses on asset liquidity risk (or market liquidity)
modeling, and the third dimension considers asset-liability liquidity risk
management (or asset-liability matching). The purpose of this research is to
propose a methodological and practical framework in order to perform liquidity
stress testing programs, which comply with regulatory guidelines (ESMA, 2019)
and are useful for fund managers. The review of the academic literature and
professional research studies shows that there is a lack of standardized and
analytical models. The aim of this research project is then to fill the gap
with the goal to develop mathematical and statistical approaches, and provide
appropriate answers.
  In this first part that focuses on liability liquidity risk modeling, we
propose several statistical models for estimating redemption shocks. The
historical approach must be complemented by an analytical approach based on
zero-inflated models if we want to understand the true parameters that
influence the redemption shocks. Moreover, we must also distinguish aggregate
population models and individual-based models if we want to develop behavioral
approaches. Once these different statistical models are calibrated, the second
big issue is the risk measure to assess normal and stressed redemption shocks.
Finally, the last issue is to develop a factor model that can translate stress
scenarios on market risk factors into stress scenarios on fund liabilities.",80,"http://arxiv.org/pdf/2101.02110v1
http://dx.doi.org/10.13140/RG.2.2.14893.72165
http://arxiv.org/abs/2101.02110v1
http://arxiv.org/pdf/2101.02110v1"
I. Williamson,Internalized homophobia and health issues affecting lesbians and gay men.,2000-02-01 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.1093/HER/15.1.97,"This paper investigates the concept of internalized homophobia in both theory and research relating to lesbian and gay health. It offers a contemporary and critical review of research in this area, and discusses a range of recent findings relating to a range of health issues including HIV and AIDS. Whilst the concept has a resonance for gay men and lesbians, and is widely used in 'lesbian and gay-affirmative' interventions, the paper demonstrates that research findings have been equivocal and the term is often used without full consideration of its sociopolitical consequences. The paper concludes that the concept does have a valuable role to play in health promotion work with lesbians and gay men but invites further discussion and examination of the construct.",81,"https://www.semanticscholar.org/paper/c1b8b9dccfd8298a636250e385733dd3ab4762d9
https://academic.oup.com/her/article-pdf/15/1/97/9809304/150097.pdf"
"Alchourrón,Artzner,Couso,Davey,De Cooman,De Cooman,De Cooman,De Cooman,De Cooman,de Finetti,de Finetti,de Finetti,Dempster,Erik Quaeghebeur,Filip Hermans,Fishburn,Föllmer,Gert de Cooman,Good,Greenleaf,Hammer,Keynes,Koopman,Levi,Miranda,Pelessoni,Quaeghebeur,Quaeghebeur,Seidenfeld,Seidenfeld,Seidenfeld,Shafer,Shimony,Smith,Suppes,Wagner,Walley,Walley,Whittle,Williams,Williams,Williams",Accept & Reject Statement-Based Uncertainty Models,2015-01-01 00:00:00,SupportedSources.CORE,10.1016/j.ijar.2014.12.003,"We develop a framework for modelling and reasoning with uncertainty based on
accept and reject statements about gambles. It generalises the frameworks found
in the literature based on statements of acceptability, desirability, or
favourability and clarifies their relative position. Next to the
statement-based formulation, we also provide a translation in terms of
preference relations, discuss---as a bridge to existing frameworks---a number
of simplified variants, and show the relationship with prevision-based
uncertainty models. We furthermore provide an application to modelling symmetry
judgements.Comment: 35 pages, 17 figure",82,https://core.ac.uk/download/301648752.pdf
"Rachel L Morehouse,Vivek Kusumakar,Stanley P Kutcher,John LeBlanc,Roseanne Armitage","Temporal coherence in ultradian sleep EEG rhythms in a never-depressed, high-risk cohort of female adolescents",2002-01-01 00:00:00,SupportedSources.INTERNET_ARCHIVE,10.1016/s0006-3223(01)01297-5,"Previous work has indicated that low temporal coherence of ultradian sleep electroencephalographic rhythms is characteristic of depressed patients and of depressed women, in particular. It may also be evident in one quarter of those at high risk, based on a family history of depression. Methods: The present study evaluated temporal coherence of sleep electroencephalographic rhythms in 41 adolescent girls with a maternal history of depression (high risk) and 40 healthy controls (low risk). The entire sample was followed clinically every 6 months for 2 years. Results: Temporal coherence was significantly lower among the high-risk girls than in controls. Regression analyses predicted group from coherence values and correctly classified 70% of the high-risk group with a false-positive rate of 5% among controls. Moreover, 54% of the high-risk girls were identified with extreme low coherence. On clinical follow up, 14 girls showed depressive symptoms, 9 in the high-risk group (22.5%) and 5 controls (12.2%). Six met DSM-IV criteria for firstepisode major depressive disorder, five high-risk and one control. Most importantly, 41% of those identified as having the most abnormal coherence values either showed symptoms of depression or met diagnostic criteria upon follow up. Conclusions: Low temporal coherence is evident in adolescent girls at high risk for depression. The more abnormal the coherence, the greater the risk of a first episode of major depressive disorder within 2 years of sleep study, approximately 10 times greater than in controls. Biol Psychiatry 2002;51:446 -456",83,"https://web.archive.org/web/20170818234516/https://deepblue.lib.umich.edu/bitstream/handle/2027.42/60181/Morehouse,%202002.pdf?sequence=1"
"F. Prati,G. Guagliumi,G. Mintz,Marco Costa,E. Regar,T. Akasaka,P. Barlis,G. Tearney,I. Jang,Elosia Arbustini,H. Bezerra,Y. Ozaki,N. Bruining,D. Dudek,M. Radu,A. Erglis,P. Motreff,F. Alfonso,K. Toutouzas,N. Gonzalo,C. Tamburino,T. Adriaenssens,F. Pinto,P. Serruys,C. Di Mario","Expert review document part 2: methodology, terminology and clinical applications of optical coherence tomography for the assessment of interventional procedures",2012-05-31 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.1093/eurheartj/ehs095,"This document is complementary to an Expert Review Document on Optical Coherence Tomography (OCT) for the study of coronary arteries and atherosclerosis.1 The goal of this companion manuscript is to provide a practical guide framework for the appropriate use and reporting of the novel frequency domain (FD) OCT imaging to guide interventional procedures, with a particular interest on the comparison with intravascular ultrasound (IVUS).1–4

In the OCT Expert Review Document on Atherosclerosis, a comprehensive description of the physical principles for OCT imaging and time domain (TD) catheters (St Jude Medical, Westford, MA, USA) was provided.1

The main advantage of FD-OCT is that the technology enables rapid imaging of the coronary artery, using a non-occlusive acquisition modality. The FD-OCT catheter (DragonflyTM; St Jude Medical) employs a single-mode optical fibre, enclosed in a hollow metal torque wire that rotates at a speed of 100 r.p.s. It is compatible with a conventional 0.014″ angioplasty guide wire, inserted into a short monorail lumen at the tip. The frequency domain optical coherence tomography lateral resolution is improved in comparison with TD-OCT, while the axial resolution did not change. These features, together with reduced motion artefacts and an increased maximum field of view up to 11 mm, have significantly improved both the quality and ease of use of OCT in the catheterization laboratory.3,4 However, the imaging depth of the FD-OCT is still limited to 0.5–2.0 mm.5

The main obstacle to the adoption of TD-OCT imaging in clinical practice is that OCT cannot image through a blood field, and therefore requires clearing or flushing of blood from the lumen.1 The 6 Fr compatible DragonflyTM FD-OCT catheter is so far the only one in the market, as two other systems from Volcano and Terumo, which …",84,"https://www.semanticscholar.org/paper/48f2f306ec59da947484a2fc7dfef7204cd04cdb
https://academic.oup.com/eurheartj/article-pdf/33/20/2513/1222472/ehs095.pdf"
Kerem Uğurlu,A new coherent multivariate average-value-at-risk,2021-09-06 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.1080/02331934.2021.1970755,"A new operator for handling the joint risk of different sources has been presented and its various properties are investigated. The problem of risk evaluation of multivariate risk sources has been studied, and a multivariate risk measure, so-called multivariate average-value-at-risk, , is proposed to quantify the total risk. It is shown that the proposed operator satisfies the four axioms of a coherent risk measure while reducing to one variable average-value-at-risk, , in case N = 1. In that respect, it is shown that is the natural extension of to N-dimensional case maintaining its axiomatic properties. We further show is flexible by giving the investor the option to choose the risk level of each random loss i differently. This flexibility is novel and can not be achieved applying univariate with corresponding risk level α to the sum of the risk marginals. The framework is applicable for Gaussian mixture models with dependent risk factors that are naturally used in financial and actuarial modelling. A multivariate tail variance and its connection with is also presented via Chebyshev inequality for tail events. Examples with numerical simulations are also illustrated throughout.",85,https://www.semanticscholar.org/paper/c806592b0ded03bf96c90345ae4d0b78e079e3ea
"Ojima, J.",Measures to reduce risk from welding fume exposure,2023-03-20 00:00:00,SupportedSources.CROSSREF,10.1539/sangyoeisei.2022-018-w,,86,"https://www.jstage.jst.go.jp/article/sangyoeisei/65/2/65_2022-018-W/_pdf
http://dx.doi.org/10.1539/sangyoeisei.2022-018-w"
"Colin Bryson,John Burgess,Richard Blackwell",Managing temporary workers in higher education: still at the margin?,2006-01-01 00:00:00,SupportedSources.CORE,10.1108/00483480610645830,"Purpose – To evaluate whether “numerical flexibility” – specifically a form of temporary and precarious employment – hourly-paid part-time teaching in the UK higher education sector – adds strategic value and demonstrates good practice.   Design/methodology/approach – The study is based on new evidence drawn from five case study organisations in which a range of managers was interviewed in depth.   Findings – Analysis identifies a continuum of strategies from integration into the main workforce through to “deepened differentiation”. Although integration is somewhat problematic when applied to a diverse group, differentiation seems predicated on a defensive, risk management approach designed to further marginalise this activity. Also, differentiation fails to address the aspirations of many employees, creating tensions between institutional strategy and the needs of academic heads.   Research limitations/implications – The number of case studies is limited. These case studies were selected because they had the most proactive strategies on this issue, which infers that the majority of employers in HE have not been rather less strategic or proactive.   Practical implications – The paper is of particular value to HR professionals considering the use of numerical flexibility approaches. It also contributes to the academic debate on the strategic value of such approaches.   Originality/value – The paper explores a neglected but important area of the workforce. The paper notes that some supposed benefits of numerical flexibility might be illusory, such as the deployment of allegedly “cheap and disposable” substitute workers which may be offset by unintentional consequences including rigidities in an organisation's human resource systems",87,https://core.ac.uk/download/30633481.pdf
"Hamid Eghbal-zadeh,Khaled Koutini,Paul Primus,Verena Haunschmid,Michal Lewandowski,Werner Zellinger,Bernhard A. Moser,Gerhard Widmer",On Data Augmentation and Adversarial Risk: An Empirical Analysis,2020-07-06 11:16:18+00:00,SupportedSources.ARXIV,,"Data augmentation techniques have become standard practice in deep learning,
as it has been shown to greatly improve the generalisation abilities of models.
These techniques rely on different ideas such as invariance-preserving
transformations (e.g, expert-defined augmentation), statistical heuristics
(e.g, Mixup), and learning the data distribution (e.g, GANs). However, in the
adversarial settings it remains unclear under what conditions such data
augmentation methods reduce or even worsen the misclassification risk. In this
paper, we therefore analyse the effect of different data augmentation
techniques on the adversarial risk by three measures: (a) the well-known risk
under adversarial attacks, (b) a new measure of prediction-change stress based
on the Laplacian operator, and (c) the influence of training examples on
prediction. The results of our empirical analysis disprove the hypothesis that
an improvement in the classification performance induced by a data augmentation
is always accompanied by an improvement in the risk under adversarial attack.
Further, our results reveal that the augmented data has more influence than the
non-augmented data, on the resulting models. Taken together, our results
suggest that general-purpose data augmentations that do not take into the
account the characteristics of the data and the task, must be applied with
care.",88,"http://arxiv.org/pdf/2007.02650v1
http://arxiv.org/abs/2007.02650v1
http://arxiv.org/pdf/2007.02650v1"
"Francesco Tommasi,Ferdinando Toscano,Davide Giusino,Andrea Ceschi,Riccardo Sartori,Johanna Lisa Degen",Meaningful or Meaningless? Organizational Conditions Influencing Doctoral Students' Mental Health and Achievement,2022-01-01 00:00:00,SupportedSources.INTERNET_ARCHIVE,10.28945/5011,"Aim/Purpose: This paper presents a quantitative investigation of the organizational factors predicting the attrition of doctoral students' experience of meaning and how meaningful experience and meaningless work affect doctoral students' mental health and achievements. Background: Today's academic environment subsumes neoliberal principles of individualism, instrumentality, and competition. Such an environment can harm doctoral students' meaningful experience. Universities' market-driven practices, indeed, can lower doctoral students' motivation and affect their mental health. Methodology: In this paper, we referred to empirical knowledge to identify the ways through which today's academia erodes doctoral students' meaningful experiences. We hypothesized that environmental sources of meaning (e.g., coherence, significance, purpose, and belonging) become subsumed under neoliberal principles of individualism, instrumentality, and competition. Lower levels of sources of meaning directly predict the experience of meaningless work, which is linked to higher levels of anxiety, depression, and intention to quit among doctoral students. We conducted a cross-sectional study on a sample of N = 204 doctoral students who volunteered to participate by completing a survey with self-reported measures. We analyzed data collected via structural equation modelling to test the associations among the variables. Contribution: The present paper represents one an attempt attempts to investigate doctoral students' experience as subsumed to market-driven principles of the neoliberal ideology. Findings: Results of structural equation modelling show that higher levels of anxiety and depression symptoms and intention to quit are associated with the lack of external supporting factors (i.e., PhD support), the perception of broad-based managerial practices as meaningless and instrumental, and a general sense of emptiness at work (i.e., meaningless work). Ultimately, doctoral students may strive to have a meaningful experience in today's academic environment. The experience of meaningless work leads to the risk of mental illness symptoms and quitting intention. Recommendations for Practitioners: This study suggests to practitioners to improve doctoral students' well-being with multilevel interventions approach as well as including academic stakeholders to have broader practical implications. Recommendation for Researchers: For researchers, it is suggested to focus on the managerial and organizational conditions of the academic environment that influence the basis of doctoral students' experience of doing a PhD. Impact on Society: This study affords society the importance of prioritizing the academic environment by looking at the meaning in work through the intersection of meaningful experience and meaningless work for doctoral students' mental health and achievement. Future Research: Future research can consider the role of factors contributing to doctoral students' meaningful experience by probing doctoral programs to understand students' mental health and achievement.",89,https://web.archive.org/web/20220819183122/http://ijds.org/Volume17/IJDSv17p301-321Tommasi8096.pdf
"D. Gyrd-Hansen,I. Kristiansen,J. Nexøe,J. B. Nielsen",How Do Individuals Apply Risk Information When Choosing Among Health Care Interventions?,2003-08-01 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.1111/1539-6924.00348,"A sample of 3,201 Danes was subjected to personal interviews in which they were asked to state their preferences for risk‐reducing health care interventions based on information on absolute risk reduction (ARR) and relative risk reduction (RRR). The aim of the study was to measure the relative weighting of different types of risk information under various circumstances. The effect of presenting questions, and of explicitly formulating RRR, was analyzed. A preference for increases in RRR was demonstrated. There was a stronger inclination to choose the intervention that offered the highest RRR if RRR was explicitly stated. Individuals with more than 10 years of schooling also demonstrated a preference for increased ARR, but only when facing individually framed choices. In a social choice context, preferences for RRR remained intact, but the magnitude of ARR had no impact on choices. Results imply that social framing may induce a propensity to prefer interventions that target high‐risk populations. Those respondents who had received ≤10 years of schooling demonstrated preferences for RRR but not ARR, and no impact of social framing was observed.",90,https://www.semanticscholar.org/paper/41a15e7ac1b37291ed3d8315d74f7b90804bc8b2
Jiang Ke,Quantitative Models Remedying VaR to Measure Extreme Financial Risk,None,SupportedSources.SEMANTIC_SCHOLAR,,"Based on coherent and the situation of fat tail distribution,multi-variables co-dependence and dynamic distribution among extreme financial risks,CVaR,ES,Copula,UBSR and SRM are proposed to use separately measuring continuous,discontinuous,co-dependence and dynamic distribution conditions of different type financial risk such as operational risks,which give a clear future research direction on measuring all kinds of extreme financial risks in the world.",91,https://www.semanticscholar.org/paper/c11fcdcbdb9ebdb2291938a009317883ec5967b8
"Daniele Romanini,Sune Lehmann,Mikko Kivelä",Privacy and Uniqueness of Neighborhoods in Social Networks,2020-09-21 15:56:40+00:00,SupportedSources.ARXIV,,"The ability to share social network data at the level of individual
connections is beneficial to science: not only for reproducing results, but
also for researchers who may wish to use it for purposes not foreseen by the
data releaser. Sharing such data, however, can lead to serious privacy issues,
because individuals could be re-identified, not only based on possible nodes'
attributes, but also from the structure of the network around them. The risk
associated with re-identification can be measured and it is more serious in
some networks than in others. Various optimization algorithms have been
proposed to anonymize the network while keeping the number of changes minimal.
However, existing algorithms do not provide guarantees on where the changes
will be made, making it difficult to quantify their effect on various measures.
Using network models and real data, we show that the average degree of networks
is a crucial parameter for the severity of re-identification risk from nodes'
neighborhoods. Dense networks are more at risk, and, apart from a small band of
average degree values, either almost all nodes are re-identifiable or they are
all safe. Our results allow researchers to assess the privacy risk based on a
small number of network statistics which are available even before the data is
collected. As a rule-of-thumb, the privacy risks are high if the average degree
is above 10. Guided by these results we propose a simple method based on edge
sampling to mitigate the re-identification risk of nodes. Our method can be
implemented already at the data collection phase. Its effect on various network
measures can be estimated and corrected using sampling theory. These properties
are in contrast with previous methods arbitrarily biasing the data. In this
sense, our work could help in sharing network data in a statistically tractable
way.",92,"http://arxiv.org/pdf/2009.09973v1
http://arxiv.org/abs/2009.09973v1
http://arxiv.org/pdf/2009.09973v1"
"A. I. Titov,M. Fujiwara,T. S. -H. Lee",Coherent phi and omega meson photoproduction from deuteron and non-diffractive channels,2002-07-27 05:46:29+00:00,SupportedSources.ARXIV,10.1103/PhysRevC.66.022202,"For coherent photoproduction of phi and omega mesons from deuteron at forward
angles, the isovector pi-exchange amplitude is strongly suppressed.
  We show a possibility to study the non-diffractive channels associated with
the unnatural parity exchange in phi-photoproduction and with the baryon
resonance excitations in omega-photoproduction by measuring the spin
observables.",93,"http://arxiv.org/pdf/nucl-th/0207079v1
http://dx.doi.org/10.1103/PhysRevC.66.022202
http://arxiv.org/abs/nucl-th/0207079v1
http://arxiv.org/pdf/nucl-th/0207079v1"
"H. Levy,A. Levy",Arrow-Pratt Measures of Risk Aversion--The Multivariate Case,1991-11-01 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.2307/2527041,"Arrow-Pratt measures of risk aversion have been defined for the univariate case. For utility functions having the same ordinal preferences, the authors extend K. J. Arrow's probability premium index to the multivariate case and obtain a unique solution that can be employed to risk-aversion comparison analysis. They also extend G. T. Duncan's definition of the risk premium vector and show that it can be employed in comparative risk aversion once they confine themselves to the same preference ordering. Hence, the authors end up with two multivariate risk indexes that are parallel to the Arrow and Pratt univariate indexes. Copyright 1991 by Economics Department of the University of Pennsylvania and the Osaka University Institute of Social and Economic Research Association.",94,https://www.semanticscholar.org/paper/c5b4851c6af499440eda0ab72454b2b21dff5617
"Alan Matthews,Frank Barry,Michael King",Policy Coherence for Development: Five Challenges,None,SupportedSources.CORE,,"‘Policy Coherence for Development’ (PCD) seeks to ensure that non-aid public policies are consistent with a government’s international development goals. In the light of a number of years of PCD reviews and institutional reforms at both EU and member state level, this paper reflects on the dynamics of the PCD policy environment and discusses five challenges for the PCD policy agenda. These include the opposing interests of domestic and development constituencies, conflicts between development objectives themselves, disagreements between experts on what ‘good’ development policy is, difficulties in identifying the true development interest of developing countries, and the growing heterogeneity between and within developing countries. While the challenges discussed in this paper have general relevance, we draw on EU and Irish policies to illustrate the arguments. We conclude with a series of recommendations on how these challenges might be addressed and how to make the PCD agenda more effective.Policy Coherence for Development, European Trade and Agriculture Policy, Development Policy, Millennium Development Goals",95,https://core.ac.uk/download/pdf/6332356.pdf
"L. Pospisil,J. Vecer,Mingxin Xu",The Cost of Negative Returns,None,SupportedSources.SEMANTIC_SCHOLAR,,"We study the impact of negative returns on the health of a given nancial portfolio. It is often the case that a series of signicant negative returns trigger a credit event such as a downgrade in rating, or even a default of the portfolio owner. We focus our attention on a Weighted Average of Ordered Returns, which is a statistic that allows us to weight returns according to their relative adverse impact. We use an option pricing approach to derive the theoretical price and properties of a forward, a swap contract, a call and a put option written on the Weighted Average of Ordered Returns under dierent assumptions about the distribution of returns. The models of returns considered in this paper are dened by the following underlying price processes: geometric Brownian motion, Merton model with Poisson jumps, and GARCH model. We present a convergence result which states that the price of a forward on the Weighted Average of Ordered Returns converges to the theoretical law invariant coherent risk measure. Finally, we show that the forward price process itself satises the axioms of a dynamic coherent risk measures.",96,https://www.semanticscholar.org/paper/c472ea252d094b5bfeb7edac628a836ddb323524
"Susanne Still,Imre Kondor",Regularizing Portfolio Optimization,2009-11-09 15:16:27+00:00,SupportedSources.ARXIV,10.1088/1367-2630/12/7/075034,"The optimization of large portfolios displays an inherent instability to
estimation error. This poses a fundamental problem, because solutions that are
not stable under sample fluctuations may look optimal for a given sample, but
are, in effect, very far from optimal with respect to the average risk. In this
paper, we approach the problem from the point of view of statistical learning
theory. The occurrence of the instability is intimately related to over-fitting
which can be avoided using known regularization methods. We show how
regularized portfolio optimization with the expected shortfall as a risk
measure is related to support vector regression. The budget constraint dictates
a modification. We present the resulting optimization problem and discuss the
solution. The L2 norm of the weight vector is used as a regularizer, which
corresponds to a diversification ""pressure"". This means that diversification,
besides counteracting downward fluctuations in some assets by upward
fluctuations in others, is also crucial because it improves the stability of
the solution. The approach we provide here allows for the simultaneous
treatment of optimization and diversification in one framework that enables the
investor to trade-off between the two, depending on the size of the available
data set.",97,"http://arxiv.org/pdf/0911.1694v1
http://dx.doi.org/10.1088/1367-2630/12/7/075034
http://arxiv.org/abs/0911.1694v1
http://arxiv.org/pdf/0911.1694v1"
"Garde,  A.",EU law and obesity prevention.,2010-10-01 00:00:00,SupportedSources.CORE,,,98,https://core.ac.uk/download/266706.pdf
"Rachel Jewkes,Kristin Dunkle,Mzikazi Nduna,Nwabisa Shai","Intimate partner violence, relationship power inequity, and incidence of HIV infection in young women in South Africa: a cohort study",2010-07-03 00:00:00,SupportedSources.OPENALEX,10.1016/s0140-6736(10)60548-x,,99,"https://openalex.org/W2127502584
https://doi.org/10.1016/s0140-6736(10)60548-x
http://www.thelancet.com/article/S014067361060548X/pdf"
