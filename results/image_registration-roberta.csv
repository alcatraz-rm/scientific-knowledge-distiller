authors,title,pub_date,source,doi,abstract,rank,url
"Srikanchana, R.,Xuan, J.,Freedman, M.,Nguyen, C.,Wang, Y.",Non-Rigid Image Registration by Neural Computation,2004-01-01 00:00:00,SupportedSources.CROSSREF,10.1023/b:vlsi.0000027488.23703.ba,,0,http://dx.doi.org/10.1023/b:vlsi.0000027488.23703.ba
Elizabeth McKenzie,A Neural Network Approach to Deformable Image Registration,None,SupportedSources.SEMANTIC_SCHOLAR,,,1,https://www.semanticscholar.org/paper/05a25d08a3118d65237b5d9c50dc9f4bd215498a
"Caianiello, E.,Petrosino, A.","Neural Networks, Fuzziness and Image Processing",1994-01-01 00:00:00,SupportedSources.CROSSREF,10.1007/978-1-4899-1004-2_23,,2,"http://link.springer.com/content/pdf/10.1007/978-1-4899-1004-2_23
http://dx.doi.org/10.1007/978-1-4899-1004-2_23"
朱毅,Image recognition method based on convolutional neural network in non-finite category,2014-09-23 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,,"The invention discloses an image recognition method based on a convolutional neural network in a non-finite category. The method includes the steps of model training, data registration and match recognition, wherein in the model training process, a training sample is input in a convolutional neural network model, the error of a binary code of an output layer and a category binary code of the sample is calculated, and parameters of the model are adjusted; in the data registration process, sample images needing to be registered are input in the convolutional neural network model, and an output result of a hidden layer before the output layer serves as a feature vector and is stored; in the match recognition process, matches to be recognized are input in the convolutional neural network, an output result of the hidden layer before the output layer serves as a feature vector, the feature vector is matched with the registered feature vector, and therefore a match recognition judgment result is acquired.",3,https://www.semanticscholar.org/paper/eb44e1381f9b684108727eda0c50a3888a535093
"Mitchell, R.",Artificial neural networks for image understanding,1994-01-01 00:00:00,SupportedSources.CROSSREF,10.1016/0262-8856(94)90045-0,,4,"https://api.elsevier.com/content/article/PII:0262885694900450?httpAccept=text/xml
https://api.elsevier.com/content/article/PII:0262885694900450?httpAccept=text/plain
http://dx.doi.org/10.1016/0262-8856(94)90045-0"
"Sipes, S.",Image quality reconstruction with neural networks,None,SupportedSources.CROSSREF,10.31979/etd.368v-gxbd,,5,"https://scholarworks.sjsu.edu/cgi/viewcontent.cgi?article=3155&amp;context=etd_theses&amp;unstamped=1
http://dx.doi.org/10.31979/etd.368v-gxbd"
"Dinh-Luan Nguyen,Vinh-Tiep Nguyen,M. Tran,A. Yoshitaka",Deep Convolutional Neural Network in Deformable Part Models for Face Detection,2015-11-25 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.1007/978-3-319-29451-3_53,,6,https://www.semanticscholar.org/paper/f94f366ce14555cf0d5d34248f9467c18241c3ee
"Qi Zhang,Jingyu Xiao,Chunwei Tian,Jerry Chun-Wei Lin,Shichao Zhang",A robust deformed convolutional neural network (CNN) for image denoising,2022-06-15 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.1049/cit2.12110,,7,https://www.semanticscholar.org/paper/c6daaf1c5edb1d31833cecea91cac207b9322e4c
"Murino, V.,Vernazza, G.",Artificial Neural Networks for Image Analysis and Computer Vision,2001-01-01 00:00:00,SupportedSources.CROSSREF,10.1016/s0262-8856(00)00112-8,,8,"https://api.elsevier.com/content/article/PII:S0262885600001128?httpAccept=text/xml
https://api.elsevier.com/content/article/PII:S0262885600001128?httpAccept=text/plain
http://dx.doi.org/10.1016/s0262-8856(00)00112-8"
"Yao Su,Xin Dai,Lifang He,Xiangnan Kong",ABN: Anti-Blur Neural Networks for Multi-Stage Deformable Image Registration,2022-11-01 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.1109/ICDM54844.2022.00057,"Deformable image registration, i.e., the task of aligning multiple images into one coordinate system by non-linear transformation, serves as an essential preprocessing step for neuroimaging data. Recent research on deformable image registration is mainly focused on improving the registration accuracy using multi-stage alignment methods, where the source image is repeatedly deformed in stages by a same neural network until it is well-aligned with the target image. Conventional methods for multi-stage registration can often blur the source image as the pixel/voxel values are repeatedly interpolated from the image generated by the previous stage. However, maintaining image quality such as sharpness during image registration is crucial to medical data analysis. In this paper, we study the problem of anti-blur deformable image registration and propose a novel solution, called Anti-Blur Network (ABN), for multi-stage image registration. Specifically, we use a pair of short-term registration and long-term memory networks to learn the nonlinear deformations at each stage, where the short-term registration network learns how to improve the registration accuracy incrementally and the long-term memory network combines all the previous deformations to allow an interpolation to perform on the raw image directly and preserve image sharpness. Extensive experiments on both natural and medical image datasets demonstrated that ABN can accurately register images while preserving their sharpness.",9,https://www.semanticscholar.org/paper/605555cf258d1582d774f85e3089da646eab40de
"Yao Su,Xin Dai,Lifang He,Xiangnan Kong",ABN: Anti-Blur Neural Networks for Multi-Stage Deformable Image Registration,2022-12-06 19:21:43+00:00,SupportedSources.ARXIV,10.1109/ICDM54844.2022.00057,"Deformable image registration, i.e., the task of aligning multiple images
into one coordinate system by non-linear transformation, serves as an essential
preprocessing step for neuroimaging data. Recent research on deformable image
registration is mainly focused on improving the registration accuracy using
multi-stage alignment methods, where the source image is repeatedly deformed in
stages by a same neural network until it is well-aligned with the target image.
Conventional methods for multi-stage registration can often blur the source
image as the pixel/voxel values are repeatedly interpolated from the image
generated by the previous stage. However, maintaining image quality such as
sharpness during image registration is crucial to medical data analysis. In
this paper, we study the problem of anti-blur deformable image registration and
propose a novel solution, called Anti-Blur Network (ABN), for multi-stage image
registration. Specifically, we use a pair of short-term registration and
long-term memory networks to learn the nonlinear deformations at each stage,
where the short-term registration network learns how to improve the
registration accuracy incrementally and the long-term memory network combines
all the previous deformations to allow an interpolation to perform on the raw
image directly and preserve image sharpness. Extensive experiments on both
natural and medical image datasets demonstrated that ABN can accurately
register images while preserving their sharpness. Our code and data can be
found at https://github.com/anonymous3214/ABN",10,"http://arxiv.org/pdf/2212.03277v1
http://dx.doi.org/10.1109/ICDM54844.2022.00057
http://arxiv.org/abs/2212.03277v1
http://arxiv.org/pdf/2212.03277v1"
"Swarnendu Ghosh,Nibaran Das,Mita Nasipuri",Reshaping inputs for convolutional neural network: Some common and uncommon methods,2019-09-01 00:00:00,SupportedSources.OPENALEX,10.1016/j.patcog.2019.04.009,,11,"https://openalex.org/W2937557681
https://doi.org/10.1016/j.patcog.2019.04.009"
"D. Banarse,A. Duller",Vision Experiments with Neural Deformable Template Matching,1997-04-01 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.1023/A:1009661908220,,12,https://www.semanticscholar.org/paper/d8e75a9c1660780637a5884adae96cec85a61127
"Zhuo Chen,Weisi Lin,Shiqi Wang,Long Xu,Leida Li",Image Quality Assessment Guided Deep Neural Networks Training,2017-08-13 09:51:07+00:00,SupportedSources.ARXIV,,"For many computer vision problems, the deep neural networks are trained and
validated based on the assumption that the input images are pristine (i.e.,
artifact-free). However, digital images are subject to a wide range of
distortions in real application scenarios, while the practical issues regarding
image quality in high level visual information understanding have been largely
ignored. In this paper, in view of the fact that most widely deployed deep
learning models are susceptible to various image distortions, the distorted
images are involved for data augmentation in the deep neural network training
process to learn a reliable model for practical applications. In particular, an
image quality assessment based label smoothing method, which aims at
regularizing the label distribution of training images, is further proposed to
tune the objective functions in learning the neural network. Experimental
results show that the proposed method is effective in dealing with both low and
high quality images in the typical image classification task.",13,"http://arxiv.org/pdf/1708.03880v1
http://arxiv.org/abs/1708.03880v1
http://arxiv.org/pdf/1708.03880v1"
"Deng, Y.,Wang, X.,Chen, L.",Learning visual-based deformable object rearrangement with local graph neural networks,2023-04-12 00:00:00,SupportedSources.CROSSREF,10.1007/s40747-023-01048-w,,14,"https://link.springer.com/content/pdf/10.1007/s40747-023-01048-w.pdf
https://link.springer.com/article/10.1007/s40747-023-01048-w/fulltext.html
https://link.springer.com/content/pdf/10.1007/s40747-023-01048-w.pdf
http://dx.doi.org/10.1007/s40747-023-01048-w"
"Ameneh Sheikhjafari,Michelle Noga,Kumaradevan Punithakumar,Nilanjan Ray",Unsupervised deformable image registration with fully connected generative neural network,2018-04-11 00:00:00,SupportedSources.OPENALEX,,,15,https://openalex.org/W2902335457
"Lei Qu,Wan Wan,Kaixuan Guo,Yu Liu,Jun Tang,Xiaolei Li,Jun Wu",Triple-Input-Unsupervised neural Networks for deformable image registration,2021-11-01 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.1016/j.patrec.2021.08.032,,16,https://www.semanticscholar.org/paper/51bf2cc2e5085ba8e958eddfceffd85a00e3bfb1
Chi Wing Mok,Unsupervised affine and deformable medical image registration with convolutional neural networks,None,SupportedSources.SEMANTIC_SCHOLAR,10.14711/thesis-991013106358203412,,17,https://www.semanticscholar.org/paper/9daae223cd9c1b757b2336a8a1b1428898090d1f
"Ghennam, S.,Benmahammed, K.",Multiresolution Support for Adaptive Image Restoration Using Neural Networks,2002-01-01 00:00:00,SupportedSources.CROSSREF,10.1007/3-540-46084-5_194,,18,"http://link.springer.com/content/pdf/10.1007/3-540-46084-5_194
http://dx.doi.org/10.1007/3-540-46084-5_194"
"Xiaodong Yang,Daping Li,Qiaolin He,Zhu Wang,Ying Fu,Jiliu Zhou,Jinrong Hu",A Novel Keypoints-Based Image Registration Method with Fully Convolutional Neural Network,None,SupportedSources.SEMANTIC_SCHOLAR,10.1007/978-981-15-8083-3_9,,19,https://www.semanticscholar.org/paper/c11a917a3c393fb2c851ce7fcfee19c185eaeda9
"Kulshrestha, S.",What Is A Convolutional Neural Network?,2019-01-01 00:00:00,SupportedSources.CROSSREF,10.1007/978-1-4842-5572-8_6,,20,"http://link.springer.com/content/pdf/10.1007/978-1-4842-5572-8_6
http://dx.doi.org/10.1007/978-1-4842-5572-8_6"
"Nicholas J. Tustison,Brian B. Avants,James C. Gee",Learning image-based spatial transformations via convolutional neural networks: A review,2019-06-11 00:00:00,SupportedSources.OPENALEX,10.1016/j.mri.2019.05.037,,21,"https://openalex.org/W2951445562
https://doi.org/10.1016/j.mri.2019.05.037"
"Aoki, H.",Applications of Complex-Valued Neural Networks for Image Processing,2003-01-01 00:00:00,SupportedSources.CROSSREF,10.1142/9789812791184_0009,,22,http://dx.doi.org/10.1142/9789812791184_0009
"Wang, F.,Liu, H.,Cheng, J.",Visualizing deep neural network by alternately image blurring and deblurring,2018-01-01 00:00:00,SupportedSources.CROSSREF,10.1016/j.neunet.2017.09.007,,23,"https://api.elsevier.com/content/article/PII:S0893608017302095?httpAccept=text/xml
https://api.elsevier.com/content/article/PII:S0893608017302095?httpAccept=text/plain
http://dx.doi.org/10.1016/j.neunet.2017.09.007"
"Haim Karniely,H. Siegelmann",Sensor registration using neural networks,None,SupportedSources.SEMANTIC_SCHOLAR,10.1109/7.826314,One of the major problems in multiple sensor surveillance systems is inadequate sensor registration. We propose a new approach to sensor registration based on layered neural networks. The nonparametric nature of this approach enables many different kinds of sensor biases to be solved. As part of the implementation we develop some modifications to the common network training algorithm to tackle the inherent randomness in all components of the training set.,24,https://www.semanticscholar.org/paper/a907982a5c5ad6024dbe8cef9e2b1a3a29836350
"Fracastoro, G.,Valsesia, D.",Graph Neural Networks for Image Processing,2021-08-05 00:00:00,SupportedSources.CROSSREF,10.1002/9781119850830.ch10,,25,"https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119850830.ch10
https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119850830.ch10
http://dx.doi.org/10.1002/9781119850830.ch10"
"Axel Wismüller,Florian Vietze,Dominik R. Dersch,Johannes Behrends,Klaus M. Hahn,Helge Ritter",The deformable feature map - a novel neurocomputing algorithm for adaptive plasticity in pattern analysis,2002-10-01 00:00:00,SupportedSources.OPENALEX,10.1016/s0925-2312(01)00641-5,,26,"https://openalex.org/W1997269994
https://doi.org/10.1016/s0925-2312(01)00641-5"
K. Fukushima,Neural network model restoring partly occluded patterns,2003-09-03 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.3233/KES-2004-8202,"Even the identical image is perceived differently by human beings depending on the shape of occluding objects. This paper proposes a neural network model that has an ability to recognize and restore partly occluded patterns in a similar way as our perception. It is a multi-layered hierarchical neural network, in which visual information is processed by interaction of bottom-up and top-down signals. Occluded parts of a pattern are restored mainly by feedback signals from the highest stage of the network, while the unoccluded parts are reproduced mainly by signals from lower stages. The model does not use a simple template matching method. It can recognize and restore even deformed versions of learned patterns.",27,https://www.semanticscholar.org/paper/62306f35068bd0a30f5018df7a314799fc2cb58a
"Vikram, D.,G.H. Raisoni College of Engineering & management, Wagholi, Pune",Convolution Neural Networks by Image Net,2017-09-30 00:00:00,SupportedSources.CROSSREF,10.18535/ijetst/v4i9.30,,28,http://dx.doi.org/10.18535/ijetst/v4i9.30
"S. Phandi,C. Velayutham",Neural Network Based Image Registration Using Synthetic Reference Image Rotation,2018-05-16 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.1007/978-3-030-00665-5_88,,29,https://www.semanticscholar.org/paper/dd4935366f229eab3de4a89fbd7e07065f0f8df2
"Onur Keleş,A. Murat Tekalp,Junaid Malik,Serkan Kıranyaz",Self-Organized Residual Blocks for Image Super-Resolution,2021-05-31 12:47:51+00:00,SupportedSources.ARXIV,,"It has become a standard practice to use the convolutional networks (ConvNet)
with RELU non-linearity in image restoration and super-resolution (SR).
Although the universal approximation theorem states that a multi-layer neural
network can approximate any non-linear function with the desired precision, it
does not reveal the best network architecture to do so. Recently, operational
neural networks (ONNs) that choose the best non-linearity from a set of
alternatives, and their ""self-organized"" variants (Self-ONN) that approximate
any non-linearity via Taylor series have been proposed to address the
well-known limitations and drawbacks of conventional ConvNets such as network
homogeneity using only the McCulloch-Pitts neuron model. In this paper, we
propose the concept of self-organized operational residual (SOR) blocks, and
present hybrid network architectures combining regular residual and SOR blocks
to strike a balance between the benefits of stronger non-linearity and the
overall number of parameters. The experimental results demonstrate that
the~proposed architectures yield performance improvements in both PSNR and
perceptual metrics.",30,"http://arxiv.org/pdf/2105.14926v1
http://arxiv.org/abs/2105.14926v1
http://arxiv.org/pdf/2105.14926v1"
"Lei, Y.,Fu, Y.,Harms, J.,Wang, T.,Curran, W.,Liu, T.,Higgins, K.,Yang, X.",4D-CT Deformable Image Registration Using an Unsupervised Deep Convolutional Neural Network,2019-01-01 00:00:00,SupportedSources.CROSSREF,10.1007/978-3-030-32486-5_4,,31,"http://link.springer.com/content/pdf/10.1007/978-3-030-32486-5_4
http://dx.doi.org/10.1007/978-3-030-32486-5_4"
"Pekar, V.,Gladilin, E.",Deformable Image Registration by Adaptive Gaussian Forces,2004-01-01 00:00:00,SupportedSources.CROSSREF,10.1007/978-3-540-27816-0_27,,32,"http://link.springer.com/content/pdf/10.1007/978-3-540-27816-0_27.pdf
http://dx.doi.org/10.1007/978-3-540-27816-0_27"
"Gadde, P.",AFFINE IMAGE REGISTRATION USING ARTIFICIAL NEURAL NETWORKS,None,SupportedSources.CROSSREF,10.15368/theses.2013.133,,33,http://dx.doi.org/10.15368/theses.2013.133
"Karol Gregor,Ivo Danihelka,Alex Graves,Danilo Jimenez Rezende,Daan Wierstra",DRAW: A Recurrent Neural Network For Image Generation,2015-02-16 16:48:56+00:00,SupportedSources.ARXIV,,"This paper introduces the Deep Recurrent Attentive Writer (DRAW) neural
network architecture for image generation. DRAW networks combine a novel
spatial attention mechanism that mimics the foveation of the human eye, with a
sequential variational auto-encoding framework that allows for the iterative
construction of complex images. The system substantially improves on the state
of the art for generative models on MNIST, and, when trained on the Street View
House Numbers dataset, it generates images that cannot be distinguished from
real data with the naked eye.",34,"http://arxiv.org/pdf/1502.04623v2
http://arxiv.org/abs/1502.04623v2
http://arxiv.org/pdf/1502.04623v2"
"Delibasis, K.,Maglogiannis, I.,Georgakopoulos, S.,Kottari, K.,Plagianakos, V.",Assessing Image Analysis Filters as Augmented Input to Convolutional Neural Networks for Image Classification,2018-01-01 00:00:00,SupportedSources.CROSSREF,10.1007/978-3-030-01418-6_19,,35,"http://link.springer.com/content/pdf/10.1007/978-3-030-01418-6_19
http://dx.doi.org/10.1007/978-3-030-01418-6_19"
"Yun Gong,Mengjia Yang",An Improved Indoor Image Registration Algorithm Based on Shallow Convolutional Neural Network Descriptor,2019-08-23 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.1007/978-3-030-34110-7_22,,36,https://www.semanticscholar.org/paper/4b065e090ffd179546aa38177656b64767e9cbfb
"Kulshrestha, S.",Developing An Image Classifier Using Convolutional Neural Networks,2019-01-01 00:00:00,SupportedSources.CROSSREF,10.1007/978-1-4842-5572-8_7,,37,"http://link.springer.com/content/pdf/10.1007/978-1-4842-5572-8_7
http://dx.doi.org/10.1007/978-1-4842-5572-8_7"
"Andresen, J.,Kepp, T.,Ehrhardt, J.,von der Burchard, C.,Roider, J.,Handels, H.",Unsupervised Non-correspondence Detection in Medical Images Using an Image Registration Convolutional Neural Network,2022-01-01 00:00:00,SupportedSources.CROSSREF,10.1007/978-3-031-11203-4_1,,38,"https://link.springer.com/content/pdf/10.1007/978-3-031-11203-4_1
http://dx.doi.org/10.1007/978-3-031-11203-4_1"
"Singh, G.",Think positive: An interpretable neural network for image recognition,2022-01-01 00:00:00,SupportedSources.CROSSREF,10.1016/j.neunet.2022.03.034,,39,"https://api.elsevier.com/content/article/PII:S0893608022001125?httpAccept=text/xml
https://api.elsevier.com/content/article/PII:S0893608022001125?httpAccept=text/plain
http://dx.doi.org/10.1016/j.neunet.2022.03.034"
"Cierniak, R.",A Practical Approach To Image Reconstruction From Projections Using Neural Networks Structure,2003-01-01 00:00:00,SupportedSources.CROSSREF,10.1007/978-3-7908-1902-1_69,,40,"http://link.springer.com/content/pdf/10.1007/978-3-7908-1902-1_69
http://dx.doi.org/10.1007/978-3-7908-1902-1_69"
"Milosevic, N.",What are Artificial Neural Networks? Part 1,2020-01-01 00:00:00,SupportedSources.CROSSREF,10.1007/978-1-4842-5648-0_2,,41,"http://link.springer.com/content/pdf/10.1007/978-1-4842-5648-0_2
http://dx.doi.org/10.1007/978-1-4842-5648-0_2"
"Hessam Sokooti,B. D. Vos,F. Berendsen,B. Lelieveldt,I. Išgum,M. Staring",Nonrigid Image Registration Using Multi-scale 3D Convolutional Neural Networks,2017-09-10 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.1007/978-3-319-66182-7_27,,42,https://www.semanticscholar.org/paper/bbee923434518e92ee9c03dcd487e7f0b6042b78
"Fracastoro, G.,Valsesia, D.",Graph Neural Networks,2021-08-05 00:00:00,SupportedSources.CROSSREF,10.1002/9781119850830.ch3,,43,"https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119850830.ch3
https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119850830.ch3
http://dx.doi.org/10.1002/9781119850830.ch3"
"Milosevic, N.",Introduction to Convolutional Neural Networks,2020-01-01 00:00:00,SupportedSources.CROSSREF,10.1007/978-1-4842-5648-0,,44,"http://link.springer.com/content/pdf/10.1007/978-1-4842-5648-0.pdf
http://link.springer.com/content/pdf/10.1007/978-1-4842-5648-0
http://dx.doi.org/10.1007/978-1-4842-5648-0"
Joshua Bowren,A Sparse Coding Interpretation of Neural Networks and Theoretical Implications,2021-08-14 21:54:47+00:00,SupportedSources.ARXIV,,"Neural networks, specifically deep convolutional neural networks, have
achieved unprecedented performance in various computer vision tasks, but the
rationale for the computations and structures of successful neural networks is
not fully understood. Theories abound for the aptitude of convolutional neural
networks for image classification, but less is understood about why such models
would be capable of complex visual tasks such as inference and anomaly
identification. Here, we propose a sparse coding interpretation of neural
networks that have ReLU activation and of convolutional neural networks in
particular. In sparse coding, when the model's basis functions are assumed to
be orthogonal, the optimal coefficients are given by the soft-threshold
function of the basis functions projected onto the input image. In a
non-negative variant of sparse coding, the soft-threshold function becomes a
ReLU. Here, we derive these solutions via sparse coding with orthogonal-assumed
basis functions, then we derive the convolutional neural network forward
transformation from a modified non-negative orthogonal sparse coding model with
an exponential prior parameter for each sparse coding coefficient. Next, we
derive a complete convolutional neural network without normalization and
pooling by adding logistic regression to a hierarchical sparse coding model.
Finally we motivate potentially more robust forward transformations by
maintaining sparse priors in convolutional neural networks as well performing a
stronger nonlinear transformation.",45,"http://arxiv.org/pdf/2108.06622v2
http://arxiv.org/abs/2108.06622v2
http://arxiv.org/pdf/2108.06622v2"
朱毅,Convolutional neural network image recognition method based on dynamic adjustment of training targets,2014-09-24 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,,"The invention discloses a convolutional neural network image recognition method based on dynamic adjustment of training targets. The method comprises the three steps of training model building, data registration, and recognition and matching. In the training model building process, training samples are input into a convolutional neural network model, the mean value of output vectors of output layers of the same class of samples is worked out to serve as the target vector of the current round of training, and then the error between the output vector of each sample and the target vector is reversely transmitted to adjust the parameters of a convolutional neural network till the training requirement is met; in the data registration process, sample images needing to be registered are input into the convolutional neural network model, and output results of the output layers serve as feature vectors to be stored; in the recognition and matching process, sample images needing to be recognized and matched are input into the convolutional neural network, output results of the output layers serve as feature vectors, and then matching is carried out on the feature vectors and registered feature vectors so as to provide the judgment result of recognition and matching.",46,https://www.semanticscholar.org/paper/370f998e561a63bb7499906610aa27b7e21e8153
"J. Wolterink,Jesse C. Zwienenberg,C. Brune",Implicit Neural Representations for Deformable Image Registration,None,SupportedSources.SEMANTIC_SCHOLAR,,"Deformable medical image registration has in past years been revolutionized by the use of convolutional neural networks. These methods surpass conventional image registration techniques in speed but not in accuracy. Here, we present an alternative approach to leveraging neural networks for image registration. Instead of using a convolutional neural network to predict the transformation between images, we optimize a multi-layer perceptron to represent this transformation function. Using recent insights from differentiable rendering, we show how such an implicit deformable image registration (idir) model can be naturally combined with regularization terms based on standard automatic differentiation techniques. We demonstrate the effectiveness of this model on 4D chest CT registration in the DIR-LAB data set and find that a three-layer multi-layer perceptron with periodic activation functions outperforms all published deep learning-based results on this problem, without any folding and without the need for training data. The model is implemented using standard deep learning libraries and flexible enough to be extended to include different losses, regularizers, and optimization schemes.",47,https://www.semanticscholar.org/paper/d3857fcd457aa50cec2b198d40800078472ef3ea
"Sanghun Park,Kwanggyoon Seo,Junyong Noh",Neural Crossbreed: Neural Based Image Metamorphosis,2020-09-02 08:56:47+00:00,SupportedSources.ARXIV,,"We propose Neural Crossbreed, a feed-forward neural network that can learn a
semantic change of input images in a latent space to create the morphing
effect. Because the network learns a semantic change, a sequence of meaningful
intermediate images can be generated without requiring the user to specify
explicit correspondences. In addition, the semantic change learning makes it
possible to perform the morphing between the images that contain objects with
significantly different poses or camera views. Furthermore, just as in
conventional morphing techniques, our morphing network can handle shape and
appearance transitions separately by disentangling the content and the style
transfer for rich usability. We prepare a training dataset for morphing using a
pre-trained BigGAN, which generates an intermediate image by interpolating two
latent vectors at an intended morphing value. This is the first attempt to
address image morphing using a pre-trained generative model in order to learn
semantic transformation. The experiments show that Neural Crossbreed produces
high quality morphed images, overcoming various limitations associated with
conventional approaches. In addition, Neural Crossbreed can be further extended
for diverse applications such as multi-image morphing, appearance transfer, and
video frame interpolation.",48,"http://arxiv.org/pdf/2009.00905v1
http://arxiv.org/abs/2009.00905v1
http://arxiv.org/pdf/2009.00905v1"
"Huang, Y.,Ahmad, S.,Fan, J.,Shen, D.,Yap, P.",Difficulty-aware hierarchical convolutional neural networks for deformable registration of brain MR images,2021-01-01 00:00:00,SupportedSources.CROSSREF,10.1016/j.media.2020.101817,,49,"https://api.elsevier.com/content/article/PII:S136184152030181X?httpAccept=text/xml
https://api.elsevier.com/content/article/PII:S136184152030181X?httpAccept=text/plain
http://dx.doi.org/10.1016/j.media.2020.101817"
"Nalin Gupta,M. P. Ross",Disorders of Neural Tube Development,2017-01-01 00:00:00,SupportedSources.OPENALEX,10.1016/b978-0-323-37101-8.00025-4,,50,"https://openalex.org/W2497105953
https://doi.org/10.1016/b978-0-323-37101-8.00025-4"
"Y. Xing,Jing Sun,B. Li",New method for medical image registration based on neural networks,None,SupportedSources.SEMANTIC_SCHOLAR,,,51,https://www.semanticscholar.org/paper/9b64affa58aaf53812d6df883fb2f7081c31e604
"Hang Yang,Xiaotian Wu,Xinglong Sun",Select Good Regions for Deblurring based on Convolutional Neural Networks,2020-08-12 01:58:35+00:00,SupportedSources.ARXIV,,"The goal of blind image deblurring is to recover sharp image from one input
blurred image with an unknown blur kernel. Most of image deblurring approaches
focus on developing image priors, however, there is not enough attention to the
influence of image details and structures on the blur kernel estimation. What
is the useful image structure and how to choose a good deblurring region? In
this work, we propose a deep neural network model method for selecting good
regions to estimate blur kernel. First we construct image patches with labels
and train a deep neural networks, then the learned model is applied to
determine which region of the image is most suitable to deblur. Experimental
results illustrate that the proposed approach is effective, and could be able
to select good regions for image deblurring.",52,"http://arxiv.org/pdf/2008.05065v1
http://arxiv.org/abs/2008.05065v1
http://arxiv.org/pdf/2008.05065v1"
"Matthew C. Humphrey,G. Holmes,S. Cunningham",Improving the image recognition capability of Hopfield neural networks,1993-11-24 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.1109/ANNES.1993.323072,"Hopfield neural networks can be used for image recognition when only a partial image is available. However, the image recognition process is very sensitive to the position of the input; shifting the image by only one pixel can cause the network to fail to find a matching exemplar. The authors present a technique for modifying the input image so that an ordinary Hopfield neural network will recognize a shifted image. This technique makes use of the image. The authors run an experiment with random bitmap images to determine how accurately a Hopfield neural network can recognize shifted and blurred images. The results indicate that the neural network can recognize shifted images only if they are modified.<<ETX>>",53,https://www.semanticscholar.org/paper/bb2c2323251bd6e299a56b441c544136eeba8138
"Yang, J.,Liao, X.,Deng, S.,Yu, M.,Zheng, H.",Neural Networks Based Image Recognition: A New Approach,None,SupportedSources.CROSSREF,10.1007/978-3-540-72393-6_86,,54,"http://link.springer.com/content/pdf/10.1007/978-3-540-72393-6_86.pdf
http://dx.doi.org/10.1007/978-3-540-72393-6_86"
"Han, L.,Dou, H.,Huang, Y.,Yap, P.",Deformable Registration of Brain MR Images via a Hybrid Loss,2022-01-01 00:00:00,SupportedSources.CROSSREF,10.1007/978-3-030-97281-3_20,,55,"https://link.springer.com/content/pdf/10.1007/978-3-030-97281-3_20
http://dx.doi.org/10.1007/978-3-030-97281-3_20"
"Goltsev, A.,Gritsenko, V.",Investigation of efficient features for image recognition by neural networks,2012-01-01 00:00:00,SupportedSources.CROSSREF,10.1016/j.neunet.2011.12.002,,56,"https://api.elsevier.com/content/article/PII:S0893608011003170?httpAccept=text/xml
https://api.elsevier.com/content/article/PII:S0893608011003170?httpAccept=text/plain
http://dx.doi.org/10.1016/j.neunet.2011.12.002"
Han Zhou,Deformable Image Registration Using Attentional Generative Adversarial Networks,2021-01-22 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.11575/PRISM/38593,,57,https://www.semanticscholar.org/paper/b1232074d0dc1b41f0729fab90184daec92edd08
Romuald A. Janik,Aesthetics and neural network image representations,2021-09-16 16:50:22+00:00,SupportedSources.ARXIV,,"We analyze the spaces of images encoded by generative neural networks of the
BigGAN architecture. We find that generic multiplicative perturbations of
neural network parameters away from the photo-realistic point often lead to
networks generating images which appear as ""artistic renditions"" of the
corresponding objects. This demonstrates an emergence of aesthetic properties
directly from the structure of the photo-realistic visual environment as
encoded in its neural network parametrization. Moreover, modifying a deep
semantic part of the neural network leads to the appearance of symbolic visual
representations. None of the considered networks had any access to images of
human-made art.",58,"http://arxiv.org/pdf/2109.08103v2
http://arxiv.org/abs/2109.08103v2
http://arxiv.org/pdf/2109.08103v2"
"Hartmut Maennel,Ibrahim Alabdulmohsin,Ilya Tolstikhin,Robert J. N. Baldock,Olivier Bousquet,Sylvain Gelly,Daniel Keysers",What Do Neural Networks Learn When Trained With Random Labels?,2020-06-18 12:07:22+00:00,SupportedSources.ARXIV,,"We study deep neural networks (DNNs) trained on natural image data with
entirely random labels. Despite its popularity in the literature, where it is
often used to study memorization, generalization, and other phenomena, little
is known about what DNNs learn in this setting. In this paper, we show
analytically for convolutional and fully connected networks that an alignment
between the principal components of network parameters and data takes place
when training with random labels. We study this alignment effect by
investigating neural networks pre-trained on randomly labelled image data and
subsequently fine-tuned on disjoint datasets with random or real labels. We
show how this alignment produces a positive transfer: networks pre-trained with
random labels train faster downstream compared to training from scratch even
after accounting for simple effects, such as weight scaling. We analyze how
competing effects, such as specialization at later layers, may hide the
positive transfer. These effects are studied in several network architectures,
including VGG16 and ResNet18, on CIFAR10 and ImageNet.",59,"http://arxiv.org/pdf/2006.10455v2
http://arxiv.org/abs/2006.10455v2
http://arxiv.org/pdf/2006.10455v2"
"Wajdi Bellil,Hajer Ben Brahim,Chokri Ben Amar",Gappy wavelet neural network for 3D occluded faces: detection and recognition,2016-01-01 00:00:00,SupportedSources.OPENALEX,10.1007/s11042-014-2294-6,,60,"https://openalex.org/W2071881355
https://doi.org/10.1007/s11042-014-2294-6"
"Zhang, S.,Salari, E.",A Neural Network Method for Image Resolution Enhancement from a Multiple of Image Frames,2011-01-01 00:00:00,SupportedSources.CROSSREF,10.1007/978-3-642-21111-9_22,,61,"http://link.springer.com/content/pdf/10.1007/978-3-642-21111-9_22
http://dx.doi.org/10.1007/978-3-642-21111-9_22"
"M. B. Sukhaswami,Arun K. Pujari",Restoration of geometrically aberrated images using a self-organising neural network,1996-01-10 00:00:00,SupportedSources.OPENALEX,10.1016/0167-8655(95)00053-4,,62,"https://openalex.org/W2069185367
https://doi.org/10.1016/0167-8655(95)00053-4"
"Liu, J.",Deformable Model-Based Image Registration,2007-01-01 00:00:00,SupportedSources.CROSSREF,10.1007/978-0-387-68413-0_15,,63,"http://link.springer.com/content/pdf/10.1007/978-0-387-68413-0_15.pdf
http://dx.doi.org/10.1007/978-0-387-68413-0_15"
"Sahni, M.,Sahni, R.,M Merigo, J.","Neural Networks, Machine Learning, and Image Processing",2022-11-03 00:00:00,SupportedSources.CROSSREF,10.1201/9781003303053,,64,http://dx.doi.org/10.1201/9781003303053
"Alhussein Fawzi,Horst Samulowitz,D. Turaga,P. Frossard",Image inpainting through neural networks hallucinations,2016-07-11 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.1109/IVMSPW.2016.7528221,"We consider in this paper the problem of image inpainting, where the objective is to reconstruct large continuous regions of missing or deteriorated parts of an image. Traditional in-painting algorithms are unfortunately not well adapted to handle such corruptions as they rely on image processing techniques that cannot properly infer missing information when the corrupted holes are too large. To tackle this problem, we propose a novel approach where we rely on the hallucinations of pre-trained neural networks to fill large holes in images. To generate globally coherent images, we further impose smoothness and consistency regularization, thereby constraining the neural network hallucinations. Through illustrative experiments, we show that pre-trained neural networks contain crucial prior information that can effectively guide the reconstruction process of complex inpainting problems.",65,https://www.semanticscholar.org/paper/ea9f0d5bb700ddb6d6e3c53d9050b48c0210cb73
"S. Perry,L. Guan",Weight assignment for adaptive image restoration by neural networks,None,SupportedSources.SEMANTIC_SCHOLAR,10.1109/72.822518,"This paper presents a scheme for adaptively training the weights, in terms of varying the regularization parameter, in a neural network for the restoration of digital images. The flexibility of neural-network-based image restoration algorithms easily allow the variation of restoration parameters such as blur statistics and regularization value spatially and temporally within the image. This paper focuses on spatial variation of the regularization parameter.We first show that the previously proposed neural-network method based on gradient descent can only find suboptimal solutions, and then introduce a regional processing approach based on local statistics. A method is presented to vary the regularization parameter spatially. This method is applied to a number of images degraded by various levels of noise, and the results are examined. The method is also applied to an image degraded by spatially variant blur. In all cases, the proposed method provides visually satisfactory results in an efficient way.",66,https://www.semanticscholar.org/paper/9bb8913c550d7e053c2d3214981b0d38d53deb05
"Bashkirova, D.",Convolutional Neural Networks for Image Steganalysis,2016-08-02 00:00:00,SupportedSources.CROSSREF,10.1007/s12668-016-0215-z,,67,"http://link.springer.com/content/pdf/10.1007/s12668-016-0215-z.pdf
http://link.springer.com/article/10.1007/s12668-016-0215-z/fulltext.html
http://link.springer.com/content/pdf/10.1007/s12668-016-0215-z
http://dx.doi.org/10.1007/s12668-016-0215-z"
"Jeripothula Prudviraj,Vishnu Chalavadi,C. Mohan",Attentive Contextual Network for Image Captioning,2021-07-18 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.1109/IJCNN52387.2021.9533970,"Existing image captioning approaches fail to generate fine-grained captions due to the lack of rich encoding representation of an image. In this paper, we present an attentive contextual network (ACN) to learn the spatially transformed image features and dense multi-scale contextual information of an image to generate semantically meaningful captions. At first, we construct deformable network on intermediate layers of convolutional neural network (CNN) to cultivate spatial invariant features. And the multi-scale contextual features are produced by employing contextual network on top of last layers of CNN. Then, we exploit attention mechanism on contextual network to extract dense contextual features. Further, the extracted spatial and contextual features are combined to encode the holistic representation of an image. Finally, a multi-stage caption decoder with visual attention module is incorporated to generate fine-grained captions. The performance of the proposed approach is demonstrated on COCO dataset, the largest dataset for image captioning.",68,https://www.semanticscholar.org/paper/6d9c777c870cb31399971a3bc3d49bfe8b1b820c
"Yuanwei Wang,Mei Yu,G. Jiang,Zhiyong Pan,Jiqiang Lin",Image Registration Algorithm Based on Convolutional Neural Network and Local Homography Transformation,2020-01-21 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.3390/app10030732,"In order to overcome the poor robustness of traditional image registration algorithms in illuminating and solving the problem of low accuracy of a learning-based image homography matrix estimation algorithm, an image registration algorithm based on convolutional neural network (CNN) and local homography transformation is proposed. Firstly, to ensure the diversity of samples, a sample and label generation method based on moving direct linear transformation (MDLT) is designed. The generated samples and labels can effectively reflect the local characteristics of images and are suitable for training the CNN model with which multiple pairs of local matching points between two images to be registered can be calculated. Then, the local homography matrices between the two images are estimated by using the MDLT and finally the image registration can be realized. The experimental results show that the proposed image registration algorithm achieves higher accuracy than other commonly used algorithms such as the SIFT, ORB, ECC, and APAP algorithms, as well as another two learning-based algorithms, and it has good robustness for different types of illumination imaging.",69,"https://www.semanticscholar.org/paper/7b9bfbe4ce287ee21c3d0ebbb46560a64c4040c2
https://www.mdpi.com/2076-3417/10/3/732/pdf?version=1580809798"
"Fanfani, M.,Piva, A.,Colombo, C.",PRNU registration under scale and rotation transform based on convolutional neural networks,2022-01-01 00:00:00,SupportedSources.CROSSREF,10.1016/j.patcog.2021.108413,,70,"https://api.elsevier.com/content/article/PII:S0031320321005896?httpAccept=text/xml
https://api.elsevier.com/content/article/PII:S0031320321005896?httpAccept=text/plain
http://dx.doi.org/10.1016/j.patcog.2021.108413"
"H. Sarnel,Y. Senol",Accurate affine image registration using radial basis neural networks,2008-05-01 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.21608/ICEENG.2008.34357,,71,"https://www.semanticscholar.org/paper/afbae8c22437bdcd6558486a1b0b200f65d2bfcd
http://iceeng.journals.ekb.eg/article_34357_80c1e83071ce81dc54ec011880d0c763.pdf"
"Liu, D.,Wang, Z.",A Method of X-Ray Image Recognition Based on Fuzzy Rule and Parallel Neural Networks,None,SupportedSources.CROSSREF,10.1007/978-3-540-72393-6_145,,72,"http://link.springer.com/content/pdf/10.1007/978-3-540-72393-6_145.pdf
http://dx.doi.org/10.1007/978-3-540-72393-6_145"
"Dongming Zhou,Canlong Zhang,Zhixin Li,Zhiwen Wang",Multi-level Visual Fusion Networks for Image Captioning,2020-07-01 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.1109/IJCNN48605.2020.9206932,"Image captioning is a multi-modal complex task in machine learning. Traditional methods focus only on entities in visual strategy networks, and can’t reason about the relationship between entities and attributes. There are problems of exposure bias and error accumulation in language strategy networks. To this end, this paper proposes a multi-level visual fusion network model based on reinforcement learning. In the visual strategy network, multi-level neural network modules are used to transform visual features into feature sets of visual knowledge. The fusion network generates function words that make the description more fluent, and is used for the interaction between the visual strategy network and the language strategy network. The self-criticism strategy gradient algorithm based on reinforcement learning in language strategy networks is used to achieve end-to-end optimization of visual fusion networks. We evaluated our model on the Flickr 30K and MS-COCO datasets, and verified the accuracy of the model and the diversity of model learning subtitles through experiments. Our model achieves better performance over state-of-the-art methods.",73,https://www.semanticscholar.org/paper/a32ac0995afcbc748fa6533b941e9834ec7bfc2e
"Junyu Chen,Ye Li,E. Frey",Generating Patient-like Phantoms Using Fully Unsupervised Deformable Image Registration with Convolutional Neural Networks,2019-12-06 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,,"The use of Convolutional neural networks (ConvNets) in medical imaging research has become widespread in recent years. However, a major drawback of these methods is that they require a large number of annotated training images. Data augmentation has been proposed to alleviate this. One data augmentation strategy is to apply random deformation to existing image data, but the deformed images often will not follow exhibit realistic shape or intensity patterns. In this paper, we present a novel, ConvNet based image registration method for creating patient-like digital phantoms from the existing computerized phantoms. Unlike existing learning-based registration techniques, for which the performance predominantly depends on the domain-specific training images, the proposed method is fully unsupervised, meaning that it optimizes an objective function independently of training data for a given image pair. While classical methods registration also do not require training data, they work in lower-dimensional parameter space; the proposed approach operates directly in the high-dimensional parameter space without any training beforehand. In this paper, we show that the resulting deformed phantom competently matches the anatomy model of a real human while providing the ""gold-standard"" for the anatomies. Combined with simulation programs, the generated phantoms could potentially serve as a data augmentation tool in today's deep learning studies.",74,https://www.semanticscholar.org/paper/be1a4a018df5c75244d39df70b4076604adfbd04
"Famao Ye,W. Luo,Yanfei Su,Xuqing Zhao,Hui Xiao,Weidong Min",Application of convolutional neural network feature to remote sensing image registration,2019-05-23 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.6046/GTZYYG.2019.02.05,,75,https://www.semanticscholar.org/paper/604a05560368d8cd4ed14c8a9a9bc124bb69b796
,Edge Detection Using Model-Based Neural Networks,2001-12-21 00:00:00,SupportedSources.CROSSREF,10.1201/9781420042269.ch8,,76,http://dx.doi.org/10.1201/9781420042269.ch8
"Adali, T.,Wang, Y.,Li, H.",Applications of Neural Networks to Biomedical Image Processing,2018-10-03 00:00:00,SupportedSources.CROSSREF,10.1201/9781315220413-12,,77,http://dx.doi.org/10.1201/9781315220413-12
"Danyang Cao,Zhixin Chen,Lei Gao",An improved object detection algorithm based on multi-scaled and deformable convolutional neural networks,2020-04-11 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.1186/s13673-020-00219-9,,78,https://www.semanticscholar.org/paper/3530963234161950ba2aef95b6a2b8ce329f0da9
"Mali Halac,Murat Isik,Hasan Ayaz,Anup Das",Multiscale Voxel Based Decoding For Enhanced Natural Image Reconstruction From Brain Activity,2022-05-27 18:09:07+00:00,SupportedSources.ARXIV,,"Reconstructing perceived images from human brain activity monitored by
functional magnetic resonance imaging (fMRI) is hard, especially for natural
images. Existing methods often result in blurry and unintelligible
reconstructions with low fidelity. In this study, we present a novel approach
for enhanced image reconstruction, in which existing methods for object
decoding and image reconstruction are merged together. This is achieved by
conditioning the reconstructed image to its decoded image category using a
class-conditional generative adversarial network and neural style transfer. The
results indicate that our approach improves the semantic similarity of the
reconstructed images and can be used as a general framework for enhanced image
reconstruction.",79,"http://arxiv.org/pdf/2205.14177v1
http://arxiv.org/abs/2205.14177v1
http://arxiv.org/pdf/2205.14177v1"
"Srivastava, S.,Lall, B.",Brain-Inspired Machine Intelligence for Image Analysis: Convolutional Neural Networks,2017-08-14 00:00:00,SupportedSources.CROSSREF,10.1002/9781119242963.ch6,,80,"https://api.wiley.com/onlinelibrary/tdm/v1/articles/10.1002%2F9781119242963.ch6
https://onlinelibrary.wiley.com/doi/full/10.1002/9781119242963.ch6
http://dx.doi.org/10.1002/9781119242963.ch6"
"Bhavin Choksi,Milad Mozafari,Callum Biggs O'May,Benjamin Ador,Andrea Alamia,Rufin VanRullen",Predify: Augmenting deep neural networks with brain-inspired predictive coding dynamics,2021-06-04 22:48:13+00:00,SupportedSources.ARXIV,,"Deep neural networks excel at image classification, but their performance is
far less robust to input perturbations than human perception. In this work we
explore whether this shortcoming may be partly addressed by incorporating
brain-inspired recurrent dynamics in deep convolutional networks. We take
inspiration from a popular framework in neuroscience: 'predictive coding'. At
each layer of the hierarchical model, generative feedback 'predicts' (i.e.,
reconstructs) the pattern of activity in the previous layer. The reconstruction
errors are used to iteratively update the network's representations across
timesteps, and to optimize the network's feedback weights over the natural
image dataset-a form of unsupervised training. We show that implementing this
strategy into two popular networks, VGG16 and EfficientNetB0, improves their
robustness against various corruptions and adversarial attacks. We hypothesize
that other feedforward networks could similarly benefit from the proposed
framework. To promote research in this direction, we provide an open-sourced
PyTorch-based package called Predify, which can be used to implement and
investigate the impacts of the predictive coding dynamics in any convolutional
neural network.",81,"http://arxiv.org/pdf/2106.02749v2
http://arxiv.org/abs/2106.02749v2
http://arxiv.org/pdf/2106.02749v2"
"A. Zhu,Tian Wang,H. Snoussi",Hierarchical graphical-based human pose estimation via local multi-resolution convolutional neural network,2018-03-20 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.1063/1.5024463,"This paper addresses the problems of the graphical-based human pose estimation in still images, including the diversity of appearances and confounding background clutter. We present a new architecture for estimating human pose using a Convolutional Neural Network (CNN). Firstly, a Relative Mixture Deformable Model (RMDM) is defined by each pair of connected parts to compute the relative spatial information in the graphical model. Secondly, a Local Multi-Resolution Convolutional Neural Network (LMR-CNN) is proposed to train and learn the multi-scale representation of each body parts by combining different levels of part context. Thirdly, a LMR-CNN based hierarchical model is defined to explore the context information of limb parts. Finally, the experimental results demonstrate the effectiveness of the proposed deep learning approach for human pose estimation.",82,"https://www.semanticscholar.org/paper/03968973b0bd4842c7d24fb96a7893242c7aa6ff
https://aip.scitation.org/doi/pdf/10.1063/1.5024463"
"Gary Tam,Michael Edwards,Robert Palmer,Xianghua Xie",Graph convolutional neural network for multi-scale feature learning,2019-01-01 00:00:00,SupportedSources.CORE,10.1016/j.cviu.2019.102881,,83,https://core.ac.uk/download/266980797.pdf
"Dhara, A.,Bagaini, C.",Seismic Registration Using Convolutional Neural Networks,2021-01-01 00:00:00,SupportedSources.CROSSREF,10.3997/2214-4609.202011141,,84,http://dx.doi.org/10.3997/2214-4609.202011141
"Matan Atzmon,David Novotny,Andrea Vedaldi,Yaron Lipman",Augmenting Implicit Neural Shape Representations with Explicit Deformation Fields,2021-08-19 00:00:00,SupportedSources.INTERNET_ARCHIVE,,"Implicit neural representation is a recent approach to learn shape collections as zero level-sets of neural networks, where each shape is represented by a latent code. So far, the focus has been shape reconstruction, while shape generalization was mostly left to generic encoder-decoder or auto-decoder regularization. In this paper we advocate deformation-aware regularization for implicit neural representations, aiming at producing plausible deformations as latent code changes. The challenge is that implicit representations do not capture correspondences between different shapes, which makes it difficult to represent and regularize their deformations. Thus, we propose to pair the implicit representation of the shapes with an explicit, piecewise linear deformation field, learned as an auxiliary function. We demonstrate that, by regularizing these deformation fields, we can encourage the implicit neural representation to induce natural deformations in the learned shape space, such as as-rigid-as-possible deformations.",85,https://web.archive.org/web/20210826002227/https://arxiv.org/pdf/2108.08931v1.pdf
"Zhang, Y.,Shi, L.,Wu, Y.,Cheng, K.,Cheng, J.,Lu, H.",Gesture recognition based on deep deformable 3D convolutional neural networks,2020-01-01 00:00:00,SupportedSources.CROSSREF,10.1016/j.patcog.2020.107416,,86,"https://api.elsevier.com/content/article/PII:S0031320320302193?httpAccept=text/xml
https://api.elsevier.com/content/article/PII:S0031320320302193?httpAccept=text/plain
http://dx.doi.org/10.1016/j.patcog.2020.107416"
Aaron Hertzmann,Aesthetics of Neural Network Art,2019-03-13 19:45:54+00:00,SupportedSources.ARXIV,,"This paper proposes a way to understand neural network artworks as
juxtapositions of natural image cues. It is hypothesized that images with
unusual combinations of realistic visual cues are interesting, and, neural
models trained to model natural images are well-suited to creating interesting
images. Art using neural models produces new images similar to those of natural
images, but with weird and intriguing variations. This analysis is applied to
neural art based on Generative Adversarial Networks, image stylization, Deep
Dreams, and Perception Engines.",87,"http://arxiv.org/pdf/1903.05696v2
http://arxiv.org/abs/1903.05696v2
http://arxiv.org/pdf/1903.05696v2"
"Teuwen, J.,Moriakov, N.",Convolutional neural networks,2020-01-01 00:00:00,SupportedSources.CROSSREF,10.1016/b978-0-12-816176-0.00025-9,,88,"https://api.elsevier.com/content/article/PII:B9780128161760000259?httpAccept=text/xml
https://api.elsevier.com/content/article/PII:B9780128161760000259?httpAccept=text/plain
http://dx.doi.org/10.1016/b978-0-12-816176-0.00025-9"
"Nie, Z.,Li, C.,Liu, H.,Yang, X.",Deformable Image Registration Based on Functions of Bounded Generalized Deformation,2021-02-04 00:00:00,SupportedSources.CROSSREF,10.1007/s11263-021-01439-x,,89,"https://link.springer.com/content/pdf/10.1007/s11263-021-01439-x.pdf
https://link.springer.com/article/10.1007/s11263-021-01439-x/fulltext.html
https://link.springer.com/content/pdf/10.1007/s11263-021-01439-x.pdf
http://dx.doi.org/10.1007/s11263-021-01439-x"
"Elmahdy, M.S.,Lelieveldt, B.P.F.,Sokooti, H.,Staring, M.,Yousefi, S.",Hierarchical prediction of registration misalignment using a convolutional LSTM: application to chest CT scans,2021-01-01 00:00:00,SupportedSources.CORE,10.1109/access.2021.3074124,"In this paper we propose a supervised method to predict registration misalignment using convolutional neural networks (CNNs). This task is casted to a classification problem with multiple classes of misalignment: ""correct"" 0-3 mm, ""poor"" 3-6 mm and ""wrong"" over 6 mm. Rather than a direct prediction, we propose a hierarchical approach, where the prediction is gradually refined from coarse to fine. Our solution is based on a convolutional Long Short-Term Memory (LSTM), using hierarchical misalignment predictions on three resolutions of the image pair, leveraging the intrinsic strengths of an LSTM for this problem. The convolutional LSTM is trained on a set of artificially generated image pairs obtained from artificial displacement vector fields (DVFs). Results on chest CT scans show that incorporating multi-resolution information, and the hierarchical use via an LSTM for this, leads to overall better F1 scores, with fewer misclassifications in a well-tuned registration setup. The final system yields an accuracy of 87.1%, and an average F1 score of 66.4% aggregated in two independent chest CT scan studies.Radiolog",90,https://core.ac.uk/download/493012218.pdf
"Daniel J. Saunders,Hava T. Siegelmann,Robert Kozma,Miklós Ruszinkó",STDP Learning of Image Patches with Convolutional Spiking Neural Networks,2018-08-24 15:27:39+00:00,SupportedSources.ARXIV,,"Spiking neural networks are motivated from principles of neural systems and
may possess unexplored advantages in the context of machine learning. A class
of \textit{convolutional spiking neural networks} is introduced, trained to
detect image features with an unsupervised, competitive learning mechanism.
Image features can be shared within subpopulations of neurons, or each may
evolve independently to capture different features in different regions of
input space. We analyze the time and memory requirements of learning with and
operating such networks. The MNIST dataset is used as an experimental testbed,
and comparisons are made between the performance and convergence speed of a
baseline spiking neural network.",91,"http://arxiv.org/pdf/1808.08173v1
http://arxiv.org/abs/1808.08173v1
http://arxiv.org/pdf/1808.08173v1"
"Abidi, M.,Yasuki, S.,Crilly, P.",Image Compression Using Hybrid Neural Networks,1994-01-01 00:00:00,SupportedSources.CROSSREF,10.1109/icce.1994.582157,,92,"http://xplorestaging.ieee.org/ielx2/4451/12624/00582157.pdf?arnumber=582157
http://dx.doi.org/10.1109/icce.1994.582157"
"Xuanyi Dong,Yan Yan,Wanli Ouyang,Yi Yang",Style Aggregated Network for Facial Landmark Detection,2018-03-12 03:46:12+00:00,SupportedSources.ARXIV,,"Recent advances in facial landmark detection achieve success by learning
discriminative features from rich deformation of face shapes and poses. Besides
the variance of faces themselves, the intrinsic variance of image styles, e.g.,
grayscale vs. color images, light vs. dark, intense vs. dull, and so on, has
constantly been overlooked. This issue becomes inevitable as increasing web
images are collected from various sources for training neural networks. In this
work, we propose a style-aggregated approach to deal with the large intrinsic
variance of image styles for facial landmark detection. Our method transforms
original face images to style-aggregated images by a generative adversarial
module. The proposed scheme uses the style-aggregated image to maintain face
images that are more robust to environmental changes. Then the original face
images accompanying with style-aggregated ones play a duet to train a landmark
detector which is complementary to each other. In this way, for each face, our
method takes two images as input, i.e., one in its original style and the other
in the aggregated style. In experiments, we observe that the large variance of
image styles would degenerate the performance of facial landmark detectors.
Moreover, we show the robustness of our method to the large variance of image
styles by comparing to a variant of our approach, in which the generative
adversarial module is removed, and no style-aggregated images are used. Our
approach is demonstrated to perform well when compared with state-of-the-art
algorithms on benchmark datasets AFLW and 300-W. Code is publicly available on
GitHub: https://github.com/D-X-Y/SAN",93,"http://arxiv.org/pdf/1803.04108v4
http://arxiv.org/abs/1803.04108v4
http://arxiv.org/pdf/1803.04108v4"
"Hongyun Ye,Zhanping Yang,Jun Li,Shiling Li",BP Neural Networks Based Sensor Registration Algorithm,2011-10-21 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.1109/ICCIS.2011.107,"In multi-sensor multi-target fusion systems the sensor registration is the major problem which is generally inadequate. The typical registration algorithms are based on statistics, such as LSE, ML etc. and on filtering theory, such as KF, EKF etc. They all are parametric methods namely. We propose a new algorithm that is based on ANN, nonparametric and many different kinds of sensor error variables to be solved. The algorithm is modified by adjusting the learning rate in which fuzzy logic is applied. That is to say, the learning rate of the NN is adaptive.",94,https://www.semanticscholar.org/paper/4a02836d44282a38725f471a2d66d5aa24fc2025
Gajraj Kuldeep,Image Classification using Sequence of Pixels,2022-09-23 09:42:44+00:00,SupportedSources.ARXIV,,"This study compares sequential image classification methods based on
recurrent neural networks. We describe methods based on recurrent neural
networks such as Long-Short-Term memory(LSTM), bidirectional Long-Short-Term
memory(BiLSTM) architectures, etc. We also review the state-of-the-art
sequential image classification architectures. We mainly focus on LSTM, BiLSTM,
temporal convolution network, and independent recurrent neural network
architecture in the study. It is known that RNN lacks in learning long-term
dependencies in the input sequence. We use a simple feature construction method
using orthogonal Ramanujan periodic transform on the input sequence.
Experiments demonstrate that if these features are given to LSTM or BiLSTM
networks, the performance increases drastically.
  Our focus in this study is to increase the training accuracy simultaneously
reducing the training time for the LSTM and BiLSTM architecture, but not on
pushing the state-of-the-art results, so we use simple LSTM/BiLSTM
architecture. We compare sequential input with the constructed feature as input
to single layer LSTM and BiLSTM network for MNIST and CIFAR datasets. We
observe that sequential input to the LSTM network with 128 hidden unit training
for five epochs results in training accuracy of 33% whereas constructed
features as input to the same LSTM network results in training accuracy of 90%
with 1/3 lesser time.",95,"http://arxiv.org/pdf/2209.11495v1
http://arxiv.org/abs/2209.11495v1
http://arxiv.org/pdf/2209.11495v1"
"Kumar, A.,Tesfaye Jule, L.,Ramaswamy, K.,Sountharrajan, S.,Yuuvaraj, N.,Gandomi, A.",Analysis of false data detection rate in generative adversarial networks using recurrent neural network,2021-01-01 00:00:00,SupportedSources.CROSSREF,10.1016/b978-0-12-823519-5.00012-9,,96,"https://api.elsevier.com/content/article/PII:B9780128235195000129?httpAccept=text/xml
https://api.elsevier.com/content/article/PII:B9780128235195000129?httpAccept=text/plain
http://dx.doi.org/10.1016/b978-0-12-823519-5.00012-9"
"Qingguang Li,Cen Gao,Xianfeng Wu,Dehua Li",A method for range image registration via neural network and ICP algorithm,2010-09-28 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.1007/s11859-010-0673-z,,97,https://www.semanticscholar.org/paper/3da165cf69e0f8f4169d2ce08db1d02eb0740c9f
"Motasem Alfarra,Adel Bibi,Naeemullah Khan,Philip H. S. Torr,Bernard Ghanem",DeformRS: Certifying Input Deformations with Randomized Smoothing,2021-07-02 12:20:15+00:00,SupportedSources.ARXIV,,"Deep neural networks are vulnerable to input deformations in the form of
vector fields of pixel displacements and to other parameterized geometric
deformations e.g. translations, rotations, etc. Current input deformation
certification methods either 1. do not scale to deep networks on large input
datasets, or 2. can only certify a specific class of deformations, e.g. only
rotations. We reformulate certification in randomized smoothing setting for
both general vector field and parameterized deformations and propose
DeformRS-VF and DeformRS-Par, respectively. Our new formulation scales to large
networks on large input datasets. For instance, DeformRS-Par certifies rich
deformations, covering translations, rotations, scaling, affine deformations,
and other visually aligned deformations such as ones parameterized by
Discrete-Cosine-Transform basis. Extensive experiments on MNIST, CIFAR10, and
ImageNet show competitive performance of DeformRS-Par achieving a certified
accuracy of $39\%$ against perturbed rotations in the set
$[-10\degree,10\degree]$ on ImageNet.",98,"http://arxiv.org/pdf/2107.00996v2
http://arxiv.org/abs/2107.00996v2
http://arxiv.org/pdf/2107.00996v2"
"Michael Blot,M. Cord,Nicolas Thome",Max-min convolutional neural networks for image classification,2016-08-19 00:00:00,SupportedSources.SEMANTIC_SCHOLAR,10.1109/ICIP.2016.7533046,"Convolutional neural networks (CNN) are widely used in computer vision, especially in image classification. However, the way in which information and invariance properties are encoded through in deep CNN architectures is still an open question. In this paper, we propose to modify the standard convolutional block of CNN in order to transfer more information layer after layer while keeping some invariance within the network. Our main idea is to exploit both positive and negative high scores obtained in the convolution maps. This behavior is obtained by modifying the traditional activation function step before pooling. We are doubling the maps with specific activations functions, called MaxMin strategy, in order to achieve our pipeline. Extensive experiments on two classical datasets, MNIST and CIFAR-10, show that our deep MaxMin convolutional net outperforms standard CNN.",99,"https://www.semanticscholar.org/paper/8e94bc5ee1a4cfe890fbc0920818a25e6f59fef8
http://arxiv.org/pdf/1610.07882"
